{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/ehartford--dolphin to /home/kosenko/.cache/huggingface/datasets/ehartford___json/ehartford--dolphin-d6a3823292d2c825/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2101.35it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 228.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/kosenko/.cache/huggingface/datasets/ehartford___json/ehartford--dolphin-d6a3823292d2c825/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 43.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 891857\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "\n",
    "dataset = load_dataset(\"ehartford/dolphin\", data_files=\"flan1m-alpaca-uncensored.jsonl\")\n",
    "dataset = dataset[\"train\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.train_test_split(test_size=3000, seed=42)\n",
    "dataset = dataset[\"test\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.',\n",
       " 'input': 'Answer the following question: Here\\'s a short story: Josh was riding his bike down the driveway. His sister was riding her tricycle near him. Josh rode much faster. The _____ traveled a greater distance. (A) tricycle (B) bicycle.  What is the most sensical answer between \"bicycle\" and  \"tricycle\"?\\nAnswer:',\n",
       " 'output': \"(B) bicycle\\n\\nStep 1: Read and analyze the question. The question requires determining who traveled a greater distance based on the information provided in the short story.\\n\\nStep 2: Process the given story. According to the story, Josh, who's riding his bike (a bicycle), goes much faster than his sister, who's riding a tricycle.\\n\\nStep 3: Interpret the story correctly. Normally, the one who moves faster, in this case, Josh or the bicycle, would cover a greater distance over the same period of time than the one who moves slower.\\n\\nTherefore, based on these steps and the information provided in the story, the most sensical answer is (B) bicycle.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "Creating parquet from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 29.45ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub('dim/dolphin_flan1m_alpaca_uncensored_3k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 473/473 [00:00<00:00, 3.28MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/kosenko/.cache/huggingface/datasets/dim___parquet/dim--dolphin_flan1m_alpaca_uncensored_3k-1ab74790d48de6b6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 2.95M/2.95M [00:00<00:00, 5.63MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 324.66it/s]\n",
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/kosenko/.cache/huggingface/datasets/dim___parquet/dim--dolphin_flan1m_alpaca_uncensored_3k-1ab74790d48de6b6/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 690.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'instruction': 'You are an AI assistant. User will you give you a task. Your goal is to complete the task as faithfully as you can. While performing the task think step-by-step and justify your steps.',\n",
       " 'input': 'Answer the following question: Here\\'s a short story: Josh was riding his bike down the driveway. His sister was riding her tricycle near him. Josh rode much faster. The _____ traveled a greater distance. (A) tricycle (B) bicycle.  What is the most sensical answer between \"bicycle\" and  \"tricycle\"?\\nAnswer:',\n",
       " 'output': \"(B) bicycle\\n\\nStep 1: Read and analyze the question. The question requires determining who traveled a greater distance based on the information provided in the short story.\\n\\nStep 2: Process the given story. According to the story, Josh, who's riding his bike (a bicycle), goes much faster than his sister, who's riding a tricycle.\\n\\nStep 3: Interpret the story correctly. Normally, the one who moves faster, in this case, Josh or the bicycle, would cover a greater distance over the same period of time than the one who moves slower.\\n\\nTherefore, based on these steps and the information provided in the story, the most sensical answer is (B) bicycle.\"}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dim/dolphin_flan1m_alpaca_uncensored_3k\")\n",
    "dataset = dataset[\"train\"]\n",
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
