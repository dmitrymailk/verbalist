{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import markdownify\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://essayforum.com/writing/average-cell-phone-national-fixed-87878/\"\n",
    "# url = \"https://essayforum.com/writing/people-think-students-study-science-food-94982/\"\n",
    "base_url = (\n",
    "    \"https://essayforum.com/writing/shortage-housing-big-cities-cause-severe-94815/\"\n",
    ")\n",
    "response = requests.get(url=base_url)\n",
    "soup = BeautifulSoup(response.text)\n",
    "all_messages = soup.find_all(\n",
    "    \"article\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(str(all_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hazard'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = all_messages[0].find(\"div\", \"fl\").find_all(\"a\")\n",
    "if len(author) > 0:\n",
    "    author = author[0].find(\"b\").text\n",
    "else:\n",
    "    author = all_messages[0].find(\"div\", \"fl\").text.replace(\"/\", \"\").strip()\n",
    "author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 hrs ago'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = all_messages[0].find(\"div\", \"fr\").find(\"a\").text\n",
    "date = all_messages[0].find(\"div\", \"fr\").text.replace(number, \"\").strip()\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = str(all_messages[0].find(\"div\", \"pTx\"))\n",
    "\n",
    "message = markdownify.markdownify(message, heading_style=\"ATX\")\n",
    "message = re.sub(\"\\!\\[\\]\\(\\w+.*\\)\", \"\", message).strip()\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in all_messages:\n",
    "    author = message.find(\"div\", \"fl\").find(\"a\").find(\"b\").text.strip()\n",
    "    print(author)\n",
    "\n",
    "    number = all_messages[0].find(\"div\", \"fr\").find(\"a\").text\n",
    "    date = all_messages[0].find(\"div\", \"fr\").text.replace(number, \"\").strip()\n",
    "    print(date)\n",
    "\n",
    "    message = str(message.find(\"div\", \"pTx\"))\n",
    "    message = markdownify.markdownify(message, heading_style=\"ATX\")\n",
    "    message = re.sub(\"\\!\\[\\]\\(\\w+.*\\)\", \"\", message).strip()\n",
    "    print(message)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/kosenko/verbalist/verbalist/datasets/essayforum/essayforum.py:26: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 26 of the file /cephfs/home/kosenko/verbalist/verbalist/datasets/essayforum/essayforum.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from verbalist.datasets.essayforum.essayforum import EssayForumMessagesParser\n",
    "\n",
    "\n",
    "links = pd.read_csv(\"./verbalist/datasets/essayforum/essayforum_writing_links.csv\")\n",
    "links = links.to_dict(\"records\")\n",
    "links = links[:10]\n",
    "\n",
    "parser = EssayForumMessagesParser(urls=links)\n",
    "parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['message', 'author', 'date', 'position', 'url', 'forum_type'],\n",
       "    num_rows: 13\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.from_list(parser.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://essayforum.com/writing/2/\"\n",
    "response = requests.get(url=base_url)\n",
    "soup = BeautifulSoup(response.text)\n",
    "all_links = soup.find_all(\"a\", class_=\"txtNr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://essayforum.com/writing/discuss-view-give-opinion-zoo-closed-due-94830/'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links[0][\"href\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'478'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_pages = soup.find_all(\"a\", class_=\"navCell\")[-1].text\n",
    "total_pages = int(total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 478/478 [05:56<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from verbalist.datasets.essayforum.essayforum import EssayForumLinksParser\n",
    "\n",
    "links_parser = EssayForumLinksParser(urls=[\"https://essayforum.com/writing\"])\n",
    "links_parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28669"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links_parser.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(links_parser.dataset).to_csv(\n",
    "    \"./verbalist/datasets/essayforum/essayforum_writing_links.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert into prompts for llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/kosenko/.cache/huggingface/datasets/dim___parquet/dim--essayforum_writing_10k-208b845e5ffb772e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 1/1 [00:00<00:00, 568.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>position</th>\n",
       "      <th>url</th>\n",
       "      <th>forum_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>## Some companies block their employees from u...</td>\n",
       "      <td>mrhuyprono1</td>\n",
       "      <td>Feb 4, 2023</td>\n",
       "      <td>0</td>\n",
       "      <td>https://essayforum.com/writing/toeic-part-comp...</td>\n",
       "      <td>essayforum.com_writing_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The presentation is not grammatically perfect ...</td>\n",
       "      <td>Holt</td>\n",
       "      <td>Feb 4, 2023</td>\n",
       "      <td>1</td>\n",
       "      <td>https://essayforum.com/writing/toeic-part-comp...</td>\n",
       "      <td>essayforum.com_writing_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***Some people believe that the personal infor...</td>\n",
       "      <td>Heo Nguyen</td>\n",
       "      <td>Jan 28, 2023</td>\n",
       "      <td>0</td>\n",
       "      <td>https://essayforum.com/writing/violent-crimina...</td>\n",
       "      <td>essayforum.com_writing_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is a common belief  \\nA \"common belief\" can...</td>\n",
       "      <td>Holt</td>\n",
       "      <td>Jan 28, 2023</td>\n",
       "      <td>1</td>\n",
       "      <td>https://essayforum.com/writing/violent-crimina...</td>\n",
       "      <td>essayforum.com_writing_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Regarding the introduction, it is my view that...</td>\n",
       "      <td>Camtu25</td>\n",
       "      <td>Jan 28, 2023</td>\n",
       "      <td>2</td>\n",
       "      <td>https://essayforum.com/writing/violent-crimina...</td>\n",
       "      <td>essayforum.com_writing_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message       author  \\\n",
       "0  ## Some companies block their employees from u...  mrhuyprono1   \n",
       "1  The presentation is not grammatically perfect ...         Holt   \n",
       "2  ***Some people believe that the personal infor...   Heo Nguyen   \n",
       "3  It is a common belief  \\nA \"common belief\" can...         Holt   \n",
       "4  Regarding the introduction, it is my view that...      Camtu25   \n",
       "\n",
       "           date  position                                                url  \\\n",
       "0   Feb 4, 2023         0  https://essayforum.com/writing/toeic-part-comp...   \n",
       "1   Feb 4, 2023         1  https://essayforum.com/writing/toeic-part-comp...   \n",
       "2  Jan 28, 2023         0  https://essayforum.com/writing/violent-crimina...   \n",
       "3  Jan 28, 2023         1  https://essayforum.com/writing/violent-crimina...   \n",
       "4  Jan 28, 2023         2  https://essayforum.com/writing/violent-crimina...   \n",
       "\n",
       "                forum_type  \n",
       "0  essayforum.com_writing_  \n",
       "1  essayforum.com_writing_  \n",
       "2  essayforum.com_writing_  \n",
       "3  essayforum.com_writing_  \n",
       "4  essayforum.com_writing_  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "dataset = load_dataset(\"dim/essayforum_writing_10k\")\n",
    "dataset = dataset[\"train\"].to_pandas()\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_reviews = {}\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    url = dataset[\"url\"].iloc[i]\n",
    "    pos = dataset[\"position\"].iloc[i]\n",
    "    message = dataset[\"message\"].iloc[i]\n",
    "    author = dataset[\"author\"].iloc[i]\n",
    "    if url in write_reviews and author == \"Holt\":\n",
    "        write_reviews[url][\"answer\"] = message\n",
    "    elif not url in write_reviews:\n",
    "        write_reviews[url] = {}\n",
    "        write_reviews[url][\"prompt\"] = message\n",
    "\n",
    "write_reviews = list(write_reviews.values())\n",
    "write_reviews = [item for item in write_reviews if \"answer\" in item]\n",
    "# write_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.from_list(write_reviews).to_pandas().to_csv(\n",
    "    \"./verbalist/datasets/essayforum/essayforum_writing_prompts_6k.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 7/7 [00:00<00:00, 94.95ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:04<00:00,  4.21s/it]\n"
     ]
    }
   ],
   "source": [
    "Dataset.from_list(write_reviews).push_to_hub(\"dim/essayforum_writing_prompts_6k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.from_list(write_reviews).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 411/411 [00:00<00:00, 3.31MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/kosenko/.cache/huggingface/datasets/dim___parquet/dim--essayforum_writing_prompts_6k-a911bbef273f1337/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 11.8M/11.8M [00:00<00:00, 13.8MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 250.32it/s]\n",
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/kosenko/.cache/huggingface/datasets/dim___parquet/dim--essayforum_writing_prompts_6k-a911bbef273f1337/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 643.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prompt': \"## Some companies block their employees from using social media network\\n\\n  \\n  \\nIn many corporations, despite its rules, staff cannot access social media platforms like Facebook, Twitter, and Instagram during working time. Personally, I totally agree with that decision. Indeed, prohibiting employees from using social media can help them avoid getting distracted, get more attention to their tasks, build real-life relationships with other employees, and lead to a result that boosts company performance.  \\n  \\nWithout a doubt, social media is a common source of interruption. For example, people can quickly get interested in something new that pops up in their newsfeed or their friend's messages when using Facebook. Some researchers said that you need an average of 20 minutes to get back to work when visiting social media platforms.  \\n  \\nSo that, if they are prohibited from using social media, employees will hardly get any other distraction sources in the office. For that reason, they clearly spend more time on work, and when needing the support of their colleagues, they must make real-life conversations with their co-workers. In the long path, it will decrease the time required for tasks and create friendly social behavior in the company and all of that benefits help the company thrives.  \\n  \\nIn conclusion, I think that restricting the use of social media networks in the workplace is a wise decision. Lots of managers realize the benefits when comparing the company's performance before and after publicizing that policy. I hope that blocking access to social media platforms when working will become more and more common in the future.  \\n  \\nShort brief: Prohibiting staff from using social media when working is a wise decision because it stops them from being distracted, reduces the time required for tasks, and improves the real-life relationship between co-workers.\",\n",
       " 'answer': 'The presentation is not grammatically perfect but works for the purpose of the writer. While there are some incorrect phrases and references used in the essay, it does not deter the reader from understanding the opinion of the writer. The fact that he uses public knowledge as references works well for the presentation. However, some personal experience information would have also been beneficial to the presentation since it would have balanced the discussion between public and personal throughout the paragraphs.  \\n  \\nSometimes the reasoning the writer provides feels incomplete. Paragraph 2 in particular, feels under developed. It could have used better experience and knowledge referencing to add to the impact of the explanation. It almost feels like the next paragraph was accidentally separated from the previous paragraph. Had the 2 paragraphs combined, the discussion would have been better developed.  \\n  \\nThe writer shows enough knowlege of everyday English words. The discussion feels natural to a limited extent. I believe the limitation was caused by the ESL writing method of the student. There are instances when he seems to have transliterated the sentences, leading to incorrect sentence formation. This can be overcome in the future through regular English language speaking and writing practice.'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"dim/essayforum_writing_prompts_6k\")\n",
    "dataset['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
