{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TasksParser:\n",
    "    def __init__(self):\n",
    "        self.urls = [\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi.shtml\",\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi_2.shtml\",\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi_3.shtml\",\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi_4.shtml\",\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi_5.shtml\",\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi_6.shtml\",\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi_7.shtml\",\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi_8.shtml\",\n",
    "            \"https://www.potehechas.ru/zadachi/zadachi_9.shtml\",\n",
    "        ]\n",
    "        \n",
    "        self.dataset = []\n",
    "        \n",
    "    def parse_tasks(self):\n",
    "        for url in self.urls:\n",
    "            response = requests.get(url=url)\n",
    "            soup = BeautifulSoup(response.text)\n",
    "            all_tasks = soup.find_all(\"table\", class_=\"comments_generall_table\")\n",
    "            for item in all_tasks:\n",
    "            # print(item)\n",
    "            # print(\"-\"*50)\n",
    "                try:\n",
    "                    task_text = item.find(\"td\", class_=\"zadacha_text\").text.strip()\n",
    "                    task_text = task_text.replace(\"«« Ответ к задаче »»\", \"\")\n",
    "                    task_text = task_text.replace(\"\\r\", \"\")\n",
    "                    print(task_text)\n",
    "                    answer_text = (\n",
    "                        item\n",
    "                        .find(\"div\", class_=\"otvet_zadachi_in\")[\"onmousedown\"]\n",
    "                        .replace(\"this.innerHTML=\", \"\")\n",
    "                    )\n",
    "                    answer_text = answer_text.replace(\"'\", \"\")\n",
    "                    answer_text = answer_text.replace(\"<br>\", \"\\n\")\n",
    "                    print(answer_text)\n",
    "                    \n",
    "                    title = item.find(\"td\", class_=\"comments_info_2\").text.strip()\n",
    "                    print(title)\n",
    "                    print(\"=\" * 50)\n",
    "                    \n",
    "                    self.dataset.append({\n",
    "                        \"title\": title,\n",
    "                        \"answer\": answer_text,\n",
    "                        \"task\": task_text\n",
    "                    })\n",
    "                except:\n",
    "                    # print(item)\n",
    "                    pass\n",
    "        \n",
    "        pd.DataFrame(data=self.dataset).to_csv(\"./verbalist/datasets/logic_tasks_ru/logic_tasks_ru.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = TasksParser()\n",
    "\n",
    "parser.parse_tasks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 763.71ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "Downloading metadata: 100%|██████████| 107/107 [00:00<00:00, 439kB/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "path = \"./verbalist/datasets/logic_tasks_ru/logic_tasks_ru - labeled.csv\"\n",
    "dataset = pd.read_csv(path)\n",
    "dataset = dataset.to_dict(\"records\")\n",
    "dataset = Dataset.from_list(dataset)\n",
    "dataset.push_to_hub(\"dim/logic_tasks_ru\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
