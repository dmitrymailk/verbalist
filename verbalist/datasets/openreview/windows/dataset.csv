paper_url,paper_id,reviews
https://openreview.net/forum?id=rRzl6UQxEb5 ,rRzl6UQxEb5,"[{'id': 'B89x5zOf0Gc', 'original': None, 'number': 2, 'cdate': 1648400401863, 'mdate': 1648400401863, 'ddate': None, 'tcdate': 1648400401863, 'tmdate': 1648400401863, 'tddate': None, 'forum': 'rRzl6UQxEb5', 'replyto': 'rRzl6UQxEb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/-/Official_Review', 'content': {'title': 'Review for Team DMG at CMCL 2022 Shared Task', 'review': '# Summary\nFor their contribution, the authors used a pre-trained XLM-R language model and trained an adapter, inserted into the frozen pre-trained LM in order to predict eye-tracking reading measures (first fixation duration & total reading time). They test several methods for both subtask 1 (1 adapter for all languages, language-specific adapters) and subtask 2 (zero-shot, e.g. using the adapters from subtask 1, translation of training set, translation of test set).\n\n#\xa0Pros\n* Novel and efficient approach \n* Good results (placed 2nd)\n* The paper is nicely written and easy to follow\n* Besides the task itself, the authors also address and comment on interesting conceptual issues (e.g. what types of patterns does a single vs. language-specific adapters capture)\n* Translating the train/test sets is a simple (in a good way) yet effective approach for subtask 2\n\n# Cons\n* Since there seemed to be some space left, the methodology section could have been a bit more detailed or it could have been used for a formal definition of the problem setting & adapters.', 'rating': '7: Good paper, accept', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/Reviewer_xo68'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/Reviewer_xo68']}, {'id': 'rOdxON0njf9', 'original': None, 'number': 1, 'cdate': 1648246320368, 'mdate': 1648246320368, 'ddate': None, 'tcdate': 1648246320368, 'tmdate': 1648246320368, 'tddate': None, 'forum': 'rRzl6UQxEb5', 'replyto': 'rRzl6UQxEb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/-/Official_Review', 'content': {'title': 'Team DMG at CMCL 2022 Shared Task', 'review': '# Summary\nIn this work, the authors propose the application of adapters to predict first fixation duration (FFD) and total fixation duration (TFD) averaged across tokens.\nThe authors utilize frozen pre-trained language models in combination with bottleneck adapters to predict the properties mentioned before.\nThey investigate several approaches: e. g. fine-tuning, mono- and multilingual PLMs, training or test set translations.\nThe final approach placed second in the Shared Task.\n\n\n# Pros\n- A novel approach using frozen PLMs with adapters to predict token reading measures.\n- Discuss various approaches with possible theoretical explanations.\n- Reproducibility via publicly available code.\n- Second place on the leaderboard.\n\n\n# Cons\n- None.\n\n\n## Minor comments and missing references\nSome minor suggestions/comments: \n\n- Research by Sood et al. [1] suggests that  RNNs/CNNs resemble more human attention than transformer-based architectures.\n\n- During the hyperparameter search, the epochs were always the maximum in the grid. My question is whether training further might have even further improved the performance?\n\n\n### References\n[1] Sood, Ekta and Tannert, Simon and Frassinelli, Diego and Bulling, Andreas. Interpreting Attention Models with Human Visual Attention in Machine Reading Comprehension. 2020. Proc. ACL SIGNLL Conference on Computational Natural Language Learning (CoNLL). doi:10.18653/v1/P17.', 'rating': '7: Good paper, accept', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/Reviewer_6qvh'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/Reviewer_6qvh']}]"
https://openreview.net/forum?id=HF-ez2Bi7-9 ,HF-ez2Bi7-9,"[{'id': 'B6Gl4IHekXc', 'original': None, 'number': 3, 'cdate': 1648457036496, 'mdate': 1648457036496, 'ddate': None, 'tcdate': 1648457036496, 'tmdate': 1648457036496, 'tddate': None, 'forum': 'HF-ez2Bi7-9', 'replyto': 'HF-ez2Bi7-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/-/Official_Review', 'content': {'title': 'Meta-review', 'review': 'The paper presents the system description of Team ÚFAL for the CMCL 2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior. The authors present a range of model comparisons for eye-tracking prediction. As pointed out by the reviewers, the paper has potential but requires some improvements. The descriptions should be more precise, especially regarding the motivation of the chosen model architectures and the discussion/analysis of the results.\n\nWe urge the authors to take the feedback from the reviewers into account and to improve their paper for the camera-ready deadline.', 'rating': '6: Marginally above acceptance threshold', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Program_Chairs'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Program_Chairs']}, {'id': 'HgZguqDwNf5', 'original': None, 'number': 2, 'cdate': 1647765391623, 'mdate': 1647765391623, 'ddate': None, 'tcdate': 1647765391623, 'tmdate': 1647765391623, 'tddate': None, 'forum': 'HF-ez2Bi7-9', 'replyto': 'HF-ez2Bi7-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/-/Official_Review', 'content': {'title': 'High potential, but further work is needed', 'review': ""The paper describes the system proposed for the CMCL2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior, and the different architectures implemented and compared by the Team ÚFAL.\n\n**Pros**:\ninteresting approach, the different results of the various systems implemented and compared have a high potential in explaining both possible psycholinguistic insights and the computational models' natures.\n\n**Cons**:\nthe paper is generally not precise enough. In particular: 1) no reason for the different architectures is provided, 2) the results are only reported, but not analyzed deep enough (i.e., the study lacks attempt in finding psycholinguistic-related explanations for the different performances)\n\n**General suggestions**:\n1) Give a justification for each different system (i.e., sys1, sys2, CWR, classifier, whole, first, mean, sum), that is, why you tried and compared these approaches.\n2) collect the tables in an Appendix to have more space for results discussion\n\n\nMinor\n\nIntroduction:\n - “have also shown state-of-the-art performance on cross-lingual understanding tasks”, insert at least one reference to a shared task or a study on cross-lingual understanding.\n- reference to Huggingface\n\nExperiments:\n- “All systems under the System-1/2 label were further trained as a BERT (bert) based system or a XLM (xlm)”: labelS\n\nResults:\n- 4.1: “However, it should be noted than 12 out of the first 20 best performing models”: noted THAT\n\n"", 'rating': '5: Marginally below acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/Reviewer_Ck4k'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/Reviewer_Ck4k']}, {'id': 'HazggDbk0b5', 'original': None, 'number': 1, 'cdate': 1647337816174, 'mdate': 1647337816174, 'ddate': None, 'tcdate': 1647337816174, 'tmdate': 1647337816174, 'tddate': None, 'forum': 'HF-ez2Bi7-9', 'replyto': 'HF-ez2Bi7-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/-/Official_Review', 'content': {'title': 'Potentially informative contribution, but missing discussion of results', 'review': '\nThis paper presents the system description for a contribution to the CMCL 2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior. The authors propose to tackle to task using pretrained language models and performed a systematic study of the effects of model (mBERT vs. XLM), context information, input representation, lexical features, and fine-tuning.\n\n# Pros\n\n- The authors carried out a systematic study of a range of different model configurations for the task\n- Different contributions to final performance are analyzed using an exhaustive grid-search\n\n# Cons\n\n- Figure 3, 4, 5: The x-axis label and ticks are not very informative. What are the different models? All possible model configurations? If yes, which configuration is which index? This information is crucial in order to allow the reader are more fine-grained interpretation of the results.\n\n- The results should analyzed for statistical significance. This is especially important for cases with only marginal differences, as for example the comparison between BERT and XLM (Section 4.2): Here, the difference in MAE is probably not significant.\n\n- The results are not discussed in relation to previous approaches for the task (especially regarding work on the challenge from 2021). In order to highlight the significance of the work, the authors should point out which results agree with previous findings, and which are novel.\n \n- The performance of the best model is only marginally better than the mean baseline as reported in the challenge (MAE 5.72 vs. 5.73) and substantially worse than the mean baseline taking into account the target language (MAE 4.27). The authors do not discuss the performance of their models with respect to this baseline. It would be interesting to analyze why even the best of all 48 different models perform that poorly. Is it because of the high variance of feature values between the languages? Would these models perform better if they were trained and evaluated only on one language?\n\n## Minor\n\n### Abstract\n- effects: affects\n- lesser: smaller\n\n### Introduction:\n- Missing reference for “Huggingface”\n\n### Results:\n- Table 2 &3: Wouldn’t it be more infromative to report scores for the best performing model, instead of average over all tested models?\n- The results presented in Figure 1 and 2 could be presented in Tables, as they show only 4 and 2 data points. This would save space and make the results more readable.\n\n- Tables 6, 7, 8, and 10 are not at all mentioned in the text. If the results are not relevant, they can probably be removed?\n', 'rating': '4: Ok but not good enough - rejection', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/Reviewer_Yo9z'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/Reviewer_Yo9z']}]"
https://openreview.net/forum?id=rSHxo6ljXW9 ,rSHxo6ljXW9,"[{'id': 'BqLezEpnSf9', 'original': None, 'number': 2, 'cdate': 1647852841598, 'mdate': 1647852841598, 'ddate': None, 'tcdate': 1647852841598, 'tmdate': 1647852841598, 'tddate': None, 'forum': 'rSHxo6ljXW9', 'replyto': 'rSHxo6ljXW9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/-/Official_Review', 'content': {'title': 'The official shared task paper for CMCL 2022', 'review': 'The present presents the full description of the 2022 CMCL Shared Task which covers multilingual and crosslingual prediction of human reading behavior using diverse eye-tracking datasets. The paper illustrates the performance of each registered team with respect to their proposed (novel) solutions for both tasks evaluated via MSE. This paper merits a default acceptance as it summarizes the entire activity and contributions done for the Shared Task.', 'rating': '9: Top 15% of accepted papers, strong accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/Reviewer_LKSF'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/Reviewer_LKSF']}, {'id': 'rgWxW4ezVGq', 'original': None, 'number': 1, 'cdate': 1647743016545, 'mdate': 1647743016545, 'ddate': None, 'tcdate': 1647743016545, 'tmdate': 1647743016545, 'tddate': None, 'forum': 'rSHxo6ljXW9', 'replyto': 'rSHxo6ljXW9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/-/Official_Review', 'content': {'title': 'Good description of the multilingual eye-tracking feature prediction shared task at the CMCL workshop.', 'review': '### Summary\nThis paper presents the second shared task on eye-tracking data prediction of the CMCL workshop. In this year\'s shared task, the participating teams submit systems to predict 4 eye-tracking features, including: the mean and the standard deviation of the first fixation duration (FFDavg and FFDstd), and the mean and standard deviation of the total reading time (TRTavg and TRTstd). The shared task contains two challenges. Subtask 1 requires the participants to predict the features in 6 provided langauges (zh, hi, ru, en, nl, de), and subtask 2 involves a new language (dk). This paper describes the dataset, preprocessing steps, the scoring metric, and the baseline methods. This paper also lists the results of the systems.\n\n### Reasons to accept\n- CMCL shared task is an important initiative. The datasets collected and the methods examined in CMCL shared task have a lot of potential future impacts.    \n- The version of this year introduces additional dataset, and considers how models trained on given languages can generalize to a held-out language.\n- This paper describes the shared task, the data, and the participating systems clearly.\n\n### Reasons to reject\nI do not find reasons to reject this paper.\n\n### Comments\n- Abstract at second last line: ""transformer"" -> ""Transformer""  \n- Capture of figure 1: ""Example sentence"" -> ""An example sentence""\n- The line above Secetion 7: ""zer-o-shot learning"" -> ""zero-shot learning""  \n- The last bibliography entry at page 6 appears in blue font, while other entries appear in normal font. (Probably this is a problem with my display?)  \n- Lample & Conneau (2019) bib entry appears duplicated.  \n- Merkx and Frank (2021) bib entry appears duplicated.  ', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/Reviewer_5fgw'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/Reviewer_5fgw']}]"
https://openreview.net/forum?id=rVheScUGfZq ,rVheScUGfZq,"[{'id': 'SWgrd37iz9', 'original': None, 'number': 2, 'cdate': 1648209004608, 'mdate': 1648209004608, 'ddate': None, 'tcdate': 1648209004608, 'tmdate': 1648209004608, 'tddate': None, 'forum': 'rVheScUGfZq', 'replyto': 'rVheScUGfZq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/-/Official_Review', 'content': {'title': 'A good paper that could use some more explanations', 'review': 'The paper describes a regression-based approach for the tasks of CMCL-2022. One of the systems described, achieves the lowest MAE score in the competition. The authors use regression features of a target word and the features of the preceding words along with surprisal of the word for their systems.  A total of 46 features were used as regression features. \nThe feature description could use some elaboration. For instance, it is not clear what normalized word index is. Also, how surprisal was calculated is not described. \nIt would have been interesting to have a cross-validation section to check if there was overfitting in the model.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/Reviewer_fcRw'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/Reviewer_fcRw']}, {'id': 'HGzgE2KYyzc', 'original': None, 'number': 1, 'cdate': 1647446444008, 'mdate': 1647446444008, 'ddate': None, 'tcdate': 1647446444008, 'tmdate': 1647446444008, 'tddate': None, 'forum': 'rVheScUGfZq', 'replyto': 'rVheScUGfZq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/-/Official_Review', 'content': {'title': 'HkAmsters at CMCL 2022 Shared Task: Predicting Eye-Tracking Data from a Gradient Boosting Framework with Linguistic Features', 'review': 'The paper describes the authors\' regression approach to the first subtask of the CMCL 2022 Shared Task which scored best across all submissions. There are some parts of the analysis that are not clear to me and need, in my opinion, clarification before publication. Particularly how the model has been selected/evaluated. What part of the dataset have you used for that? This is crucial when comparing results from other participants in the shared task.\n\nFurther comments/questions:\n* binary features for capitalized words were used for all languages, have you evaluated the effect on languages like German where many more words are capitalized than in other languages?\n* what is meant with ""normalized word index""?\n* how many ""previous words"" are included in the features?\n\nAnother comment concerns the number of features, 46 features seems a lot. The model might benefit from some cross-validation for feature selection to prevent overfitting. Have you looked at that?', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/Reviewer_KK5N'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/Reviewer_KK5N']}]"
https://openreview.net/forum?id=B0lg2tPwOxc ,B0lg2tPwOxc,"[{'id': 'HaveFEq3BGq', 'original': None, 'number': 2, 'cdate': 1647852081409, 'mdate': None, 'ddate': None, 'tcdate': 1647852081409, 'tmdate': 1647852154217, 'tddate': None, 'forum': 'B0lg2tPwOxc', 'replyto': 'B0lg2tPwOxc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/-/Official_Review', 'content': {'title': 'Very well described details of the working system ', 'review': '## Summary\n\nThis paper describes the system of NU-HLT for the CMCL 2022 shared task. The system, inspired by previous works in speech recognition, uses a novel preprocessing step involving the transformation of words to a global vector space using IPA. Next fourteen features were then extracted from the transcriptions. The features included features like length and frequency of words and language-model based features in the form of different n-gram based statistics. Psychologically-motivated features in the form of imageability and concreteness were also extracted. Finally, information theoretic features in the form of surprisal was extracted for the systems. Using WEKA, four ML algorithms ( Linear regression, MLP, Random Forest and k-NN) were used to train the systems for predicting FFDAvg and TRTAvg features. Additionally, top 50% of the predictors are identified using their correlation with FFDAvg and TRTAvg.\n\n## Reasons to accept \n\n* The system description is very clear, concise and informative. All the details about the features, experiments and hyperparameters are mentioned.\n* The idea of transforming the raw words into IPA is novel.\n\n\n\n', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/Reviewer_idfb'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/Reviewer_idfb']}, {'id': 'SO-gWxQ3Qfc', 'original': None, 'number': 1, 'cdate': 1647719144867, 'mdate': None, 'ddate': None, 'tcdate': 1647719144867, 'tmdate': 1647743040161, 'tddate': None, 'forum': 'B0lg2tPwOxc', 'replyto': 'B0lg2tPwOxc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/-/Official_Review', 'content': {'title': 'Good descriptions of a working system', 'review': '### Summary\nThis paper describes the NU-HLT system in CMCL 2022 shared task. This system is inspired by both classical and recent previous works in speech recognition systems. First, the raw terms are transformed into a global shared space using IPA. Then, some features, including the frequency, length, N-gram, and information-theoretic features are extracted. Specifically, there are two psycholinguistically-motivated features: imageability and concreteness. Four ML algorithms from WEKA (LinReg, MLP, RF, kNN) are used to train to predict the FFDAvg and TRTAvg scores. Additionally, top predictor features with their correlation coefficients are identified.\n\n### Reasons to accept\n- The description of the system is clear. The hyperparameters including learning rate and the number of iterations are reported, allowing easy reproduction of the results.\n- The idea of transforming into IPA turns out to be novel and effective for predicting the FFDAvg and TRTAvg tasks.\n\n### Reasons to reject\nI see no serious issues with this paper.\n\n### Comments\n- The reporting of some results could be improved. E.g., in Table 1, there are many mentions of `k`, `m`. What do they mean?  \n- Table 2: highest correlation coefficients. Do you mean ""highest absolute correlation coefficients""? Some numbers are negative there.  \n- Probably an additional feature selection procedure can be useful for further improving the predicting performance.\n- Reference: Some entries have urls, but the remaining do not. Recommend adding (or removing) urls to all entries to keep the style consistent.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/Reviewer_MaeN'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/Reviewer_MaeN']}]"
https://openreview.net/forum?id=HZxe1KUug5, HZxe1KUug5,"[{'id': 'rIqgko-jtM5', 'original': None, 'number': 2, 'cdate': 1648107926518, 'mdate': 1648107926518, 'ddate': None, 'tcdate': 1648107926518, 'tmdate': 1648107926518, 'tddate': None, 'forum': 'HZxe1KUug5', 'replyto': 'HZxe1KUug5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/-/Official_Review', 'content': {'title': 'Combining transformer representations with handcrafted features for the prediction of multi- and cross-lingual eye-tracking reading data', 'review': ""This paper presents an approach that utilizes contextualized representations from transformer-based multilingual pretrained models along with 3 length-related handcrafted features for the prediction of multi- and cross-lingual human reading behavior. The results show that the models outperform the mean baselines and attain the 4th and the 1st places in the CMCL 2022 Subtask 1 and Subtask 2, respectively.\n\n**Pros**\n\nThe author explores a nice selection of models, involving mBERT, XLM and XLM-RoBERTa.\n\nThe author also implements various baselines (median baseline and regression models taking only the handcrafted features).\n\nExtensive results are reported regarding the prediction of each eye-tracking feature per model and feature ablation is conducted on the handcrafted features, which provides insightful information.\n\n\n**Cons**\n\nI think the model setups should be detailed further. For instance, why did the author use single-length output in baselines and 4-length output in the transformed-based models and would that have an effect on the final results? Why did the author choose to calculate a median baseline and what is the rationale behind the set of selected regression models?\n\nIt would be better if you could point to related work using transformers and handcrafted features for similar tasks earlier. For instance, Oh (2021) is mentioned, but only in Section 4.\n\n**Questions**\n\nWhat happens to rel_len if there is no preceding word?\n\nDid the author notice interesting outcomes depending on the input language?\n\n\n**Writing**\n\nWhat is meant by 'brain triggers'? Maybe using a different term here would be better.\n\nIn several lines, there seems to be an extra space before the comma (i.e. 'In this paper ,').\n\nend to end -> end-to-end\n\nseperate -> separate\n\nbreifly -> briefly\n\nIn the XLM paragraph, 'for different languages'\n\nIn the XLM-RoBERTa paragraph, add a space before 'It'\n\n'The entire model architecture is explained in Figure 1.' instead of 'in 1'.\n\n3.1 Features: Maybe first mention the features that you used and then, indicate the ones you discarded. It would also be nice if the author can clarify the connection to the dual pathways mentioning compound words.\n\nIn 4.1 'one of the possible reasons could be'\n\nIn the references, for the CMCL 2022 paper, also write '2022.' after the authors' names\n\n"", 'rating': '7: Good paper, accept', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/Reviewer_3TrC'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/Reviewer_3TrC']}, {'id': 'H-eLKZJUG9', 'original': None, 'number': 1, 'cdate': 1647862141724, 'mdate': 1647862141724, 'ddate': None, 'tcdate': 1647862141724, 'tmdate': 1647862141724, 'tddate': None, 'forum': 'HZxe1KUug5', 'replyto': 'HZxe1KUug5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/-/Official_Review', 'content': {'title': 'A new SOTA paper for crosslingual eye-tracking prediction', 'review': 'The paper describes a method for predicting human reading behavior across multiple datasets that can be used for both multilingual and crosslingual setting. The proposed method extracts neural-based embeddings from large language models such as mBERT, XLM, and XLM-RoBERTa and combines them with traditional predictors such as token and sentence-based lengths. This hybrid method is shown to successfully work for the crosslingual prediction setting after obtaining 1st place against other proposed methods. This merits a clear accept for the paper.\n\nMinor questions for improvement of discussion:\n1. Figure 1 looks oddly large when the paper is read. I suggest resizing the figure to add more space for supporting discussions and analysis.\n2. Although using Transformer-based embeddings produced high results, readers working on the same topic, especially non-CS people, might appreciate insights from the author/s on possible weaknesses of embeddings from large language models compared to theoretically-grounded predictors such as surprisal. \n3. Aside from the size or parameter count, what other properties of XLM-RoBERTa do you think made it useful for crosslingual prediction? Based on the results, what property or nature of mBERT made it perform better than XLM for multilingual prediction?', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/Reviewer_9pP4'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task', 'aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/Reviewer_9pP4']}]"
https://openreview.net/forum?id=Bduz_QYg8Z5 ,Bduz_QYg8Z5,"[{'id': 'Sce3OMKhf5', 'original': None, 'number': 3, 'cdate': 1648296564312, 'mdate': 1648296564312, 'ddate': None, 'tcdate': 1648296564312, 'tmdate': 1648296564312, 'tddate': None, 'forum': 'Bduz_QYg8Z5', 'replyto': 'Bduz_QYg8Z5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper23/-/Official_Review', 'content': {'title': 'It performs well on the binary tasks, but has it really learned the distinction?', 'review': 'This paper tries to uncover whether transformers are able to distinguish temporal verbal aspect, in both fine-tuned and non-fine-tuned settings on two binary classification tasks related to telicity and duration?\n\nStrength:\nThe authors look at this problem from multiple perspectives. They created a dataset for French in addition to the available test set for English and create a qualitative dataset to zoom into particular cases.\n\nThe experimental set up allows us to see the contribution of several factors individually. For example,  by showing results for unseen vs seen verbs, the contribution of verb-specific knowledge becomes clear. The fine-tuned vs non-fine-tuned set up allows us to see in how far transformers are able to do the task with the general knowledge they contain etc.\n\nWeaknesses:\nEven though the experimental design is set up in such a way that we learn quite a bit on how well transformers fare on the task, given several pieces of information, I don’t feel the paper gives an answer to whether transformers actually learn aspectual information. I think this is due to the fact that many tendencies in the results are not explained. For example you mention ‘Examining the probability distribution of the two labels, all models were very confident in classifying sentences, regardless of their accuracy. This to me is a bad sign. The models should be less confident in cases when they are making the incorrect choice if they have actually learned someting. Also, the results on French are worse. The explanation given is not sufficient to me.\n\nI am still afraid that the model just picked up some superficial signals that allow it to do the task wel, without having actually learned the distinction.  Perhaps a simple baseline based on surface cues that the systems could outperform could take away these concerns. Or perhaps the task could be rephrased. Instead of a simple binary decision task, the model could be probed for its understanding of the telicity and durational aspects.\n\nThe authors make no specific reference to cognitive theory. It would be nice if they did given the workshop’s focus.\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_s1jw'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_s1jw']}, {'id': 'rCfetfrZuzc', 'original': None, 'number': 2, 'cdate': 1648002321401, 'mdate': 1648002321401, 'ddate': None, 'tcdate': 1648002321401, 'tmdate': 1648002321401, 'tddate': None, 'forum': 'Bduz_QYg8Z5', 'replyto': 'Bduz_QYg8Z5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper23/-/Official_Review', 'content': {'title': ""A look at aspect in transformers: it's probably there but it's not clear how"", 'review': 'This paper explores the question of whether sentential embeddings derived from pre-trained language models support the classification of aspect. The paper reports experiments on categorizing two types of aspectual information in English and French using a variety of pre-trained transformer architectures, together with some baseline models. The results point to a positive conclusion, though it is interesting to note that the results in cases where the verb is not explicitly labeled do not represent all that much of an improvement over previous models (Friedrich and Gateva report an F1 of about 76%, which is just a hair lower than most of the no verb cases reported in Figure 10). I appreciated the paper\'s contribution, though I think it would benefit from a few modifications.\n\n1. I was very interested to read the discussion of the qualitative patterns in the results. However, I found it difficult to extract any general lessons about how the transformers were doing the tasks. The specific deficits that were uncovered in the qualitative analysis could be further probed, by breaking down the quantative results  along a variety of dimensions. For example, it would be revealing to break the results down by aspectual category (e.g., are telic or atelic sentences classified better?), by structure (e.g., are past tense or present tense sentences better classified wrt telicity? what about sentences with definite or indefinite objects?), and by corpus (given that each one was skewed toward one or the other of the categories).  Doing this might allow us to begin to more systematically understand how these complex models are going about the task and why the qualtitative patterns you observed are as they are. I\'d like to know for instance how argument definiteness compares as a cue as compared to adverbial type as compared to verb tense as compared to the lexical semantics of the verb.  \n\n2. The description of the experiment was not as complete as I would have liked. How was classification done? Specifically, during finetuning, which embedding was used to do classification? Was it the [CLS] token or the verb embedding, and if the latter, what happened in cases where the verb was divided into multiple tokens? Were the embeddings averaged?\n\n3. The discussion of aspect in the paper isn\'t entirely clear on the distinction between aspect that is lexically determined and that which is the result of structural context (e.g., the properties of the object, adverbial modifiers, or inflectional morphology). The paper doesn\'t make explicit which of these is being targeted in the classification task discussed in the paper. I would have thought it was the latter, given some of the test cases (in Table 3 we see that ""eat"" can be either telic or atelic depending on its object). However, some of the comments in the paper lead me to think otherwise: ""it has been annotated for telicity and duration based on the verb\'s aspect"" (line 182), ""aspect is generally attributed to the verb"" (line 215). It would be helpful to clarify this, and to be clear about what diagnostics are being assumed to characterize each of the aspectual categories under discussion. Providing some more detailed characterization of the categories would be particularly helpful in the case of ""duration"", as it wasn\'t clear to me what the distinction was -- is it between states and activities (possibly habitual)? Is there a third category of non-durative predicates? \n\n4. I am skeptical that the translation-generated French dataset is sufficiently reliable as to produce interpretable results. Moreover the qualitative assessment didn\'t reveal any particularly clear generalizations that we can compare with those from English (where the results of the qualitative evaluation were similarly mixed). Moreover, the fact that the results of the pre-trained models was no better than the CNNs makes me worry that they are suffering from a mismatch between the pre-training data and the odd sentences in the aspectual fine-tuning data. Though I am in general quite pleased to see work that compares results across multiple languages, it might not be a bad idea to leave these French results aside until better data sets can be obtained.  \n\nSpecific comments:\n\nline 167: The procedure for creating the silver annotations in Friedrich and Gateva\'s dataset strikes me as possibly poblematic. Do we know how reliable it is in producing labels that English speakers agree with? Has this been checked in previous work?\n\nline 226: I don\'t understand the use of token_type_ids. Is this to specify which embeddings are used for classification? Or does this information get fed into the model so that it facilitate classication? The latter clearly seems like cheating, since we might have expected that the language model would learn about the importance of the verb for aspectual classifcation without any explicit annotation of the verb. And even the former doesn\'t seem ideal -- shouldn\'t we be able to classify the entire predicate (or even he entire sentence) as, say, telic or atelic, as compared to the word itself.\n\nTable 1: the differing skew with respect to the duration categories in the datasets is quite striking. As the paper notes, the model could sensibly try to solve this task by determining which corpus it comes from. Do you have a sense that this has happened to any degree? Does it perform worse on durative examples from Friedrich than it does on those from Captions (and vice versa for statives)? Also, why don\'t the number of labels for telicity equal the number of labels for duration?  Are some sentences only marked for one or the other?\n  \nLine 339: What contectual embedding did you use if more than one token is associated with the verb (in the case of subword tokenization)?\n\nFootnote 4: What is the measure of translation accuracy? Entire sentence correctness? Is there a correlation between problematic translations and problematic classification of aspect?\n\nLine 397: Do you have any ideas on why the BERT models yielded more categorical classifcations for aspect (but not duration) as compared to the others?\n\nline 471: Any idea about what made this case difficult? \n\nline 485: Any thoughts on why?\n\nline 494 et seq: Again any thoughts on why?\n\nline 517 (Figure 3): The differences across layers are pretty small. Should we take this to suggest that this classification task can be done using fairly superficial features, such as verb form. Also, it wasn\'t clear to me whether this probing study was done using the fine-tuned model or not. If not, what do you make of the fact that the results are nearly as good as those obtained from fine-tuning?\n\nline 542: An alternative interpretaion (which doesn\'t necessarily implicate the use of context) is that the input embedding of the unseen verb is relevantly similar to verbs on which the classifier was trained.\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_5HRU'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_5HRU']}, {'id': 'HreglUjhBGq', 'original': None, 'number': 1, 'cdate': 1647852359619, 'mdate': 1647852359619, 'ddate': None, 'tcdate': 1647852359619, 'tmdate': 1647852359619, 'tddate': None, 'forum': 'Bduz_QYg8Z5', 'replyto': 'Bduz_QYg8Z5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper23/-/Official_Review', 'content': {'title': 'A great addition to the workshop', 'review': 'This is a very well crafted study, with a good combination of qualitative and quantitative results and a thorough analysis. The conclusions - albeit relatively ""obvious in hindsight"" - are a good addition to the ""BERTology"" program and point to some interesting directions for future research. I would have liked to have seen the next step in the analysis, namely, whether verb aspect classification performance is critical to downstream success (i.e. would a Transformer model be able to recover from a misclassification make a correct e.g. event ordering prediction), but this is also a good follow-up topic. Overall, I think this paper is great addition to the workshop.\n\n## Questions to authors\nIn footnote 4, what does an annotation accuracy of 73.5% refer to? The accuracy of the projected annotations from English? Or the accuracy of the annotator? If it\'s the former, what was the IAA rate for the whole sample?\n\nWas the finding that BERT had the highest performance for both telicity and duration surprising? Given the (excellently succinct) attribute presentation in §3.3, why weren\'t the other models able to take advantage of their improvements over BERT?\n\nDo the findings in §4.3 indicate that these models are mostly taking advantage of morphological information? Is that something that could be (or has been) checked with the qualitative datasets?\n\nCould another type of qualitative analysis be constructed with novel (nonse) verbs (Mary daxed carrots all day) and novel contexts (Mary sliced blinkets in foo minutes)?\n\nFor the decreased performance of models in French with the verb position information, is parsing accuracy the main culprit (if understand lines 557-8 correctly)? A manual annotation of a small sample of sentences could provide a sanity check for this. \n\nI\'m not sure I undersrand the final point in the Discussion section. If the model architectures are different wouldn\'t it make sense to represent the semantics of language differently?', 'rating': '9: Top 15% of accepted papers, strong accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_776c'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_776c']}]"
https://openreview.net/forum?id=B_ux_XFeIWq ,B_ux_XFeIWq,"[{'id': 'BFLgzk5bCG9', 'original': None, 'number': 3, 'cdate': 1648396762233, 'mdate': 1648396762233, 'ddate': None, 'tcdate': 1648396762233, 'tmdate': 1648396762233, 'tddate': None, 'forum': 'B_ux_XFeIWq', 'replyto': 'B_ux_XFeIWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper22/-/Official_Review', 'content': {'title': 'Attention in humans and neural systems ', 'review': 'This paper investigates the relationship between human attention (in the form of eye movements) and the attention used by pre-trained transformers. The authors perform a nice comparison between the way humans and multiple models process text. All in all, I find this paper well written and definitely of some interest to the CMCL community. For this reason, I would be happy to see it published.\n\nSaid so, I would still like to read more about the following aspects. The authors could easily shrink the related work section a little bit and gain the half-a-column necessary for clarification.\n\n* You claim that the first/early layers show the highest correlation overall. It is important to support this claim with some analysis and a bit more discussion on why we are seeing this pattern and what we can conclude.\n\n* Directionality is always tricky when dealing with human processing. Why not addressing it? There are plenty of uni-directional models that you could include in the analysis as a comparison point. \n\n* Given the audience, it would be nice to read more about the reason why it is important to draw a line between attention in humans vs. models. You could specify if such correlation can tell us more about processing in general. ', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_zT3s'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_zT3s']}, {'id': 'SpfxlH9dYfc', 'original': None, 'number': 2, 'cdate': 1648097848236, 'mdate': 1648097848236, 'ddate': None, 'tcdate': 1648097848236, 'tmdate': 1648097848236, 'tddate': None, 'forum': 'B_ux_XFeIWq', 'replyto': 'B_ux_XFeIWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper22/-/Official_Review', 'content': {'title': 'Review of eye-gaze and self-attention', 'review': '\nThe paper discusses an approach to modeling eye-gaze using BERT and similar models. In particular it shows that dwell time in human eye-tracking data correlated with attention patterns in early layers of these models. Additionally, this correlation was found to be weak on data where participants had to respond to questions after reading sentences.\n\nI thought it was very well written paper. Tha authors do a wonderful job in stating the assumptions, in describing the hypothesis, situating their work in the previous literature as well as in discussing the results.\n\nMy key concern is with regard to the interpretation of the correlation and indeed, with the hypothesis of relating attention in transformers with human overt attention (operationalized via gaze duration/dwell time). This is because of the underlying nature of the model like BERT -- the authors state ""Its bidirectional structure means that each word token is placed in the context of the entire sequence instead of just the tokens appearing before it."" Now, it seems to me that while such a mechanism could be used to model grammatical knowledge but it\'s difficult for me to understand how it could model an online process such as overt attention. This is because when English native speakers read a word in a sentence they have very limited access to the context on the right of a word that they are fixating. It is true that the authors are modeling gaze duration (rather than a measure like first fixation duration) which implies that the measure captures reading time due to regressions as well (i.e., looking at the word again after accessing right context), but we know that regressions are rare during reading. So, regressions being rare while typical reading implies that reading doesn\'t involve use of right context. Can this be said of the models being use to model overt attention? Indeed, given the nature of how BERT works one would expect the correlations to be in fact stronger in cases where reading involves active search for information (i.e., when reading to answer questions). This is because one could expect more rereading in such a setting.\n\nSo, my main concern is that the \'overt attention\' - \'transformer attention\' link that has been established in this paper is rather tenuous and in my understanding theoretically weak. I would request the authors to at least acknowledge this limitation of the work in the final draft, if the paper were to get accepted. The authors state that ""... this paper will present experimental evidence of a link showing the relationship between the two."" I suggest that the author qualify the nature of this link; as it is currently stated, the use of the word \'link\'  implies process parallelism which as discussed above is very misleading.\n', 'rating': '5: Marginally below acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_YKVU'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_YKVU']}, {'id': 'SV3eLdbBLz5', 'original': None, 'number': 1, 'cdate': 1647886702081, 'mdate': None, 'ddate': None, 'tcdate': 1647886702081, 'tmdate': 1647912600167, 'tddate': None, 'forum': 'B_ux_XFeIWq', 'replyto': 'B_ux_XFeIWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper22/-/Official_Review', 'content': {'title': 'Human vs machine attention during reading', 'review': ' ## Overall\n \nThis paper analyzes the degree of correspondence between human eye fixation patterns during text reading and the attention distributions of pretrained transformer language models. Results show an overall high degree of correlation between model-generated attention weights and human gaze distributions across transformer architectures and layers, suggesting that transformers may converge via pretraining on a relatively human-like assessment of the importance of words in texts. Although I have some concerns about framing and methods, I think this paper should be of interest to computational psycholinguistics.\n\n\n## Major\n\n- Framing and motivation leave something to be desired. First, attention in the deep learning toolkit and attention as a cognitive process happen to be referred to with the same word in English, but that doesn\'t entail that the relationship between them is inherently scientifically interesting. The authors\' assumed stance on the relationship between these two constructs is confusingly presented: the first sentence of the paper implies that both attentions are considered to be the same thing, whereas the first sentence of the 2nd par implies that they are ""appear to be completely different"". In reality, ""attention"" in DNNs is a cognitively inspired architectural innovation that improves task performance but whose role in the model\'s reasoning process is not well understood (e.g. Jain & Wallace 19, Serrano & Smith 19), let alone its relationship to human cognition. The paper would benefit from a clearer framing of the constructs under investigation. Second, why does the relationship between model and human attention matter? What do we learn about models or humans from a particular level of correlation between attention weights and eye gaze? To be clear, I\'m *not* saying that these questions don\'t matter, only that it\'s on the authors to explain what\'s at stake. The paper dives right into the details without clearly setting up the questions that the authors want to answer.\n\n- Human gaze distributions were averaged prior to analyses. Because reading patterns are known to be highly variable across individuals, I think this is a serious weakness. In particular, it may lead to an exaggerated impression of human-model similarity by eliminating a major source of variation in the eye movement record. More realistic estimates could be derived from e.g. regression models of detailed (unaveraged) fixation distributions given model attention proportions, ideally in a mixed effects design. In addition, interpretation is made difficult by the absence of baselines. How good is 0.6 Spearman correlation, and what drives the correlations? Without controls, it\'s hard to say whether this is really about the model\'s learned attention vs less interesting phenomena that attention may merely reflect in some way, like the length or frequency of words.\n\n- This paper surveys a lot of the models in the huggingface inventory but the absence of GPT (and variants) is a liability, especially since GPT is one of the only SOTA transformer LMs that respects incrementality (a constraint faced by human readers) and produces representations that are substantially more similar to the human brain response to language than many of the other models considered here (Schrimpf et al 21, cited here). GPT is available from the same software library as the others -- why was it omitted?\n\n- Several critical claims are made based on numerical differences without direct statistical comparison. For example, none of the following claims are directly supported quantitatively:\n    - Lower layers are better correlated with human gaze than higher layers\n    - There is no relationship between the size of the model and attention-gaze correlation (this one actually isn\'t quantified at all, e.g. via correlation between nparams and spearman corr)\n    - BERT is better overall than the other models\n    - Attention-gaze correlations are higher during free (vs task-directed) reading\n    - Lower layers model eye movement control whereas middle layers model specific language processing operations\n\n\n## Minor\n\n- Rai & Le Callet 2018 is a suboptimal single citation to provide for the overt-covert attention distinction. Posner 1980 would be better.\n- Fig 1 is hard to interpret. Sure, many maxima are in early layers, but there are plenty of exceptions, and many from the highest layers. What\'s the pattern? How different are the layers from each other? A distribution would be a lot more informative here.\n- Ettinger 20 is cited as a study about eye movements vs machines, but they didn\'t look at eye movements. This cite should either be removed, or the context should be rephrased.\n- This paper is heavily inspired by Sood et al 20 and cites it frequently, but the presentation of that earlier work is strange. In particular, it\'s never said clearly enough that this paper is asking a different question from Sood et al 20. Sood et al 20 asked whether *model performance* on a QA task was anticorrelated with the *similarity* between model attention distributions and human gaze distributions. They showed that models that do well on the QA task have more similar attention distributions to humans, which is not the same as this paper\'s question about the *overall similarity* of human and model attention, independent of task. This is why Sood et al\'s associations are negative, which is an otherwise confusing outcome as presented here. It\'s also not clear why the authors feel beholden to account for ""departures"" of their findings from Sood et al\'s results at the start of S3.3. I\'m glad this resulted in some interesting error analysis about the importance of normalizing over sentences vs paragraphs (though see next point), but I don\'t understand the reason for the question in the first place -- Sood et al and this paper are analyzing different things in response to different questions, so why would the results be expected to be the same?\n- The finding that model-human correlations are higher when normalizing over sentences vs paragraphs is presented as a puzzle and the authors speculate that model-human alignment may degrade with longer texts. However, the texts and model attention distributions are the same in both analyses (only the domain of normalization changes), so this explanation doesn\'t make sense to me. Plus isn\'t matching at the level of paragraphs strictly harder than matching at the level of sentences, since at the paragraph level, the model needs to reproduce the gaze distribution of each component sentence (i.e. the sentence-level task) *and* the overall proportion of gaze across sentences? So I think the degradation when normalizing over paragraphs just falls out from sentences being substrings of paragraphs. Which domain of normalization is more appropriate depends on the scientific question, which isn\'t fully spelled out here (see major point 1).\n- The paper puts all description of datasets in the appendix, but some high level description should be provided in the main text, especially since they go on to analyze differences between datasets/tasks in S3.3.\n- There are known potential problems with averaging bounded variables like normalized attention distributions: because the bound isn\'t taken into account in the average, values in the center of the range can have an excessive influence, and the degree of concentration toward the extremes can be poorly estimated. In the domain of Pearson correlation, this is often handled with Fisher transformation. Have the authors considered and tried to address possible influences of edge effects on their results?\n- To compute model attention distributions, averages were first taken across attention heads and token-level attention distributions, and then the weights on subword tokens were averaged to bring the tokenization into alignment with reading experiments. But it seems like a more principled method would first *sum* the attention weights allocated to each subword before any other averaging, since this sum represents the total proportion of attention allocated to the entire word.', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_oK4s'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_oK4s']}]"
https://openreview.net/forum?id=rTzgPQtx8-9 ,rTzgPQtx8-9,"[{'id': 'BK8gPiYm3M9', 'original': None, 'number': 3, 'cdate': 1648273822750, 'mdate': 1648273822750, 'ddate': None, 'tcdate': 1648273822750, 'tmdate': 1648273822750, 'tddate': None, 'forum': 'rTzgPQtx8-9', 'replyto': 'rTzgPQtx8-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper20/-/Official_Review', 'content': {'title': 'Promising idea, but I had a hard time figuring out exactly what was done', 'review': ""This paper describes a model of scalar implicatures that is based on entropy and surprisal, evaluated against human judgements.\n\nIt seems like a promising idea, but I had a hard time figuring out exactly what was done.  I suppose the system interprets a weak word to be faint praise if there is a strong word with a high probability in the same context according to T5.  If so, then I suppose the entropy mentioned in the paper is just a high probability of the strong word compared to the weak word?  In any case, I think the presentation would benefit from a simple equation for the estimator and a clear example.\n\nIn particular, in the discussion, I did not follow the paragraph describing the example containing the phrase 'if guaranteed has low surprisal when the weak item is possible, then entropy might be low but the surprisal of certain could be high'.  Why does the surprisal depend on the weak item (aren't they alternatives?), and what is the entropy of?\n"", 'rating': '6: Marginally above acceptance threshold', 'confidence': '2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_iSz7'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_iSz7']}, {'id': 'BdbeAkZH5M5', 'original': None, 'number': 2, 'cdate': 1648148710216, 'mdate': 1648148710216, 'ddate': None, 'tcdate': 1648148710216, 'tmdate': 1648148710216, 'tddate': None, 'forum': 'rTzgPQtx8-9', 'replyto': 'rTzgPQtx8-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper20/-/Official_Review', 'content': {'title': 'Nicely written paper on modeling crucial aspects of scalar implicatures', 'review': 'The work reported in these pages tested the hypothesis that scalar implicatures (SI) rates depend on the listener\'s confidence in the underlying scale, where the availability was estimaed by using T5. The authors reported a significant correlation between SI rates and scale uncertainty.\n\nThis paper is well written and sufficently easy-to-read. The methodology is sound and the reported results may follow-up studies.\n\nA few issues:\n- the proposed methodology cannot be applied to all kinds of scalar implicatures. For instance, it is difficult to see how this approach can be used to model SIs implying a negation such as the fact that a sentence like ""The Sonic Youth played some songs of their fist album"" implies that ""The Sonic Youth  didn\'t play all the songs of their fist album"". I think that the authors should clearly explain the limitations of their methodology\n- by looking at figures 1.b and c it seems that there are a few leverage points that affect the linear relationship between SI rates and entropy or entropy over clusters. How does the correlation score change if we remove these outliers? I\'m afraid that it may change significantly, at least in the case of SI ~ Entropy over completions.\n- it would be intesteresting to measure the correlation between Entropy over completions and Entropy over clusters.', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_Z16g'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_Z16g']}, {'id': 'rNexdUwbPfq', 'original': None, 'number': 1, 'cdate': 1647937360359, 'mdate': 1647937360359, 'ddate': None, 'tcdate': 1647937360359, 'tmdate': 1647937360359, 'tddate': None, 'forum': 'rTzgPQtx8-9', 'replyto': 'rTzgPQtx8-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper20/-/Official_Review', 'content': {'title': 'Interesting study using language models to explain scalar diversity', 'review': 'The paper addresses the linguistic hypothesis that scalar implicatures rates depend on the availability of a strong alternative. They operationalize availability as confidence in the underlying scale and estimate this using neural language modes. The results suggest that such uncertainty over alternatives can explain scalar diversity. \n\nThe paper is well-written, with clear explanations of the phenomenon of interest and of the methods used. The methodology introduced is creative and could inspire analogous applications of language models for linguistics.\n\nOther than the correlation values reported, it would be good to have some analysis like a regression, jointly with other potential predictors, in order to clarify the causal role of these uncertainty estimates over the scalar implicature rates.', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_hMpT'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_hMpT']}]"
https://openreview.net/forum?id=rzfGP7FeLZc ,rzfGP7FeLZc,"[{'id': 'SOWlyhs1nGc', 'original': None, 'number': 3, 'cdate': 1648257958735, 'mdate': None, 'ddate': None, 'tcdate': 1648257958735, 'tmdate': 1648258271916, 'tddate': None, 'forum': 'rzfGP7FeLZc', 'replyto': 'rzfGP7FeLZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper19/-/Official_Review', 'content': {'title': 'Review of Modeling the Relationship between Input Distributions and Learning Trajectories with the Tolerance Principle', 'review': '## Overall\n\nThis paper shows via computational simulations that the Tolerance Principle (TP; Yang 05), a theory of rule learning in child language acquisition, can explain previously attested uniformity across child learners of English in (a) which morphological patterns are acquired as productive rules and (b) the timecourse of rule acquisition. The TP defines a deterministic threshold over the proportion of exceptions that can be ""tolerated"" by a productive rule. Under the assumptions of the TP, the authors show empirically that rules may move in and out of productivity during learning due to variation in the relative number of exceptions learned, that the shape of these learning trajectories is influenced by the token frequencies of exceptions, and that simulations using data-driven token frequencies roughly replicate the timecourse of rule learning attested in studies of child language learning.\n\nThe writing and interpretation are generally clear, the motivation and methods are sound, and the results support the conclusions. I think this work is appropriate for CMCL, although the breadth of interest may be limited by how embedded it is within a particular theory (Yang 05).\n\n\n## Major\n\n- The TP framework assumed by this work takes for granted that children tasked with morphological rule learning can already (1) unambiguously segment words in running speech, (2) correctly identify the types of these segmented words as well as any lexical features that could be used to define domains of rules (e.g. syntactic category), and (3) conduct a global search over their entire vocabulary and hypothesized rule set each time a new word is learned, since this is required in order to determine (a) which words fall under the domain of application of each rule and (b) how many of these are exceptional, in order to decide whether to retain the rule according to the tolerance principle. No attempt is made here to show that the TP is more successful than some alternative theory at explaining a set of facts, so the results may be of limited interest to readers who reject one or more of these assumptions.\n- About 1/3 of the introduction is dedicated to discussing classical U-shaped trajectories (overregularization) from the acquisition literature, but this work isn\'t about overregularization. Neither the TP itself nor the computational simulations conducted here concern whether/when a learned rule will be incorrectly applied to an exception. The only question at issue here is when rules are learned in the first place (which certainly could be a necessary condition for overregularization, but not the whole story). Likewise, the abstract concludes that the study shows the TP underlies cross-linguistic differences in learning trajectories, but this again seems like a red herring. This study only uses data from English past tense verb morphology and says nothing directly about cross-linguistic variation. Sure, the result implies that languages with different token frequencies will have different trajectories, but whether this model replicates any known cross-linguistic differences is never evaluated. Thus, the framing of the abstract+intro seems to set up different questions than the ones the authors ultimately address.\n\n## Minor\n\n- The mathematical notation in S3.1 confusingly overloads variable names. In reality, there are 4 quantities involved: (a) the true in-domain vocabulary size, (b) the true number of exceptions, (c) the infant\'s vocabulary size at a particular point in learning (the sample size parameter of the hypergeometric distribution), and (d) the number of exceptions learned by the infant at a particular point in processing (the support of the hypergeometric distribution). But the authors use $N$ to refer to both (a) and (c) and $e$ to refer to both (b) and (d), so I had to puzzle over that section for a while in order to figure out how the hypergeometric distributions were being parameterized and thus what the plots were representing. Clearer notation would be helpful.\n- The plot axes (e and N-e) are a bit of a head trip because they both depend on e. Why not plot e vs N? Barring that, I was able to get my head around the plots by mentally relabeling the y axis as ""Num irregular"" and the x axis as ""Num regular"". Revising the axis labels along these lines would clarify things a lot.', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_rnzi'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_rnzi']}, {'id': 'BAgg4QUXsGq', 'original': None, 'number': 2, 'cdate': 1648207387764, 'mdate': None, 'ddate': None, 'tcdate': 1648207387764, 'tmdate': 1648210105412, 'tddate': None, 'forum': 'rzfGP7FeLZc', 'replyto': 'rzfGP7FeLZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper19/-/Official_Review', 'content': {'title': 'Interesting ideas but scientific contribution is not clear ', 'review': 'The paper proposes to explain uniformity in children\'s language learning despite possible differences in individual learning trajectories. The authors investigate these ideas using the Tolerance Principle (TP) (Yang, 2016).\n\nI think the idea is interesting and the use of TP is a good way to approach this question. I do however have several comments/concerns that the authors need to address before they consider a publication.\n\n-First, I am sure if CMLC is a suitable venue since the paper does not use computational linguistic methods\n\n-While TP is a very simple concept, its description in the paper is extremely convoluted and unintuitive. Besides, the authors made use of highly ambiguous word choice and phrasing that impedes understanding for people who are not familiar with TP. To illustrate, the caption in Figure 1 says ""If e lies below θ, then the learner should acquire *it* and memorize the exceptions"" here the reader would think that *it* refers to ""e"" whereas it should refer to the ""productive rule"" (which is not mentioned at all in the caption). The authors also talk about the ""sing-sang"" pattern, which is highly confusing. The pattern they mean is not sing-sang but ""-ing -> -ang"". Sing-sang is an example, but the author never makes this clear. I highly recommend the author to rewrite several parts of the paper to make it understandable. As is, the writing is unnecessarily cryptic and does not allow readers to understand what the authors are doing.\n\n-The authors do several simulations that are in my opinion totally unnecessary: the formula is extremely simple, and does not require more clarification through simulations. In fact, these simulations are counter-productive because they are harder to understand than the formula itself!\n\n-In my opinion, the only aspect of this work that is slightly novel is the fact of presenting words with different frequency distribution and showing that this leads to different learning trajectories. However, here again, I am afraid the result is obvious and doesn\'t require simulations. It is discussed in more intuitive terms in Yang 2016 and subsequent work and the concept of ""transient"" periods in learning trajectories is talked about lengthily. \n\nSure, if you do some weird sampling of words (by selecting the lowest frequency, lowest and highest, etc;.) you end up with different transient modes, but these are not insightful about real development since the sampling performed by the author is extreme/artificial and does not correspond to variability in the order of acquisition in children. It would have been more interesting if the authors took real longitudinal vocab acquisition (for example using http://wordbank.stanford.edu/) and showed there to be real variability in transient periods of productive vs. unproductive rule depending on variability in order of word learning of real children.\n\nThe part about CHILDES is completely disconnected from everything else. The authors use only one learning trajectory of how vocabulary grows, so we don\'t see any variability in the learning trajectory. In fact, this part is just duplicating the work in Yang 2016 who used exactly the same phenomena (i.e.,  the -ed rule vs. ing-ang) and the same CHILDES data.\n\nTo conclude, while I am sympathetic to the underlying ideas, the work does not make a solid case for it or present anything that we don\'t already know. In my opinion, the simulations only muddy the water (sorry!) instead of adding insights. Instead of simulations, I really encourage the author to use real data of variability in children learning trajectories and study the extent to which it follows the predictions of TP. \n ', 'rating': '5: Marginally below acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_D2pM'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_D2pM']}, {'id': 'SN2e36RP9G9', 'original': None, 'number': 1, 'cdate': 1648160451828, 'mdate': 1648160451828, 'ddate': None, 'tcdate': 1648160451828, 'tmdate': 1648160451828, 'tddate': None, 'forum': 'rzfGP7FeLZc', 'replyto': 'rzfGP7FeLZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper19/-/Official_Review', 'content': {'title': 'Quantitatively assessing impact of child language input distributions on developmental learning trajectories', 'review': 'This paper models the relationship of child language input distributions on learning trajectories. This work is based on a cognitively motivated type-based learning model known as the Tolerance Principle that estimates a threshold of minimum exceptions to a linguistic pattern that are allowed for the language learner to productively use (and presumably influence decision-making and learning) a generalization in the grammar (in contrast to just memorizing individual items). The TP model has previously been used to account for inter-learner uniformity or how children acquire the same grammatical rules despite different learning input/environments (e.g., lexical variation).  \n\nThe authors show that the TP model accurately predicts how the type distribution of irregulars governs the overall learning outcome in line with previous work showing it can account for inter-learning uniformity. However, the novelty of this paper is in using the TP model to quantitatively assess how input distributions may drive variation in developmental learning trajectories. Specifically, how the token distribution (relative token frequencies or the order of acquisition of regular and irregular items) can lead to different learning trajectories. \nThe authors show this capability through an example using three different distributions of irregulars and their dramatic impact on the learning trajectory. They then show an application to real-world data mainly showing how this model can be used to quantify (visualize) the learning trajectories of the productive English past tense (the default past -ed) and the unproductive sing-sang sub-pattern drawing on CHILDES database.  \n\nThis has potential application towards quantitatively assessing how variation in input distributions accounts for observed cross-linguistical developmental learning trajectories. It would be great if the authors could give a specific example of this if the space allows for it as it would give the paper more breadth. I would also be interested in understanding how (if) this modeling approach could be extended to the developmental learning of larger linguistic structures (e.g., constructions or other)? \n\nThe theoretical description of the TP model and application to understanding how input distributions can impact developmental trajectories is very well explained. However, I think a little more effort should be spent in explaining how the different graphs/visualizations were created. Additionally, sometimes graphs are not referenced explicitly in the text such as in 3.1 in the last paragraph the authors reference a figure indirectly by simply stating “The second illustration demonstrates this”. I think a bit of clean up in these areas and making sure the graph/visualizations are clearly explained despite space constraints will greatly benefit this paper overall. \n\nSmall edits: In 3.1 there is a typo, mainly “If irregulars are distributed uniformly [throughout] the distribution of types…” should replace “If irregulars are distributed uniformly [through out] the distribution of types…”.\n', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_Skum'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_Skum']}]"
https://openreview.net/forum?id=HOu4PQtgUWq ,HOu4PQtgUWq,"[{'id': 'H-Egf7POkm5', 'original': None, 'number': 3, 'cdate': 1648490265549, 'mdate': None, 'ddate': None, 'tcdate': 1648490265549, 'tmdate': 1648532571078, 'tddate': None, 'forum': 'HOu4PQtgUWq', 'replyto': 'HOu4PQtgUWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper18/-/Official_Review', 'content': {'title': 'Looking for word co-occurrence probabilities in pre-trained word embeddings', 'review': 'This paper recycles the log-bilinear model (LBL), in a clever way to estimate bilexical co-occurrence probabilities using word embeddings. The motivation behind this work is that estimating word pair probabilities is often difficult due to the sparse nature of this data. Yet, having accurate word pair probabilities is relevant when conducting psycholinguistic experiments that evaluate usage-based cognitive language models (also likely in neurolinguistics it could be used as a useful baseline when trying to understand/evaluate the performance of word embeddings in decoding neural language activity in the brain). The authors propose to re-use the log-bilinear model from Mnih and Hinton 2007, arguably the simplest of neural language models, to estimate word-pair probabilities, specifically, by using as input to the LBL pre-trained static word embeddings (fastText word-vectors).\n\nThe performance of the LBL model is examined across four different languages (Arabic, English, Spanish, and Korean) while controlling for the size of the training data. They specifically look at predicting the distribution of attributive adjectives given nouns and nominal direct objects given verbs. The results are convincing with the log-bilinear model outperforming several baselines (i.e., lower negative log\nlikelihood). Particularly revealing is that it also consistently did better than a softmax distribution on target words as a function of the context word embedding (or when only using a word embedding for the context not the target word) confirming the utility of using word embeddings. I imagine that due to the light-weight nature of this model it would be of particular interest to language\nresearchers in cognitive science. The authors are also planning on making the code (trained model) available after publication. The only issue I have is that the paper doesn’t really address the sparse nature problem they originally used to partially motivate this work. To this extent, it would be good to note if the authors observed any significant performance advantages when changing the size of the\ntraining data set (compared to the baselines)? It would be good to give users a rough guideline on these metrics so that this model can be properly used (also performance using other common word embeddings other than fastText).\n\nTypo: Page 4, Section 4.3 Results, “These is perhaps not surprising…” should be “This is perhaps not surprising”.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_8X5b'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_8X5b']}, {'id': 'S9ewkG2uM9', 'original': None, 'number': 2, 'cdate': 1648046558970, 'mdate': 1648046558970, 'ddate': None, 'tcdate': 1648046558970, 'tmdate': 1648046558970, 'tddate': None, 'forum': 'HOu4PQtgUWq', 'replyto': 'HOu4PQtgUWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper18/-/Official_Review', 'content': {'title': 'A potentially useful tool for psycholinguists', 'review': 'This paper describes an estimation technique for word co-occurrence probabilities, unifying two relatively old pieces of technology: static word embeddings and a log-bilinear model from Mnih and Hinton 2008. The authors show that word pair probabilities remain useful in some psycholinguistic analyses and argue that large pretrained LMs which are now the state of the art in word prediction may not be able to read off the probabilities of interest without extensive computational effort (e.g. evaluating every word in the target set, in a particular context). Their model outperforms some basic LM smoothing techniques and is relatively lightweight and easy to estimate.\n\nBoth the mathematical framework and the presentation of related work are admirably clear given the limited space available. Results are very good across multiple languages (variants of this technique outperform very reasonable baselines, such as learning a softmax distribution over the target word, by large margins on many languages).\n\nGiven the space constraints, I would not expect to see a lot of task-specific analyses here. It would be nice to have an idea of how performance varies in training set size, and why performance is so low when the target vocabulary is unrestricted. These are likely to be important questions for psycholinguists considering how to use this technique.', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_tnxr'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_tnxr']}, {'id': 'rTMe-jAuPG5', 'original': None, 'number': 1, 'cdate': 1647967896897, 'mdate': 1647967896897, 'ddate': None, 'tcdate': 1647967896897, 'tmdate': 1647967896897, 'tddate': None, 'forum': 'HOu4PQtgUWq', 'replyto': 'HOu4PQtgUWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper18/-/Official_Review', 'content': {'title': 'An old model made new with word embeddings', 'review': ""This paper proposes a way to estimate word co-occurrence probabilities by leveraging word embeddings. The method uses a log-linear bilinear model that had been proposed by Mnih and Hinton some time ago, but marries it with pre-trained word embeddings that are derived from a much larger corpus, and which are not specialized to specific types of word co-occurrence. The results are fairly impressive: the trained model yields lower negative log likelihood in all cases, as compared to a number of other baselines. Overall, I found the approach sensible, if not groundbreaking, and the evaluation reasonably compelling.  I have a couple of points I'd like to raise:\n\n1. There is considerable variation in performance across the languages (In the adj-noun case, Korean is uniformly the best performing, and . Arabic and Spanish the worst, though there is some variation across models. Things are different in the verb-object case.) Does this stem from the differently-sized test sets (I am assuming that the training data were identically sized across languages), or from differences in the fasttext embeddings (perhaps stemming from differences in training data again), or from differences in the languages, or something else? It would be helpful for the paper to say something about this. For one thing, it would be useful to give sizes of the datasets, as well as measures of the number of distinct context and target words. \n\n2. The paper starts by talking about the cognitive utility of having estimates of co-occurrence probability, and the difficulty of doing that in the context of limited (parsed) data. It would be helpful to know the degree to which the proposed method is doing better in contexts of limited data.  In particular, it would be interesting to know how performance of the different models varies as the training data changes in size. For models that can do better with less data, we'd expect to see convergence with smaller datasets.  It would also be useful to know just how well the different models can do in the limit, if we give them limitless data (or nearly as much as we have). Part of the lower performance might be due to difficulty in parameter estimation, and part might be due to the structure of the model, so it'd be useful to know the degree to which the proposed method is really solving the sparse data problem.  \n\n3. Given that this is for CMCL, I'd like to have seen some discussion about the cognitive plausibility of the approach. it is commonly thought that word embeddings represent lexical semantics, but clearly similar meaning will not be sufficient to capture co-occurence probability (as in cases of differences in register, or word collocations). Instead, the important property of word embeddings that is being exploited here is that they are derived exactly from attempts to predict co-occurrence. From that perspective, should we expect that any specific way of deriving word embeddings would perform better than another?  \n\nSpecific comments:\n\nline 61: why can't we use a language model to get predicted adjectives by renormalizing the predicted distribution to limit the support to the same 20k adjectives you look at here? How do the distributions we get in this way from existing large language models (e.g., GPT-3 or BERT) compare to what we get here?\n\nline 204: why these hyper parameters?\n\nline 282: what does it mean that nouns are more open class? That there are more of them? If so, say that. They are both clearly open class."", 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_JehU'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_JehU']}]"
https://openreview.net/forum?id=BuO4I7FgUbq ,BuO4I7FgUbq,"[{'id': 'HAxe04UznGc', 'original': None, 'number': 3, 'cdate': 1648268854249, 'mdate': 1648268854249, 'ddate': None, 'tcdate': 1648268854249, 'tmdate': 1648268854249, 'tddate': None, 'forum': 'BuO4I7FgUbq', 'replyto': 'BuO4I7FgUbq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper12/-/Official_Review', 'content': {'title': 'Interesting work on improving Codenames clue generation but conclusions are unclear', 'review': ""This paper reports an attempt to improve models/agents playing the game Codenames. The authors use co-occurrence-based relatedness measures to select clues. They modify the scoring functions used in prior work and compare performance of all pairwise combinations of their relatedness measures and scoring functions at generating clues which lead to correct guesses by English and Hungarian speakers.\n\nMAJOR\n\nThis is an interesting study though the implications for cognition or linguistics could be made more salient given the scope/audience of CMCL. The innovations in terms of scoring functions seem useful. However, I'm not quite sure what the main take-away of this study is. Performance across all the combinations was very different for English vs. Hungarian. The authors suggest that the Hungarian data are more valid, but it's unclear which differences are reliable/interesting.\n\nI also found it odd that the choice of lambda isn't justified anywhere. It seems like it would be helpful to know more about how it impacts the agents' behavior, how the value of 0.5 was chosen in previous work, and whether that is still the optimal value given the new relatedness metrics and scoring functions.\n\n\nMINOR\n\nThe abstract of the paper is not very clear. I think it assumes that the reader already knows how codenames works. I actually did and still found it very opaque. \n\nThe paper fails to cite relevant work by Kumar, Garg, and Hawkins (2021). It would be useful to reference this work and clarify any major differences between their approach and the one presented here.\n\nAshok Kumar, A., Garg, K., & Hawkins, R. (2021). Contextual Flexibility Guides Communication in a Cooperative Language Game. Proceedings of the Annual Meeting of the Cognitive Science Society, 43. Retrieved from https://escholarship.org/uc/item/92m138t3\n\n\n"", 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_28kX'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_28kX']}, {'id': 'BF-xYQQYizc', 'original': None, 'number': 2, 'cdate': 1648231200617, 'mdate': None, 'ddate': None, 'tcdate': 1648231200617, 'tmdate': 1648231226627, 'tddate': None, 'forum': 'BuO4I7FgUbq', 'replyto': 'BuO4I7FgUbq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper12/-/Official_Review', 'content': {'title': 'Solid work but some questions about conclusions and prior literature', 'review': 'This paper contributes to a small but growing literature investigating the codenames board game as a way to evaluate models of human semantic memory. The authors separate sources of semantic relatedness and decision rules and evaluate both of these in their ability to guide human players in an online game. \n\nThe direct evaluation of algorithm outputs is a major strength of the paper, as is the systematic evaluation of the space of different relatedness/scoring pairs. There is surprisingly little variation in performance among relatedness/scoring pairs, however, and there  is not much systematicity (e.g., sometimes a particular scoring rule performs better with one relatedness measure and worse with another). Further,  no statistical analysis is presented. These observations make me worried that – despite the large amount of data –\xa0the conclusions in favor of specific settings are tentative. \n\nA notable new line of work by Kumar and colleagues has investigated both other sources of relatedness and judgments and other metrics, though both the details of the games and the evaluations are different enough to be difficult to compare:\n- Kumar et al. (2021a) - https://escholarship.org/uc/item/92m138t3\n- Kumar et al. (2021b) - https://onlinelibrary.wiley.com/doi/full/10.1111/cogs.13053\n\nAlso, there was no reference to an older, foundational paper, Xu & Kemp (2010) - https://proceedings.neurips.cc/paper/2010/file/766d856ef1a6b02f93d894415e6bfa0e-Paper.pdf\n\nIn sum, this seems like solid work but my enthusiasm was dampened by my limited confidence in the meaningfulness of results comparisons and by the omission of prior work. ', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_GDsD'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_GDsD']}, {'id': 'SrHe4J2DjGq', 'original': None, 'number': 1, 'cdate': 1648225244280, 'mdate': 1648225244280, 'ddate': None, 'tcdate': 1648225244280, 'tmdate': 1648225244280, 'tddate': None, 'forum': 'BuO4I7FgUbq', 'replyto': 'BuO4I7FgUbq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper12/-/Official_Review', 'content': {'title': 'nice work', 'review': 'This paper builds on and improves previous work on modeling the Codename game. The authors introduce both new semantic association measures and new scoring functions that optimize the choice of clue words. The authors also compare the model predictions to human players online in both English and Hungarian.\n\nThe paper is well written,  the methods are clearly justified, and the results are compared with previous work and show increased performance.\n\nI am not an expert in this sub-filed of study but I enjoyed reading the paper and found it interesting. I do not have any major concerns and thus, I recommend acceptance.', 'rating': '9: Top 15% of accepted papers, strong accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_zsee'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_zsee']}]"
https://openreview.net/forum?id=B6PlLQtl8Zq ,B6PlLQtl8Zq,"[{'id': 'BudxT5AzRM5', 'original': None, 'number': 3, 'cdate': 1648402069050, 'mdate': 1648402069050, 'ddate': None, 'tcdate': 1648402069050, 'tmdate': 1648402069050, 'tddate': None, 'forum': 'B6PlLQtl8Zq', 'replyto': 'B6PlLQtl8Zq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper8/-/Official_Review', 'content': {'title': 'Investigating multimodal referring items using transformers', 'review': 'In this paper, the authors use CLIP (a multimodal vision + language neural model) to quantify the descriptiveness and discriminative of human dialogues when describing visual inputs.\n\nThe work is interesting, and overall well presented. The only part I would like spelled out better is the ability to really get cognitive insights into the possible strategies adopted by humans. So far, the link is really not there and unfortunately, undermines the conclusions we can draw from this study.', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_6fTE'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_6fTE']}, {'id': 'S-EgB8Grjzq', 'original': None, 'number': 2, 'cdate': 1648214604977, 'mdate': 1648214604977, 'ddate': None, 'tcdate': 1648214604977, 'tmdate': 1648214604977, 'tddate': None, 'forum': 'B6PlLQtl8Zq', 'replyto': 'B6PlLQtl8Zq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper8/-/Official_Review', 'content': {'title': 'An interesting study on multimodal referring utterances', 'review': ""This paper presents experiments on quantifying the descriptiveness and discriminativeness of referring utterances in dialogues, by using a pre-trained multimodal modal. The study is well-presented and has shown interesting results. I only have one minor question about the COCO dataset. It says that the COCO set used in this study was a part of the PB-GOLD, but while PB-GOLD's utterances were related (section 2), later it says COCO dataset's captions were independently produced (page 3). Maybe some clarification would help us understand the nature of PB-GOLD dataset."", 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_yWif'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_yWif']}, {'id': 'rKbeqBXNUGq', 'original': None, 'number': 1, 'cdate': 1647883073555, 'mdate': 1647883073555, 'ddate': None, 'tcdate': 1647883073555, 'tmdate': 1647883073555, 'tddate': None, 'forum': 'B6PlLQtl8Zq', 'replyto': 'B6PlLQtl8Zq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper8/-/Official_Review', 'content': {'title': 'Nice work. Applies state-of-the-art tools in a simple and effective manner in order to measure human language usage in a conversation.', 'review': 'The paper uses the CLIP language-vision model in order to measure the descriptiveness (how well an utterance describes an image in isolation) and discriminativeness (to what extent an utterance is effective in picking out a single image among similar images) of human language as it develops in a conversation.  The focus is on utterances that refer to visual entities. The paper presents interesting conclusions, reasonable explanations and it paves the way for future research with CLIP and similar tools.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_YG2K'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_YG2K']}]"
https://openreview.net/forum?id=BduGIXtlLZc ,BduGIXtlLZc,"[{'id': 'HbxytlD9M9', 'original': None, 'number': 3, 'cdate': 1648156791454, 'mdate': 1648156791454, 'ddate': None, 'tcdate': 1648156791454, 'tmdate': 1648156791454, 'tddate': None, 'forum': 'BduGIXtlLZc', 'replyto': 'BduGIXtlLZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper7/-/Official_Review', 'content': {'title': 'Well written paper with unimpressive results', 'review': ""The authors describe a classification experiment in which they mixed linguistic and visual features to predict the semantic relation holding between the components of a noun noun compound. \n\nBy itself the paper is well written and the topic very interesting. \n\nHowever, I find the reported results a bit unimpressive due to a series of reasons:\n- first of all, the differences in the reported F-measures are mostly almost negiglible. The authors should at least comment on that\n- the negative correlation between concreteness score and classification success is really puzzling, almost worrying. From an intuitive point of view, it suggest that the visual information (as encoded in this experiment) is not really that useful\n- it is not clear why the authors didn't test the performance of the visual features in isolation\n- a crucial piece of information that is missing from the paper is an analysis of the relation-wise perfomance of the best-performing classifier"", 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_Zq1M'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_Zq1M']}, {'id': 'ShVlqDNH9G5', 'original': None, 'number': 2, 'cdate': 1648149601835, 'mdate': 1648149601835, 'ddate': None, 'tcdate': 1648149601835, 'tmdate': 1648149601835, 'tddate': None, 'forum': 'BduGIXtlLZc', 'replyto': 'BduGIXtlLZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper7/-/Official_Review', 'content': {'title': 'A useful contribution in need of some clarity/reframing', 'review': 'This is a well-written paper; the authors clearly lay out the objective, the previous work on the topic, and their contribution. However, the reported performance increases are very modest, and some methodological choices are unclear. Overall, I think this paper is appropriate for CMCL if the authors adjust the framing and provide some clarifications.\n\n1.\tThe main claim is that concatenating word2vec and visual (ResNet) activations will improve interpretation (classification) of compound nouns by providing additional semantic information. However, the actual increases are very small (an average of 1% or less). It would be helpful if the authors acknowledged that the increases are actually quite modest. Moreover, Table 5 in the appendix shows that comparable performance gains can be observed even in cases where the nouns do not have a visual representation (so their final representation is word2vec + zeros). Thus, the utility of visual representations remains debatable.\n2.\tImageNet representations are obtained by averaging representations of several images. Has that been shown to be a useful approach for representing visual concepts? I would imagine that even if providing visual information is beneficial, averaging several distinct image vectors might make the visual representation less useful than it could have been if, say, the most prototypical image was chosen (this might depend on the specific object type too, e.g. less concrete objects are likely more visually diverse).\n3.\tI don’t quite get the way the Full Additive Model was implemented. Were the x, y, and z vectors pretrained word2vec vectors? More generally, you state toward the beginning that the goal is to learn a way to represent compounds compositionally, yet if the compound is frequent enough to have its own ground truth representation (z), doesn’t it violate the compositionality premise? \n4.\tIs there a reason why visual reps alone aren’t used for classification? Seems like a useful baseline.\n5.\tThe authors address the question of whether word concreteness affects their results by (a) examining how many imagenet images each word is associated with, (b) performing additional tests of whether image availability and concreteness affects classification accuracy. However, a key question here seems to be addressed only indirectly: do compounds with concrete words benefit more from adding visual representations? This could be done by dividing the compounds into 2 groups, concrete and abstract, and examining whether the benefits of adding visual reps vary between these two groups. Alternatively, the tests in Table 6 can be complemented by an explicit comparison of relative concreteness effects in L and VL modalities. The question of whether adding image vectors benefits only highly concrete words arose for me as soon as I read the title/abstract, so I think it’d be important to address it a bit more.\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_rwmZ'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_rwmZ']}, {'id': 'HYLgPTXQKz9', 'original': None, 'number': 1, 'cdate': 1648075711056, 'mdate': 1648075711056, 'ddate': None, 'tcdate': 1648075711056, 'tmdate': 1648075711056, 'tddate': None, 'forum': 'BduGIXtlLZc', 'replyto': 'BduGIXtlLZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper7/-/Official_Review', 'content': {'title': 'Seems to work, but the prose oversells the results', 'review': ""This paper investigates whether and to what extent augmenting linguistic representations with visual representations can improve a system's classification of noun-noun compounds (NNCs). NNCs come from the Tratz (2011) data set. They try a few different ways of combining the linguistic and visual representations.\n\nI appreciated that they specified several data splits up front: course vs fine-grained labels, and train/dev/test splits controlling for both the modifier and head members of the NNCs. This allows, in theory, for a lot of interesting comparison and analysis.\n\nOne major challenge which the authors faced was how to match up images from ImageNet with the Tratz NNCs. They present an algorithm to do this which seems reasonable, but is still quite approximate. This bring this up again in the conclusion. My worry is that their results might be greatly affected by their matching heuristic rather than the problem at hand, and while this is a great topic for a follow-up, I wish they had addressed it in this paper. I believe it is more critical than they made it out to be.\n\nThey present F1 scores for a family of 3 baseline models which take majority classes of the entire compound, head, or modifier in the training data. Providing a sensible baseline is something that is often skipped these days, so I appreciated this. \n\nThey test a concatenate and an additive model for combining ResNet visual representations with word2vec linguistic representations. \n\nThey find similar but not identical results for the additive and concatenative model. The latter performed slightly better on average, and in both cases they generally outperform word2vec alone. I was a bit surprised when I got to the results though, because +ResNet really is only a little bit better than word2vec alone. It seemed kind of incongruous with the big claims made in the prose of the paper. It's sort of trivial to assume that including additional informative data (as through ResNet) should help performance if it's combined correctly, and that is what we see from the results. So my question is, are these results dramatic enough to be interesting? And why aren't they better? Was it because of the matching heuristic? I don't know\n\nAlso not sure what part of this paper is meant to be cognitive modeling. "", 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_JpgF'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_JpgF']}]"
https://openreview.net/forum?id=rTMeHmKeI-5 ,rTMeHmKeI-5,"[{'id': 'SKIeR28BJ75', 'original': None, 'number': 3, 'cdate': 1648477877952, 'mdate': 1648477877952, 'ddate': None, 'tcdate': 1648477877952, 'tmdate': 1648477877952, 'tddate': None, 'forum': 'rTMeHmKeI-5', 'replyto': 'rTMeHmKeI-5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper4/-/Official_Review', 'content': {'title': 'An interesting new model of language representation but not entirely convincing ', 'review': 'This paper presents a new model for word embeddings that is based on the Unitary-Evolution Recurrent Neural Network architecture. The main advantage of the proposed embeddings is that they don\'t rely on non-linear cell operations making the resulting representations more interpretable and natively compositional. \n\nWhile the promise of a more interpretable language representation model is very interesting, I\'m not entirely convinced the new embeddings provide more intuitive explanations of what is being represented. The analysis still relies on linear algebra operations and interpretation of arbitrary distance values. The examples of syntactic and semantic closeness are equally transparent in the geometric interpretation of traditional word vectors and the effect size is easily mapped on the attention weight of regular attention-based DNN. In addition, we didn\'t see a concrete example of the advantage of URNs being able to handle compositionality natively. Ideally, there would be a ""head-to-head"" comparison (either qualitative or quantitative) between the proposed unitary embeddings and the more established techniques.\n\nRegarding the model\'s performance on a language task, despite the claims of the authors, there is no comparison with state-of-the-art methods for agreement task. For example, Goldberg (2019) achieves very similar results (up to 4 attractors) to the ones reported for TURN.\n\nThere are mentions of the current model\'s higher computational cost, but there are no figures to demonstrate whether this type of modeling can be practically used instead of the current generation of Transformer-based architectures.\n\nFinally, despite claims to this effect, there is no evidence of the proposed model\'s neurological validity. The reference to models of human learning and representation in the Introduction (lines 87-89) is vague and lacks supporting citations.\n\nOverall, while the use of URNs as embeddings is an interesting concept to explore, I\'m not entirely sure this paper has created a convincing account. \n\n\n## Comments to authors\nI didn\'t find the mathematical (modeling) sections of the paper very easy to follow. I would highly recommend the use of a running example throughout sections 2 and 3.\n\nTo prove the claim that ""[unitary embeddings] can focus on specific dimensions of meaning and structure, and they can be driven by specific NLP tasks"" it would be very interesting to show the same words being characterised differently due to the task (e.g. showing that the distances in Table 2 flip to group together semantically similar concepts rather than syntacticly similar ones).', 'rating': '5: Marginally below acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_AkA5'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_AkA5']}, {'id': 'SZEgKOXVcfq', 'original': None, 'number': 2, 'cdate': 1648145264588, 'mdate': 1648145264588, 'ddate': None, 'tcdate': 1648145264588, 'tmdate': 1648145264588, 'tddate': None, 'forum': 'rTMeHmKeI-5', 'replyto': 'rTMeHmKeI-5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper4/-/Official_Review', 'content': {'title': 'Robust mathematical implementation of a new RNN which provide a totally explainable deep learning model for natural language learning and representation', 'review': 'This paper introduces a new Recurrent Neural Network that includes Unitary Matrices at each step. The cell uses a linear transformation of the space instead of applying non-linear activations.\nThe authors evaluate how the RNN captures long-distance dependencies on two tasks: number agreement and Dick-language modeling (a symbolic synthetic language). The tasks are well-described and coherent with their research questions; results demonstrate how this mathematical implementation can help understand the linguistic representations created by deep neural architectures.\n\nThe paper offers a solid mathematical explanation and motivation for the implementation. The authors make everything as precise as possible, even if mathematical sections are a bit demanding for non-mathematicians. The only point that maybe could be more transparent regards the ""average effect."" In section 4.1, the exposition is condensed into very few lines. I suggest providing more details about this measure, making it more painless for a larger audience.\n\nThe only limitation of the presented work is perhaps that one must train the network for every specific task in a supervised way.\n\nThe overall judgment is favorable. I would be glad to see this model tested on semantic compositional tasks in NLP.', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_PSXn'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_PSXn']}, {'id': 'SUXlElS4Uf5', 'original': None, 'number': 1, 'cdate': 1647883499778, 'mdate': 1647883499778, 'ddate': None, 'tcdate': 1647883499778, 'tmdate': 1647883499778, 'tddate': None, 'forum': 'rTMeHmKeI-5', 'replyto': 'rTMeHmKeI-5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper4/-/Official_Review', 'content': {'title': 'An interesting paper which proposes a new neural embedding network which emphasizes compositionality and sentence embedding. The network is linear and hence arguably paves the way to interpretable comparisons with humans.', 'review': 'This paper proposes a new neural model for word embeddings, which uses unitary matrices as the primary device for encoding lexical information. This model does not employ non-linear activation functions, and can hence be used with linear algebra tools. The model emphasizes compositionality. The model is interesting but I am not sure the work is directly related to the theme of the workshop (which is the main reason that I did not give the work a higher score). ', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_7SS9'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_7SS9']}]"
https://openreview.net/forum?id=BGMfS7tgIWq ,BGMfS7tgIWq,"[{'id': 'rHxx0-PQ0zc', 'original': None, 'number': 3, 'cdate': 1648404229919, 'mdate': 1648404229919, 'ddate': None, 'tcdate': 1648404229919, 'tmdate': 1648404229919, 'tddate': None, 'forum': 'BGMfS7tgIWq', 'replyto': 'BGMfS7tgIWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper3/-/Official_Review', 'content': {'title': 'Combining vision and language to model semantic similarity and relatedness', 'review': 'In this paper, the authors investigate the use of multimodal (text+image) embeddings to predict semantic similarity and relatedness between word pairs.\nAll in all, the paper is well written and discusses a topic that is central to the CMCL community. However, there are still parts that are unclear and this makes the overall contribution weaker.\n\n* It is not clear to me how you can say that: VGEs explain additional variance after including text-based representations? This really needs more explanations. \n\n* Similarly, it is not clear how you can quantify the non-overlapping information captured by the different models. \n\n* Figure 1 needs more attention. Firstly, it has to be explained in more detail. Moreover, the two scales should be the same: this is extremely misleading. ', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_4sDq'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_4sDq']}, {'id': 'r4heOuEdof9', 'original': None, 'number': 2, 'cdate': 1648227440345, 'mdate': 1648227440345, 'ddate': None, 'tcdate': 1648227440345, 'tmdate': 1648227440345, 'tddate': None, 'forum': 'BGMfS7tgIWq', 'replyto': 'BGMfS7tgIWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper3/-/Official_Review', 'content': {'title': 'Careful experiments that disentangle visual information in text and actual image data', 'review': 'This is a well-written paper that carefully experiments with VGEs and compares the additional variance that can be explained using VGEs compared to text-based models.\xa0\n\n\nStrong points:\n\nThe paper makes a contribution to previous work by disentangling the visual information that may be contained in the text part of a dataset such as MSCOCO and the actual image data.\xa0\n\n\nIt shows results on a large number of datasets and tasks and meaningful subparts thereof. There is definitely substance.\n\n\nWeak points:\n\nThe paper investigates a worthwhile but considerably researched topic on two  well-known tasks. The method for creating VGEs is taken from previous work with some adaptations. In terms of novelty, the paper does not excel.\n\n\nEven after careful re-reading, I am not completely convinced that the results between the VGE model and the textual models are comparable. The method used to create the VGE is so different (more contextualised than the text-based models) that one wonders whether the contributions of the VGE model are not due to the model instead of the visual features.\xa0\n\n\nI would also like to see Figure 1 better explained, in particular the grey bars. These represent ‘the partial R2 of the VGEs after controlling for the variance explained by that text-based model’. Do you mean here the given text-based model, so word2vec for example? From the way these scores are represented, one on top of the other, you would get the idea that these scores can be added to arrive at a combined performance. I doubt that this is true though. Perhaps the partial R2 scores could be explained in more detail.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_wj8M'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_wj8M']}, {'id': 'rpPl9_IV8Gq', 'original': None, 'number': 1, 'cdate': 1647883889601, 'mdate': 1647883889601, 'ddate': None, 'tcdate': 1647883889601, 'tmdate': 1647883889601, 'tddate': None, 'forum': 'BGMfS7tgIWq', 'replyto': 'BGMfS7tgIWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper3/-/Official_Review', 'content': {'title': 'The paper presents visually grounded word embeddings and show that they predict both human reaction times and human judgements of word similarity. This is an interesting work that very well fits the theme of the workshop.', 'review': 'The paper presents visually grounded word embeddings and shows that they predict both human reaction times and human judgements of word similarity. I like the fact that the paper compares both to a reaction time experiment  and to word similarity judgement data. The fact that the proposed model performs well no both, is a nice indication of its cognitive plausibility.', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_P9g8'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_P9g8']}]"
https://openreview.net/forum?id=ruuMvmFeIb5 ,ruuMvmFeIb5,"[{'id': 'H2Gx_Gy7Azq', 'original': None, 'number': 3, 'cdate': 1648402192038, 'mdate': 1648402192038, 'ddate': None, 'tcdate': 1648402192038, 'tmdate': 1648402192038, 'tddate': None, 'forum': 'ruuMvmFeIb5', 'replyto': 'ruuMvmFeIb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper17/-/Official_Review', 'content': {'title': 'A Bayesian model of phase coherence in frequency-tagged EEG data', 'review': 'This paper discusses disadvantages of a frequentist ITPC analysis (such as loss of statistical power, no full characterization of the structure of the data) of frequency-tagged EEG data, and introduces a Bayesian model as a novel alternative. \nThe model includes:\n* a wrapped Cauchy distribution as a model of the data (a set of angles drawn from a unimodal probability distribution on the circle)\n* a prior for the mean phase for each participant-electrode-condition triplet as a uniform on a circle\n* a condition-dependent prior for the scale parameter of the distribution, resulting in different mean resultants\n \nThe authors show that the posterior distributions yielded by this model give a richer and more complete picture of the data than the original frequentist ITPC analysis.\n \n**General**\n\nThe paper is clearly written and of theoretical interest to the community. The characterization of the data derived via the analysis allows for interesting new conclusions that were not detectable using the ITPC method, which are relevant to the original research question. As someone without a background in EEG time-series analysis, the proposed Bayesian model nevertheless strikes me as straightforward and well-motivated. To make the novel contribution of the paper even stronger I suggest a discussion of how this approach compares to a mixed-effects model, which can also model the random effects in the data that ITPC as a summary statistic glosses over.\n \n**Specific questions/Comments**\n* One thing that wasn’t clear to me from the write-up is how the simplifying assumption of choosing independent location parameters per participant-electrode-condition triplet instead of per participant-electrode pair affects the model results (lines 144ff).\n* I would have liked to see the unabbreviated names for all 6 conditions somewhere in the paper, especially since the ML condition for which the model provides a novel result in relation to RR is not listed as an experimental condition in the Burroughs et al. (2021) paper; The same is true for the RV condition, but this name is more transparent given the other conditions. I assume ML and RV correspond to the two extra conditions described as fillers in the Methods section of Burroughs et al. (2021), and analyzed in Figure 2 of their Supplementary Materials, where RV = RRRV and ML = ADVP, but it would be good to make this correspondence clear. Furthermore, if this alignment is correct it may be good to discuss a potential effect of these two streams having 12 four-word phrases instead of 24 two-word phrases as the other conditions on the critical ML-RR modeling results.\n \nOverall, I think this paper provides an interesting contribution and I am looking forward to seeing the full description of the different Bayesian models and their robustness advertised at the end of the paper.', 'rating': '7: Good paper, accept', 'confidence': '2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_khn9'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_khn9']}, {'id': 'SV3lXBvmKz9', 'original': None, 'number': 2, 'cdate': 1648076602532, 'mdate': 1648076602532, 'ddate': None, 'tcdate': 1648076602532, 'tmdate': 1648076602532, 'tddate': None, 'forum': 'ruuMvmFeIb5', 'replyto': 'ruuMvmFeIb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper17/-/Official_Review', 'content': {'title': 'A Bayesian analysis of a neurolinguistic EEG study', 'review': 'This submission describes a Bayesian analysis of frequency-tagged EEG experiments, a type of experimental paradigm used in neurolinguistics research. The analysis is meant to serve as an alternative to a traditional frequentist analysis from prior works, which averages over electrodes and items instead of explicitly accounting for associated variance.\n\nMain contributions of the work:\n1.\tA discussion of a Bayesian EEG analysis as an alternative to frequentist methods\n2.\tAn attempt to explicitly model item and participant effects\n3.\tA nuanced discussion of Bayesian priors required to model inter-trial phase coherence (ITPC) effects\n\nQuestions and clarifications:\n1.\tThe authors pitch the need to model item and participant effects as the main incentive for switching to Bayesian analysis. However, there is a frequentist approach that achieves the same effect — mixed effects modeling. Mixed effects models have been gaining popularity for EEG analyses, including analyses of ITPC (see e.g. Koerner & Zhang, 2017). Of course, this doesn’t mean that the Bayesian analysis has no value, but I would recommend the authors to adjust their motivating arguments (and possibly mention mixed effects models as a frequentist alternative)\n2.\tDifferential effects across electrodes/participants. The authors correctly state that averaging the data across electrodes and participants “washes out” effects of interest that vary across them. However, their analysis doesn’t quite seem to address this issue: the effect of condition is modeled to be the same across all electrodes and participants if I understand it correctly. Thus, while modeling the variance in participant-, electrode-, and condition-specific averages is certainly a step forward, differential effects across participants and electrodes remain unaccounted for in this model.\n3.\tHow much data are required for the proposed analysis? It might be helpful to have a brief discussion of guidelines for determining whether the number of, e.g., item repetitions across participants is sufficient to fit the model. \n4.\tIn eqs. 7 and 8, does alpha without a subscript correspond to the baseline value shared across participants, electrodes and conditions? The current wording is a bit ambiguous on that point.\n5.\tThe justification for using the log-logistic link function to model gamma is unclear to me (an outsider to this subfield). We don’t need to know the specifics but a one-line explanation or a reference would help.\n\n\nMinor:\n-\tTo better advertise the analysis for scientists used to frequentist methods, it might be useful to include Bayesian factor as a more direct alternative to frequentist hypothesis testing\n-\tIn Figure 3, you might want to highlight the key conditions of interest\n\nOverall, this is an interesting contribution to the field of EEG data analysis, with clear applications in the domain of neurolinguistics.\n', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_vD5a'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_vD5a']}, {'id': 'HbNxNl3OJfc', 'original': None, 'number': 1, 'cdate': 1647442923613, 'mdate': 1647442923613, 'ddate': None, 'tcdate': 1647442923613, 'tmdate': 1647442923613, 'tddate': None, 'forum': 'ruuMvmFeIb5', 'replyto': 'ruuMvmFeIb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper17/-/Official_Review', 'content': {'title': 'a nice methodological note regarding a previous analysis', 'review': ""This would make a nice poster at CMCL. It simply lays out a Bayesian version of Frequentist analysis that was used in a published paper last year. Although there is no cognitive modeling per se, the method itself will be interesting to a variety of CMCL attendee. There is probably *not* enough here for an article in a journal like _Bayesian Analysis_ so it's appropriate that we offer a venue in which to share this work."", 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_Pgx7'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_Pgx7']}]"
https://openreview.net/forum?id=H__evmFlUZ9 ,H__evmFlUZ9,"[{'id': 'r42lKWqKsM5', 'original': None, 'number': 3, 'cdate': 1648232961289, 'mdate': 1648232961289, 'ddate': None, 'tcdate': 1648232961289, 'tmdate': 1648232961289, 'tddate': None, 'forum': 'H__evmFlUZ9', 'replyto': 'H__evmFlUZ9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper16/-/Official_Review', 'content': {'title': 'Learning non-local alternations via tier creation', 'review': 'The authors propose a model for learning non-local phonological alternations via the creation of feature tiers. The work sits at the intersection of tier-based analyses of phonotactic computational complexity (Heinz et al) and artifical grammar learning (AGL) experiments on learning of local and nonlocal phonological processes. The submission is as an extended abstract.\n\nThe authors provide pseudocode for the functioning of the model, walk the reader through an example of its functioning on some data, and discuss its relevance to human performance on previous AGL experiments. They also compare the model\'s performance against those of competing HMM and FSM based models.\n\nThe authors make a number of claims that require non-trivial support e.g. (i) that learning non-local is harder than local, which may be true in AGL scenarios but this says little or nothing about natural language acquisition scenarios, or (ii) claims from model learning results that human learners construct tiers.\n\nThere is a fair amount of unclarity in the formalism and notation: it feels like much of this could have been eliminated from this submission but would benefit a subsequent lengthier submission where there is more room for definitions and examples.\n\nSome specific notes:\n- opening discussion of English plural morph refers to it as a phonological segment (omitting discussion of the [-Id] realization)\n- the composition of V should be clarified in line 94 (i.e. input-output pairs of what; this is unclear from context)\n- if segments are treated as bundles of features (line 117) then it\'s not clear why segments continue to be referred to\n- it\'s not clear how the final tier is written back to the final output form; the tier projection operation as described seems to be lossy (the ""final sequence"" in lines 135-137 appears to only be the final tier representation)\n- the input V (set of input-output pairs) to Algorithm 1 appears to not be used/referenced anywhere in the algorithm\n- the notion of ""accuracy"" referenced on line 148 and in Algorithm 1 is not clear; accuracy at what?\n- the work is reminiscent of the search/copy approach (Samuels, Nevins, Reiss/Mailhot) to phonological operations (including the observation that strict locality is merely a special case of non-locality), only with unnecessary notational baggage and it\'s not clear what it\'s benefit is\n\nNotwithstanding all of the above, the paper is a promising start to work that could eventually make contact with the tier-based formal work from the Stony Brook group providing some linking hypotheses across Marrian levels of phonology. It would benefit from being presented and critiqued and I\'d like to see it accepted and presented.', 'rating': '7: Good paper, accept', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_ztMY'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_ztMY']}, {'id': 'r6wga0xrizc', 'original': None, 'number': 2, 'cdate': 1648214228875, 'mdate': 1648214228875, 'ddate': None, 'tcdate': 1648214228875, 'tmdate': 1648214228875, 'tddate': None, 'forum': 'H__evmFlUZ9', 'replyto': 'H__evmFlUZ9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper16/-/Official_Review', 'content': {'title': 'Interesting but the model could benefit from more phonological knowledge?', 'review': ""This paper reports a model that learns distant phonological alternations. The results of the model are overall comparable to human learners' performance. I think the paper is quite interesting, but to be honest I'm not sure what would be the application of this model. In natural language, non-local alternations are often conditioned by the phonological context (e.g., assimilation, which is the case in the real-language examples cited in this paper). The current model doesn't seem to have phonological knowledge. I'm curious to know what would be the next step of this project. Is the goal to simulate human learners?"", 'rating': '6: Marginally above acceptance threshold', 'confidence': ""1: The reviewer's evaluation is an educated guess""}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_pZXL'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_pZXL']}, {'id': 'HYbgbbq38z9', 'original': None, 'number': 1, 'cdate': 1647917560607, 'mdate': 1647917560607, 'ddate': None, 'tcdate': 1647917560607, 'tmdate': 1647917560607, 'tddate': None, 'forum': 'H__evmFlUZ9', 'replyto': 'H__evmFlUZ9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper16/-/Official_Review', 'content': {'title': 'Learning Non-Local Phonological Alternations via Automatic Creation of Tiers', 'review': 'The article presents a computational model for dealing with phonological alternations. It presents a cognitive argument for why this is interesting, but could also use a computational argument for why this is interesting, i.e., how might this model be used? Overall it is very well written and easy to understand. The only problems I had with the article were about formatting:\n\n1. Place Figures and Tables below the paragraphs that you first mention them in. For instance, Figure 1 is on the first page but not mentioned until the second, while Table 2 is before the paragraph starting on line 271.\n2. As far as I know (although if I\'m wrong please ignore this), the symbol, ""§"", is not required of you to use. I was quite confused about what it was supposed to mean and you don\'t use it consistently. For a while I thought you were trying to use a symbol for the word \'Figure\'. After clicking on it I grasped that you\'re using it to mark the presence of a footnote, but then later you also use it to denote a section in the main text. \nIn terms of footnotes, seeing as the citations are spelled out, i.e., not superscripted, there\'s no reason to use a confusing symbol that takes up space. I recommend you use superscripts for footnotes and delete the ""§"" (as you did on line 267). That\'s my first opinion. My second opinion is that you can do without footnotes entirely. You don\'t say anything that can\'t be added to the main text or left out. For instance, footnote 1 is there just to tell you that in 3.1.1 there is more info... You don\'t need a footnote for that. I would even say that footnote 2 is something that should be in the main text as its an important detail. \nIn terms of using the ""§"" symbol to denote sections in the main text... I suppose the question would be ""why?"" Does it facilitate reading? On line 153, does it make reading easier to tell the reader they can find out more in the section that immediately follows? My first opinion is that you get rid of these as I don\'t understand what purpose they serve. My second opinion is that if you really want to keep them then you need to follow writing logic and put them in parentheticals because they do not belong within the syntax of the sentences you are placing them in. You did this correctly on line 211.\n\nBelow are some minor writing mistakes\n1. line 028: \'phonological environments\'\n2. line 072: \'a phonological tier is a representation\', or \'phonological tiers are representations\'\n3. line 102: \'process\'\n4. line 112, \'a local rule, 𝑟adj, applied\'\n5. line 228: \'the one that scored higher\'\n6. line 239: \'over the non-harmonizing choice\'\n7. line 246 and 247: \'and consequently could not generalize from the training data to test instances even when humans did\'\n8. line 258: \'All vowels that participate\'\n9. line 273 and 274: \'consisting of 200 training words and 800 novel words\'\n10. line 275: \'D2L learned\'', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_tYg5'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_tYg5']}]"
https://openreview.net/forum?id=r4exumYxLWq ,r4exumYxLWq,"[{'id': 'SExgWGEWqMq', 'original': None, 'number': 3, 'cdate': 1648133128663, 'mdate': 1648133128663, 'ddate': None, 'tcdate': 1648133128663, 'tmdate': 1648133128663, 'tddate': None, 'forum': 'r4exumYxLWq', 'replyto': 'r4exumYxLWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper25/-/Official_Review', 'content': {'title': 'Interesting work', 'review': 'This work uses a transformer model to investigate learning the past tense from child-directed speech. The study focuses on whether the model variants can exploit information from morphology, auxiliaries, or temporal adverbs.\n\nI found the study very interesting and relevant, and a very good fit for this venue.\n\nThere are a number of points that could be improved. The nonce test is definitely relevant, but it is based on a very small number of items. I also found the paper could do a better job at situating the results.  It is unclear to me what we learn from comparing the 3 tokenizers. I also missed some reflection on what the results entail for language acquisition.The authors almost apologetically mention that the model is not cognitively plausible, but I think that is not necessarily a downside: these are conclusions from a data-driven model, which are relevant to gather insight on which linguistic information can be exploited. Some discussion on this would make the paper stronger.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_R9j9'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_R9j9']}, {'id': 'BAM-OWRsdf9', 'original': None, 'number': 2, 'cdate': 1648045568462, 'mdate': 1648045568462, 'ddate': None, 'tcdate': 1648045568462, 'tmdate': 1648045568462, 'tddate': None, 'forum': 'r4exumYxLWq', 'replyto': 'r4exumYxLWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper25/-/Official_Review', 'content': {'title': 'English tense information is mostly carried by auxiliaries in child-directed speech', 'review': 'This paper describes a simulation study in learning to predict tense from CDS sentences from the Adam corpus. The model uses auxiliaries and the past suffix -ed to detect tense, but does not learn morphologically irregular past tenses nor the periphrastic future ""going to"". These effects are linked to trends in input frequency as well as analyses from the human learning literature.\n\nI found the paper very interesting in its focus on language acquisition of an important semantic distinction and in linking explicitly to work on human learning. I also appreciated the use of nonce verbs and various probing techniques in analyzing the reuslts.\n\nI did have some problems in following the argumentation.\n\n1: Line 63 says ""the other hypothesis is that temporal adverbs could facilitate"" the learning of tense. But I don\'t see where this hypothesis comes from. The cited research on the following lines suggests that children don\'t pay much attention to temporal adverbs. So whose hypothesis is this and why is it worth studying?\n\n2: I am a bit confused about the model setup. My understanding is that the model is a 2-layer transformer without any pretraining (section 4.1) and that only the tokenizers are adopted from pretrained LMs (section 4.2). Table 2 shows the training data sizes of three models, Roberta, BabyBerta and 2y/o BabyBerta and also their number of parameters (which should be irrelevant if no pretraining is used). I think these pretrained models are used only to create the tokenizers, not the model itself. However, I am not perfectly clear on this point, especially because later tables 3 and 5 report performance by ""Model"" ranging across Roberta, BabyBerta and 2y/o. \n\n3: Following from this, if no pretraining is used, I am not sure why this decision was made. Pretraining followed by fine-tuning is known to learn more robust semantic representations than just learning to classify and would potentially do a better job of extracting the lexical semantics of irregular verbs based on their distribution. Why train a new transformer from scratch instead of using BabyBerta itself as a model and adding a classifier layer on top of it?\n\n4: Although the three tokenizers are compared throughout, there is no clear conclusion about the differences between them; I am not sure in the end why this comparison is important.', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_71ka'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_71ka']}, {'id': 'HLXxJbntdG9', 'original': None, 'number': 1, 'cdate': 1648036854869, 'mdate': 1648036854869, 'ddate': None, 'tcdate': 1648036854869, 'tmdate': 1648036854869, 'tddate': None, 'forum': 'r4exumYxLWq', 'replyto': 'r4exumYxLWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper25/-/Official_Review', 'content': {'title': 'Some good ideas, but not sure about the point', 'review': 'This paper asks whether linguistic input alone (i.e., without situational context) is sufficient for acquiring English tense. They hypothesize that it is, and test with three related transformer models, RoBERTa, which uses BPE to capture sub-word information, BabyBERTa, which is trained on English CHILDES, and a 2yo-BabyBERTa trained on a fraction of CHILDES. They conclude that there results support the hypothesis.\n\nI like that the authors trained on CHILDES and used BabyBERTa. The recognize that RoBERTa, which trained on orders of magnitude more data than a learner would receive by age 2-3 may overachieve for that reason. 2yo-BabyBERTa seems unecessary to me. BabyBERTa was trained on 5M words, but that\'s just a large fraction of what an individual learner would hear. It seems unnecessary to restrict it further.\n\nI\'m worried about the posibility of test-on-train here. Isn\'t 5M words pretty much all of English CHILDES? Can the authors be sure that BabyBERTa (or even RoBERTa? I don\'t know) weren\'t trained on the subset of CHILDES that they\'re testing on?\n\nThe authors report results on a held out (but see above) test set and a set of sentences with nonce verbs. They find very good (.90-.92 accuracy) on the held out set, and middling performance (0.48-0.59) on the nonce set.\n\nI don\'t believe the author\'s conclusion is motivated for two reasons:\n\nFirst, they argue based on the results on the held-out test set, that since the transformers learn to distinguish tenses well, that this shows that language input alone is sufficient. However, they could\'ve come to the opposite conclusion based on the nonce study. A contrarian could easily conclude language alone is insufficient.\n\nSecond, and I think more profoundly, is that there\'s no particular reason to believe that transformers are good models of human learning. The authors rightly acknowledge this: ""Although the transformer models do not represent children’s acquisition mechanisms, we hope this study could provide some insight in understanding the acquisition process of tense.""\n\nSo we can\'t conclude anything about acquisition from this study, other than, perhaps, that training on a big chunk of CHILDES works almost as well as training on 30B tokens of miscellaneous text for this purpose.', 'rating': '4: Ok but not good enough - rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_UzZu'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_UzZu']}]"
https://openreview.net/forum?id=H_u4_mYxL-c ,H_u4_mYxL-c,"[{'id': 'BCelhH5NAMc', 'original': None, 'number': 3, 'cdate': 1648409156313, 'mdate': None, 'ddate': None, 'tcdate': 1648409156313, 'tmdate': 1648409301049, 'tddate': None, 'forum': 'H_u4_mYxL-c', 'replyto': 'H_u4_mYxL-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper24/-/Official_Review', 'content': {'title': 'Difficult to confirm the conclusions since key details of the model setup and evaluation are missing', 'review': 'This paper proposes a cue-based retrieval model for a really interesting pronoun resolution phenomenon in German: The distinction in reference preferences between personal vs. demonstrative pronouns, depending on different aspects contributing to a referent’s saliency. Contributing factors to a referent’s saliency that are considered include subjecthood, agenthood and order of mention, which are fleshed out in terms of (weighted) cue prominence in the new models proposed. The authors show that a model with these additional weighted prominence cues is able to account for key empirical patterns in human data found by Schumacher et al. (2006), as defined in Effects 1-3 in the paper.\n\n**General**\n\nThe paper is well-written and provides a great overview of the phenomenon of interest and motivation for the modeling work that is its main contribution. The models seem (mostly) straightforward; however, key information about the model and evaluation methodology and are omitted, which leave the conclusions the authors want to draw unwarranted (for now).\n\n**Specific questions/Comments**\n\n* A key component missing in the paper is a well-defined model evaluation metric. For example, looking at Table 2, we see that Models 2 & 3a severely overestimate condition a., underestimate b., and are about in the right ballpark for conditions c. & d. Yet, Model 3a is claimed to capture the relevant variance in the human data. What are the variances for the conditions in the human data? What is the variance in the model results? Do they align? The way it reads now is a qualitative comparison of proportions where an Effect is captured if the target referent is chosen more than 50% of the times, disregarding differences in preferences between conditions in the human data, which seems unsatisfactory.\n* Relatedly, is there a particular reason why there is no effect described that relates to the AA-NC condition? The baseline model seems to be closest, quantitatively & qualitatively speaking, to the human data here, whereas both other models underestimate the proportion. So *is* the baseline model capturing some crucial variance in the data that the other models are not?\n\n* Again relatedly, is a unanimous preference for the second referent expected for the baseline model given that the retrieval cues are always consistent with both referents (provided I understand this correctly)? Shouldn’t the model perform at chance? Clarifying the model description and training regime would be helpful for this I believe.\n* “In the modified model we weighted the retrieval cue of thematic role 1.5 times higher than other cues used to retrieve the antecedent”. Is it true that the thematic role cue is weighted 1.5 times higher than the baseline model cues as well, or only higher than other prominence-inducing cues (grammatical role/ order of mention)? The former seems counter-intuitive as grammatical features should provide a stronger bias for pronoun resolution than thematic roles. If my interpretation is correct, it would be good to add empirical evidence for this effect, as I don’t think this is concluded by Schumacher et al. (2016), which is their reference.\n\n**Thoughts regarding future extensions to the modeling work (do not need to be included in the paper!)**\n\n* As it stands the paper assumes a complementary distribution between personal pronouns *er/sie/es* and demonstrative pronouns *der/die/das*. I wonder how other demonstrative pronouns like *dieser, jener, derjenige* will figure into this constellation?\n* Furthermore, given the way in which the models for PPros and DPros are set up, I wonder how this approach will extend to contexts in which there are more than two referents in the context? (cf. Patterson & Schumacher 2021)\n\n**Minor**\n\n* For reader orientation, it would be good to spell out the critical effects in terms of predictions that clearly relate to the human data in Table 2. I.e., Effect 1: P(first referent|AA-CA, PPro) > P(second referent|AA-CA, PPro)\n\nOverall, this paper takes a cool approach to modeling an interesting phenomenon, but given the lack of detail in the model description and evaluation, the conclusions it draws do not seem sufficiently supported.', 'rating': '4: Ok but not good enough - rejection', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_ahUb'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_ahUb']}, {'id': 'Sgl6tAzAMq', 'original': None, 'number': 2, 'cdate': 1648402053071, 'mdate': 1648402053071, 'ddate': None, 'tcdate': 1648402053071, 'tmdate': 1648402053071, 'tddate': None, 'forum': 'H_u4_mYxL-c', 'replyto': 'H_u4_mYxL-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper24/-/Official_Review', 'content': {'title': 'Some critical details missing in the current submission', 'review': '\nThe paper describes an approach to model personal and demonstrating pronoun resolution using the ACT-R cue-based theory. The authors compare the baseline model with 3 models that differ in terms of use of prominence features (thematic role, grammatical role, order of mention) as retrieval cues and weights assigned to these cues. The results show that the models with weighted cues perform best in capturing pronoun resolution patterns found in the human data. The model for the personal pronoun resolution captures all the 3 effects, while the model for the demonstrative pronoun resolution captures 2 out of 3 effects. The weighted cues model outperforms the baseline and prominence (but no weights) models.\n\nI found the paper to be well motivated as well as well written. However one key issue with the paper is that the claims are unsubstantiated, i.e., not enough details are provided regarding the methodology and evaluation. For example, we don\'t know if the difference in percentages found in the human data significantly different? Similarly, the authors claim that the models 2 and 3a/3b are able to capture various effects, e.g., ""The model captured Effect-1 and Effect-2 for the PPro: ..."" what is the basis of saying this? Is it based on the fact that the differences in the percentages found in the human data and the models are qualitatively similar or was there some objective way of testing this similarity? On similar lines, the authors state that ""Model predictions are generated by running 10000 simulations for each model"" and ""The antecedent preferences of the model are determined by calculating proportions of referents retrieved across all simulations"". This evaluation criterion is not backed by a rationale, for example, to make the prediction of the model more comparable with the experiment, shouldn\'t the model be evaluated on the same number of items that the humans were exposed to? and then to take correct proportion of PPro/DPro from them? \n\nIn sum, this is a good work, but I am unable to evaluate it with confidence given the lack of information regarding some critical issues related to methodology and evaluation.\n\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_SofH'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_SofH']}, {'id': 'BY8xoGa23f9', 'original': None, 'number': 1, 'cdate': 1648311570843, 'mdate': 1648311570843, 'ddate': None, 'tcdate': 1648311570843, 'tmdate': 1648311570843, 'tddate': None, 'forum': 'H_u4_mYxL-c', 'replyto': 'H_u4_mYxL-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper24/-/Official_Review', 'content': {'title': 'It is difficult to find clear evidences from this short paper supporting the initial claim. ', 'review': 'This paper addresses the question of pronoun reference focusing on personal and demonstrative pronouns in German. It proposes different models and study more specifically the question of prominence, showing the interest in adding this constraint in predictive model. The paper addresses an interesting question and proposes different models for studying the problem. However, it suffers from lack of details  in the description of the models, the  evaluation of the results and the discussion. It is difficult to find clear evidences from this short paper supporting the initial claim. ', 'rating': '4: Ok but not good enough - rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_oGD6'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_oGD6']}]"
https://openreview.net/forum?id=ruOUP7FxLbc ,ruOUP7FxLbc,"[{'id': 'SzMg8YXrjzq', 'original': None, 'number': 3, 'cdate': 1648214909932, 'mdate': 1648214909932, 'ddate': None, 'tcdate': 1648214909932, 'tmdate': 1648214909932, 'tddate': None, 'forum': 'ruOUP7FxLbc', 'replyto': 'ruOUP7FxLbc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper21/-/Official_Review', 'content': {'title': 'Good paper but I wish there were more explanations about the goal', 'review': ""This paper explores the effectiveness of a small RNN when learning a phenomenon of vowel harmony. I guess it's assumed that if a smaller neural network could do the job as well as a larger model, the smaller model is a better choice than the larger one. But still, I wish the authors had explained in more concrete terms what are the benefits of a small RNN. Also, the current phenomenon under investigation is vowel harmony. Would the model results be very different if it is working on a different phenomenon of complex pattern recognition? Is the design of the current model informed by morphophonological conditions of vowel harmony in any way?"", 'rating': '6: Marginally above acceptance threshold', 'confidence': ""1: The reviewer's evaluation is an educated guess""}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_8gan'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_8gan']}, {'id': 'r9IxZwMqabq', 'original': None, 'number': 2, 'cdate': 1647317592993, 'mdate': 1647317592993, 'ddate': None, 'tcdate': 1647317592993, 'tmdate': 1647317592993, 'tddate': None, 'forum': 'ruOUP7FxLbc', 'replyto': 'ruOUP7FxLbc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper21/-/Official_Review', 'content': {'title': 'Nice paper on an understudied phenomenon, but lots of morphophonological assumptions are implicitly built into the model', 'review': ""Seems like a nice and well-motivated study, and I appreciate the authors' effort to look into modeling a linguistic phenomenon that is relatively understudied despite being typologically common.\n\nI am a bit unsure what to make of the claims about the model doing well based on a small RNN, because no matter how small you make the model, there is still a lot of morphophonological knowledge implicitly built in to the very assumptions of the model (e.g. Marantz, 2013 [doi: 10.1080/01690965.2013.779385])."", 'rating': '6: Marginally above acceptance threshold', 'confidence': ""1: The reviewer's evaluation is an educated guess""}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_XYm7'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_XYm7']}, {'id': 'HlxubaytWc', 'original': None, 'number': 1, 'cdate': 1647013120333, 'mdate': 1647013120333, 'ddate': None, 'tcdate': 1647013120333, 'tmdate': 1647013120333, 'tddate': None, 'forum': 'ruOUP7FxLbc', 'replyto': 'ruOUP7FxLbc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper21/-/Official_Review', 'content': {'title': 'Promising first exploratory step', 'review': ""The authors explore whether small-scale neural networks learn vowel harmony. I am not familiar with the precise literature on modeling phonology using deep learning (so I cannot evaluate the novelty), but the task is straightforward and the phenomenon/task is simple.\n\nI believe this is a nice first exploratory step. For this effort to contribute to the literature, more work needs to be done.\n\n-The authors use a relatively large RNN model originally designed to account for past-tense morphology and scale it down to learn vowel harmony. I don't think we can draw a conclusion from this work as we are comparing apples and oranges.\n\n-The authors show that a model can map some lemmas to their inflections, it's not clear to me what cognitive insight we get from these results? Is the idea to show that humans (babies) learn vowel harmony from distributional information? in which case, does the model reproduce some patterns in children's development?\n\n-There is no quantitative test of vowel harmony, no comparison to previous work?\n\n-The authors select two languages from SIG-MORPHON Shared Task without justifying why these two languages? is it because of their morphological complexity or their typological difference? How does the model behave in the other languages? It is a very simple task and more data is available (about 100 languages in the SIG-MORPHON Shared Task), and I don't see a reason why limit the study to two languages?\n\n-The authors should do a thorough/quantitative investigation of separation between front and back vowels (because that's the latent representation of interest) and not just a qualitative visualization. Also, strangely, the authors do not show results in Turkish to verify if the latent separation exists in Turkish as well.\n\n-No abstract?"", 'rating': '5: Marginally below acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_A28a'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_A28a']}]"
https://openreview.net/forum?id=BMMeDmKg8Zc ,BMMeDmKg8Zc,"[{'id': 'rCelwiw1J7c', 'original': None, 'number': 3, 'cdate': 1648453534883, 'mdate': 1648453534883, 'ddate': None, 'tcdate': 1648453534883, 'tmdate': 1648453534883, 'tddate': None, 'forum': 'BMMeDmKg8Zc', 'replyto': 'BMMeDmKg8Zc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper15/-/Official_Review', 'content': {'title': 'Hard to identify the main messages the authors want to convey', 'review': 'There\'s something potentially of interest here but this version of the paper feels very disjointed. It is hard to identify the key thread of ideas that the authors intend to be the main take-home message, and it is hard to understand the logical links between various sections of the paper.\n\nPerhaps the key concrete point that I can identify is that classifiers tend to change from narrowly-applicable to more general over historical time, and the model presented in section 4 correctly recreates this effect. This is the most meaningful common thread I can find running through the paper. The empirical point about the historical change is buried in the middle of section 2 (lines 174-183) in amongst discussion of all sorts of other things, and the fact that the simulations recreate this pattern is mentioned (lines 468-473) as one of three findings in section 4.2. (Even this would be clearer if the authors explicitly mentioned that more features means more specific. And at line 460, it should be stated explicitly that the graphs show the average number of features *per classifier*.) In between, there\'s very little to help the reader connect the dots: for example, the intro to section 4 says nothing about what kind of patterns the authors are hoping to recreate (only that they will ""investigate the dynamics of classifier systems over time"").\n\nThe logic of the relationship between section 3 and section 4 seems muddled. In section 3 itself, the corpus study is presented as evidence *against* the non-neutral, ambiguity-avoidance hypothesis, and this is presented as justification for adopting a model without functional pressures in section 4. But the abstract, for example, says that ""acquisition without reference to ambiguity avoidance is *sufficient* to drive broad trends"", which makes it sound like the paper will be treating the neutral hypothesis as the simpler/null hypothesis and showing that additional assumptions (i.e. non-neutrality) are unnecessary. So there\'s a confusing inconsistency in the way the authors talk about which hypothesis (neutral or non-neutral) is the one that makes ""additional assumptions"".\n\nThere\'s a lot of material in section 2 which seems to be irrelevant: differences between classifiers and noun classes, age at which children exhibit competent use, semantic vs. arbitrary. All of this leaves the reader thinking that maybe some of these empirical facts will be things that the authors end up offering an explanation for, but as far as I can tell most of it plays no role. This includes the fact that the timecourse of a single child\'s acquisition demonstrates a move towards over-use of general classifiers; I don\'t understand how the simulations have any connection to that. (I\'m still confused after lines 532-536.)\n\nIn section 3, I think I understand the important take-home message of the corpus study itself, but the presentation is somewhat confusing at times.\n\t- The logic at lines 244-248 seems slightly wrong. The preceding paragraph already established a candidate cause of greater homophony in Mandarin than Cantonese. Given this, if it\'s *also* true that homophony avoidance drives change, then we\'d expect more classifier disambiguation in Mandarin than in Cantonese. The phrasing in the paper seems to suggest that the homophony avoidance hypothesis plays a part in predicting the increased ambiguity in Mandarin.\n\t- As far as I can tell, the terms ""homophony"" and ""ambiguity"" are used more or less interchangeably. This isn\'t necessarily incorrect, but the logic could be clearer if the authors stuck to just one term.\n\t- Similarly, the phrase ""homophony avoidance"" is somewhat confusing. As defined by the authors (line 266), the degree of homophony is just determined by the particular collection of form-transcription pairs that occur in the corpus. (It might also help to note that the transcription effectively determines the pronunciation.) So there\'s no way for classifier usage to ""avoid"" homophony. So something like ""homophony mitigation"" or ""homophony circumvention"" would be better than ""homophony avoidance"". (Perhaps the authors intended to distinguish between *homophony* and *ambiguity avoidance*, which would make sense, but the usage doesn\'t seem to be consistently in line with that.)\n\t- It might help to mention that matching on types means matching on *character* types, not *transcription* types.\n\t- In Table 1, why is the number of types for Mandarin_type not exactly 1182?\n\nIt\'s (mostly) unclear what the authors really want the reader to take away from the presentation of the results in section 4. They mention three findings (lines 456), but only one is clear the me: the one about moving towards generality, in the paragraph beginning at line 464. The second finding is something about the fact that the simulations tend to reach steady states (476-488), but I can\'t find any mention of what empirical point this is intended to align with. The last paragraph (489-501) seems to be framed as the third finding, but again this just seems to be a report of how certain simulations turned out, rather than an identifiable trend that meaningful aligns with an empirical target. A few lines later this is all just summarized as ""provides insight into the long-term dynamics of classifier systems"" (507), but the authors don\'t even seem to be trying to express what that insight is.\n\nThe opposition between ""input"" and ""functional factors"" (line 219) seems like a category error to me. Certainly there is always a tension between the input and generalization in any form of learning; but then the question of what role functional factors play is a question about the nature of the generalization that occurs, not the balance between input and generalization. I had a similar reaction around lines 506: would a proponent of functional pressures say that their account is not ""acquisition-driven""? The idea that acquisition drives change (which is virtually a truism) seems orthogonal to the question about functional pressures.', 'rating': '4: Ok but not good enough - rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_eXxh'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_eXxh']}, {'id': 'HqUli4lv0G5', 'original': None, 'number': 2, 'cdate': 1648418867356, 'mdate': 1648418867356, 'ddate': None, 'tcdate': 1648418867356, 'tmdate': 1648418867356, 'tddate': None, 'forum': 'BMMeDmKg8Zc', 'replyto': 'BMMeDmKg8Zc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper15/-/Official_Review', 'content': {'title': 'Analyzing and simulating the acquisition of noun classifiers over generations', 'review': ""This paper analyzes classifier systems that categorize nouns in Mandarin and Cantonese child-directed speech and in light of the findings of this analysis, proposes a population-based model of classifier acquisition and change over time. Models with various setups produce classifiers that are more generalized with fewer features as the simulation progresses, seeming to indicate a neutral learning scheme based on inputs rather than functional factors.\n\n**Pros**\n\nThe authors explore various setups of simulations and an interesting set of results are reported, providing insightful information regarding possible theories of the evolution of classifiers.\n\nThe authors motivate their population-based transmission simulation with findings from the analysis of actual human data and also relevant developmental literature, focusing on neutral learning from input.\n\nThe simulation results point to an inclination toward the production of generalized classifiers, seeming to confirm the authors’ motivation behind the implementation of these models.\n\n**Cons**\n\nI was confused by the significance findings reported in footnote 2. Even though for the types, the difference is insignificant, for the tokens, Mandarin has more disambiguated homophones. Then, in Section 5, it is written that Mandarin classifiers disambiguate homophones significantly less often, which I thought was more in line with what was reported in Table 1. It would be nice if the authors clarify what numbers were exactly being contrasted in these tests to provide a stronger motivation for their choice of simulation model. \n\nThe simulation models seem to be rather independent of the child-directed speech data, apart from the idea of neutral learning. It would be informative to contrast these models with a model that follows functional objectives or models that include noun attributes and classifier features akin to the ones observed in real human data. \n\n**Writing**\n\n004 amiguity -> ambiguity\n\n031 Remove 'encode'\n\n032 concretely -> concreteness (?)\n\n063 'during the' repeated\n\n105 are -> our (?)\n\n119 is -> has\n\n130 concretely -> concreteness (?)\n\n286 'the' repeated\n\n604 variability\n"", 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_8g4d'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_8g4d']}, {'id': 'SxlmRGd3zc', 'original': None, 'number': 1, 'cdate': 1648292554659, 'mdate': 1648292554659, 'ddate': None, 'tcdate': 1648292554659, 'tmdate': 1648292554659, 'tddate': None, 'forum': 'BMMeDmKg8Zc', 'replyto': 'BMMeDmKg8Zc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper15/-/Official_Review', 'content': {'title': 'An interesting study on modeling the acquisition of classifier systems, though not so much on modeling language change.', 'review': 'This paper shows two sets of experiments in an attempt to explicitly model change in classifier systems as some outcome of child language acquisition. The topic is interesting, and the paper includes several interesting ideas, and has great suggestions about future work. However, there are some parts that are not clear to me. While it assumes that language acquisition may drive trends in classifier patterns over time, what the changes are have not been clearly defined. For example, in the introduction, the authors mentioned the replacement of the general classifier \'mei\' with the currently more dominantly-used \'ge\' over time; while this indeed is an interesting point of inquiry, the studies presented in the paper were not able to address this type of change. Alos, is adults\' using more specific classifiers while dropping the general classifiers considered ""a change""? If yes, this point should be elaborated. The authors mentioned that such selections may be related to discourses, or due to sociolinguistic factors, but the experiment results only show that children tend to acquire the (old or new) uses of classifiers presented by adults, and then stabilize the use of them, and therefore although I agree with the authors that the results support the trends of learning and neutral processes, they do not seem to be related to language change. \n\nBelow are some minor suggestions about the organization and the contents. \n1. Introduction: Need to reconsider what role the example of \'mei\'-\'ge\' plays in the paper.\n2. Section 2 can directly highlight how similar classifier systems and inflectional agreement systems are in terms of modeling, and then elaborate how the classifier system can be modeled. Currently, the first half of the section suggests the otherwise (i.e., they are very different grammatical properties).\n3. The differences between classifiers and measure words do not seem to be relevant to the current study. Maybe using classifiers as a cover term would be enough.\n4. Mandarin \'ge\' although is a general classifier, it functions as an individualizer (i.e., its function is to pick out one individual entity in particular); the description of it at the beginning of the paper is a bit misleading. ', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_t543'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_t543']}]"
https://openreview.net/forum?id=B_OII7tlIZ5 ,B_OII7tlIZ5,"[{'id': 'rclDhfW2zq', 'original': None, 'number': 3, 'cdate': 1648263854762, 'mdate': 1648263854762, 'ddate': None, 'tcdate': 1648263854762, 'tmdate': 1648263854762, 'tddate': None, 'forum': 'B_OII7tlIZ5', 'replyto': 'B_OII7tlIZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper14/-/Official_Review', 'content': {'title': 'Neural language models predict hireability', 'review': 'This paper reports an investigation of how neural language models can be used to judge a candidate\'s ""hireability"" and other traits from transcripts of job interviews and writing samples (E1) and prosodic information (E2). They find that embeddings derived from linguistic information alone can outperform the feature-engineered baseline model from previous work which included features for prosody, eye movements, etc. Adding prosodic features results in some performance improvement, but not for the model which already had the highest correlation with human ratings on its own (word2vec).\n\nOVERALL\n\nThis is an interesting set of studies, however, I\'m not sure that CMCL is the best venue for it. The primary take-away seems to be that neural language models could be used to aid in the process of evaluating candidates, but it\'s not at all clear what the cognitive/linguistic implications are. If the goal is primarily application, the authors should discuss the important limitations of using these kinds of algorithms to make decisions that impact people\'s lives, given the well-known biases that they tend to reflect. If the goal is to draw some conclusions about cognition, the link needs to be made much more clear in the framing. \n\n\nMINOR \n\nThe main conclusion suggests that NLMs can be useful for candidate trait evaluation but in fact the evidence presented here only shows that the 4 models highlighted in the main text provide any advantage. It\'s unclear how many of the model variants actually outperform the baseline. It appears that only a few best-performing ones are statistically compared to the baseline, so the conclusion becomes even more narrow. Again, this would be fine if the goals are about engineering a model that predicts well but unclear what to make of this in terms of cognitive interpretations.\n\nIt seems like the choice to only use prosody in addition to embeddings could be better motivated. I am not familiar with the original work (Naim et al., 2018) but it seems like the lack of performance improvement due to facial features in those models doesn\'t preclude that they could explain meaningful variance in the current models, when paired with a different set of predictors.\n', 'rating': '4: Ok but not good enough - rejection', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_WANP'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_WANP']}, {'id': 'HVeeTjFVsG5', 'original': None, 'number': 2, 'cdate': 1648212388659, 'mdate': 1648212388659, 'ddate': None, 'tcdate': 1648212388659, 'tmdate': 1648212388659, 'tddate': None, 'forum': 'B_OII7tlIZ5', 'replyto': 'B_OII7tlIZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper14/-/Official_Review', 'content': {'title': 'Predicting hireability from interview transcripts', 'review': ""The authors set out to demonstrate that behavioral/personality traits that are deemed relevant for job interview scoring can be predicted on the basis of neural representations of paragraphs of interview transcripts. They compare against a baseline model using hand-crafted features and show that neural representations (static e.g. word2vec and contextual i.e. BERT, also augmented with prosodic information) significantly outperform the baseline. It's somewhat surprising to see this submitted to CMCL, as there is no clear cognitive modeling component to the paper.\n\nIt is interesting and unexpected (to this reader) that simple word2vec representations were effectively the best performing representations. I suggest this has more to do with the human raters from whom target scores were obtained (about whom we get no information, e.g. were they trained human resources professionals?) than with the authors' suggestions that prosodic cues are only leveraged when insufficient linguistic cues are available.\n\nI have serious concerns with the ethical implications of this work, especially in light of the fact that ethical considerations are not discussed at all. Technology like this has a very real potential to be misused, but more concerningly often proves discriminatory even when used without nefarious intent. There is a growing literature on the disparate impacts of technology used to assess personal/behavioral traits across demographics. At the very least these concerns need to be addressed in depth in order for a paper like this to be accepted (even setting aside the question of fit for CMCL)."", 'rating': '3: Clear rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_9nkW'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_9nkW']}, {'id': 'rWExVFu2wGq', 'original': None, 'number': 1, 'cdate': 1647982715880, 'mdate': 1647982715880, 'ddate': None, 'tcdate': 1647982715880, 'tmdate': 1647982715880, 'tddate': None, 'forum': 'B_OII7tlIZ5', 'replyto': 'B_OII7tlIZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper14/-/Official_Review', 'content': {'title': 'Text prediction of hireability', 'review': 'This paper describes text-based systems for predicting various qualities related to job interview performance. Systems using word2vec and BERT can outperform traditional feature-based classifiers using small feature sets like LIWC and some basic computer vision applied to interview video. Some scores (including whether the interview candidate smiled) are actually better predicted from text than video. Where differences between w2v and BERT exist, w2v is generally better; the gap can potentially be closed by using prosody.\n\nThe work\'s main strengths are the somewhat surprising fact that some non-textual scores can be predicted from text and the significant improvement over previous work.\n\nI see two main weaknesses: fit with CMCL and misgivings about the paper\'s impact.\n\nWith regard to fit, there is relatively little in this paper that seems cognitive or psychological. The most significant psychological point made is that ""when not enough linguistic cues are available at the lexical-semantic level, additional extra-linguistic materials are required to successfully process the information provided"", but the argument for this is that prosody improves the weaker BERT classifier more than the strong w2v classifier. Adding extra features generally improves weak classifiers more than strong ones. Moreover, the analysis in the paper does not single out instances where ""not enough linguistic cues are provided"", but rather ones where the classifier is not making good use of the cues it already has. (As an additional point, failure to find significance should not be considered as an indicator that the effect does not exist, particularly when the models have different variances--- lines 237-244.)\n\nWith regard to impact, automated systems for hiring are an ethical minefield (with Amazon\'s famously sexist hiring tool frequently cited as an example of what not to do). This paper does not consider potential ethical issues resulting from real-world deployment of this technology. Some things that would have to be considered are: the paper makes predictions about qualities such as smiling and speech rate from text which *must be* purely correlational. Such indicators cannot be reported to a decision-maker without explaining that they are imputed without reference to the actual phenomena they claim to be measuring. The paper does not evaluate bias on the basis of demographic characteristics in the classifier output. The current system outperforms the baseline on most of the individual personality factors but not on overall hireability, leading to questions about the validity of this judgment in the first place. While these questions are probably beyond the scope of this work, the paper should include a clear statement that this system cannot be deployed for any practical purpose and a citation to the ethics literature to explain why.', 'rating': '4: Ok but not good enough - rejection', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_TVRN'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_TVRN']}]"
https://openreview.net/forum?id=HpPE8mKeIZc ,HpPE8mKeIZc,"[{'id': 'HN2x1T9PvM9', 'original': None, 'number': 3, 'cdate': 1647962807225, 'mdate': 1647962807225, 'ddate': None, 'tcdate': 1647962807225, 'tmdate': 1647962807225, 'tddate': None, 'forum': 'HpPE8mKeIZc', 'replyto': 'HpPE8mKeIZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper10/-/Official_Review', 'content': {'title': 'The rediscovery of syntactic structure', 'review': 'This paper puts forward what I imagine is intended as a novel model of syntactic structure for natural language, which allows uniformities across languages to be straightforwardly characterized via a single underlying (declarative) structure. The paper then goes on to argue that this model could be used as the basis for an MT system. \n\nMuch as I am sympathetic to the importance of abstract structure in characterizing natural language syntax and in deriving underlying meaning, the current paper does not advance our state of understanding of this area. The proposed theory comes across as a rehashing of existing ideas that have popped up repeatedly in the history of grammatical description. The synapper structures for noun phrases look very much like dependency trees. The proposal for interrogatives in section 4.3 recalls Zelig Harris\'s idea that non-canonical sentence types need to be transformed into a ""normal form"".  The idea that structures can exhibit ambiguity goes back to Chomsky\'s earlier arguments (in ""Syntactic Structures""). And the proposal that syntactic structure should allow recursive embedding has a similarly long history.  The one novel contribution concerns the cyclic character of word order patterns, and the division into clockwise and counter-clockwise languages. This is a novel idea, so far as I am aware (though one could imagine deriving this distinction from the approach to word order explored by R. Kayne in his ""Antisymmetry of Syntax"" book). This idea would be more compelling if it could be shown that the distinction between these two classes of languages correlated with some other property. Otherwise, it comes across as merely taxonomic. \n\nThe paper\'s discussion of MT is even weaker. After a detailed recounting of the performance of existing systems on the translation of a single Korean sentence into English, the paper puts forward what would be the translation of the same sentence derived from the current approach. The problem is, as far as I can tell, there is no implemented system. And in carrying out this translation, the paper permits arbitrary changes to be made in service of producing the translation (e.g. lines 596-600). Saying what the answer *would* be if such a system existed will not be convincing at all to readers with any appreciation of the complexity of building MT systems. While I don\'t think that NLP progress should be held hostage to performance on benchmark datasets, as incremental advances won\'t necessarily lead to fundamental progress, the bar for progress is higher than what is done here. \n\nFinally, the paper presents this structure-based approach to MT as though it is a novel contribution. However, the idea that translation should be done via a mapping between a cross-linguistically uniform underlying structure is a well-studied one, called either syntactic transfer or interlingua, depending on the abstraction of the analysis.  For more recent syntactic-transfer approaches, see the discussion in Williams, Sennrich, Post, and Koehn\'s book on Syntax-Based Statistical Machine Translation. And it would be worth paying attention to the many well-studied cases of structural divergence, where the mapping from the structure of one language to the structure of another is far from isomorphism, since they will pose problems for the approach proposed in this paper. (For an old, but still useful discussion, see B. Dorr\'s 1994 Computational Linguistics paper ""Machine Translation Divergences: A Formal Description and Proposed Solution"", but there\'s lots of work since then on this topic.)  I should also point out that much of the debate on per-NN syntax-based MT models concerned how to best represent the mapping between languages so as to best accommodate the divergences that exist.', 'rating': '1: Trivial or wrong', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_DEGb'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_DEGb']}, {'id': 'BdZxXScrSM5', 'original': None, 'number': 2, 'cdate': 1647823419409, 'mdate': 1647823419409, 'ddate': None, 'tcdate': 1647823419409, 'tmdate': 1647823419409, 'tddate': None, 'forum': 'HpPE8mKeIZc', 'replyto': 'HpPE8mKeIZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper10/-/Official_Review', 'content': {'title': 'An unclear approach to ""Machine Translation"" via cyclic graphs', 'review': 'I like to believe I always try to write constructive reviews, but I have to say that reading this paper was a puzzling experience.\nAs it is written, the paper lacks any depth in its relation to the vast variety of literatures the authors seems to want to connect to. \nWhat is the paper about? Left to the introduction alone, one would first think it a critique of constituency-based approaches to syntactic structure. Then it seems to be about how purely syntactic approaches are unnecessary for the task of machine translation, then it becomes a critique of Probabilistic models (in general. Any model whose output is probabilistic is unfit for machine translation according to the authors).\n\nThe paper  introduces a representation of sentences in the forms of unlabelled, cyclic graphs: a curious chimera of constituency structure, dependency trees, and a hint to lexical-functional graphs --- that has none of the formal advantages of these existing approaches, while attempting to capture the same information. The authors claim this ""new"" representation is better for Machine Translation broadly defined, but there is no evidence of this from a quantitative nor qualitative perspective.\n\nContent issues aside, the paper is just not thematically fit for CMCL. To clarify, I do think that there are many different ways to do “computational modeling”, and that a purely formal approach can be plenty “computational”. However, there is no modeling in here in any possible interpretation of the term, nor there is a computational contribution beyond the trivial existence of graphs (in fact, this is stated explicitly in the abstract!), nor there is anything resembling a “cognitive” topic. \n\n\n## Specific Comments\n\nLack of focus aside, the paper makes an astounding number of unsupported claims (basically, one per paragraph), which are at best trivial and often plainly wrong. I address some of the broader ones in what follows to exemplify how the paper is completely disconnected from current work in linguistics and computational linguistics.\n\n- The first part of the introduction seems to take issue with how constituency based approaches deal with the mapping between syntactic variation and semantic interpretation. While of course there are plenty of approaches that argue for a tighter relation between syntax and semantics, it is a strong claim that similarly interpreted sentences cross-linguistically should map to the same syntactic structure. Additionally, this shows a misunderstanding of what standard constituency approaches do --- that is exactly to give identical syntactic structures to the same grammatical relations across languages, modulo what the authors seem to care about most, *head directionality*. Even putting these two points aside, the issue of semantic representations across languages is one the paper never goes back to. In fact, the papers end up adopting a representation (in the form of cyclic undirected graphs) that has NO explicit encoding of basic grammatical dependencies.\n\n- On the same page, the authors go ahead to claim *No one has yet been able to demonstrate how such a process can take place 6almost instantaneously in the human brain.*\n\n    *Such a process* here being the process of establishing grammatical relations between words. Now, putting aside the decades of psycholinguistic work on parsing across a variety of syntactic frameworks that the authors seem to think not relevant, this is once again a point the paper never goes back to. Again, the “formalism ” adopted by the paper is then a form of cyclic graph  which the authors never bother to formally introduce. How are these graphs derived from sentences?\n\n- We then get to what seems to be the main focus on the contribution: an improved machine translation model. Apart from not defining the scope of the problem at all, there is no attempt to contextualize the contribution with respect to the existing literature in the subfield --- apart from a few random references to transformers models. In fact, given how focused the intro is on syntactic representations, it is puzzling how the paper completely ignores the vast literature on how syntactic information (be if from constituency or dependency trees or both) has been incorporate in MT approaches of different kind.\n\n- They also state that “probabilistic” approaches are problematic because they do not lead to a 100% accuracy — which I take to mean a 1-t-1 correspondence between two sentences in two different languages — which is of course a puzzling statement by itself given that contextual translation is never 1-to-1 even when done by human annotators.\n\n- The rest of the paper becomes even harder to follow. The method section presents a “decomposition” of sentences based on S, V, O elements, which basically reintroduces constituency/dependency structures, again sprinkled with a variety of unsubstantiated claims.\n\n    Crucially, their “model” is not, in fact, a model. There is no attempt to explain the properties of their representations, how the system is supposed to work theoretically, how it would handle things like modifiers alternation, and within language word order variation. The authors seem to believe this ""multidimensional"" approach to be somehow simpler that constituency/dependency trees, while of course formally it is far from being simple (and putting aside the fact that hierarchical representations are trivially multidimensional).\n\n- There is also a puzzling section about “ambiguity” which is not about ambiguity at all. Their non-ambiguous examples aside, the authors quickly claim that lexical ambiguity can be dealt with within their “framework” (I use the term loosely) but do not even mention crucial cases of syntactic ambiguity?\n\n- Additionally, it was truly unclear to me how to interpret the “Comparison of MT Models” section, as there is no comparison (unless we think extrapolating one paragraph from Google Translate counts as a comparison). Reading this section made it seem like the authors believe that translating a sentence can truly be reduced to the task of one to one translation of words (dismissed as an easy trick itself) and picking a point to start from in their graph.\n\n\n', 'rating': '1: Trivial or wrong', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_MJq5'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_MJq5']}, {'id': 'rddl_MtnEGq', 'original': None, 'number': 1, 'cdate': 1647786255815, 'mdate': 1647786255815, 'ddate': None, 'tcdate': 1647786255815, 'tmdate': 1647786255815, 'tddate': None, 'forum': 'HpPE8mKeIZc', 'replyto': 'HpPE8mKeIZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper10/-/Official_Review', 'content': {'title': 'A bizarre submission', 'review': 'The paper is too general, too vague and full of statements that are not supported by references, experiments or even a rigorous case study. Closer to central theme of the paper, the denouncement that applications of syntax trees have been very limited in scope, with the exception of UD ignores a rich tradition of computational linguistics and NLP research. Even if we limit our scope to the field of MT, there are a number of studies that explicitly use syntactic parsing as part of their modeling which is not mentioned (let alone compared to) in this paper.\n\nThere are numerous misconceptions in this work, the two most pressing ones being the idea that there is such a thing as ""100% accurate translation"" (ignoring the fact that translation is highly subjective and even human expert translations can produce more than one perfectly valid translation), and that matching syntactic structures across languages is sufficient (or even necessary) for a faithful translation.\n\nFinally (albeit less critical than it should be) there is the point that the paper is neither computational nor modeling (both of which are part of the workshop\'s name).', 'rating': '1: Trivial or wrong', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_3nkC'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_3nkC']}]"
https://openreview.net/forum?id=rpPGIQtxI-q ,rpPGIQtxI-q,"[{'id': 'rK8xW55nhfc', 'original': None, 'number': 3, 'cdate': 1648310921327, 'mdate': 1648310921327, 'ddate': None, 'tcdate': 1648310921327, 'tmdate': 1648310921327, 'tddate': None, 'forum': 'rpPGIQtxI-q', 'replyto': 'rpPGIQtxI-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper9/-/Official_Review', 'content': {'title': 'Not enough discussion', 'review': 'This paper adresses the question of left-corner parsing and the cognitive motivation of reinforcement learning approaches to this problem. The paper first recalls the main aspects of the LC parsing technique and provides  examples. This first part is very pedagogical, but could be reduced and leave place for the core of the paper. The paper then describes the experiment by presenting first what authors call the environment setup. The idea consists in extracting from the PTB several trees and analyze the behavior of a parser. At each step, depending on the action selected by the parser, a penalty is associated with the state. The experiment itself consists in studying the behavior of 15 reinforcement learning algorithms, applied to a subset of trees chosen for their simplified structures (reduced depth, all starting with an NP-subject). A description of the main characteristics of each RL technique is given, and a  summary of the results with a short discussion is proposed. \n\nThe paper presents an interesting and important idea, proposing a method and some results in the perspective of arguing in favor of a cognitive ground for RL algorithms. However, it suffers from several drawback. First, the method for selecting the penalty is not well motivated, and looks arbitrary. The same for the proposed evaluation metrics, that are very basic. But the main problem of the paper is that it fails at providing any evidence in favor of a cognitive motivation. There is no precise analysis of the core of  RL mechanisms that should be arguments in favor of that. The paper only gives a set of results, with no precise discussion and no conclusion. At this stage, even though the idea is interesting, it seems to me not elaborated enough to be presented at CMCL. ', 'rating': '3: Clear rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_BjvH'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_BjvH']}, {'id': 'Bb4lFrPZ2G9', 'original': None, 'number': 2, 'cdate': 1648265025065, 'mdate': 1648265025065, 'ddate': None, 'tcdate': 1648265025065, 'tmdate': 1648265025065, 'tddate': None, 'forum': 'rpPGIQtxI-q', 'replyto': 'rpPGIQtxI-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper9/-/Official_Review', 'content': {'title': 'Unclear motivation', 'review': ""The paper describes a method for training a left-corner parser through reinforcement learning using word vectors from a variety of off-the-shelf language models.  Evaluations compare several of these models.\n\nMy main difficulty with the paper is that it does not motivate the need to use reinforcement learning in this way.  For example, is this a model of human grammar acquisition?  If so, there should be more discussion of theories of grammar acquisition that might be supported by the these results.\n\nSecondarily, the paper provides extensive explanations of things like self-paced reading and garden path effects that are probably quite familiar to CMCL audiences, and very little explanation of reinforcement learning or what an 'environment' is in this context, which are more unusual.  Also, it is a bit strange to have an example parse with no formal specification of the parsing rules, even if they are taken from another paper.\n\nFinally, there's no discussion of earlier uses of reinforcement learning in incremental parsing, e.g. Le and Fokkens 2017 in EACL.\n\nThere might be an idea here, but I think the presentation must be reworked fairly substantially to be acceptable.\n\nMore minor: the paper should include citations for claims like 'AC architectures have been argued to be cognitively realistic' on page 8, and other mentions of 'cognitively realistic'.\n"", 'rating': '3: Clear rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_DZ3M'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_DZ3M']}, {'id': 'rclcTQZBG5', 'original': None, 'number': 1, 'cdate': 1647805378125, 'mdate': None, 'ddate': None, 'tcdate': 1647805378125, 'tmdate': 1647805785826, 'tddate': None, 'forum': 'rpPGIQtxI-q', 'replyto': 'rpPGIQtxI-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper9/-/Official_Review', 'content': {'title': ""This paper presents an approach to left-corner parsing of constituency structure (as CFGs) based on Reinforcement learning. The authors explore various RL environments, and evaluate them with respect to several baselines. However, the paper is lacking in motivation, and there is no clear placement of the authors' question/motivation/techniques with respect to the broader cognitive modeling literature. "", 'review': 'To the Editors: I feel compelled to state that I had already reviewed this paper for a previous conference several months ago, and none of the issues found there have been addressed. Because of this, I can\'t confidently believe the authors\' would  take the reviews into account in a potential camera ready. The rest of my review is the same as my previous one, since nothing in the paper has been changed.\n\n## Big Picture Comments\n\nFrom one side, the paper is generally well-written and the technical results seem sound (it is not possible to replicate the results, since the authors do not share their code, but the technical set-up appears correct to me, independently of the specific numerical scores).\nThe contribution is **potentially** interesting, but in ways that are made hard to evaluate given the paper.\nUnfortunately, the main issue with this paper  its lack in clarity with respect to aims and overall conceptual contribution. In short: it is unclear what we are actually learning from the paper, and who the authors\' think should be interested in their results (psycholinguists?computational linguists interested in symbolic models? neural network researchers? all of the above?). This is partially an artifact of significant presentation issues. I hope my comments below might help the authors\' clarify the goals of the paper and its contribution to the broader literature.\n\n## Specific Comments\n\nOne issue in presentation is, in my opinion, the focus of the first half of the paper given the audience. The authors spend almost half of the paper motivating constituency parsing, and walking us through an example of the shift/predict/scan operations. This to me seems quite trivial, and if the purpose is to exemplify the rewards, that\'s anyway made clearer in the later section.\nHowever, what is missing is the motivation behind why applying a RL approach to this problem is valuable, and a walkthrough of RL fundamental intuitions, which seems to me way more needed given the scope of the paper than the scan/predict example.\n\nI know it seems I am being picky about form, but the reason is that this lack of motivations makes the rest of the paper relatively weak.\nIt seems like the whole contribution is to substitute the classical control structure of these kind of parsing algorithms with a RL agent. Which, fine, but what is the advantage?\nThe authors seem to be implying that the contribution is showing that the economy heuristic guiding the agents is learned from experience, but that just doesn\'t seem to be true in any relevant sense. The fact that shortest parsing paths are preferred is baked into the reward structure, both at the local choice level and in terms of total reward, which explicitly penalized longer paths. So ok, this is less explicit than an oracle considering number of actions explicitly, but I would not say it ""derives"" from experience.\n\nIn turn, this leads the experimental section to land quite flatly. The authors claim implementing these kind of algorithms is challenging for RL. But so what is the contribution meant to be? In the introduction it seemed that the authors were arguing for advantages coming from applying RL to this parsing ""problem"". But then towards the end it seems that the contribution is in highlighting the limits of RL?\nI am not saying these are not interesting results per se, they could be, but the authors never state why they should.\n\nIn short,  I think the conceptual foundation is missing from the paper, and thus the reader is left wondering. In this sense, the paper could benefit from a conclusion/summary section moving back from the particular results of the last section to the broader contribution. Clarifying what the authors think the aim of their approach is.\n\n\nSome minor notes:\n\n- The authors put a lot of emphasis on the parsers being ""cognitively plausible"", and I think they mean two things: (a) the eargerness of the left corner strategy (cue Resnik) and (b) the shortest path (parsing step counting) heuristic. Is that correct? I have no problems with either, in principle. But I don\'t think the prominence of either in the actual suggested contribution justifies having ""cognitively plausible"" in the title. The referenced literature seems to be lacking in this sense, missing a lot of work on connecting symbolic parsing algorithms to sentence processing behavior (boston2008parsing,chen2021quantifying,stanojevic2021modeling) Also note that there is a variety of ways (depending on what kind of cognitive, representational commitments one entails) in which these kind of minimal-steps ideas can be understood.\n\n- In the abstract and through, the authors mention evaluating the""psycholinguistic implications"" of RL algorithms, but there is barely a mention of that towards the end (that is left uninterpretable given the content of the paper). It is also left unclear how actually plausible these algorithms are, since the tree depth and things like adjunction seem to matter in ways that clearly do not for the human parser (sturt2005processing). In fact, we are even left wondering what the ""cognitively plausible"" mentioned in the title refers to.\n\n## Some References\n\n@article{boston2008parsing,\ntitle={Parsing costs as predictors of reading difficulty: An evaluation using the Potsdam Sentence Corpus},\nauthor={Boston, Marisa Ferrara and Hale, John and Kliegl, Reinhold and Patil, Umesh and Vasishth, Shravan},\njournal={Journal of Eye Movement Research},\nvolume={2},\nnumber={1},\nyear={2008}\n}\n\n@article{chen2021quantifying,\ntitle={Quantifying Structural and Non-structural Expectations in Relative Clause Processing},\nauthor={Chen, Zhong and Hale, John T},\njournal={Cognitive Science},\nvolume={45},\nnumber={1},\npages={e12927},\nyear={2021},\npublisher={Wiley Online Library}\n}\n\n@inproceedings{kobele2013memory,\ntitle={Memory resource allocation in top-down minimalist parsing},\nauthor={Kobele, Gregory M and Gerth, Sabrina and Hale, John},\nbooktitle={Formal grammar},\npages={32--51},\nyear={2013},\norganization={Springer}\n}\n\n\n@inproceedings{stanojevic2021modeling,\ntitle={Modeling incremental language comprehension in the brain with Combinatory Categorial Grammar},\nauthor={Stanojevi{\\\'c}, Milo{\\v{s}} and Bhattasali, Shohini and Dunagan, Donald and Campanelli, Luca and Steedman, Mark and Brennan, Jonathan and Hale, John},\nbooktitle={Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics},\npages={23--38},\nyear={2021}\n}\n\n@article{sturt2005processing,\ntitle={Processing coordinated structures: Incrementality and connectedness},\nauthor={Sturt, Patrick and Lombardo, Vincenzo},\njournal={Cognitive Science},\nvolume={29},\nnumber={2},\npages={291--305},\nyear={2005},\npublisher={Wiley Online Library}\n}', 'rating': '4: Ok but not good enough - rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_xqgf'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_xqgf']}]"
https://openreview.net/forum?id=SO_e8XKgUbq ,SO_e8XKgUbq,"[{'id': 'HWVxfQq4pGq', 'original': None, 'number': 3, 'cdate': 1648343578226, 'mdate': 1648343578226, 'ddate': None, 'tcdate': 1648343578226, 'tmdate': 1648343578226, 'tddate': None, 'forum': 'SO_e8XKgUbq', 'replyto': 'SO_e8XKgUbq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper6/-/Official_Review', 'content': {'title': ""Misses the point I'm afraid"", 'review': 'This paper addresses the phenomenon of human comprehenders frequently misassign thematic roles to arguments in ways that seem to be driven by ""processing heuristics based on their expectations about events ... rather than relying on syntactic rules"". For example, participants frequently misinterpret \'The dog was bitten by the man\' as having the man as the patient and the dog as the agent. The authors train a neural network model to construct a representation of a sentence which captures information about the assignment of thematic roles to arguments. They find that, in line with what has been observed in humans, the model\'s accuracy in assigning roles is lowest for passive, semantically-anomalous sentences like \'The dog was bitten by the man\', and highest for active, non-anomalous sentences like \'The dog bit the man\'.\n\nThis would be somewhat interesting if the only empirical facts at hand were the facts about misinterpretations that the authors review in the introduction. (There would be the usual questions about the interpretability of the neural model, but there would at least be something to talk about.) But the whole interest of the Ferreira-style findings is the fact that those interpretations are *mis*interpretations -- when we say that they are *mis*interpretations, we don\'t mean that they diverge from what the stodgy old syntax textbooks say, we mean that they diverge from what those same human comprehenders will tell you if you give them a couple of extra seconds to think about it. That\'s the other fact at hand which the authors seem to completely disregard (and that\'s why the stodgy old syntax textbooks say what they say). The whole interest, in other words, is what sort of mind would exhibit this divergence between interpretations at two different timescales. The model described in the paper does not exhibit any such divergence, it only captures one half of the picture.', 'rating': '3: Clear rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_GMha'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_GMha']}, {'id': 'BcgyPM43fq', 'original': None, 'number': 2, 'cdate': 1648276054578, 'mdate': None, 'ddate': None, 'tcdate': 1648276054578, 'tmdate': 1648276538125, 'tddate': None, 'forum': 'SO_e8XKgUbq', 'replyto': 'SO_e8XKgUbq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper6/-/Official_Review', 'content': {'title': 'The paper could be a bit more carefully worded', 'review': ""This paper describes a neural role-filler model that correctly mixes up arguments in sentences manipulated to have inverted canonical subjects and objects.\n\nI think there's a contribution here, but the motivation should be worded a bit more carefully.  Evidence of human errors on these kinds of manipulated stimuli may suggest an auxiliary 'good enough' comprehension model which runs in parallel with a more precise parser that can reliably comprehend complex sentences with nested conditions, conjunctions, negations, etc.  This would not challenge the view that parsers are necessary, as claimed in the first paragraph.  Statements like 'Most theories ...' in the introduction need some citations, as does the sentence after that (presumably that refers to Ferreira and Kutas, et al).\n\nAlso, a clarity issue: on line 125 there a reference to 'Fasttext' which isn't explained.\n\nA minor point: swapped arguments is also a kind of speech error; I wonder if comprehension errors are simply assuming a speech error has happened?\n\nFinally, the acknowledgements section is usually omitted in anonymous submissions, as it has the potential to de-anonymize the submission.\n"", 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_iUsJ'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_iUsJ']}, {'id': 'St-eQNfYyG5', 'original': None, 'number': 1, 'cdate': 1647444522684, 'mdate': 1647444522684, 'ddate': None, 'tcdate': 1647444522684, 'tmdate': 1647444522684, 'tddate': None, 'forum': 'SO_e8XKgUbq', 'replyto': 'SO_e8XKgUbq', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper6/-/Official_Review', 'content': {'title': 'the perennial appeal of syntax-free comprehension', 'review': 'This paper represents a revival of the view originally championed by Tom Bever in 1970 that some route of the human sentence processing mechanism is free from the influence of grammar.  While Bever\'s own proposal includes a 2nd route that is influenced by grammar, this submission only focuses on the first route. The paper exhibits a model that faithfully misperceives Patients as Agents when they are more plausible in that semantic role.\n\nIn the writing, I sense a suggestion that somehow modeling this phenomenon bolsters the view that syntax is unnecessary (e.g. ""pose a challenge to classic linguistic theories and models"" page 4). This is not true. This view, while perennially-appealing to syntax-haters around the world, is simply not supported by Ferriera\'s results, Kuperberg\'s or by this paper\'s modeling. Rather what I think this paper shows is that recurrent neural networks can faithfully implement what David Caplan (MIT Press 1992) has called the ""heuristic route"" -- I take this to be roughly the same as Bever\'s syntax-free Perceptual Strategies from the 1970s.\n\nIf this submission\'s rhetoric were recalibrated to say for example ""this is a model of what people with Broca\'s Aphasia can do"" it could make a valuable contribution by deriving predictions about new cases where plausibility might override structure. Another improvement would be to characterize the contribution of the gated units (i.e LSTM) as compared to Doug Rohde\'s thesis which used ungated, Elman style Simple Recurrent Nets.\n\nI am recommending reject because publication of this version would reflect badly on CMCL. As inclusive as we are at this workshop, scholarship is a non-negotiable requirement. However, if the author were to reframe the contribution i.e. to remove the spurious argument against classic linguistic theories and models, I think it would be appropriate to accept.', 'rating': '4: Ok but not good enough - rejection', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_Noc4'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_Noc4']}]"
https://openreview.net/forum?id=BffxIQYlLbc ,BffxIQYlLbc,"[{'id': 'SglyyuKiG9', 'original': None, 'number': 3, 'cdate': 1648232406879, 'mdate': 1648232406879, 'ddate': None, 'tcdate': 1648232406879, 'tmdate': 1648232406879, 'tddate': None, 'forum': 'BffxIQYlLbc', 'replyto': 'BffxIQYlLbc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper5/-/Official_Review', 'content': {'title': 'Preliminary blend of two RSA extensions', 'review': 'The authors study ""habituality"" inferences using an example from a previously-collected dataset by Kravtchenko & Denberg, 2015). They attempt to derive these under the rational speech acts framework and find that a base RSA agent fails, but that a blend of habitual and noisy channel RSA variants can produce these inferences and can mirror the empirical observation that when the triggering statement is more prominent, the inference gets stronger. \n\nThis is an interesting but somewhat incremental extension to RSA theory, picking up on the Bergen and Goodman (2015) noisy channel RSA model. The theoretical contribution is to work out how these two model variants can be combined, and that seems quite appropriate for the current venue. Unfortunately, the empirical side is not yet well fleshed-out: the prior data are not described in any depth, and the evaluation is completely qualitative. Further, the model depends on establishing a confusion matrix for utterances that is (as noted as a limitation by the authors) currently simply invented. A minimum step here would be to conduct some kind of sensitivity analysis to show that it is not the specific details of this confusion matrix that produce the result. \n\nIn sum, this feels like a good start but some further evaluation is needed to cement the contribution of the work. ', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_HsPv'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_HsPv']}, {'id': 'rubgaf4_Dfq', 'original': None, 'number': 2, 'cdate': 1647965205287, 'mdate': 1647965205287, 'ddate': None, 'tcdate': 1647965205287, 'tmdate': 1647965205287, 'tddate': None, 'forum': 'BffxIQYlLbc', 'replyto': 'BffxIQYlLbc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper5/-/Official_Review', 'content': {'title': 'Interesting but too preliminary, with clear empirical limitations', 'review': 'This paper presents a formal model — within the RSA framework — of pragmatic inferences about the frequency of an activity that arise when utterances contain information that is in principle redundant (under default assumptions for an event type). The authors first present a version of the model (hRSA) that incorporates prior expectations given common ground knowledge, building on Degen et al (2015).  This model fails to account for the possible preference of speakers to use more costly utterances to convey unusual meanings and the fact that these more costly utterances strengthen the inference. To remedy this, the authors proposed a modified version of the model (noisy hRSA), which takes into account the memorability of a given utterance form, building on Bergen and Goodman (2015).\n\nI have read the paper with interest, but do not think that it is suitable for CMCL. The paper makes theoretical predictions, which is a strength. However, the work in its current state is largely incomplete: \n\n- the model revolves around one single example (the one given in the introduction) and no details about data are given (e.g., the data collected by Kravtchenko & Demberg (2015) is not described; nothing is said about how many types of events were targeted in the experiments by Kravtchenko (2021) regarding habituality priors);\n- most importantly, no empirical evidence is provided for assumption (c), i.e., the hypothesized speaker behaviour which the model captures has not been empirically validated and it’s not clear why this should hold; \n- similarly, no evidence for the claim that “speakers are very reluctant to use exclamation marks or other markers even in this condition” (lines 304-306);\n- the values in table 1 are made up (“intuitively plausible” with no empirical evidence and not substantiated by a well-defined theory);\n\nThe authors acknowledge these weaknesses at the end of the conclusions. Given these limitations, my assessment is that the paper does not currently contain enough substance and is not a good fit for this workshop in particular. \n\nOther comments: \n\n- The RSA framework is given for granted. The paper should include a brief description of its main components. Space is clearly not an issue. \n\n- The term “atypicality inferences” used in the title is never used in the paper, where instead the phenomenon studied is referred to as “habituality inferences”.\n\n- What does hRSA stand for? (Is it “habituality RSA?). This acronym is used in section 3.1 without spelling out what it stands for, and without a citation (in line 246, it appears that this is not a contribution of the present paper but rather a model introduced in previous work). \n\n- Lines 169 and 385: wrong citation format. \n\n- Consider shortening the abstract, using one single paragraph, which is the established scholarly practice in the field. ', 'rating': '4: Ok but not good enough - rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_ACau'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_ACau']}, {'id': 'BrBgAx9ca-c', 'original': None, 'number': 1, 'cdate': 1647319541761, 'mdate': 1647319541761, 'ddate': None, 'tcdate': 1647319541761, 'tmdate': 1647319541761, 'tddate': None, 'forum': 'BffxIQYlLbc', 'replyto': 'BffxIQYlLbc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper5/-/Official_Review', 'content': {'title': 'Interesting study, could use some more attention to existing understanding of implicature and common ground', 'review': 'I\'m not sure that the way the authors measured the habituality prior will really get accurate measurements. If we assume that paying the cashier logically follows from going shopping, then even asking the question of how often he pays the cashier may introduce the same sort of Q-implicatures that stating ""he paid the cashier"" does -- respondents might think ""why ask me that unless there is reason to suspect that he often doesn\'t""? Thus, these ratings might not be giving a baseline habituality level; they might just be showing the same inferences that the main experiment is showing.\n\nIt seems to me that many potential implicatures may become available in the sorts of utterances used here. ""John went shopping -- oh yeah, and he paid the cashier"" might implicate that he doesn\'t usually pay, but it might implicate lots of other things as well, and it\'s not even clear to me that ""John usually doesn\'t pay"" is even the most likely implicature to arise (hence the rather small effect seen in the author\'s previous studies -- even in the more marked conditions, there is still a plurality of participants thinking that John usually pays). It\'s especially hard to know what implicature to recover here without any context (so it would be useful to see the full stories that were used in the study; if participants only see these utterances in a minimal context I suspect that their interpretations would be so all over the place there would be nothing interesting to model; the authors mention that these were put in story contexts but I don\'t see the full texts anywhere). It seems like it\'s easy for an interlocutor to notice that the utterance is weird (flouting the maxim of quantity, the Q-principle, or whatever we want to call it) and that the speaker intends to produce some implicature, but exactly what that implicature is is very underdetermined -- indeed this has been one of the core criticisms of Gricean pragmatics ever since it started. \n\nThe authors state near the beginning of the paper that there has been little research attention to pragmatic inferences that involve changing one\'s beliefs about the common ground, but this doesn\'t seem right. Quite a lot of theorizing in pragmatics and discourse analysis has assumed that communication is all about updating the common ground and mutual knowledge; e.g., contra stuff like Grice\'s theory of non-natural meaning, some approaches argue that the whole point of communication is to get an interlocutor to introduce something new into their understanding of the common ground. (e.g. Discourse Representation Theory.) Some pragmatic phenomena, particularly presupposition and conventional implicature, have been explained with recourse to how they put things into the common ground (e.g. work by Stalnaker, Potts; for a summary of work from the very dawn of pragmatics see e.g. chapter 4.4 of Levinson 1983).', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_px8X'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_px8X']}]"
https://openreview.net/forum?id=SGfgrQYeUWc ,SGfgrQYeUWc,"[{'id': 'SBgezgC2YG9', 'original': None, 'number': 3, 'cdate': 1648115177561, 'mdate': 1648115177561, 'ddate': None, 'tcdate': 1648115177561, 'tmdate': 1648115177561, 'tddate': None, 'forum': 'SGfgrQYeUWc', 'replyto': 'SGfgrQYeUWc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper2/-/Official_Review', 'content': {'title': 'Not relevant for the CMCL venue', 'review': ""The paper compares BERT predictions for texts written in two different registers, in Italian: newspapers and poetry.\n\nI do not see a fit for this paper in this venue, as there is no cognitive modelling involved, just a test of BERT's predictions for different registers. There is a section reviewing a small amount of computational psycholinguistic work in sentence processing, but the current study differs from the reviewed ones in that it does not compare against human behavior. Hence conclusions cannot be related to cognitive processing in any meaningful way.\n\nThe dataset is extremely small (18 sentences). The authors justify this choice based on the fact that they can do more extensive qualitative analysis on a small dataset. However, given this size, it is highly doubtful that the results are robust enough to draw any conclusions.\n\nOther comments:\n- acronym DL is not introduced in the abstract, and it seems like a too general way to refer to the models used in the paper, which are all instances of BERT, as far as I could tell.\n- explaining what is non-canonicity in the introduction would be helpful\n- self-citations should be avoided to preserve anonymity"", 'rating': '2: Strong rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_YeEh'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_YeEh']}, {'id': 'rawlYnyw_G9', 'original': None, 'number': 2, 'cdate': 1648025521319, 'mdate': 1648025521319, 'ddate': None, 'tcdate': 1648025521319, 'tmdate': 1648025521319, 'tddate': None, 'forum': 'SGfgrQYeUWc', 'replyto': 'SGfgrQYeUWc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper2/-/Official_Review', 'content': {'title': 'Linguistically relevant but computationally vague work', 'review': ""This paper explores the ability of Transformer Models to predict a word in Italian sentences. The authors investigate how predictions vary in canonical and non-canonical order of the same sentences from two different domains (poetry and newspapers). \n\nThe investigation is relevant, and the linguistic motivations are well defined. However, there are some substantial limits. \nOn a theoretical side, the authors claim their work is part of the line of research where human word predictivity is compared and tested by the performance of DNNs in next-word-prediction tasks. If this is was the aim, authors should test their results with behavioral data. In my opinion, this is more of a study on the linguistic abilities of Transformer Models.\n\nMoreover, the dataset selected is too small to make strong claims about the results. While it is true that this allows a detailed error analysis, the setup is questionable; among all, sentences are not balanced between the two domains.\n\nThe critical aspect, however, is the computational implementation. The description of the experimental setup is too vague. \nOn the one side, some decisions are not motivated (why do they choose the output of the first or projection layer and not other layers?), and the resources used are not clearly stated. For instance, the authors state they use BERT, but then they cite UmBERTo, which actually inherits from RoBERTa the base model architecture. On the other side, the way the evaluation is described is so obscure that it is hard to understand what was concretely done, yet making it hard to reproduce. For instance, it is unclear what they mean by 'We evaluate word co-occurrence frequencies by means of embeddings as the cosine value made available by BERT': the cosine is used as a measure to compute the similarity between two word-embeddings, but in the paper, I cannot find which are the two embeddings directly compared. The prediction technique should be given more details, specifically how the authors deal with cases when a word is split into subtokens by the tokenizer.\n\nI recommend that the authors rewrite the paper entirely by reformulating the research questions and detailing the experimental method precisely.\n\nLast but not least, the paper is not anonymized. Indeed, in two cases, the authors explicitly refer to their previous works (line 126: 'We already discussed 126 elsewhere (Delmonte, 2021)..',  and footnote 5 '5We comment and analyze in depth all sentences in a paper..'), which is against the double-blind reviewing policy."", 'rating': '3: Clear rejection', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_DaR1'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_DaR1']}, {'id': 'SqLlPxqM_Gc', 'original': None, 'number': 1, 'cdate': 1648007663442, 'mdate': 1648007663442, 'ddate': None, 'tcdate': 1648007663442, 'tmdate': 1648007663442, 'tddate': None, 'forum': 'SGfgrQYeUWc', 'replyto': 'SGfgrQYeUWc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CMCL/Paper2/-/Official_Review', 'content': {'title': 'Interesting work but lacking in many aspects', 'review': 'The current work investigates word prediction in Italian sentences. A BERT model is used to predict a masked word in sentences with differing complexity. The complexity of the sentences is operationalised via the genre of the text (new vs poetry); in particular via frequency of the word as well as word order/semantics. \n\nWhile this is an interesting and pertinent investigation, I am afraid the way the paper is written makes it extremely difficult to understand the experimental setup, the key hypothesis and the results. For example, at no point in the paper do the author clearly state how the masked word prediction task is operationalized. The authors state ""To this aim we ran BERT by masking each content word and some function word, ... "" -- what does masking some function word mean? Relatedly, it is unclear if while making a prediction, the model has access to the right context of the masked word. This is important because the model is being compared to how humans predict a word. Human word prediction is incremental in nature where only the left context is used to make upcoming prediction.\n\nIn addition, the work is not contextualised in the larger psycholinguistic prediction literature; the current citations in section 2 is cursory at best.\n\nMy suggestion would be that the authors should completely rewrite the paper by making the research questions, the experimental method and the results more accessible.\n\nFinally, the submission to the CMCL workshop has to be anonymous and self citations have to be avoided -- the authors write ""We already discussed elsewhere (Delmonte, 2021) that languages like Italian, which have a rich morphology, ...""; such a statement is a clear violation of the guidelines.\n\n\n', 'rating': '3: Clear rejection', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_P5MN'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CMCL', 'aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_P5MN']}]"
https://openreview.net/forum?id=rhz7nqYfF-q ,rhz7nqYfF-q,"[{'id': 'HN2gHFt6qGq', 'original': None, 'number': 5, 'cdate': 1648183677147, 'mdate': None, 'ddate': None, 'tcdate': 1648183677147, 'tmdate': 1648183677147, 'tddate': None, 'forum': 'rhz7nqYfF-q', 'replyto': 'rhz7nqYfF-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review', 'content': {'title': 'Interesting idea and reasonable experiment results', 'review': 'This paper proposed an interesting idea to learn the Tokenizer/Vocabulary for federated language models. The previous word-level tokenizer/vocabulary can be potentially generated by the following methods: (1) use a public dataset, which may have distribution shift compared to the targeting task; (2) directly collect from target task, which may cause privacy concern; (3) use private heavy hitter to directly collect from target task, which does not seem to provide desirable privacy utility tradeoff. This paper proposed to train a sub-word language model with differentially private federated learning from the targeting task, and then use the trained model to generate/sample words to build the word-level tokenizer. Experiments on stackoverflow, reddits with wiki data as extra public dataset show the effectiveness  of the proposed method. \n\nIn general, I think the idea is interesting. The paper is well written, technically solid, and the experiments seem to make sense. I think the draft can be further improved by clarifying the following\n(1) Why do we still want to sample a word-level tokenizer if we can train good models with sub-word tokenizer?\n(2) I cannot get the intuition why the proposed method can be better than private heavy hitters. Could the authors provide more intuition and highlight it in experiments?\n\nThe authors may also be interested in the following paper and blogpost that show how to get DP in FL in practice:\nPractical and Private (Deep) Learning without Sampling or Shuffling https://arxiv.org/abs/2103.00039\nFederated Learning with Formal Differential Privacy Guarantees https://ai.googleblog.com/2022/02/federated-learning-with-formal.html', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_qmwZ'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_qmwZ']}, {'id': 'rCexZR_kqMc', 'original': None, 'number': 4, 'cdate': 1648126152907, 'mdate': None, 'ddate': None, 'tcdate': 1648126152907, 'tmdate': 1648126152907, 'tddate': None, 'forum': 'rhz7nqYfF-q', 'replyto': 'rhz7nqYfF-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review', 'content': {'title': 'Review', 'review': 'This paper proposes a federated learning framework to train a tokenizer while it does not require additional privacy budget in differential privacy. Training the tokenizer is an important part of learning a language model (e.g., Transformer and BERT), but to my best knowledge, it is the first work to study how to train the tokenizer in federated learning setting. \nAlthough the first two contributions (i.e., 1) performance degradation from training with a different distribution and 2) sub-word tokenizer eliminates the out-of-vocabulary problem) are quite obvious, I appreciate this work and advocate accepting the article in this workshop to discuss further. Here are some of my concerns:\n1.\tI am confused about the system and privacy model, especially how public (Wiki) and private (Reddit or StackOverflow) dataset is distributed over the server/clients. The authors assume that stale tokenizer is trained with the public dataset with a certain privacy budget. However, if the public dataset is utilized to train the model, why should differential privacy be applied? In addition, who generates dataset by utilizing the stale (or old) tokenizer and who update the model embeddings? Clarification about these questions from the FL perspective can improve the paper.\n2.\tIn experiments, it would be better to highlight the paper’s contribution if comparing the two settings in the same privacy budget: 1) proposed scheme (i.e., train old tokenizer with DP and train the new tokenizer without additional privacy budget) and 2) directly train the tokenizer based on private dataset in private FL with the same privacy budget. \n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_9nuF'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_9nuF']}, {'id': 'BublvHd3KG9', 'original': None, 'number': 3, 'cdate': 1648113726610, 'mdate': None, 'ddate': None, 'tcdate': 1648113726610, 'tmdate': 1648113760569, 'tddate': None, 'forum': 'rhz7nqYfF-q', 'replyto': 'rhz7nqYfF-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review', 'content': {'title': 'Review', 'review': ""This paper provides a novel method on training a tokenizer along with the language model privately in a federated learning setting. By utilizing the post-processing theorem of differential privacy, the authors claim that the proposed method satisfies DP without additional privacy cost on training the tokenizer. Empirical results show that the proposed method outperforms heavy-hitters algorithm both in terms of privacy and utility.\n\nIn general this paper is well written, with enough background knowledge explained for readers to understand. The motivation is also clear and the algorithm description makes sense. Here are some comments I have to improve the work:\n- The authors should clearly clarify what type of privacy the proposed method is protecting. It seems that client-level privacy is enforced and a trustworthy server is assumed. I feel it is important to explicitly state this so that it is clear where the clipping and noise is happening in the FL algorithm.\n- It seems from that the proposed method outperforms heavy hitters algorithm even omitting the extra privacy budget induced by the latter. Could the authors provide the exact \\epsilon and \\delta for the heavy hitters algorithm? Alternatively, could the authors show the utility performance difference given the same privacy budget, including the separate privacy budget, in order to see how much the proposed method outperforms the former.\n- There are two minor questions during training a sub-word tokenizer: 1. How does it encode the word when there are multiple sub word combinations? Does it simply search for the one that appears earliest in the dictionary? 2. When updating model embeddings with sub-words, it doesn't seem to be a bijection: different combinations of subwords could result in the same summation, causing words with different semantic meanings to be mapped to the same embedding. Could the authors explain whether this will cause problem to the proposed method?"", 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_zXFH'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_zXFH']}, {'id': 'HV2leMxUtM5', 'original': None, 'number': 2, 'cdate': 1648087048282, 'mdate': None, 'ddate': None, 'tcdate': 1648087048282, 'tmdate': 1648087048282, 'tddate': None, 'forum': 'rhz7nqYfF-q', 'replyto': 'rhz7nqYfF-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review', 'content': {'title': 'Reasonable idea, good results, but more work needs to be done before this can be used in practice', 'review': 'Thanks for the submission! I enjoyed reading this paper. The goal of this paper is to improve the tokenizer using the samples matching the real distribution of the data without incurring an additional PFL budget. The basic idea is to start with a tokenized from a public dataset, which might not match real data, and then improve that tokenizer using samples obtained from the trained model. After that, replace the old tokenizer with the new one and repeat this process. Evaluations show good results on Reddit and StackOverflow datasets. \n\n1. To apply it to real-world use cases, it’s a bit unclear when we should start sampling the trained model and using the new tokenizer. Experiments shown in Section 5.4 seem to suggest that there is no easy answer, and it might depend on the underlying dataset and algorithm. Given that, any suggestions on how ML practitioners can adopt this? I assume they cannot try multiple options and pick the best one because that would require an additional budget?\n2. The experiments seem to be conducted with a fixed budget. I am curious to learn how the proposed algorithm compares with baselines if we got the chance to increase the budget to hit a target perplexity?\n3. The evaluation results look good. I am curious if the improvements can also be proven in theory as well. And is it possible to quantify the improvements before training? \n4. Are there any limitations of the proposed algorithm?\n5. IIUC, before replacing the old tokenizer with the new one, we will need to pause the current process, and use samples from the model to train the new tokenizer. In practice, how long does it take to bring the new tokenizer to a reasonable state, and will this delay be an issue? \n6. Is it viable to allocate some dedicated budget to train the tokenizer, say 20%? Is there any estimation of how the proposed algorithm compares to that?\n', 'rating': '7: Good paper, accept', 'confidence': '2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_n2wc'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_n2wc']}, {'id': 'H-g7KFpHMq', 'original': None, 'number': 1, 'cdate': 1647855995395, 'mdate': None, 'ddate': None, 'tcdate': 1647855995395, 'tmdate': 1647855995395, 'tddate': None, 'forum': 'rhz7nqYfF-q', 'replyto': 'rhz7nqYfF-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review', 'content': {'title': ""The authors propose a method to train a 'matched' tokenizer alongside the decentralized and private federated learning of an NLP model over the client data."", 'review': ""The authors propose a method to train a 'matched' tokenizer alongside the decentralized and private federated learning of an NLP model over the client data. In particular, the authors consider the problem of having tokenizer for the NLP model that is reflective of the data on the clients that participate in the decentralized federated learning process. When the tokenizer is not matched with the private client, such as when the tokenizer is trained on a public dataset, the authors demonstrate a significant drop in accuracy of the trained model, compared to when using an oracle tokenizer i.e. when the tokenizer is trained on the client data itself. While having a matched tokenizer is essential, training tokenizer on the private client is quite challenging and can potentially cause additional privacy leakage over the existing leakage from DP based FL. Hence, the authors propose a new protocol that samples new datasets for tokenizer up dation using the language model trained using the DP based FL itself. This additional step is integrated into the existing federated learning protocol, and the authors claim that there is no additional privacy leakage. Experiments with many settings are provided that demonstrate that the proposed schemes can match the language model performance of the federated training with oracle tokenizer.\n\nWhile the problem considered is interesting and relevant, and the algorithm also has some novelty, the claim that there is no additional privacy leakage is not proved formally. In particular, when the tokenizer is modified during the private federated learning, it essentially splits the training into different stages with their own DP guarantees. I don't think the post-processing guarantee of DP applies in such a scenario. A composition analysis to bound the DP privacy budget is needed."", 'rating': '5: Marginally below acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_gZjY'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_gZjY']}]"
https://openreview.net/forum?id=H3NUh9Kft-c ,H3NUh9Kft-c,"[{'id': 'SMlOUQ9Ffc', 'original': None, 'number': 3, 'cdate': 1648104271805, 'mdate': None, 'ddate': None, 'tcdate': 1648104271805, 'tmdate': 1648105210926, 'tddate': None, 'forum': 'H3NUh9Kft-c', 'replyto': 'H3NUh9Kft-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/-/Official_Review', 'content': {'title': 'Adapting intrinsic gradient compression in federated settings', 'review': 'Summary:\nA gradient compression technique for federated settings based on the intrinsic dimension concept is proposed. Three variations of the technique are implemented and their tradeoffs in terms of parameter exploration, federation performance and uplink and downlink cost are presented.\n\nStrong and Weak Points:\n\n(S1) Interesting adaptation of intrinsic dimension in federated learning settings for compressing clients\' (local) gradients.\n(S2) Extensive empirical evaluation against different baselines and on multiple domains.\n(S3) Promising insights to employ intrinsic gradient compression techniques against inference attacks.\n\n(W1) Presentation of preliminaries, background, gradient compression and approximation, and algorithms can be improved.\n\nDetailed comments:\n(W1) In section 1, it would be better to cite the original intrinsic dimension work the first time it is discussed. In section 2 it would be better to create a table with all the notations you use throughout your work for faster notation indexing. Section 2.2 ""the data is averaged"", please change to ""gradients or weights are averaged"". Related Work: Federated Learning, please add some discussion on recent works on weight and gradient pruning in federated settings (e.g., [1], [2]). Please elaborate more on the concept of reconciliation; it is not clear what it is and what its challenges are (maybe pointing to specific lines of the algorithm will be helpful). In your time-varying gradient compression it is not clear why we need twice the bandwidth for downlink and where do the $\\theta^{final}$ stems from. For the choice of the compression matrix, why do you need an entire Dxd matrix and not consider the model parameters as a collection of smaller dense matrices? Figures 1 and 2 need to come before table 2 since they are discussed first in the paper. Also you compare against LocalTop-K but you never presented or discussed the technique in the paper.\n\nPlease be consistent with your notation, for instance in the static intrinsic gradient compression algorithm why use $\\mathcal{L}$ as loss. In section 2.1 wouldn\'t it be more appropriate to replace $\\theta_2$ with $\\theta^\\prime$; also does it hold that $T < L$? Moreover, why refer to $\\ell$ as a task when it has already been defined as loss, maybe another symbol could resolve this. A couple notations and concepts used in algorithm 1 are never presented in the paper (e.g., $A(\\sum_{t-1}$) - no need for parenthesis, $z_j$, sketches). In section 3, shouldn\'t be $A\\theta^\\prime + \\theta_0$ instead of $A\\theta^\\prime$ in the subscript of function f in the first line of equations? Also, how did you derive the A transpose multiplied with the gradient transpose from the previous line and in equation (5) why is $A\\theta_{t+1}^\\prime$ equal to $\\theta_{t+1}$?\n\n\n[1] Jiang, Yuang, Shiqiang Wang, Victor Valls, Bong Jun Ko, Wei-Han Lee, Kin K. Leung, and Leandros Tassiulas. ""Model pruning enables efficient federated learning on edge devices."" arXiv preprint arXiv:1909.12326 (2019).\n\n[2] Bibikar, Sameer, Haris Vikalo, Zhangyang Wang, and Xiaohan Chen. ""Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better."" arXiv preprint arXiv:2112.09824 (2021).', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_S2Br'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_S2Br']}, {'id': 'rhMgz5JYYz9', 'original': None, 'number': 2, 'cdate': 1648099210227, 'mdate': None, 'ddate': None, 'tcdate': 1648099210227, 'tmdate': 1648099210227, 'tddate': None, 'forum': 'H3NUh9Kft-c', 'replyto': 'H3NUh9Kft-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/-/Official_Review', 'content': {'title': 'Adopting a classical sketching idea into federated learning applications', 'review': 'This paper proposes to use a classical sketching idea in federated SGD-like algorithms to improve the communication efficiency of federated learning algorithms. The proposed method has been used widely in centralized distributed SGD with good efficiency. Thus I am a bit concerned about the novelty of the paper.\n\nConceptually, I believe the sketching idea can also be adopted on top of federated averaging, i.e., conduct $A^\\top A$ over the model updates instead of gradient updates. How does that variant work? Moreover, the error feedback scheme seems to be always helpful for gradient/model compression, does it also help the proposed method?', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_MH3S'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_MH3S']}, {'id': 'H6Gg5eQ2HGq', 'original': None, 'number': 1, 'cdate': 1647850225549, 'mdate': None, 'ddate': None, 'tcdate': 1647850225549, 'tmdate': 1647850225549, 'tddate': None, 'forum': 'H3NUh9Kft-c', 'replyto': 'H3NUh9Kft-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/-/Official_Review', 'content': {'title': 'The authors propose a set of communication-efficient federated learning algorithms that are based on the prior idea of intrinsic dimension in theoretical machine learning. ', 'review': 'The authors propose a set of communication-efficient federated learning algorithms that are based on the prior idea of intrinsic dimension in theoretical machine learning. Essentially, it has been known in theoretical ML that in the overall parameter space of the ML model, there is an intrinsic subspace, with potentially much smaller dimension than the model parameter space, where optimization can be carried out. Exploiting this concept and related ideas on intrinsic dimension, the authors propose a set of three novel strategies that enables compression of updates communicated between the FL server and clients, reducing the communication load dramatically. The underlying idea is to use a projection matrix for compression at the clients/decompression at the server, so that both training and global update can be done in the model parameter space while communications can be done in the lower dimensional space. The first algorithm considers the projection matrix to be fixed throughout training, the other two consider different versions of variable projection matrices. Multiple experiments for NLP and vision tasks have been presented that demonstrate reasonable drop in accuracy even for very high (>1000x) compression rates.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_sQhs'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_sQhs']}]"
https://openreview.net/forum?id=B2E4hqYfKWq ,B2E4hqYfKWq,"[{'id': 'B_blH-rtTz9', 'original': None, 'number': 4, 'cdate': 1648362749214, 'mdate': None, 'ddate': None, 'tcdate': 1648362749214, 'tmdate': 1648362893599, 'tddate': None, 'forum': 'B2E4hqYfKWq', 'replyto': 'B2E4hqYfKWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/-/Official_Review', 'content': {'title': 'Concerns about the privacy definition', 'review': 'This paper proposed adaptive differential privacy. For a DP-SGD like algorithm, when adding noise, this paper proposed to use the ""frequency"" to scale the noise. The ""frequency"" is estimated by estimating perplexity based on a trustworthy language model. \n\nMy main concern is that the privacy definition is not clear to me. Is it possible to give a formal definition for adaptive DP and its accounting,  something similar to Def 2.4 in ""The Algorithmic Foundations of Differential Privacy"" and Theorem 1 of ""Deep Learning with Differential Privacy"". Without a definition, I cannot understand how the (\\epsilon, \\delta) bound is computed and compared. \n\nA relatively minor concern is that it is not clear to me how to get the trustworthy language model. If it is based on public data, why it can represent the private data?', 'rating': '4: Ok but not good enough - rejection', 'confidence': '2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_7hxZ'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_7hxZ']}, {'id': 'BbNeQxtUtzq', 'original': None, 'number': 3, 'cdate': 1648089323006, 'mdate': None, 'ddate': None, 'tcdate': 1648089323006, 'tmdate': 1648089323006, 'tddate': None, 'forum': 'B2E4hqYfKWq', 'replyto': 'B2E4hqYfKWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/-/Official_Review', 'content': {'title': 'review', 'review': ""This paper proposes a novel look at differentially private training by focusing on adding more noise to data points that are rare and less noise to popular datapoints, e.g. making an adaptive noise. \n\nThis idea is interesting, however, it contradicts multiple important assumptions of differential privacy: \n1. DP says that removal of any point should result in roughly the same model, however from the proposed method not all the points are equal, e.g. some datapoints experience more noise than others. Therefore the proposed algorithm will not be differentially private.\n2. Noise is correlated against a pre-trained model assuming that the training dataset is also correlated with the dataset that the pre-trained model was trained on. For example, let's assume that the dataset that I want to train my model on contains password recovery questions and answers from the users -- any common phrase (from the pre-trained dataset) will then receive less noise, but since all of those pass answers are sensitive then it will violate privacy of these secret answers. This is the weird case, as you wouldn't want to train such a model but hopefully it shows that now the guarantees depend on some pre-trained model with a custom dataset.\n\nLastly the performance results in Table 1 demonstrate that if you increase privacy budget epsilon then the results improve which is trivially obvious. It might have been more correct to compare performance of your algorithm with budgets of the same value.\n"", 'rating': '4: Ok but not good enough - rejection', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_JsH6'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_JsH6']}, {'id': 'Hlg0My8Kz5', 'original': None, 'number': 2, 'cdate': 1648086806515, 'mdate': None, 'ddate': None, 'tcdate': 1648086806515, 'tmdate': 1648086806515, 'tddate': None, 'forum': 'B2E4hqYfKWq', 'replyto': 'B2E4hqYfKWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/-/Official_Review', 'content': {'title': 'This paper scales the noise to be inversely proportional to sequence frequencies to reduce exposures of privacy data. This is an interesting idea, but part of the experiments needs more explanation and can be improved. ', 'review': ""Thanks for the submission! This paper proposes to treat privacy and non-privacy data differently to improve differentially private language modeling. More specifically, this paper first made a reasonable assumption that texts with privacy information do not occur frequently in a large dataset. Based on that, the algorithm estimates the privacy probability to be proportional to the perplexity of a specific sequence. Then, the authors introduce a privacy weight, representing the privacy probability, to scale the gaussian noise. Experiments show that the proposed algorithm achieved lower test loss/perplexity and at the same time reduced the exposure of canaries. \n\n1. Since the algorithm scales the noise based on the inverse of sequence frequency, I assume this means infrequent non-privacy sequences would also end up with high perplexity? Will this be a problem?\n2. Having privacy data like “My ID is 955320” occurring 1000 times seems rare. Are there any statistics or related work describing what are the reasonable configurations for evaluations?\n3. I am curious about how the proposed algorithm compares to a slightly modified version which simply drops sequences below a certain frequency and then applies the same privacy weight to the rest of the dataset. \n4. DP-SGD seems achieved a lower exposure compared to the proposed algorithm when the canary count is 10. What is the reason for this? This seems to be a legit problem as it's likely that privacy data will occur less than 10 times, no?\n"", 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_c46X'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_c46X']}, {'id': 'BfMxD7cC_f9', 'original': None, 'number': 1, 'cdate': 1648056863437, 'mdate': None, 'ddate': None, 'tcdate': 1648056863437, 'tmdate': 1648056863437, 'tddate': None, 'forum': 'B2E4hqYfKWq', 'replyto': 'B2E4hqYfKWq', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/-/Official_Review', 'content': {'title': 'Interesting topic and idea, but contribution is not clear', 'review': 'Overall, I think the topic of paper would be interesting for the workshop, but contribution of the paper is not clear to me. I am concerned whether there is a contribution in the method as it does not compare its proposed method with standard methods for detecting private data. I am also concerned about its empirical results as it only compares with a method published in 2016.\n\n\nBelow are some comments that I hope authors will find useful.\n\nPaper describes its motivation and contribution clearly. But the following statement was not convincing for me: ""There are some previous works detecting sensitive information in un-structured texts, but relying on labeled keywords or reference texts."" \n\nInstead of using the above literature, authors claim that probability of data being private is inversely related to its occurrence frequency. While this might be a good rule of thumb, authors have not verified it. Authors mention this assumption to be one of their contributions ""we propose a method to automatically estimate the probability that a linguistic item contains privacy information..."". Why is this a contribution? Why is this proposed method better than those methods that use keywords and reference text? Does this estimation method based on frequency of the words perform better?\n\nAuthors give social security number as one example of private data. Does their method of inferring privacy based on occurrence frequency work well in detecting SSN? Would the method gather each and every number that appears once in the text? Why should we not use known references and keywords and adopt this proposed method? Is it because this method is faster or more accurate? Authors have not compared their method with standard methods for detecting private data.\n\nAuthors use the term ""non-privacy data"" over and over. perhaps they mean to say ""non-private data""?\n\nThere is considerable repetition in Introduction and Related Work sections. \n\nContribution of Abadi et al (2016) is described many times in the paper.\n\nAlgorithm 1 is already in the literature except that one line of it is modified based on equation (5). It is not clear why it has to be provided in the main text of the paper.\n\nMethod is compared with Abadi\'s method published in 2016. There are more recent methods in the literature that authors can consider comparing with.  Results do not appear to be convincing.', 'rating': '5: Marginally below acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_Zgb7'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_Zgb7']}]"
https://openreview.net/forum?id=raDf3qKzYb5 ,raDf3qKzYb5,"[{'id': 'HrrghpUFKz9', 'original': None, 'number': 4, 'cdate': 1648101059866, 'mdate': None, 'ddate': None, 'tcdate': 1648101059866, 'tmdate': 1648101059866, 'tddate': None, 'forum': 'raDf3qKzYb5', 'replyto': 'raDf3qKzYb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/-/Official_Review', 'content': {'title': 'Review of the paper', 'review': 'This paper considers an important and timely problem in federated learning on knowledge graphs (KGs), especially developing an attack model which incurs privacy leakage in an existing work, named FedE, and proposing a new privacy-preserving embedding aggregation framework to protect the privacy against the attack.\n\nThis paper proposed the attack model which can reconstruct original entities and relations of individual client based on the local embedding matrix, which is an important finding in Federated Knowledge Graph Completion from the privacy perspective. It empirically demonstrates the effectiveness of the attack with a simple 3 clients-model. Then, this paper proposed a relation embedding aggregation framework to reduce the privacy leakage while it also reduces the required bandwidth to achieve the target MRR.\n\nIt is worth to discuss the proposed attack model and defense mechanism even though the reviewer has the following concerns. \n1.\tThis paper does not contain the system model of FedE and attack model in the main body. Before reading the Appendix C and D, I cannot capture the which information is communicated between the server and clients, which information is known to the server and colluding client, and how to reconstruct the private local information. It would be helpful to provide the system model (including definition of entity/relation embeddings and  local/global update equation, and … etc)\n2.\tIn addition to 1, it is unclear what is the global update equation based on the local relation embeddings in the proposed framework, FedR.\n3.\tThere are minor typos such as: 1) there is (?) in Appendix A 2) paris => pairs in Algorithm 1 in Appendix C.\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_r89r'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_r89r']}, {'id': 'rRGeIu6HtGc', 'original': None, 'number': 3, 'cdate': 1648086382253, 'mdate': None, 'ddate': None, 'tcdate': 1648086382253, 'tmdate': 1648086382253, 'tddate': None, 'forum': 'raDf3qKzYb5', 'replyto': 'raDf3qKzYb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/-/Official_Review', 'content': {'title': 'Review', 'review': ""This paper proposed a novel reconstruction attack method to infer the client's data utilizing the model updates in a knowledge graph setting. The proposed method achieves strong attacking accuracy on previous baselines. To overcome this, the authors further proposed a new method called FedR robust to the proposed reconstruction attack method. \n\nThe method is interesting. The idea of sharing relation embedding rather than head/tail embedding for aggregation is novel and seems to effectively prevent exact inference of the user data. The experimental results seem strong and significantly outperform prior work on multiple benchmarks. Here are some of my concerns:\n- Rather than saying the proposed FedR is 'privacy-preserving', it seems that FedR is only robust to the proposed attacking method. There are a couple of things missing here: 1. How does the success rate of the attacking method transfer to the privacy level of the randomized algorithm to train KG? Could it transfer to any formal differential privacy guarantee? 2. How to evaluate the optimality of the attack evaluated in this work? Could there be stronger, defense-aware attack that could similarly break FedR? It would be great if the authors could provide additional details for these points.\n- Could the authors add a related work/background section to list relevant work on reconstruction attacks/FL on KG?\n- Could the authors add a clear algorithm description on FedR?\n- In the description of experiment, the authors claim each dataset is randomly split among clients? Does that mean the data are homogeneous among all the clients? In a typical FL setting, data are heterogeneous on each client. Could the authors add experiments on experiments under heterogenous data?"", 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_do3D'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_do3D']}, {'id': 'rc8larlpdGc', 'original': None, 'number': 2, 'cdate': 1648050244777, 'mdate': None, 'ddate': None, 'tcdate': 1648050244777, 'tmdate': 1648050244777, 'tddate': None, 'forum': 'raDf3qKzYb5', 'replyto': 'raDf3qKzYb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/-/Official_Review', 'content': {'title': 'Good idea, but some inaccuracies', 'review': 'I think overall, this paper would be interesting for the workshop, and authors have proposed an interesting approach. There are issues in presentation and claims which can be improved and fixed. Hopefully, discussions at the workshop can help authors gather more feedback and continue their work.\n\n\nBelow are some comments which I hope authors will find useful to improve their work.\n\nIt seems that authors are proposing to modify the FL setting, by assuming that server might collude with the clients. This is a modified definition of privacy for FL which is fine and interesting. However, in the abstract and introduction, authors seem to claim that they have found a severe privacy leakage for FedE method and they want to address that severe shortcoming. Contribution of this paper can be explained more clearly starting with the assumptions used in FL literature, FedE method, and authors\' method.\n\nStatements like ""FedE is not privacy-preserving"" are meaningless without proper definition of ""privacy"". From authors\' point of view, how many of the methods in FL literature can be considered ""privacy-preserving""?\n\nPhrases like ""much more"" for communication efficiency seem to be overly vague.\n\nFunction f(h,r,t) is not defined properly.\n\nIt is not clear what authors mean by ""honest-but-curious"" server. If the server is honest why should we go through all these trouble to hide the data? Authors have to define what they mean by ""honest"" and how that affects their formulation.\n\nIf a client is a traitor and shares the data with the server, why would it share only a percentage of its data and not all of it?\n\nMethod is not presented in a coherent way. First, it is mentioned that ""To guarantee the data privacy in the FedE, FEDR adopts two main strategies"". Despite this guarantee, a paragraph later, it is mentioned that ""the server still can roughly infer the relation by comparing the uploaded relation embedding with the one stored..."". It is not clear what ""roughly"" entails here and how it can combine with the statements before. It sounds like authors do not have a clear definition of privacy in mind, are they are putting bandaids on various shortcomings that they consider. The word ""guarantee"" seem to lose its meaning.\n\nFigure 4 which provides the comparison with other methods does not depict the performance of proposed method. In the legend, proposed method is shown as a solid black line, but in the plot, there is no such line.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_rKgA'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_rKgA']}, {'id': 'Hd_euz_4Tbq', 'original': None, 'number': 1, 'cdate': 1647294479841, 'mdate': None, 'ddate': None, 'tcdate': 1647294479841, 'tmdate': 1647294479841, 'tddate': None, 'forum': 'raDf3qKzYb5', 'replyto': 'raDf3qKzYb5', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/-/Official_Review', 'content': {'title': 'Review on ""Efficient Federated Learning on knowledge Graphs via Privacy-Preserving Relation Embedding Aggregation""', 'review': 'This work presents an extension of FedE, a recently proposed knowledge graph aggregation scheme in Federated Learning. Specifically, the authors tackle the privacy issue by aggregating relation embedding instead of directly aggregating the entity embedding.\n\nAlthough the idea is quite simple, it effectively addresses the privacy issue while maintaining the model performance. I appreciate this idea and advocate accepting the article in this workshop. I see a few things that can be improved as follows.\n\n1. The experimental settings can be improved. The number of clients is obviously too small. Federated Learning is a large-scale distributed learning paradigm. Considering the total number of entities in the benchmark datasets, the dataset can be distributed to more than 20 clients. If the number of clients is hundreds for example, would similar performance benefits still be available?\n\n2. Although FedE is the recently proposed representative work, comparing FedR to this single work does not provide useful insights. Additional comparisons to other works (especially referenced in FedE paper) will significantly strengthen the paper.', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_XHJY'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_XHJY']}]"
https://openreview.net/forum?id=ShNG29KGF-c ,ShNG29KGF-c,"[{'id': 'rZ4gQC_bnM9', 'original': None, 'number': 3, 'cdate': 1648265419434, 'mdate': None, 'ddate': None, 'tcdate': 1648265419434, 'tmdate': 1648265419434, 'tddate': None, 'forum': 'ShNG29KGF-c', 'replyto': 'ShNG29KGF-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/-/Official_Review', 'content': {'title': 'Overall nice work analyzing different ways to scale federated training of transformers', 'review': ""## Summary\nThis paper primarily studies the effect of partial variable training, quantization, and their combinations to enable training large language models in a federated setup. These techniques allow training large language models in cross-device federated configurations. They show that quantizing the models before uploading and downloading can reduce training costs with marginal drops in performance. \n\n### Main Observations:\n- Model quantization before uploading from local learners is more effective than quantizing before downloading to the local learner.  \n- Partial variable training combined with quantization further reduces the training and communication load.\n- Transfer learning or pretraining can speed up federated training.\n\n## Suggestions:\nOverall, I like the paper's analysis of different options available for scaling up federated training for language models and the paper is well-written. However, it still lacks comparison with prior works and baselines. For example, an alternative approach to PVT could be model pruning. So, it would be nice to compare with model pruning baselines such as TPrune ([https://dl.acm.org/doi/10.1145/3446640](https://dl.acm.org/doi/10.1145/3446640)). \n\nAlso, please clarify the following in writing:\n- How was tokenization done for federated experiments --- centralized or federated? Please clarify. \n- Do you exchange model parameters or the changes in parameters for upload and download? While this may be a minor detail, it could affect quantization performance. "", 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_kZQV'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_kZQV']}, {'id': 'SlxoQpwizc', 'original': None, 'number': 2, 'cdate': 1648225570967, 'mdate': None, 'ddate': None, 'tcdate': 1648225570967, 'tmdate': 1648225570967, 'tddate': None, 'forum': 'ShNG29KGF-c', 'replyto': 'ShNG29KGF-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/-/Official_Review', 'content': {'title': 'Official Review', 'review': '**Summary Of The Paper:** This paper leverages several techniques for mitigating the communication and computation bottlenecks to train a Transformer in cross-device federated learning. They systematically evaluate partial model training, quantization, efficient transfer learning, and communication-efficient optimizers,\n\n**Strengths.**\n- This paper is easy to read and has good structure, and is complete and coherent.\n- The topic is interesting and important because the large transformer model has become mainstream in the NLP community. It is necessary to consider how to deploy this kind of large model in the client.\n- The design of experiments is sufficient and comprehensive.\n\n**Weaknesses.** \n- All the methods are general so it would be better to design a novel method. However, I think it is okay for an analytical paper.\n\nOverall, in my view, this is a high-quality paper.', 'rating': '9: Top 15% of accepted papers, strong accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_D9ht'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_D9ht']}, {'id': 'HBeeq_sEKMc', 'original': None, 'number': 1, 'cdate': 1648081778327, 'mdate': None, 'ddate': None, 'tcdate': 1648081778327, 'tmdate': 1648081778327, 'tddate': None, 'forum': 'ShNG29KGF-c', 'replyto': 'ShNG29KGF-c', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/-/Official_Review', 'content': {'title': 'review', 'review': '**Summary**\nThe paper studies cross-device federated learning for the problem of language modelling. The paper conducts a series of empirical studies to show that large and high-performing language models can be trained in the cross-device setting, with large Transformers partially fine-tuned through federated updates and quantized communication achieving very good performance. \n\n**Overall comments**\nThe paper conducts a careful empirical study on how high-performing language models can be trained in the cross-device setting. While the techniques and methods employed in the paper already exist in the literature, the empirical results demonstrated in the paper has high practical value (and would therefore be considered as significant) to practitioners. The paper is therefore of high quality. The paper is also written clearly. I therefore recommend acceptance.\n', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_HMNd'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_HMNd']}]"
https://openreview.net/forum?id=SawenqFzFb9 ,SawenqFzFb9,"[{'id': 'BxWgKOs7az9', 'original': None, 'number': 3, 'cdate': 1648339824967, 'mdate': None, 'ddate': None, 'tcdate': 1648339824967, 'tmdate': 1648339898825, 'tddate': None, 'forum': 'SawenqFzFb9', 'replyto': 'SawenqFzFb9', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/-/Official_Review', 'content': {'title': 'Simple idea, strong empirical performance. Rigorous evaluation including interesting ablation analysis.', 'review': '## Strengths\n- Simple approach, trivial to implement\n- Strong empirical performance\n- Thorough empirical evaluation: multiple benchmarks (including skewed version of Sent140), ablation over token lengths and types of user-ids, performance of unseen users\n- Privacy preserving. Rand.All can be implemented locally with no privacy loss (Def. and Num. cannot, but they don\'t work as well)\n\n## Weaknesses\n- No comparison against some other popular FL personalization schemes (like Ditto). UserAdapter is the only comparison, while something like Ditto or pFedMe are more established\n- It is not clear why trainable user embeddings perform worse (it is very unintuitive, at least to me). Authors mention that ""coupling learning problems in both domains is useful"", but a deeper analysis might help. \n- Their intuition on why UserIdentifier outperforms UserAdapter (collaborative learning and personalization is happening simultaneously). I don\'t understand how UserIdentifier performs any collaborative learning. Assume UserA and UserB behave ""similarly"", and a method that does collaborative learning might learn this and exploit it. In UserIdentifier, A and B would get random ids - so no collaborative learning would happen\n- Large, over-parameterized models like RoBERTa-base or BERT-base are not practical in FL (on-device constraints). Would their scheme work in smaller models, where the embeddings are smaller and less over-parameterized?\n\n## Suggestions\n- Consider expanding to harder FL-NLP problems outside of sentiment classification (e.g, LM)\n- Does this scale to a large #users, say millions? As the #users increase, almost all token embeddings will be modified by some user?\n- An interesting setting would be running UserIdentifier in the same setting as UserAdapter: personalization as a separate task after global training\n- On \'unseen\' users: Another interesting setting would be to run local run train + eval on unseen users (instead of just eval, as you do)\n', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_XFKB'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_XFKB']}, {'id': 'rTPl3Dq-hfc', 'original': None, 'number': 2, 'cdate': 1648265827802, 'mdate': None, 'ddate': None, 'tcdate': 1648265827802, 'tmdate': 1648265892110, 'tddate': None, 'forum': 'SawenqFzFb9', 'replyto': 'SawenqFzFb9', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/-/Official_Review', 'content': {'title': '   ', 'review': '## Summary\n\nThis paper proposes learning a personalized sentiment analysis model from the text by appending or prepending a user-specific string (termed ""UserIdentifier"") to the input text. Then a single transformer model is finetuned on data from all the individuals. Incorporating user identifiers help learn a better and more personalized model for each individual. The proposed method is compared with three other approaches --- finetuning with original data, finetuning with original data followed by prefix-tuning, and finetuning with trainable user identifiers. The authors justified their choice of selecting user-identifiers by appropriate ablation experiments. The ""UserIdentifier"" approach outperforms other baselines on Yelp, Sent140, and IMDB datasets. \n\n## Strengths:\n- Although the solution builds upon recent findings that demonstrate parameter efficient finetuning/few-shot learning by prompting with task-specific texts or introducing trainable input embeddings, the idea of introducing user-specific strings is interesting. \n- I appreciate that the authors discussed different ways to assign user-identifiers and tried to partially explain the best choice in Sec A.3 and 4.3.\n- The paper also studied generalization to new users briefly. Interestingly, the model performance is almost similar to finetuning with no user-identifiers (though slightly lower), thus providing personalization without hurting. \n\n\n## Scope for Improvement:\n- **Federated vs. Centralized Setups**: \nSince we are eventually interested in a federated setup and personalized models, one of the baselines would be training a model per user, which is missing. While this may not be parameter efficient, each user will train its model on their local machine saving massive communication costs and maybe using similar or compute. The authors should discuss this scenario in the paper at least.  \n- **Writing**:\n     - a. The main paper is mainly motivated by federated learning & need for personalized models, but the experiments are performed in a centralized setup which is ok. However, this is not clarified until sec 4. It would be nice to have this clarified in the introduction. \n     - b. Sec 4.3 last paragraph ignores the L parameter in the discussion. The overlap will be much less even with just L=2 and sample space=400.\nMinor: Table 4 is in the appendix. Either use a different numbering convention or add a small note in brackets that it is in the appendix. \n- **Trainable Embeddings**:\nIt is counterintuitive that fixed prefixes outperform trainable embeddings, as Li & Liang (2021) and Hambardzumyan et al. (2021) show that it outperforms fixed prefixes. Even though the above references are not in the same context, ideally, more flexibility should help improve the model training. This raises the question if this can be explained by overfitting? Did the author compare training performance for these models? \nThe authors argue in the paper that simultaneous adaptation of parameters hurts learning. Would further ""embedding only training"" of the ""UserIdentifier"" approach improve or maintain performance? \n\n### Refs:\n- WARP: Word-level Adversarial ReProgramming (Hambardzumyan et al., ACL 2021)\n- Prefix-Tuning: Optimizing Continuous Prompts for Generation (Li & Liang, ACL 2021)\n', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_wnZb'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_wnZb']}, {'id': 'H87e-EbXYzc', 'original': None, 'number': 1, 'cdate': 1648075049512, 'mdate': None, 'ddate': None, 'tcdate': 1648075049512, 'tmdate': 1648075218872, 'tddate': None, 'forum': 'SawenqFzFb9', 'replyto': 'SawenqFzFb9', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/-/Official_Review', 'content': {'title': 'review', 'review': ""**Summary**\n\nThe paper proposes a data augmentation method to handle personalized prediction for text classification problems. \n\n**Overall comments**\n\nThe method is simple and seems to work well on the toy problems studied in the paper. The experiments are adequate for a workshop paper (but can be improved to provide more insight into the performance). The writing is clear. The paper is on topic. I list drawbacks below.\n\n**Cons**\n- The paper compares different methods on simple datasets for the task of sentiment classification. To make the empirical study more compelling, one may consider additional tasks (language generation) and datasets (GLUE, table2text, dialog, summarization).\n- It's unclear how the method improves upon baselines with better pre-trained models, e.g., Roberta*-large*. \n\n**Other suggestions**\n- The method could be combined with federated learning. \n- The paper explores different ways to create the user-identifier in text format, but one could easily imagine the user-identifier being prompt embeddings directly -- randomly sample high-dimensional gaussians for each user as their prompt embedding. "", 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_RU41'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_RU41']}]"
https://openreview.net/forum?id=B3z-nctzFZ5 ,B3z-nctzFZ5,"[{'id': 'SOdls4X7pzc', 'original': None, 'number': 3, 'cdate': 1648337715124, 'mdate': None, 'ddate': None, 'tcdate': 1648337715124, 'tmdate': 1648337758626, 'tddate': None, 'forum': 'B3z-nctzFZ5', 'replyto': 'B3z-nctzFZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/-/Official_Review', 'content': {'title': 'Novel and interesting approach to personalization. Extension from mean estimation to non-convex loss is not clear. ', 'review': ""Originality: High. \nAdaPerFL uses a novel, interesting and rigorous Bayesian approach to evaluate Personalization in Federated Learning (FL). To motivate the framework, the authors assume a generative hierarchical Gaussian model. FL is used for mean estimation. The authors quantify the benefit of FL in this setting (compared to a local estimation) as Personalized FL gain. \nThe concepts of inter-client certainty and intra-client certainty are very natural and potentially useful.\nEquation (10) could be a very interesting approach to global model aggregation and feels natural (inversely weighting by variance of each local estimate)\n\nClarity: Low. \nThe first part of the paper is very clear - generative Gaussian model.\nEverything after Remark 2 is not very clear. And why should optimal initialization, learning rate and #steps that are useful for a specific convex problem (mean estimation in a hierarchical Gaussian) be applicable to non-convex deep learning? Why is equation (10) useful? How does convergence to a stationary point proceed if we use eq (10)?\n\nThe empirical evaluation is also not clear. On Sent140, the authors claim that AdaPerFL is better than Ditto, but the graphs shows test accuracy to be the same. A table here would make things much clearer. On Alexa, the main benefit seems to be using equal weighted averaging instead of example weighted averaging. The benefits between FedAvg-e and AdaPerFL is small, but the difference between FedAvg-e and FedAvg-w is very large (not observed by other papers).\n\nSignificance: Medium. \nThis is a very interesting direction and approach to FL and Personalization. However, the extension to non-convex problems is not clear. And the experimental evaluation can be improved.\n\nQuality: Medium. \nOverall, I'd say the quality is medium. There is an original and potentially significant contribution here. The authors could improve the quality by proving convergence behavior of equation (10), and showing why the choice of {LR, initialization, step size} for mean estimation are useful in completely different problems that are not even convex. The experimental evaluation can also be much better. \n"", 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_RVNp'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_RVNp']}, {'id': 'H8ml0dlttf5', 'original': None, 'number': 2, 'cdate': 1648099445595, 'mdate': None, 'ddate': None, 'tcdate': 1648099445595, 'tmdate': 1648104432716, 'tddate': None, 'forum': 'B3z-nctzFZ5', 'replyto': 'B3z-nctzFZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/-/Official_Review', 'content': {'title': 'Interesting Bayesian formulation of the personalized federated learning problem.', 'review': 'Summary:\nIn this work, the authors introduce a Bayesian formulation of the personalized federated learning problem and provide theoretical insights on how to quantify (inter- and intra-) clients uncertainty during federated training. Their propose solution, AdaPerFL, views the personalization problem from the lens of a two-layer Bayesian hierarchical model that can lead to an automatic determination of the local training steps of each client and a heterogeneous- and uncertainty-aware global model aggregation rule. \n\nStrong and Weak Points:\n\n(S1) Interesting Bayesian formulation of personalized FL.\n(S2) Evaluation over a range of existing baselines.\n\n(W1) Related work and additional background/preliminary information is missing.\n(W2) Provided evaluation does not show AdaPerFL\'s improved performance.\n(W3) Missing details on experimental evaluation.\n\n\n(W1) A section that provides more background knowledge in the context of personalized FL (e.g., [1]) \nand discussion on existing Bayesian Federated Learning formulations (e.g., [2]) is missing. \nSection 2 could be summarized and placed in an Appendix in favor of such a section. Within the \nproposed section it would also be better to discuss how your approach is compared to the experimental \nbaselines so that non-expert readers can understand the trade-offs of the different approaches. Moreover,\nin equation (1) it is not clear how the definitions are derived (sum over posterior distributions?). Also, \nhow is the local objective equation (3) derived? Even though the authors discuss uncertainty quantification \nthrough GAIN, the metric is never used in the rest of the paper. What is the update rule of LocalTrain \nin Algorithm 1? Is it the local update rule presented in equation (4)?\n\n(W2) Equally weighted FedAvg seems to provide the same performance as AdaPerFL in the wake-word detection task. \nSimilar for the DITTO-e. Can the authors elaborate more on these results? Moreover, there do not seem to be any \nimprovements on the sentiment analysis task both in terms of testing and training performance. Maybe, it would\nhave been better to demonstrate the results as in the case of the Alexa Audio domain by randomly sampling a set\nof clients from the available pool of 772 clients and showing the performance of the global and personalized \nmodels on a test dataset. Additionally, it is not clear why pretraining was required for both learning tasks \n(first task is reasonable since it is harder domain bit why for the second?), maybe that reasons the learning \nbehavior in the sentiment analysis task (i.e., similar performance for all approaches)? Table 1 and Figure 1 \nhave Self-FL as a method which is never introduced; I suspect that this the AdaPerFL.\n\n(W3) For the first task you only consider 5 clients for a federation. Why a so small number?  What is the distribution\nof training/valid/test sets at each client (s/th like {\'train\': #, \'valid\': #, \'test\': #} would be appropriate) in this task?\nMoreover, your proposed method is an adaptive learning approach, what is the distribution of local steps per client in your\nexperiments? Is there a particular range of local step values that each client or all clients follow? To assign the local steps\nto each client do you use the empirical estimations of equations (11) and (12) in equation (7)? What is the learning rate\nyou used for training?  \n\n[1] Wu, Jinze, Qi Liu, Zhenya Huang, Yuting Ning, Hao Wang, Enhong Chen, Jinfeng Yi, and Bowen Zhou. \n""Hierarchical personalized federated learning for user modeling."" In Proceedings of the Web Conference 2021, pp. 957-968. 2021.\n\n[2] Yurochkin, Mikhail, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia Hoang, and Yasaman Khazaeni. \n""Bayesian nonparametric federated learning of neural networks."" In International Conference on Machine Learning, pp. 7252-7261. PMLR, 2019.', 'rating': '5: Marginally below acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_8xw5'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_8xw5']}, {'id': 'rSSgedRo8Gq', 'original': None, 'number': 1, 'cdate': 1647914600267, 'mdate': None, 'ddate': None, 'tcdate': 1647914600267, 'tmdate': 1647914600267, 'tddate': None, 'forum': 'B3z-nctzFZ5', 'replyto': 'B3z-nctzFZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/-/Official_Review', 'content': {'title': 'Interesting perspective on personalized FL ', 'review': 'Summary: The work presents a framework to analyze personalized FL with bayesian models where the posterior mean for each FL (collaborative training) and local training are theoretically analyzed so that the uncertainty of each model can be quantified, and utilized for maximum personalized FL performance. With this framework, the paper gives theoretical insights into how PFL performance can be maximized by the proper initialization, number of local steps, and global model aggregation. Empirical experiments are done on Alexa Audio Data and Sent140 Data for validation of the proposed algorithm.\n\nPros: \n- The paper looks at an important problem of personalization in FL in the views of Bayesian models which has not been looked into a lot before.\n- The paper is clear to read including the mathematical notations and description of the algorithms. \n- The paper gives a concrete analysis into what kind of parameters (initialization, local steps, and aggregation) affect the personalized FL performance in a Bayesian framework and the exact forms of those parameters to maximize personalized FL performance.\n- The paper includes empirical validation on two different datasets.\n\nCons:\n- Although the theoretical insights are interesting, they are very difficult to implement in practice due to the pre-knowledge on the variance (uncertainty) for deciding the initialization and local steps. However, despite this difficulty, the AdaPerFL that the paper proposes is able to use the sample-variance to circumvent this problem and achieve reasonable performance, thus managing to compensate for this drawback. \n\n\n\n', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_S4x7'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_S4x7']}]"
https://openreview.net/forum?id=S3ExnqKfF-9 ,S3ExnqKfF-9,"[{'id': 'HgezltOtG5', 'original': None, 'number': 3, 'cdate': 1648097513970, 'mdate': None, 'ddate': None, 'tcdate': 1648097513970, 'tmdate': 1648097513970, 'tddate': None, 'forum': 'S3ExnqKfF-9', 'replyto': 'S3ExnqKfF-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/-/Official_Review', 'content': {'title': 'Effective method for conducting backdoor attack of federated NLP tasks', 'review': ""This paper introduces a practical approach for injecting backdoor attacks into a federated learned model. The attackers only manipulate the embedding layers of a model for injecting the backdoor. Compared to the previously proposed backdoor attack on language models (where the attacker manipulates to change all layers' weights), the proposed attack is easier to inject and is harder to detect by the central server.\n\nExtensive experimental results indicate that the proposed attack is effective under various NLP tasks and transformer models. I'm convinced that the proposed attack is effective given the scales of the experiments."", 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_fc7i'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_fc7i']}, {'id': 'SW4x7e6q8zq', 'original': None, 'number': 2, 'cdate': 1647910122707, 'mdate': None, 'ddate': None, 'tcdate': 1647910122707, 'tmdate': 1647910145731, 'tddate': None, 'forum': 'S3ExnqKfF-9', 'replyto': 'S3ExnqKfF-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/-/Official_Review', 'content': {'title': 'Interesting topic and the method can be further improved', 'review': 'This work proposes a practical backdoor attack against NLP models in the Federate Learning scenarios by inserting malicious tokens in the word embeddings. The author demonstrates its effectiveness through many practical scenarios, e.g., large trigger tokens, etc. It would be better to explore inserting backdoor triggers in a more stealth manner, e.g., inserting incontinuous or dynamic backdoor triggers, inserting backdoor triggers without adding too many tokens besides the benign tokens. Since the attack method is adapted from CV methods, the robustness of the proposed method against potential defense mechanisms adapted from Image Classification tasks [1,2] should also be discussed.\n\n[1] Wang, Bolun, et al. ""Neural cleanse: Identifying and mitigating backdoor attacks in neural networks."" 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019.\n\n[2] Guo, Junfeng, Ang Li, and Cong Liu. ""AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis."" ICLR (2022).', 'rating': '5: Marginally below acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_ECVk'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_ECVk']}, {'id': 'rKIg1FTULf5', 'original': None, 'number': 1, 'cdate': 1647893879483, 'mdate': None, 'ddate': None, 'tcdate': 1647893879483, 'tmdate': 1647893879483, 'tddate': None, 'forum': 'S3ExnqKfF-9', 'replyto': 'S3ExnqKfF-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/-/Official_Review', 'content': {'title': 'review', 'review': 'The paper presents a new attack extension of the embedding attack on NLP models to FL. Instead of training to optimize the whole model the attacker only focuses on a small single embedding of an unpopular token. \n\nI really liked the idea and think that it has a good potential impact, however I have a couple of concerns:\n\n1. Motivation -- FL in NLP is motivated by a smart keyboard application and therefore language generation task. I did not understand motivation under seq2seq tasks, neither summarization nor translation seem like would be good candidates for FL as there are no privacy constraints. I can understand classification, but not on the news dataset (which is hardly private) but rather some toxicity dataset.\n\n2. Experiments -- some details on seq2seq task would be great otherwise it\'s unclear what task exactly gets evaluated (I assume it\'s a summarization task as it uses ROUGE but still not clear). ""Trigger range"" discussion is also complex as it wasn\'t introduced before. \n\n3. Novelty -- the backdoor attacks on embeddings exist in literature as well as backdoor attacks on FL. Seems like it\'s a trivial operation to apply one to another. I cannot see why 3.3 is novel as it\'s the core assumption in all other backdoor FL papers -- other participants contributions can be ignored when computing backdoored model update.\n\nIn my opinion the key interesting part of the paper is that it can possibly evade norm-bound detection by modifying only a small model\'s embedding vector, however it has a very trivial way to defend -- simply check for norm updates of each embedding vector. \n\nOverall, I really like the idea but it needs more solid motivation and exploration. ', 'rating': '5: Marginally below acceptance threshold', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_YEBb'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/FL4NLP', 'aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_YEBb']}]"
https://openreview.net/forum?id=SU5z8MKx_-9 ,SU5z8MKx_-9,"[{'id': 'rKIesg9stG5', 'original': None, 'number': 3, 'cdate': 1648110066617, 'mdate': None, 'ddate': None, 'tcdate': 1648110066617, 'tmdate': 1648110727413, 'tddate': None, 'forum': 'SU5z8MKx_-9', 'replyto': 'SU5z8MKx_-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper19/-/Official_Review', 'content': {'title': 'Well written, Clearly communicated all complexities', 'review': 'This paper improves contextually relevant knowledge extraction by introducing common sense triple selection based on a ranking model.\n     \n[Strong]\nPaper is well written with detailed results and analysis demonstrating quality of the extracted schema graphs on two popular models (MHGRN, QA-GNN) and datasets (OpenbookQA, CommonsenseQA). Current papers triple selection based on reranker, iteratively finding the shortest path between any pair of concepts (using steiner tree approximations, pathfinding methods), employing lexical and embeddings based entity linking approaches for extracting schema graphs helps foster further research in knowledge extraction space.\n\n[Weak]\nThe current approach has lesser incremental gains on CommonsenseQA dataset vs baseline (signifying lesser transferability to other domains) when compared to OpenbookQA dataset vs baseline (signifying higher gains on indomain data) \n\n[Minor Typo]\nQA-GNN paper reference is wrongly mentioned in section 3.4\n', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_1Bkt'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_1Bkt']}, {'id': 'Sddg1jwpMfc', 'original': None, 'number': 2, 'cdate': 1647658903132, 'mdate': None, 'ddate': None, 'tcdate': 1647658903132, 'tmdate': 1647658903132, 'tddate': None, 'forum': 'SU5z8MKx_-9', 'replyto': 'SU5z8MKx_-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper19/-/Official_Review', 'content': {'title': 'Simple, well-written contribution; appropriate fit for workshop', 'review': 'The authors introduce a triple selection method based on a ranking model and find that it improves QA accuracy over existing approaches. They also investigate methods to ensure that extracted triples form a connected graph. They argue that this connectivity is important both for model interpretability, and also because non-connectivity could limit the power of the GNN.\n\nOverall, the paper makes a nice contribution to the workshop and I recommend accept. It is relatively simple, and appropriate to its length. In a longer version, I would have liked to see a figure illustrating the intuition behind the approach, but due to page limits this may not have been possible.\n\nIt is also always good to include statistical significance results which seems to be missing here. ', 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_RBxX'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_RBxX']}, {'id': 'BLQe0dzjAZ5', 'original': None, 'number': 1, 'cdate': 1647387253798, 'mdate': None, 'ddate': None, 'tcdate': 1647387253798, 'tmdate': 1647990042077, 'tddate': None, 'forum': 'SU5z8MKx_-9', 'replyto': 'SU5z8MKx_-9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper19/-/Official_Review', 'content': {'title': 'Reasonable technical ideas, but lack of analysis, and question mark on reported gains', 'review': 'The paper discusses various ways to retrieve CSK statements for QA methods that rely on structured knowledge.\n\nThe ideas of zooming in on the retrieval part of the problem, in particular concerning lexical vs. embedding-based retrieval, and graph connectivity, is interesting. The technical content is reasonably presented, and the ideas are worth discussing at the workshop.\n\nAt the same time, there are critical issues:\n - Readability for all but a small expert circle is substandard, as the paper is devoid of examples\n - The analysis is narrow, on a single idiosyncratic KG, ConceptNet. The proposed methods would gain much credibility if shown to work not only on that, but also, e.g., on Quasimodo, Atomic, or Ascent.\n - There is no analysis of system outputs, only aggregate numbers. I understand that human evaluations of this task are hard, but I honestly wonder whether the authors ever looked at their data themselves. There should at least be hand-picked comparisons of system outputs. Are there any human insights on how the proposed methods do better (if they do)?\n - The reported gains are small, and it is unclear whether they are statistically significant. Having worked on this setting myself, I am skeptical of suggestions that CSKGs truly help in the problem (and the result tables should show a no-KG baseline). Moreover, there seem to be confounding factors, as different methods produce KGs of different size, which make attributing gains to the proposed methods even harder - perhaps the gains just come from finding the sweet spot of right KG size? \n\nMinor points:\n - The term ""schema graph"" appears odd. ""Schema"" to me rather refers to data organization, not to actual grounded triples.\n - ""We make our code available at anonymous"" - This isn\'t helpful - there are enough ways nowadays to anonymously share actual files, at a workshop I don\'t expect code sharing anyway, but at a conference I would not let this pass (if code/data sharing was a requirement).', 'rating': '6: Marginally above acceptance threshold', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_NAhj'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_NAhj']}]"
https://openreview.net/forum?id=H4xz8zteub9 ,H4xz8zteub9,"[{'id': 'BfxO5g9qM5', 'original': None, 'number': 3, 'cdate': 1648169103607, 'mdate': None, 'ddate': None, 'tcdate': 1648169103607, 'tmdate': 1648169164923, 'tddate': None, 'forum': 'H4xz8zteub9', 'replyto': 'H4xz8zteub9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper17/-/Official_Review', 'content': {'title': 'An interesting study with minor weaknesses', 'review': 'Summary:\n\nThe authors present a very interesting analysis of the extent to which common sense knowledge is embedded/used with large language models (LLMs) - on a narrative task. Specifically, authors aim to address the following key important questions: (a) aspects of common sense knowledge accessible to LLMs; (b) aspects of common sense that could be leveraged from signals obtained through external knowledge graph (KG) sources like COMET.  Experimental findings show that increasing size of the LLM model helps in capturing common sense better; incorporating external KG helps in improving model performance in answering questions that are not directly available in the narratives.\n\n\nStrengths:\n\nThe paper is well-organized, well-written and easy to follow. \n\nI thoroughly enjoyed reading this work and I am sure that this work would be a great fit for this workshop audience.\n\nExtensive experiments have been performed to draw several interesting insights on the problem setting. \n\n\nWeaknesses:\n\nI did not find any major weaknesses with this work.\n\nCan these findings be generalized to other datasets/domains? It would have been really great to have one more dataset (preferably on a similar but different task), to better quantify the conclusions made in the paper.\n\nIn section 6, I didn’t exactly understand the differences between goal-seeking and desire categories. Are you planning to provide supplemental material with this effort? More fine-grained categories would make this analysis even stronger.\n\nI struggle to identify the differences between the experiment setup described in section 3.2.1 and 3.2.2. It would help to make this more clear, perhaps an example would help.  \n', 'rating': '7: Good paper, accept', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_xGYV'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_xGYV']}, {'id': 'r5Ux_tFxcz9', 'original': None, 'number': 2, 'cdate': 1648130432302, 'mdate': None, 'ddate': None, 'tcdate': 1648130432302, 'tmdate': 1648130432302, 'tddate': None, 'forum': 'H4xz8zteub9', 'replyto': 'H4xz8zteub9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper17/-/Official_Review', 'content': {'title': 'Using COMET for TellMeWhy', 'review': ""In this paper, the authors study Why questions in the TellMeWhy dataset using COMET as a source of relevant commonsense relations. They analyze the relative improvements over a base T5 model when (a) increasing the model size, (b) injecting knowledge from COMET as part of the task input, and (c) asking the model to generate COMET relation type as an explanation in addition to its answer. Their results show that the larger model, as expected, yields substantial improvements over the base. Interestingly, they find that the question specific COMET relations can provide substantial improvements for both base and large models, with additional possible gains when asking the model to also generate COMET relation type.  So, they augment a large model with noisy hints from COMET and find that this improves performance on the  task. \n\nOverall this is decent work. I don't have any particular criticism, however, I have to bring this up that at this point using commonsense knowledge from COMET ATOMIC at the realm of reasoning in narratives is not particularly novel because several works have done this. such as abductive reasoning work by Bhagavatula et al. (2019) for abductive reasoning, and self talk by Shwartz et al. (2020)  \n\nThere are couple of follow up questions\n1) Since Tell me why is focused on narratives why not use ParaCOMET which is specifically designed for narratives and is discourse aware\n2) Did you also look into concept centric commonsense?\n3) Your related work on  Incorporating External Knowledge is great but there needs to be more discussion on prior work which used COMET such as\ni)  Ammanabrolu et al. (2020) for story generation,\n          Automated storytelling via causal, commonsense plot ordering\nii)  Majumder et al. (2020) for dialog generation\n         Like hiking? you probably enjoy nature: Persona-grounded dialog with commonsense expansions. \niii) Chakrabarty et al. (2020a; 2020b; 2022) \n         Rˆ3: Reverse, Retrieve, and Rank for Sarcasm Generation with Commonsense Knowledge\n         Generating similes effortlessly like a Pro: A Style Transfer Approach for Simile Generation\n         It’s not Rocket Science: Interpreting Figurative Language in Narratives"", 'rating': '7: Good paper, accept', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_w3mr'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_w3mr']}, {'id': 'rbNlbrm6QM9', 'original': None, 'number': 1, 'cdate': 1647723320816, 'mdate': None, 'ddate': None, 'tcdate': 1647723320816, 'tmdate': 1647723320816, 'tddate': None, 'forum': 'H4xz8zteub9', 'replyto': 'H4xz8zteub9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper17/-/Official_Review', 'content': {'title': 'Review', 'review': 'Summary\n- This paper considers the QA task of Why questions, which requires commonsense knowledge. The paper studies (1) what aspects of this knowledge is accessible to pretrained language models, and (2) what aspects can be made accessible via external commonsense resources such as COMET. The authors show that the QA performance can be improved by (a) increasing the LM size, (b) injecting knowledge from COMET as part of the task input, and (c) teaching the model to generate COMET relation type as output besides the answer. The paper conducts extensive experiments, and analyzes what types of commonsense knowledge pretrained LMs already have, and what can be augmented via COMET. \n\nReasons to Accept:\n- The paper asks interesting and important questions (what knowledge pretrained LMs already have, what can be gained from external knowledge, what knowledge remains inaccessible), and answers them with sufficient experiments.\n- The paper is clear and well-written. \n\nWeakness and questions:\n- Do you have an intuition why does the larger model (T5 11B) captures more COMET relations than smaller model (T5 base)? Was T5 11B trained on more data, or simply the model parameter count is larger and has more capacity to cover more relations? Why T5 11B is good at capturing particular relations (e.g. xReason) but not others (e.g. HasSubEvent)?\n\nTypos/grammar:\n- L234: ""both these"" -> ""both of these""\n- L503: ""wee"" -> ""we""', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_5cXn'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_5cXn']}]"
https://openreview.net/forum?id=Bx-fUfKedZ5 ,Bx-fUfKedZ5,"[{'id': 'BlWe9_r8qGq', 'original': None, 'number': 3, 'cdate': 1648153969995, 'mdate': None, 'ddate': None, 'tcdate': 1648153969995, 'tmdate': 1648154229976, 'tddate': None, 'forum': 'Bx-fUfKedZ5', 'replyto': 'Bx-fUfKedZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper16/-/Official_Review', 'content': {'title': 'Simple and elegant approach to post-hoc error correction', 'review': '### Paper Summary:\n\nThis paper focuses on improving GPT-3\'s performance post-deployment, without any retraining, via a growing repository of interactive user feedback. Through correcting GPT-3\'s misunderstanding of question intent via a key-value store of user questions and corrective feedback, the authors develop a system to edit prompts through such feedback from previously-asked, similar questions.\n\nEvaluating on 4 tasks (lexical relations, word scrambling, and 2 variations of ethics reasoning), the authors show that their method of maintaining a growing memory store coupled with dynamically injecting feedback into prompts is useful in improving GPT-3\'s accuracy over time.\n\n\n### Paper Strengths:\n\nThis paper takes a simple but effective step towards post-deployment error correction. Given that retraining (or, sometimes even large scale finetuning) may not always be tractable, the authors\' conceptual framework of a lookup table for previously committed errors is straightforward and task-independent. \n\nIn addition, incorporating direct user feedback in future model interactions helps to improve interpretability of model output and the model\'s usability, given that small errors in intent understanding can be corrected post-hoc.\n\n\n### Paper Weaknesses:\n\n1. Evaluation of feedback: Given that the prompt is directly edited using feedback provided by users, it would be helpful to understand the model\'s sensitivity to the user feedback. For example, analysis of lexical sensitivity, robustness to noise in feedback, or other such analysis of user-provided feedback that did not aid accuracy/performance would help to understand the practical implications of using this framework with GPT-3. \n2. Evaluation of ""u"": Likewise, for more complex questions or tasks, it seems like a more thorough evaluation of the generated question intent (via something like a human evaluation study) would be useful. Given that this approach is using humans in the loop, robust evaluation of the model\'s “understanding” of the task and the sensitivity/role of user feedback would help contextualize the limitations or practical applications of the approach.\n3. Scalability: The key-value store (and thus the retrieval component) plays an instrumental role in the performance of the overall system design, but, to my knowledge, the paper does not include a discussion of the scalability of their approach. Given that the memory is simply expected to accumulate over time, this feels like an important dimension of analysis or discussion.\n\n\n### Overall assessment\n\nOverall, I think this paper is a nice step towards post-hoc correction of models with humans in the loop, and could be incredibly effective in certain practical settings.\n\n### Typos\n\n1. Line 176: add ""than the""\n2. Line 428: ""improves"" --> ""improve""', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_hT44'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_hT44']}, {'id': 'rcUl-GC-tM5', 'original': None, 'number': 2, 'cdate': 1648070153115, 'mdate': None, 'ddate': None, 'tcdate': 1648070153115, 'tmdate': 1648070153115, 'tddate': None, 'forum': 'Bx-fUfKedZ5', 'replyto': 'Bx-fUfKedZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper16/-/Official_Review', 'content': {'title': 'Solid paper with small writing issues.', 'review': '### Pros\n\n* The paper presents a simple method that works.\n* The proposed method does not require model re-training which would be expensive.\n* The proposed method supports a natural user-machine interaction.\n\n### Cons\n\n* One downside of the paper is that it only studies the GPT-3 model. It would have been interesting to see if the results apply to the open-source equivalents: GPTNeo and GPTJ.\n\n### Minor things\n\n* Lines 127, 163: The citations should not be in parenthesis, as the authors\' names are part of the discourse.\n* Line 428: ""Does pairing GPT-3 with MEM-PROMPT improves"" - Typo. It should say ""improve"".\n\n### Issues with the references \n\n* When possible, please add URLs to the references as the template uses them.\n* Johnson et al. (2017) – Cites preprint instead of the article\'s peer-reviewed version.\n* Liu et al. (2021a) and Liu et al. (2021b) are duplicates of each other.\n* Liu et al. (2021c) is missing the ArXiv ID.\n* Marcus (2021) is missing the URL and the title is not clickable. The web page\'s URL should appear.\n* Mitchell et al. (2021) is missing the ArXiv ID.\n', 'rating': '9: Top 15% of accepted papers, strong accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_bLgH'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_bLgH']}, {'id': 'Bzg0fHqUG5', 'original': None, 'number': 1, 'cdate': 1647908117867, 'mdate': None, 'ddate': None, 'tcdate': 1647908117867, 'tmdate': 1647908117867, 'tddate': None, 'forum': 'Bx-fUfKedZ5', 'replyto': 'Bx-fUfKedZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper16/-/Official_Review', 'content': {'title': 'A generally strong paper with some weaknesses to be addressed', 'review': 'The presented work proposes a straight-forward method for improving the performance of pre-trained LMs (PLMs) on a variety of tasks through corrective feedback. The feedback is first supplied by a (simulated) user and stored in a memory component. In the main experiments, such feedback contains information that is intended to correct the model\'s faulty reasoning, e.g. by elaborating on or clarifying the task that the user is expecting the model to perform. The feedback memory can subsequently be used as a source of additional information for new queries to the model, whereby corrective feedback is retrieved from the memory that was previously provided for queries that are most similar to the current one. The query and the retrieved feedback are subsequently combined with the task-specific prompt and given to the PLM as input, which has empirically been found to outperform baselines that either do no utilize the corrective memory at all, or employ a non-selective memory module. The experimental section includes lexical as well as ethical reasoning tasks, although the authors also describe the application of the proposed method to code-switched question answering and question answering with label feedback (as opposed to natural language corrections).\n\nOverall. the proposed method is compelling, easy to implement, and effective according to the provided experimental evaluation. The corrective feedback memory is a neat idea for leveraging and re-using user feedback in an efficient manner and could potentially be applied to many diverse tasks.\n\nThere are some minor issues with the paper that should be corrected:\n- Line 180: The notation is confusing  - does x_i/j represent the input or the error? \n- Line 308: It would be appropriate to provide citation for Social Chemistry 101, as well.\n- Figure 3: Some of the example questions / templates are oddly phrased, e.g. ""on the lines of"" which should probably be either ""in the vein of"" or ""along the lines of""? Could the authors clarify?\n- Line 379: I assume this should be ""cosine similarity"" rather than ""cosine distance"", as the latter with a threshold of 0.9 would be extremely permissive.\n- Line 385: Concatenation is not a gating function (while gating may be explored in the future, it is not part of the presented approach); relatedly, the breakdown of the approach in section 3.1. makes it sound more complex than it actually is and is detrimental to the paper\'s clarity (e.g. both the ""prompter"" and the ""combiner"" are simple concatenation steps and don\'t really need extra terminology attached to them).\n- Line 428: improves -> improve\n- Table 2: Should be positioned under 4.1.1 header and does not have to include the GROW-PROMPT row. \n- Figure 4: Should get a better caption, e.g. one that explains that the legend denotes the likelihood of feedback being drawn from memory, as it does not to be explicitly stated anywhere else.\n- Figure 5: The authors should address why feedback retrieval likelihood of 0.5 performs similar to or better than 1.0.\n- Figure 6, caption: Should be ""for GROW-PROMPT and MEM-PROMPT"".\n\nIn closing, I think this paper is really neat, fits well within the body of commonsense reasoning research, and would be a worthy addition to the workshop.', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_F7Sg'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_F7Sg']}]"
https://openreview.net/forum?id=ShMlIzKgOW9 ,ShMlIzKgOW9,"[{'id': 'SNgeq8pz_Gc', 'original': None, 'number': 3, 'cdate': 1648008530079, 'mdate': None, 'ddate': None, 'tcdate': 1648008530079, 'tmdate': 1648008530079, 'tddate': None, 'forum': 'ShMlIzKgOW9', 'replyto': 'ShMlIzKgOW9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper15/-/Official_Review', 'content': {'title': 'Review of the paper', 'review': '# Summary\nThis work investigates the augmentation of pretrained language models (LMs) with knowledge graphs (KGs) for the cause-effect relation classification and commonsense causal reasoning tasks. They verbalize the ATOMC-2020 KG triples into natural language which they use to continually pretrain BERT. Their results show that the continually pretrained LM outperforms non-continually pretrained ones on two commonsense causal reasoning benchmarks, COPA and BCOPA-CE, and a Temporal and Causal Reasoning (TCR) dataset.\n\n# Contributions\n1. They study pretrained LMs augmented with the ATOMIC-2020 knowledge graph in the commonsense reasoning domain.\n2. They perform experiments to show that these augmented LMs can outperform non-continually pretrained ones and other baselines on the cause-effect relation classification and commonsense causal reasoning tasks.\n\n# Pros\n1. The writing is generally very clear, which makes the paper easy to follow.\n2. The result on the TCR task looks very good!\n3. Approach the (causal) commonsense reasoning task, which is very important.\n\n# Cons\n1. The framework of continually pertaining LMs using verbalized KG triples is something that has been done previously [1]. The only things that are different in this paper is to apply this technique to a different KG (ATOMIC-2020) and to fine-tune on a few different tasks and benchmarks. So there is a lack of novelty.\n2. I find the result in Table 4 unsatisfactory. First, what is the b-l-reg baseline and why does the ATOMIC-BERT model underperform that baseline? Second, the fact that using all the categories for ATOMIC-2020 actually hurt performance but only using the event ones does not fit well with the claim of the paper that general commonsense knowledge helps the causal commonsense reasoning task. It may just be the case that the event triples in ATOMIC-2020 is in a closer domain to the BCOPA-CE and it is actually the in-domain further pertaining that is helping. Third, why not just try using the causal relations in ATOMIC-2020 (""cause"", ""effect"" etc)?\n3. The standard deviations are not reported for all the experimental results.\n4. I know it is not a fair comparison to compare ATOMIC-BERT and T5 and DeBERTa, but looking at the latter two\'s numbers on the COPA-test, the task seems a solved one. I am not sure how significant/useful it is to continue working on this benchmark.\n\n# Other comments and questions\n1. An ablation study in the effect of different ways to verbalize the KG triples and e.g. whether the grammar correction step is necessary can be useful and interesting.\n2. Which split of ATOMIC-2020 is used?\n\n# References\n1. Guan, Jian, et al. ""A knowledge-enhanced pretraining model for commonsense story generation."" Transactions of the Association for Computational Linguistics 8 (2020): 93-108.', 'rating': '4: Ok but not good enough - rejection', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_Yi8h'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_Yi8h']}, {'id': 'B6PeGTiJuGc', 'original': None, 'number': 2, 'cdate': 1647995834097, 'mdate': None, 'ddate': None, 'tcdate': 1647995834097, 'tmdate': 1647995834097, 'tddate': None, 'forum': 'ShMlIzKgOW9', 'replyto': 'ShMlIzKgOW9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper15/-/Official_Review', 'content': {'title': 'Unique limited contribution of cause-effect models created by knowledge-augmented LM pretraining', 'review': 'This paper proposes a method for knowledge-augmented LM pretraining with cause-effect information. The method is targetted towards causal reasoning benchmarks (TCR, COPA, and BCOPA-CE). The method performs better than vanilla and existing system baselines on TCR, and below some baselines on the COPA/BCOPA-CE tasks.\n\nThe paper is overall interesting. Its novelty is limited as the method is already known in the literature, but the evaluation is unique which may be enough for a workshop paper.\n\nWeaknesses:\n* It is unclear how the citations in paragraph 1 of section 1 relate to the statement that PLMs have been leveraged in for understanding causality in language.\n* The statement that model performance is very dependent on the domain and downstream tasks is reasonable, but it is broad, and it is unclear how this paper addresses this challenge.\n* The evaluation contains various benchmark-specific adaptations which are not anticipated in the experimental setup, and feel like hacks to improve performance ad hoc. It would be good to give these configurations a better structure in the paper, ideally by stating them within the method description or within the experimental setup. Moreover, it would be good to clarify how each of these configurations relates to the research question investigated in this paper.', 'rating': '5: Marginally below acceptance threshold', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_G1op'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_G1op']}, {'id': 'HEelY6fTQGc', 'original': None, 'number': 1, 'cdate': 1647723201157, 'mdate': None, 'ddate': None, 'tcdate': 1647723201157, 'tmdate': 1647723201157, 'tddate': None, 'forum': 'ShMlIzKgOW9', 'replyto': 'ShMlIzKgOW9', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper15/-/Official_Review', 'content': {'title': 'Review', 'review': 'Summary\n- The technique of continually pretraining language models on commonsense knowledge graph triples has been shown useful for some downstream tasks, but it may depend on the specific domain and tasks. This work investigates the effect of this technique on the task of cause-effect relation classification. The authors verbalize the ATOMIC2020 knowledge graph and continue to pretrain BERT-large on it. The authors show that this simple method can boost the performance in cause-effect classification. \n\nReasons to Accept:\n- The effect of commonsense knowledge graphs for cause-effect relation classification is an interesting topic, but has not been studied systematically. This work performs an interesting investigation into this research question.\n- The paper is clear and well-written overall. \n- The authors will publicly release the knowledge graph verbalization codes and the trained models\n\nWeakness and questions:\n- Overall, I think that the experiments/analyses could be polished a bit more. Below are s few suggestions.\n- ATOMIC-BERT-large (Event, Physical, Social relations) underperforms the baseline BERT-large on two datasets (Table 2, 4). It\'d be great if the authors could investigate more into why this is the case. Do Physical/Social relations have very different distributions of knowledge than the tasks of interest (i.e. cause-effect prediction)? Even though ATOMIC-BERT-large (Event) outperforms the baseline, it is a bit concerning that in order for the proposed method to work, it needs to identify what kinds of relations within ATOMIC2020 is useful or hurting for the task and remove the hurting relations. It\'d be ideal if the authors could think about a bit more elegant method to address this issue.\n- Additionally, it is not clear why adding prompt helps for BCOPA-CE but hurts for COPA task. It\'d be great if the authors could conduct more in-depth analysis for their results. \n\nTypos/grammar:\n- L184: redundant parenthesis in ""(MLM)""?\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_327F'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_327F']}]"
https://openreview.net/forum?id=S6Pl8ztg_b5 ,S6Pl8ztg_b5,"[{'id': 'BbgP2-hYf9', 'original': None, 'number': 3, 'cdate': 1648112046659, 'mdate': None, 'ddate': None, 'tcdate': 1648112046659, 'tmdate': 1648117215837, 'tddate': None, 'forum': 'S6Pl8ztg_b5', 'replyto': 'S6Pl8ztg_b5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper14/-/Official_Review', 'content': {'title': 'a good benchmark paper overall', 'review': ""The paper proposes CIKQA, a commonsense benchmark, which unifies several commonsense task into QA format and associates them with relevant knowledge. Experiments shows that models can better learn inference and generalize across tasks with proposed formulation and usage of knowledge.\n\nStrength:\n1. the proposed benchmark can be a useful resource for the field. \n2. the experiments and analysis are comprehensive and give interesting insights. \n3. the writing is clear and easy to follow.\n\nWeakness:\n1. the coverage of proposed benchmark is limited, it doesn't include any physical or social commonsense tasks, like PIQA or SocialIQA.\n2. the idea isn't entire novel - unified task formulation and knowledge injection have already been well-studied in QA domain. \n3. missing related works: \n[1] Liu, Jiachen et al. “Generated Knowledge Prompting for Commonsense Reasoning.” ArXiv abs/2110.08387 (2021): n. pag.\n[2] Shwartz, Vered et al. “Unsupervised Commonsense Question Answering with Self-Talk.” ArXiv abs/2004.05483 (2020): n. pag.\n"", 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_9YV6'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_9YV6']}, {'id': 'SVhe50AXtf5', 'original': None, 'number': 2, 'cdate': 1648078545728, 'mdate': None, 'ddate': None, 'tcdate': 1648078545728, 'tmdate': 1648112734757, 'tddate': None, 'forum': 'S6Pl8ztg_b5', 'replyto': 'S6Pl8ztg_b5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper14/-/Official_Review', 'content': {'title': 'Commonsense benchmark paper - simple and well-presented', 'review': ""Overall the paper seems comparatively complete and solid to me. The authors propose the benchmark CIKQA with a clear task formulation and detailed steps on how to extract supporting knowledge, as well as a strong baseline that takes advantage of its format. Experiments are also well-executed to answer the authors' questions regarding leveraging provided knowledge, distinguishing gold knowledge, and model generalization ability on different tasks.\n\nHere are my comments:\n- It is a bit overclaimed to me that CIKQA can focus on learning to do the inference with the current task setting. \n- The related work discussion seems a bit sparse to me.\n- I am a bit concerned about the novelty as the unified format and injecting knowledge have all been discussed widely.\n- From Table 1, there are only 3,007 instances with gold knowledge, but for experiment results in Figure 3, even models with the suffix `_gold` could still be trained with $10^4$ training instances. Hope the authors could address the issue there."", 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_FcT2'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_FcT2']}, {'id': 'BOde3ZuhAZq', 'original': None, 'number': 1, 'cdate': 1647392771915, 'mdate': None, 'ddate': None, 'tcdate': 1647392771915, 'tmdate': 1647392771915, 'tddate': None, 'forum': 'S6Pl8ztg_b5', 'replyto': 'S6Pl8ztg_b5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper14/-/Official_Review', 'content': {'title': 'review', 'review': 'The authors propose a reformulation of commonsense reasoning QA tasks\nthat attempts to separate knowledge (e.g., facts as specified by a KG)\nfrom inference (i.e., reasoning over a given set of facts). Their\nsetup is to pair a small knowledge graph with each question that\ncontains the relevant knowledge to answer the question. They report\nexperimental results in this setting, showing that their model,\nJointI, 1) effectively incorporates the knowledge graph information in\na fewer-shot setting (e.g., 100-1000 points); and 2) transfers between\ntasks better than if the model didn\'t have explicit knowledge handed\nto it.\n\nI commend the authors for their attempt to solve a difficult problem:\nindeed, the distinction between factual knowledge and inference over\nthat knowledge is rather illspecified in the commonsense domain.  The\nproposed approach: converting and then augmenting existing QA datasets\nwith all the knowledge the might need gives a potentially nice\nsolution to this problem: i.e., by conditioning on ""all of the\nknowledge"", the algorithms can focus entirely on inference; similarly,\nby retrieving knowledge as a first step. I also think the results here\nregarding generalization are quite interesting! Because we expect that\nthe inference required for commonsense reasoning tasks may be shared,\nthe transfer results suggest that, moreso than a model without\nexplicit knowledge provided, an inference-focused model may generalize\nbetter.\n\nMy biggest concern is that I\'m not entirely convinced that this setup,\nas the authors claim, fully separates the knowledge versus inference\nquestion. While the approach makes sense in theory (i.e., conditioning\non all needed knowledge), 1) there are still pieces of commonsense\nknowledge required to, e.g., interpret the small KGs that are paired\nwith each question. To take the example in Figure 2: one simple case:\nan algorithm must know that sleeping is a type of resting. And 2)\nmodels could simply ignore the given knowledge graph in this setup,\ne.g., if one was to use a pretrained language model that was already\nimparted with both knowledge and inferential capacity. The authors do\nuse BERT-Small in some experiments and performance improves when the\ngraph is included in the input, but, I suspect that if more powerful\npretrained models were used the large performance gaps presented\nbetween Table 2 (a) vs. Table 2 (b) might vanish.\n\nOverall, the authors report some interesting results for their new\nsetup, which may have practical promise for few-shot learning with\nsmall models. However, I do worry that CIKQA has limitations that need\nto be addressed if larger models were to be applied to such a task.', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_MN7e'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_MN7e']}]"
https://openreview.net/forum?id=rg-zrfteOZc ,rg-zrfteOZc,"[{'id': 'BtZxxr8hqz5', 'original': None, 'number': 3, 'cdate': 1648178744420, 'mdate': None, 'ddate': None, 'tcdate': 1648178744420, 'tmdate': 1648178744420, 'tddate': None, 'forum': 'rg-zrfteOZc', 'replyto': 'rg-zrfteOZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper11/-/Official_Review', 'content': {'title': 'Interesting paper of producing reasoning steps for QA', 'review': 'Strengths\n- The paper describes an interesting approach to producing an explanation, in the form of a knowledge base tuple, for a QA answer. This is potentially interesting to not only the commonsense reasoning community but also people interested in understanding the explicit reasoning steps behind model answers\n- The model achieves strong performance on two evaluation settings\n\nCons\n- It is hard to determine the quality of the manual annotation and the output without seeing some examples, and there appears to be only one in the paper.\n- There are some experimental details that should be clarified, especially on the input/output of the different components\n\nQuestions:\nL165: what is this way? It should be described here, so the paper is self-contained.\nL181: What would the actual relation from a database be here?\n3.3.: Not completely clear what the answer model is actually producing\n3.2: Do you use greedy search to select a relation to use here? Or do you compute the object model over all possible relations?\nL249: how do you get the explanation from the set of relations? how does the second baseline choose the most likely inference? I think I understand some about the baselines from looking at the results, but the actual description needs to be clarified when they are introduced.\nL269: do you compute any kind of agreement here? how do you check for quality?\n\nTypos:\nL180-181: ""the commonsense usually"" --> ""the commonsense that usually""\nL182: ""physical entities"" --> ""physical attributes""\nL243: should this be ""object model"" not ""relation model""?', 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_anxb'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_anxb']}, {'id': 'HqgNkGVFMc', 'original': None, 'number': 2, 'cdate': 1648079324216, 'mdate': None, 'ddate': None, 'tcdate': 1648079324216, 'tmdate': 1648079324216, 'tddate': None, 'forum': 'rg-zrfteOZc', 'replyto': 'rg-zrfteOZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper11/-/Official_Review', 'content': {'title': 'Interesting work but can be improved with clearer presentation', 'review': 'This work proposes a method for explainable question-answering for SocialIQA. The explanations are retrieved from ATOMIC, which contains (subject, relation, object) tuples that can provide helpful evidence/explanation for answering the question. The method trains a pipeline of generative models: i) for generating a relevant relation r in ATOMIC that could be useful for predicting the answer, ii) generating the object using r; and finally, iii) generating the answer using the generated + question and context.\n\nThe three-step approach achieves results comparable to a pre-trained model, but has the added advantage that it can provide the tuples used for answering the question, possibly adding to the explainability of the model.\n\nThe paper presents an interesting case of using KB information for commonsense question answering. \nHowever, the present version contains several shortcomings in both formulation and experimental design, listed next. \n\n* Trivial baselines: The baselines for retrieving knowledge from the external KB are pretty weak. For example, we can train a simple classifier for relation prediction by treating context in SocialIQA and subject in ATOMIC as exchangeable. Then, the prediction of the classifier can be used as an explanation. It appears that such an approach will work, and might be worth experimenting with in the future.\n\n* Clarity of presentation: Several important details are unclear. For instance, ATOMIC has tuples (s, r, o), and each QA sample is (c, q, a). As the authors mention, for SOCIAL-IQA, c determines s, but r and o are unknown. However, the method description mentions that the ""object model is learned first."" How can the object model be learned without (r, c, o) tuples? This also holds for learning the relation model. I suspect it is trained by simply treating s == c in ATOMIC, but this is an important detail that should be made more explicit. Please also see possible corrections in the formulation.\n\n\n\n\n* Novelty: the main idea of leveraging external knowledge for commonsense reasoning has been explored in several works. The primary differentiation seems to be that the proposed method does not require hand-annotated explanations and uses dynamic KB. The difference with Bosselut 2021 (which the authors mention) is not completely clear. Further, see [1] for an approach that does not require explicit annotation and does not rely on fixed KBs. Overall, better positioning concerning the related work will help understand the core contributions of this work.\n\n\n\n### Possible corrections in the formulation:\n\n1. In the max_ equation, the object model should also condition on the question for the chain rule factorization to work. Currently, there is an implicit assumption that o is independent of q given c, which may or may not be valid. Consequently, the authors may try conditioning on the question in the object model as well. It might improve things! As a side remark, V* is not specified. The notation also changes from $\\theta$ to $\\theta’’$ without any explanation.\n\n2. L224: ""To get an explanation…."" The following equation appears to be incorrect. First, isn\'t z = (r, o), and thus the explanation should contain both the terms? Second, o is introduced in the equation on the RHS, but there is no marginalization over it. I suspect there\'s a typo/problem with the formulation. \n\n\n\n\n\n### Questions: \n\n1. L130: Due to 130 this ambiguity, humans tend to perform explicit 131 reasoning afterwards. Therefore, we consider the 132 explanation to come after an answer being chosen.\n\nWhat are the implications of this statement for your method? I don\'t think that the answer goes back to generating the input?\n\n\nOverall, I think the work highlights an important area of commonsense reasoning and thus will be a useful addition to the workshop. However, I hope the paper improves by adding the clarifications mentioned above.\n\n---\n\n[1] Madaan, Aman, Niket Tandon, Dheeraj Rajagopal, Peter Clark, Yiming Yang, and Eduard Hovy. ""Think about it! Improving defeasible reasoning by first modeling the question scenario."" In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 6291-6310. 2021. \n\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_F2Z9'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_F2Z9']}, {'id': 'SgZepnn-tfq', 'original': None, 'number': 1, 'cdate': 1648069812581, 'mdate': None, 'ddate': None, 'tcdate': 1648069812581, 'tmdate': 1648069860481, 'tddate': None, 'forum': 'rg-zrfteOZc', 'replyto': 'rg-zrfteOZc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper11/-/Official_Review', 'content': {'title': 'Review', 'review': '# Summary\nThis work tackles the problem of explainable commonsense QA. They propose a latent-variable model that identifies what type of knowledge from an external knowledge base may be relevant to answering the question, computes the commonsense inferences and predicts the answer. The method can therefore learn to provide posterior rationales for why a certain answer was chosen. Experimental results show that the model can identify the correct reasoning step in twice as many examples compared to an existing unsupervised approach for producing explanations for the socialIQA task, while still maintaining comparable accuracy to end-to-end pretrained models.\n\n# Contributions\n1. Propose an explainable latent-variable commonsense QA model.\n2. Perform experiments to show that the model can accurately identify the reasoning steps for the socialIQA task, while also maintaining predictive accuracy.\n\n# Pros\n1. Tackle an interesting and important problem: explainability for commonsense reasoning.\n2. Thorough evaluation of the proposed model, including manually annotating the groundtruth reasoning steps of 500 examples in socialIQA test sets and evaluating the model\'s accuracy in identifying those reasoning steps.\n3. The proposed generative model is novel.\n4. The proposed model can accurately identify ground-truth reasoning steps.\n\n# Cons\n1. The writing is not that clear and the paper is hard to follow in general. Working through an example instead of just showing this plate notation in Figure 1 can help. Restructuring and rewriting of the paper are needed.\n2. I did not get the general message of the paper until I read it several times. I suggest in your writing you stress that the paper proposes a commonsense QA model that is **explainable**.  At the end of day, the paper proposes a model for commonsense QA. The ability of generate explanations is just one of its characteristics.\n3. The arguments that humans first reach an answer then work backwards to figure out the commonsense knowledge they use on line 122-132 are not that convincing to me. Maybe switch to a better example.\n4. Not sure what the ""KB-based"" baseline is for Table 3 even after reading the description on line 251-254. Does ""external KB"" here mean COMET?\n5. No standard deviations are reported in Table 2.\n\n# Other comments and questions\n1. On line 158, what does ""such that \\sum_zP(a,z|c,q)"" mean?\n2. On line 163-166, I am not sure how this computation is done even if I have read the Bosselut et al 2021 paper.\n3. The citation on line 189 is misformatted.\n4. Notation inconsistency for V* (line 159, 161 and 220)\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_GP1G'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_GP1G']}]"
https://openreview.net/forum?id=BVelBzKlOWc ,BVelBzKlOWc,"[{'id': 'HBrxEZA3cGc', 'original': None, 'number': 3, 'cdate': 1648180732467, 'mdate': None, 'ddate': None, 'tcdate': 1648180732467, 'tmdate': 1648180732467, 'tddate': None, 'forum': 'BVelBzKlOWc', 'replyto': 'BVelBzKlOWc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper9/-/Official_Review', 'content': {'title': 'Analysis of LM understanding of specific presuppositions and implicatures ', 'review': 'Strengths\n- Probing LM understanding of pragmatic meanings is an interesting area and the paper presents a new approach to doing this\n- the results as presented are promising, using data from cognitive science\n\nWeaknesses\n- there are many missing details that make parts of the paper difficult to understand (see questions below)\n- it is difficult to fully understand the results, due to lack of clarity around the experiment details (especially the metrics) and what is being computed. There is also an issue of whether the results are affected by co-occurrence, which is mentioned but not addressed. \n- There is no analysis of the types of errors the model is making, or even what the model outputs look like on examples. These are needed to fully understand the results and approach\n\n\nQuestions\nL049-050: What is this example with ""the"" saying? Is it just an example of a presupposition? If so, this should be made clear\nL052-053: Similarly to above, its not clear what the ""some"" sentence means.\nL081: what is N400? why is this relevant?\nL106: what is ""contrastive distribution""?\nL117: what is ""percentage mean""?\nL130: the experiments and data from Singh et al. are mentioned without any description. What is this study? What was it doing? We need this information to understand the end of the paragraph around L147.\nL200: why is this the measure of pragmatic skill?\nL212: what is the data from Nieuwland et al?\nL238: this would seem to raise questions about the strength of the conclusions being drawn. Why is this not the case? \n\n\nTypos/suggestions:\nL024: ""I"" --> ""we"" (and throughout the paper)\nL052-053: ""most people generally implies"" is not grammatical\nL074: ""survey"" --> ""surveys""\nL083-084: this sentence is not grammatical\nL097: ""meaning"" --> ""meanings""\nL129: ""card"" --> ""cards""\nL166: ""shool"" --> ""school""\nL184 and L186: ""succeed"" --> ""to have succeeded""', 'rating': '5: Marginally below acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_CQLG'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_CQLG']}, {'id': 'SqLxUR_Xtfc', 'original': None, 'number': 2, 'cdate': 1648077005707, 'mdate': None, 'ddate': None, 'tcdate': 1648077005707, 'tmdate': 1648077054262, 'tddate': None, 'forum': 'BVelBzKlOWc', 'replyto': 'BVelBzKlOWc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper9/-/Official_Review', 'content': {'title': 'Interesting direction with analysis', 'review': 'This paper investigates whether transformer-based neural language models (LM) understand commonsense pragmatics and focus on presupposition and scalar implicature.\n\nStrength:\n- I really like the connection between commonsense reasoning in NLP and pragmatic semantics in this work. It provides a theory-supported lens for investigating the often vaguely-defined ""common sense"". \n- The datasets chosen to probe LMs are well-chosen and the paper provides sufficient details which I appreciate as a reviewer.\n- The experiments are direct and easy-to-follow.\n\nPlaces to improve:\n- The authors mention multiple times that these pragmatics often exist in conversations, but the actual dataset used to probe models is not conversational. I would be really interested to see how models perform in a conversation scenario in terms of commonsense pragmatics.\n- I would be very curious to learn more about the authors\' explanations on some of the experimental results and further analysis (if page limit allows)', 'rating': '6: Marginally above acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_SiFm'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_SiFm']}, {'id': 'BavgpqwAOfq', 'original': None, 'number': 1, 'cdate': 1648056212535, 'mdate': None, 'ddate': None, 'tcdate': 1648056212535, 'tmdate': 1648056212535, 'tddate': None, 'forum': 'BVelBzKlOWc', 'replyto': 'BVelBzKlOWc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper9/-/Official_Review', 'content': {'title': 'Contradicting conclusions & some issues with experiment setting ', 'review': ""This short paper aims to evaluate DistillBERT and GPT-3’s ability to make human-like pragmatic inferences, such as Scalar Implicature (SI) and Presupposition (Presp), through human behavioral and neural data.\n\nIn Section 5, the authors claim that:\n\n* DistillBERT has difficulty detecting Presp (a bit far from human rate), and its performance suffers further when fine-tuned on another Presp + Implicature dataset (ImpPress dataset [1]).\n\n* DistillBERT has difficulty detecting SI, but its performance improves to human-level when fine-tuned on the ImpPress dataset [1].\n\n* GPT-3 does not do well in either psycholinguistic task and fine-tuning helps.\n\n### Strengths\n\n* **Online human data motivation:** The paper’s motivation of using human data for conversational implicature is well-grounded. LMs are not trained the same way through many dialogues, but rather with text found on the web.\n\n* **Good sanity check on noun co-occurrence:** The authors check whether the test datasets contain enough noun co-occurrence patterns that could make the LM find a likelihood pattern rather than reason to conclude what sentence is more plausible.\n\n* **Avoids the pitfall of comparing BERT and GPT-3 with the same metrics:** This is a positive thing as they are trained very differently, and a perplexity comparison would be inconclusive.\n\n### Weaknesses\n\n* **Important definitions/examples are not very clear:** \n    - If the reader doesn’t know what SI or Presp is, they are left with definitions and examples that aren’t very clear (ex: [line 50] “by using the determiner ‘the’ most people typically presuppose the existence of such a thing in the context.”) \n    - Similarly, in [line 142], it seems as if the uniqueness of the waiter affects the context, whereas it’s the relevancy of the job to the place. If one said “a waiter,” the place could be a random location irrelevant to the person who is still unique but happens to hold that job.\n\n* **DistillBERT’s SI implicature evaluation setting doesn’t help answer the question:**\n    - By not penalizing that “some” can be above “all,” in the case where both would be in the top 5 choices, we accept the model’s choice as correct while it isn't.\n    - It’s not surprising that “all” doesn’t show up as much as other options in the top 5 choices, as the model may put many adjectives like “Dirty,” “Tall,” and so forth. These have nothing to do with the implication, yet they still make sense given that the LM’s learning algorithm uses masked loss. Instead, comparing whether “all” is relatively more likely than “some” is more useful and would lead to more valid conclusions.\n\n* **GPT-3’s success criteria calculation is not clear:** [Line 116-122] is a little confusing as to which mean we are calculating. It seems to be that the authors calculate the sequence log probability divided by the sentence length for several sentences and then calculate the mean of those.\n\n* **Contradictions in conclusions:** While the results in Section 5 state that GPT-3 doesn’t do very well with psycholinguistic tasks [line 278], the authors say that LMs understand “the implied intent shared among most people” in the abstract [line 019-022]. This is either because I misunderstood something or because even human decisions are as low as the LMs’ rates. Including the human plausibility decision rates in the plots can make it easier to compare with LMs, although the authors may have stated these numbers at [lines 152-154].\n\n### Style - points that didn’t affect the decision of acceptance/rejection but could be useful to the authors\n\n* This paper may be a single-author paper. It’s still preferred if it’s written with “we” statements instead of “I” statements.\n\n* There are many places where previously cited references aren’t referred to with LaTeX again when mentioned, and are instead typed out, which leads to typos (ex: [line 155]). In the future, it may lead to not being able to discern between different articles.\n\n### References\n\n[1] [Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition](https://aclanthology.org/2020.acl-main.768) (Jeretic et al., ACL 2020)"", 'rating': '4: Ok but not good enough - rejection', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_KJoU'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_KJoU']}]"
https://openreview.net/forum?id=Se-xHMYg_bc ,Se-xHMYg_bc,"[{'id': 'rO-gh60QKM9', 'original': None, 'number': 3, 'cdate': 1648078532046, 'mdate': None, 'ddate': None, 'tcdate': 1648078532046, 'tmdate': 1648078532046, 'tddate': None, 'forum': 'Se-xHMYg_bc', 'replyto': 'Se-xHMYg_bc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper8/-/Official_Review', 'content': {'title': 'Insightful Analysis on CCI', 'review': ""The authors present analysis on contextual commonsense inference (CCI) using GLUCOSE, a story dataset annotated with commonsense explanations. They argue that the conflation of CCI with language generation (used in original GLUCOSE task) hinders model performance and the evaluation protocol also has issues. They propose to separate CCI from NLG by proposing CIS^2 and show improvement.\n\nStrength:\n- It's always good to see (and enjoyable to read!) analysis papers that tackle a previously studied problem from a new angle and provide insights. CIS^2 looks at the CCI problem and critiques a previous task formulation which I think provides important reflections for other researchers working on this problem.\n- The experiment design is well-reasoned and thoroughly described. I really like the different diagnosis task settings trying to disentangle different factors that might influence CCI performance.\n- The analysis on evaluation metrics also provides interesting insights\n\nPlaces to improbe:\n- I do not have major weaknesses to point out, but I think some parts of the writings can be much more concise. Especially Section 3 where the authors spent 2 pages on reviewing and introducing a previous work's data and task (I know it's crucial background but think could be shortened)\n- Significance tests would be beneficial to be included for Table 4 and others."", 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_CzWL'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_CzWL']}, {'id': 'H5xM963Pfc', 'original': None, 'number': 2, 'cdate': 1647984010425, 'mdate': None, 'ddate': None, 'tcdate': 1647984010425, 'tmdate': 1647984010425, 'tddate': None, 'forum': 'Se-xHMYg_bc', 'replyto': 'Se-xHMYg_bc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper8/-/Official_Review', 'content': {'title': 'Interesting hypothesis ""Contextual Commonsense Inference should not be conflated with NLG as in GLUCOSE"" but not much evidence.', 'review': 'What the paper is about: The paper argues that for contextual commonsense inference (commonsense understanding in some story), the GLUCOSE task conflates a different skill of natural language generation, which also brings in the ills of BLEU metrics. They propose the task of CIS2 which instead of asking the model to generate a commonsense inference, merely asks it to pick/classify the correct sentence prediction. They compare with different diagnostics/ablations of the original GLUCOSE task by removing parts of the input. They find that models trained on these ablations of GLUCOSE-Original perform worse than one trained on CIS2 (note that all these variants are based on the same GLUCOSE dataset) -- when evaluating on CIS2 metric of classification.\n\nKey Shortcoming: There is no independent evidence that shows a classification task is better than generation task in training for ""contextual commonsense inference."" The only evidence is on the same metric of CIS2 which seems biased. The argument sounds like ""Standardized Tests are not good benchmarks of creativity, so we propose instead teaching/testing students the skill of playing chess. We find that students preparing for different standardized tests are worse than students preparing for chess -- when evaluated on chess."" The core hypothesis remains untested: whether chess playing (CIS2) is a better metric and task for creativity (commonsense contextual inference) than standardized testing (generation). Some ways that this could have been evaluated are:\n1. human studies - do annotators find one model to exhibit more commonsense than others in some way?\n2. independent downstream task - does the model trained on CIS2 outperform those trained on generation on some third task? ', 'rating': '4: Ok but not good enough - rejection', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_S91P'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_S91P']}, {'id': 'StZxr-sTIf5', 'original': None, 'number': 1, 'cdate': 1647921917505, 'mdate': None, 'ddate': None, 'tcdate': 1647921917505, 'tmdate': 1647921959919, 'tddate': None, 'forum': 'Se-xHMYg_bc', 'replyto': 'Se-xHMYg_bc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper8/-/Official_Review', 'content': {'title': 'The paper pinpointed a valid issue with the existing CCI task formulation. However, the findings are somewhat obvious, and the newly designed task might not generalize to settings where the CS inference is implicit and not part of the given story. ', 'review': ""This paper critiques existing methods on Contextual Commonsense Inference (CCI), which conflates generation and reasoning tasks. The authors propose reframing the CCI task as a classification task (called Cis2) to isolate commonsense reasoning from the generation. This helps in evaluating the commonsense inference ability of a model irrespective of its generation performance. For this, they convert story sentences into output tags which avoids a partial match between input and output sequences. The model is then required to generate an abstracted output which contains story sentences' tags instead of full sequences. \n\nPros:\n* It is important to evaluate the reasoning abilities of models in isolation from their generation abilities and the author pinpointed a valid issue with original GLUCOSE task formulation.\n\n\nCons:\n* Most of the findings from the diagnostic tests are obvious and expected (see comments). \n* Too much content is provided about Mostafazadeh et al. 2020 which could be easily skipped and referred to the original paper.\n* It is not clear how the newly designed task formulation handles cases where the inference output Y is not explicitly stated in the given story.\n\nComments:\n1- How does your task reformulation handle cases where the inference output Y is not explicitly stated in the story? As the authors mention in Line 196, the CS inference Y might or might not be part of the story. And example from the original GLUCOSE paper is:\n“Gage wants safety” Causes/Enables “Gage turned his bike”, while “Gage wants safety” is never stated in the story and should be inferred thus can not be replaced by a tag from the story.\n\n2- Line 259: while I agree with the authors that the original task formulation suffers from conflation of CCI and language generation tasks, I think this can be solved mostly by 1) removing the selected sentence X from the output, and 2) including a better evaluation metrics that accounts for semantic similarity such as BertScore. \n\n3- Line 367-369: Isn't this obvious? if in the training data, output always copy/paraphrase X, it's expected that the model learns this pattern and consequently the BLEU score would be high. The issue is why the model should generate X in the first place. Without including X in the output (no matter if X is in the input or not) the evaluation using n-gram overlap would be less unreliable.\n\n4- Line 380: In my opinion copying is an easier task.\n\n5- The first 5.5 pages are allocated for background and related work and only on page 6 the author started to talk about their proposed task Cis2. \n\n6- It is helpful to explicitly mention somewhere in the paper that you are using a generative classifier where the model GENERATES one of the 100 possible output sequences (using T5) and it’s not a 100-way classification task.\n\n7- Line 449: For what portion of the original data could the authors find output Y explicitly mentioned in the input story? And why not discard those with very low similarity scores?\n\nTypo: \n\nLine 406: the The → The\n\nLine 407: footnote after punctuation.\n"", 'rating': '6: Marginally above acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_EoNj'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_EoNj']}]"
https://openreview.net/forum?id=rTwMSztg_-q ,rTwMSztg_-q,"[{'id': 'rBee5cxh9G9', 'original': None, 'number': 3, 'cdate': 1648177297790, 'mdate': None, 'ddate': None, 'tcdate': 1648177297790, 'tmdate': 1648177424493, 'tddate': None, 'forum': 'rTwMSztg_-q', 'replyto': 'rTwMSztg_-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper6/-/Official_Review', 'content': {'title': 'Interesting idea, but results are not significant', 'review': 'Summary:\n\nThe authors propose a novel commonsensical vision-language pre-training framework as opposed to the current SOTA models which mainly focus on learning semantic connections between visual and language features/objects. The key novelty of the paper is to propose new pre-training tasks masked common sense modeling and commonsense type prediction. Extensive experiments on VCR and VQA demonstrate the effectiveness of the proposed approach.\n\n\nStrengths:\n\nThe paper proposes an interesting way to enrich existing large language models with common-sense reasoning skills. This could be potentially adapted to other related tasks and domains.\n\nI really liked the idea of getting commonsense inferences from Visual COMET and then using it in the newly designed pre-training tasks.\n\nAlthough I am not fully convinced of the improvements shown in the paper, experiments sufficiently validate the conclusions drawn in the paper.\n\n\nWeaknesses:\n\nHere are my major concerns:\n\nAuthors showed improvements that are less than 2% in section 4.3. I worked with ViLBERT model before on both VCR and VQA and I found that any improvement < 2% cannot be considered as significant as it could simply be due to the variance in training. It would help (and is necessary) to present results with different seeds to validate the improvements.\n\nFor the VQA model, is Visual COMET really required? because most of the questions in VQA are not created to test the temporal aspect of the events. Maybe using the COMET (Jena Hwang et al., AAAI 2021) model might be a good choice here?\n', 'rating': '6: Marginally above acceptance threshold', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_qCsY'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_qCsY']}, {'id': 'SferD8QYMq', 'original': None, 'number': 2, 'cdate': 1648076380731, 'mdate': None, 'ddate': None, 'tcdate': 1648076380731, 'tmdate': 1648076380731, 'tddate': None, 'forum': 'rTwMSztg_-q', 'replyto': 'rTwMSztg_-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper6/-/Official_Review', 'content': {'title': 'Well-motivated novel pretraining method that shows some improvements but could benefit with some more setting clarifications/discussions.', 'review': 'This paper aims to improve downstream task performance on commonsense reasoning tasks with a pre-training scheme that involves both recognition and cognition tasks in an automated fashion (i.e., without needing more human annotation for the cognition part). \n\nThe paper treats the original MSCOCO [1] captions as “low-level” as they often involve solely recognizing objects/people/events. These low-level captions are augmented to high-level captions by using templates and a visual-linguistic GPT-2 model fine-tuned on VisualCOMET [2] without a <location> sense, but with the rest of the commonsense types such as <before>, <after>, and <intent>. **Therefore the 3 domains they consider in pre-training are: image, low-level captions, and high-level captions.**\n\nThe authors propose 3 new tasks/methods. The paper claims these methods improve pretraining incrementally (with VL-BERT) in addition to prior MLM & MRC schemes:\n\n* **Masked commonsense modeling (MCM):**\n    * The task of predicting a masked high-level caption domain token conditioned on the rest of the high-level tokens as well as the visual and low-level caption tokens.\n    * For the other 2 domains, the authors still use MLM & MRC, conditioned on all 3 domains at the same time.\n\n* **Domain-wise adaptive masking:** As the automatically generated high-level captions include parts of the low-level captions, the authors propose to adjust the masking ration between the two captions domains on their semantic similarity (cosine sim w/ BERT embeddings & some more processing).\n\n* **Commonsense type prediction (CTP):** The task of predicting the type of the high-level commonsense captions by masking all of the template phrases.\n\n\n### Strengths\n**Background + motivation well-formulated:** The authors motivate their work well with prior research that separates recognition from cognition. \n\n**Novelty:** They push forward that improvement in commonsense understanding has to start from pretraining rather than a fine-tuning scheme, which is a unique approach. They find novel methods to do so, by looking for ways to overcome specialization in a certain type of commonsense knowledge/ability.\n\n**Ease of usage / scalability:** Their methods are automated and therefore don’t require more human annotation. Regardless of the automation, the results don\'t suffer form the basic templates.\n\n**Ablation study:** The authors show the possible improvement role of each proposed method.\n\n\n### Weaknesses\n**Improvement margin:** It’s hard to tell from Table 2 whether the performance has improved vastly (~1% improvements). This gets harder with pre-training schemes combined with fine-tuning. It could be the case that a single point in accuracy improvement does matter. This is the case in many zero-shot learning tasks. However, in this approach the authors finetune on a separate set of the dataset tested. Therefore it’s hard to say whether it’s the finetuning that does most of the work and the pretrained embeddings are luckily well ""initialized"" with respect to the task or whether it actually improves the representations. I think that the human survey helps to back this to a certain extent, and that the method is interesting enough that a small margin doesn’t affect the rest of the paper. However, non-finetuned results on all methods (non-pretrained, recogniton, cognition) or some comments on why this small improvement matters would have been helpful.\n\n**A little confused about the edge cases of masking even if it’s domain-wise:** It’s clear that MCM is conditioned on visual + low-level captions only, whereas MLM & MRC are conditioned on all three domains. But it’s a little hard to understand whether they are conditioned all independently or they could be all masked at the same time. For example it’s a little hard to understand from [lines 327-330] whether low-level captions and high-level inferences could be masked both at the same time, because of a combination of domain adaptive masking + MCM. It seems like no, and that’s the point of making sure a connection between images and the high-level captions exists, but it could be confusing to the reader. I think the paper could benefit from a clarification on this.\n\n**Similarity of datasets:** It’s clearly stated in the paper that a subset of the VCR dataset is in the VisualCOMET dataset. It’s also stated that the high-level captions from VisualCOMET are mostly related to humans, while there is a ""val-human"" set separated from VQA. I wish there was a little more discussion on why this doesn’t or does affect the results, whether the improvement lies in picking the right datasets or not.\n\n### Style\n**The term commonsensical:** Although I understand that this term is used to separate cognition-level tasks from recognition ones, a reader from a commonsense research background in NLP may be confused (while originally this definition at [line 071] aims to reduce confusion). I would either stick to commonsense and say here we are solely referring to it from a cognitive points of view, or completely let it go and use words related to cognition. I understand that it’s hard to thread around what it might entail.\n\n**Backbone citation:** I would change the citation at [line 045] to the actual GPT-2 citation and then move the visual-linguistic pretraining citation of [2] to the end of the sentence, as the rest of the sentence cites the actual backbone papers.\n\n### References\n\n[1] Lin, Tsung-Yi et al. “Microsoft COCO: Common Objects in Context.” ECCV (2014).\n\n[2] Park, Jae Sung et al. “VisualCOMET: Reasoning About the Dynamic Context of a Still Image.” ECCV (2020).', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_Zykj'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_Zykj']}, {'id': 'Hzgaz0qdzq', 'original': None, 'number': 1, 'cdate': 1648041492724, 'mdate': None, 'ddate': None, 'tcdate': 1648041492724, 'tmdate': 1648041492724, 'tddate': None, 'forum': 'rTwMSztg_-q', 'replyto': 'rTwMSztg_-q', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper6/-/Official_Review', 'content': {'title': 'The paper proposes a pretraining loss to improve commonsense reasoning in visual-text models.', 'review': 'The main idea of this work is to use a model that generates commonsense phrases on image, caption pairs, and then pretraining another model on the images and text (original and generated) with some standard technique (e.g. MLM).\nThe authors present experiments on the VQA and VCR datasets, and show small improvements for these datasets.\n\nThe idea is clever, and it’s a nice use of existing dataset to improve commonsense reasoning to pretraining models.\nThe authors also present some analysis showcasing the benefits of their method\n\n\nThe paper is overall quite hard to read to my taste, it often gives details that focus on the low level, and doesn’t depict the high level, and on the other hand, there aren’t enough details to replicate this study.\nIn addition, the paper is somewhat overclaiming. The method for adding commonsense, is based on silver data (as it uses the output of another model), and is very limited - it only adds information about the timeline (whether the incident is before or after), and the possible intent. Not only these inferences can often be speculative and ungrounded, this is only a tiny bit of the commonsense space.\nAnother point to note is that the examples themselves (e.g. figures 1, 3) seem unnatural. This is fine if it eventually leads to improved performance, but it should be discussed in the paper.\nAnother point regarding the results is that these aren’t state-of-the-art results. This is fine on its own, but should definitely be mentioned and discussed.\n\nThe writing should be improved in terms of clarity and scrutiny, as well as the overclaiming (as discussed above). There are some issues with the citing style (\\citet instead of \\cite, e.g. in L.75, L.199).\n', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_evpQ'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_evpQ']}]"
https://openreview.net/forum?id=HI5M4MYedZ5 ,HI5M4MYedZ5,"[{'id': 'SaMg5B7TKM5', 'original': None, 'number': 3, 'cdate': 1648116546197, 'mdate': None, 'ddate': None, 'tcdate': 1648116546197, 'tmdate': 1648117051880, 'tddate': None, 'forum': 'HI5M4MYedZ5', 'replyto': 'HI5M4MYedZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper2/-/Official_Review', 'content': {'title': 'Interesting and original work but the proposed method might need further development before the resulting CSKB can be used as a reliable resource', 'review': 'This paper studies generating commonsense knowledge directly from pre-trained language models for two CSKBs - ConceptNet and Ascent++. The direction is interesting and original, and the paper is well written and easy to follow. However, \n\n1. The paper claims that ""up to now no materialized resource of commonsense knowledge generated via pre-trained language models is publicly available."". However it\'s not true. West et al. (2021) construct AUTOTOMIC via GPT3 that\'s 10x larger than ATOMIC, and provide comprehensive and in-depth analysis and evaluation. \n2.  Lack of novelty: the proposed method directly applies previous COMET pipeline on two established CSKBs without further improvement or adaption. \n3. Evaluation shows a clear gap between proposed PLM generated CSKs and original human written CSKs. Without further filtering or purification, it\'s questionable whether the generated noisy CSKB can be used as a reliable resource. \n\nCitation:\nWest, Peter et al. “Symbolic Knowledge Distillation: from General Language Models to Commonsense Models.” ArXiv abs/2110.07178 (2021): n. pag.', 'rating': '5: Marginally below acceptance threshold', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_jbiB'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_jbiB']}, {'id': 'BdulVoYk_zc', 'original': None, 'number': 2, 'cdate': 1647995291605, 'mdate': None, 'ddate': None, 'tcdate': 1647995291605, 'tmdate': 1647995291605, 'tddate': None, 'forum': 'HI5M4MYedZ5', 'replyto': 'HI5M4MYedZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper2/-/Official_Review', 'content': {'title': 'Strong paper that fills a gap in current commonsense knowledge extraction work', 'review': 'This paper proposes to materialize neural commonsense predictions with COMET into concrete resources. The paper investigates two SotA knowledge bases (ConceptNet and ASCENT++) and two standard language models (GPT-2-XL and BART). The evaluation estimates the precision of the generated knowledge through salience and typicality, and the recall by comparison against a feature norms dataset, CSLB. The results indicate the promise of this approach, but also point to key obstacles in terms of redundancy, subject copying, and co-occurrence misreading.\n\nThe paper is overall well-written, original, and the evaluation is solid. The pointed challenges are thought-provoking. \n\nThe paper size is in between a short and a long paper, so it is unclear to me whether this paper qualifies as long of short. If this is meant to be a long paper, it would be good to include more discussion on how would the authors propose to circumvent the key challenges with this knowledge base generation method. These mitigation strategies are currently only briefly listed in the conclusion, which leaves many questions unanswered. Furthermore, some quantitative investigation of how would the downstream applications benefit from the created sources despite these challenges would be useful.', 'rating': '9: Top 15% of accepted papers, strong accept', 'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_8czw'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_8czw']}, {'id': 'HdWxPLfavf5', 'original': None, 'number': 1, 'cdate': 1647985230680, 'mdate': None, 'ddate': None, 'tcdate': 1647985230680, 'tmdate': 1648231796467, 'tddate': None, 'forum': 'HI5M4MYedZ5', 'replyto': 'HI5M4MYedZ5', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper2/-/Official_Review', 'content': {'title': 'Trained COMET models analyzed for precision+recall and used to generate new commonsense KGs -- but not clear why we need this resource?', 'review': 'What the paper is about: The authors offer a new resource generated from COMET models trained on commonsense knowledge graphs like ConceptNet and Ascent++. They study not just plausibility but also the precision (typicality and saliency) as well as recall of the models\' predictions. They analyze different base LMs and datasets on these metrics and offer insights. Finally, they demonstrate a web interface with wider customizations than the original one hosted by AI2.\n\nKey shortcoming: The authors call it a resource paper (L043). However, the benefit of the new ""generated"" commonsense knowledge graphs is not well established. Section 4.3 hints at some use cases like aggregation, joins, ranking, and text search. But the benefit of having a static set of predictions (this new resource) is not clear. (1) How are these better than the base KGs like ConceptNet and Ascent++? Perhaps they are bigger but not always more salient/typical/exhaustive than the original KGs (see Table 2). (2) How are these better than retaining the trained COMET model, which can generate such inferences and many more, on demand?\n\nPros: good analysis + useful resource.\nCons: usefulness of the resource not demonstrated.\n\nEDIT: Reviewer jbiB rightly points to a major missing related work, which further challenges the paper\'s claim to novelty.\n\nMinor:\n- Should you be referring to Untypical as Atypical instead? I was fairly confident that the latter is ""correct"" but words have no inherent meaning anyway so this is up to the authors.\n- Saliency vs Typicality could benefit from a formal definition (in English, not just in a formula) each. Do they differ in just values of k for top k extractions?', 'rating': '5: Marginally below acceptance threshold', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_Yejc'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_Yejc']}]"
https://openreview.net/forum?id=BUclNGKxObc ,BUclNGKxObc,"[{'id': 'rregRLcjYGc', 'original': None, 'number': 3, 'cdate': 1648110165949, 'mdate': None, 'ddate': None, 'tcdate': 1648110165949, 'tmdate': 1648110857035, 'tddate': None, 'forum': 'BUclNGKxObc', 'replyto': 'BUclNGKxObc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper1/-/Official_Review', 'content': {'title': 'Applied, Practical, Introduced new dataset, Multiple ablation studies are reported', 'review': 'This paper investigates commonsense knowledge acquisition in language models via classification and generation tasks.\n   \n[Strong]\nAuthors introduced  the first Story Cloze Test in Indonesian. Highly practical applied work with a lot of useful practical details. Detailed ablation results are presented.\n\n[Weak]\nNot novel', 'rating': '7: Good paper, accept', 'confidence': '3: The reviewer is fairly confident that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_5PLE'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_5PLE']}, {'id': 'rKWerzAnvGq', 'original': None, 'number': 2, 'cdate': 1647984141132, 'mdate': None, 'ddate': None, 'tcdate': 1647984141132, 'tmdate': 1647984141132, 'tddate': None, 'forum': 'BUclNGKxObc', 'replyto': 'BUclNGKxObc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper1/-/Official_Review', 'content': {'title': 'Contribution of an interesting story cloze dataset in Indonesian; comprehensive experiments against multiple baselines.', 'review': ""This paper creates a story cloze dataset in the form of ROCStories in Indonesian. The authors present analysis on the dataset indicating the presence of cultural entities/names/etc. that highlight the importance of collecting datasets in the desired language directly rather than simply translating the English dataset.\n\nThe authors present results from a number of baseline models---n-gram similarity, fastText embedding similarity, mBERT, and IndoBERT--- on the last-sentence-selection classification task, demonstrating that the naive similarity methods are not significantly better than random, while IndoBERT achieves 81% accuracy, indicating the task is not solved. They perform analysis to show that the dataset does not have the artifacts that the original ROCStories dataset has-- experiments show that the full context (first 4 sentences) is generally needed to achieve the best performance on the classification task. However, I'd ask the authors to acknowledge in the text that the models receiving no context are still far better than the 50% baseline, indicating some form of spurious correlations in the dataset.\n\nOn the last-sentence generation task, the authors show that training on both the English + Indonesian data leads to good performance on the Indonesian test set using mBART, according to manual evaluation. They also test zero-shot cross-lingual transfer on the classification task by training and testing on different variants of their dataset (Indonesian), ROCStories (English), and machine translations of each, finding that both the English and Indonesian test sets don't seem to benefit from training on the other language, and including machine translations has mixed effect.\n\nThe data is an interesting and novel contribution, and the inclusion of detailed experiments makes promising progress on the task with high-quality analysis. My only concern is that last-sentence prediction and generation from 5-sentence stories are very simplified versions of creative storytelling, and many works in the research area (albeit in English) now focus on harder tasks such as generating entire stories from a single prompt or from scratch on more complex datasets. However I think this resource could be used for such goals and is thus useful to the community as a starting point.\n\nPossible missing citation: Abductive Commonsense Reasoning-- a variant of the story cloze task (https://openreview.net/pdf?id=Byg1v1HKDB)\n\n"", 'rating': '8: Top 50% of accepted papers, clear accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_1PxG'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_1PxG']}, {'id': 'SGe89mjvfc', 'original': None, 'number': 1, 'cdate': 1647977357551, 'mdate': None, 'ddate': None, 'tcdate': 1647977357551, 'tmdate': 1647977406833, 'tddate': None, 'forum': 'BUclNGKxObc', 'replyto': 'BUclNGKxObc', 'invitation': 'aclweb.org/ACL/2022/Workshop/CSRR/Paper1/-/Official_Review', 'content': {'title': 'Story Cloze Task using Indonesian short stories', 'review': ""In this paper, the authors follow the Story Cloze Test framework of Mostafazadeh et al. (2016) in evaluating story understanding in Indonesian, by constructing a four-sentence story with one correct ending and one incorrect ending. To investigate commonsense knowledge acquisition in language models, authors experimented with: (1) a classification task to predict the correct ending; and (2) a generation task to complete the story with a single sentence. They investigate these tasks in two settings: (i) monolingual training and (ii) zero-shot cross-lingual transfer between Indonesian and English.\n\n1) The authors put a considerable amount of effort into ensuring the quality of the data. Even though it's not huge it's still an important resource towards multilingual commonsense knowledge.\n2) Authors consider both generative and discriminative settings and use extensive baselines and particular both monolingual and cross lingual methods\n3) For classification the ablation with different contexts is really neat and gives the reader an idea of the difficulty of the dataset. 81% is still a lot lower than human performance. However, the high performance without showing context shows the dataset might not be free from annotation artifacts\n4) For the generation I appreciate authors showing both human and automatic evaluation. The human eval results for presence of commonsense and good narrative flow is slightly concerning\n5) The authors should mention the agreement of human evaluations"", 'rating': '7: Good paper, accept', 'confidence': '4: The reviewer is confident but not absolutely certain that the evaluation is correct'}, 'signatures': ['aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_AtGC'], 'readers': ['everyone'], 'nonreaders': [], 'writers': ['aclweb.org/ACL/2022/Workshop/CSRR', 'aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_AtGC']}]"
 