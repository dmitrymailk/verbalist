{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tarfile\n",
    "from verbalist.datasets.openreview.arxiv_cleaner import run_arxiv_cleaner\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [00:00<00:00, 831188.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "dataset = pd.read_csv(\"./verbalist/datasets/openreview/openreview.csv\")\n",
    "dataset = dataset[dataset[\"arxiv_link\"] != \"-\"]\n",
    "\n",
    "dataset = {item[\"paper_url\"].strip(): item for item in dataset.to_dict(\"records\")}\n",
    "\n",
    "with open(\"./verbalist/datasets/openreview/openreview.json\") as f:\n",
    "    json_dataset = json.load(f)\n",
    "\n",
    "\n",
    "json_dataset\n",
    "for item in json_dataset:\n",
    "    paper_url = item[\"paper_url\"]\n",
    "    if paper_url in dataset:\n",
    "        dataset[paper_url][\"reviews\"] = item[\"reviews\"]\n",
    "\n",
    "dataset = list(dataset.values())\n",
    "\n",
    "\n",
    "def download_arxiv_paper(url):\n",
    "    latex_source = url.replace(\"abs\", \"e-print\")\n",
    "    zip_name = latex_source.split(\"e-print/\")[1]\n",
    "\n",
    "    folder_path = f\"./verbalist/datasets/openreview/papers/{zip_name}\"\n",
    "    zip_save_path = f\"{folder_path}.zip\"\n",
    "\n",
    "    Path(folder_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    if not os.path.isfile(zip_save_path):\n",
    "        urllib.request.urlretrieve(latex_source, zip_save_path)\n",
    "\n",
    "    with tarfile.open(zip_save_path) as zip_obj:\n",
    "        zip_obj.extractall(folder_path)\n",
    "    os.remove(zip_save_path)\n",
    "\n",
    "    parameters = {\n",
    "        \"input_folder\": folder_path,\n",
    "        \"resize_images\": False,\n",
    "        \"im_size\": 500,\n",
    "        \"compress_pdf\": False,\n",
    "        \"pdf_im_resolution\": 500,\n",
    "        \"images_allowlist\": {},\n",
    "        \"keep_bib\": False,\n",
    "        \"commands_to_delete\": [],\n",
    "        \"commands_only_to_delete\": [],\n",
    "        \"environments_to_delete\": [],\n",
    "        \"use_external_tikz\": None,\n",
    "        \"svg_inkscape\": None,\n",
    "        \"config\": None,\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    run_arxiv_cleaner(parameters)\n",
    "    shutil.rmtree(folder_path)\n",
    "    clean_folder_path = f\"{folder_path}_arXiv\"\n",
    "    os.rename(clean_folder_path, folder_path)\n",
    "\n",
    "\n",
    "for item in tqdm(dataset):\n",
    "    paper_url = item[\"arxiv_link\"]\n",
    "    # arxiv_url = download_arxiv_paper(url=paper_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine latex into one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob, os\n",
    "\n",
    "\n",
    "def remove_new_lines(string):\n",
    "    return re.sub(r\"[\\n\\t]{3,}\", \"\\n\", string)\n",
    "\n",
    "\n",
    "def find_main_tex(main_folder):\n",
    "    main_tex_path = \"\"\n",
    "    for item in glob.glob(f\"{main_folder}/*.tex\"):\n",
    "        tex_content = open(item).read()\n",
    "\n",
    "        if \"\\documentclass\" in tex_content:\n",
    "            main_tex_path = item\n",
    "            break\n",
    "\n",
    "    return main_tex_path\n",
    "\n",
    "\n",
    "def get_paper_text(paper_folder):\n",
    "    # main_tex_path = f\"{paper_folder}/main.tex\"\n",
    "    main_tex_path = find_main_tex(paper_folder)\n",
    "    main_tex = open(main_tex_path).read()\n",
    "    main_tex = remove_new_lines(main_tex)\n",
    "    main_tex = remove_new_lines(main_tex)\n",
    "    all_sections = re.findall(r\"\\\\input{.*}\", main_tex)\n",
    "    all_sections = [\n",
    "        item.replace(\"\\\\input{\", \"\").replace(\"}\", \"\") for item in all_sections\n",
    "    ]\n",
    "\n",
    "    section_contents = {item: \"\" for item in all_sections}\n",
    "\n",
    "    for section_name in all_sections:\n",
    "        section_path = f\"{paper_folder}/{section_name}\"\n",
    "\n",
    "        if not \".tex\" in section_path:\n",
    "            section_path += \".tex\"\n",
    "\n",
    "        section_content = open(section_path).read()\n",
    "        section_content = remove_new_lines(section_content)\n",
    "        section_content = remove_new_lines(section_content)\n",
    "        section_contents[section_name] = section_content\n",
    "\n",
    "    for section_name in all_sections:\n",
    "        section_content = section_contents[section_name]\n",
    "        replace_string = f\"\\\\input({section_name})\"\n",
    "        replace_string = replace_string.replace(\"(\", \"{\")\n",
    "        replace_string = replace_string.replace(\")\", \"}\")\n",
    "        # print(replace_string)\n",
    "        main_tex = main_tex.replace(replace_string, section_content)\n",
    "    return main_tex\n",
    "\n",
    "\n",
    "base_path = \"verbalist/datasets/openreview/papers/\"\n",
    "\n",
    "papers_paths = [base_path + item for item in os.listdir(base_path)]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    dataset_item = dataset[i]\n",
    "    folder_name = dataset_item[\"arxiv_link\"].split(\"/\")[-1]\n",
    "    papers_path = base_path + folder_name\n",
    "    latex = get_paper_text(papers_path)\n",
    "    # print(latex)\n",
    "    dataset[i][\"latex\"] = latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_url': 'https://openreview.net/forum?id=VvRbhkiAwR',\n",
       " 'paper_id': 'VvRbhkiAwR',\n",
       " 'arxiv_link': 'https://arxiv.org/abs/2008.12172',\n",
       " 'reviews': [{'id': '1cp_MEsz_cI',\n",
       "   'original': None,\n",
       "   'number': 3,\n",
       "   'cdate': 1594023893979,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1594023893979,\n",
       "   'tmdate': 1594023893979,\n",
       "   'tddate': None,\n",
       "   'forum': 'VvRbhkiAwR',\n",
       "   'replyto': 'VvRbhkiAwR',\n",
       "   'invitation': 'aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/-/Official_Review',\n",
       "   'content': {'title': 'Review of \"Cross-language sentiment analysis of European Twitter messages\"  -- interesting trends analysis but some more approach comparisons and tables for the data would be good.',\n",
       "    'review': 'The authors present an interesting, important and relevant trend analysis of sentiment across languages in several locales during the Covid-19 pandemic, using geo-tagged European Twitter data and pre-trained cross-lingual embeddings within a neural model.\\n\\nThe main contributions of the paper are: 1) the geo-tagged European Twitter dataset of 4.6 million tweets between Dec 2019 and Apr 2020, where some of these contain Covid19-specific keywords (it would be nice to see some percentage breakdown stats by language here), and 2) the important trends by country in terms of dip and recovery of sentiment over this period, including the overall trends across the board.\\n\\nIn terms of sentiment modeling, they use a pre-trained neural model trained on the Sentiment140 dataset of Go et al, which is English-only, hence they freeze the weights to prevent over-adapting to English. They use cross-lingual MUSE embeddings to train this network to better generalize sentiment prediction to multi-lingual data for each country. There is no novelty in the modeling approach itself, which works for the purposes of trend analysis being performed. However, there is no comparison being presented of results of experimentation with different approaches, to corroborate or contrast their current trends results. E.g. a simple baseline approach could have been to run Average and Polarity sentiment values using a standard python text processing package such as `textblob` to obtain sentiment predictions. Other experiments could have been done to use different pre-trained embeddings such regular GloVE or Multi-lingual BERT to provide a comparison or take the average of the approaches to get a more generalized picture of sentiment trends. Also the authors should make it clear that the model has really been used in perhaps inference mode only to obtain the final sentiment predictions for each tweet.\\n\\nThe treemap visualization gives a good overall picture of tweet stats, but a table providing the individual dataset statistics including keywords chosen by locale would be really helpful.\\n\\nSome notable trends are how the sentiment generally dips in all locales right around the time of lockdown announcements, and recovers relatively soon after, except for Germany where it dips at the same time as neighboring countries despite lockdown being started here much later, and UK, where sentiment stays low. It is also interesting to note the spikes and fluctuations in Covid19-related sentiment for Spain, and the overall trend for average sentiment by country for \"all\" tweets (including Covid19-related ones) tracking similarly over the time period considered.\\n\\nHowever, one trend it would be good to see some discussion on is how the histogram of keywords correlate with the sentiment for the keyworded tweets, as it appears interesting that heightened use of Covid-19 keywords in tweets tracks with more positive sentiment in most of the plots. Perhaps it would be helpful to have a separate discussion section for the overall trend analysis at the end.\\n\\nOverall the paper is well-motivated and in its current form provides perhaps the intended insights, and presents lot of scope to perform useful extended analyses with more meaningful comparisons for additional time spans and across countries where governmental and societal response were different than in Europe. Perhaps the authors could consider a more interpretable predictive sentiment model in future with some hand-crafted features such as geotag metadata, unigram and bi-gram features, binary features for government measures, and Covid19-specific keyword features by locale, which could provide more insight into why sentiment predictions trend a certain way during a specific period for a given locale.\\n\\n\\n\\n',\n",
       "    'rating': '6: Marginally above acceptance threshold',\n",
       "    'confidence': '3: The reviewer is fairly confident that the evaluation is correct'},\n",
       "   'signatures': ['aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer2'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer2']},\n",
       "  {'id': 'sr6Pz8LrNmZ',\n",
       "   'original': None,\n",
       "   'number': 2,\n",
       "   'cdate': 1593834884476,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1593834884476,\n",
       "   'tmdate': 1593834884476,\n",
       "   'tddate': None,\n",
       "   'forum': 'VvRbhkiAwR',\n",
       "   'replyto': 'VvRbhkiAwR',\n",
       "   'invitation': 'aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/-/Official_Review',\n",
       "   'content': {'title': 'Review on \"Cross-language sentiment analysis of European Twitter messages during the COVID-19 pandemic\"',\n",
       "    'review': 'The authors carried on a deep learning pipeline to analyze the sentiment of Twitter texts, and propose a complete research. The presentation and language part of this submission is good.\\n\\n However, the research mainly use the routine DL methodology and the analysis method is not contributive.  In general, the novelty and contribution of this research do not reach the level of publication as a ACL workshop paper. Here comes some comments and suggestions.\\n\\n1. The data statistics is missing. Though we found a rough number list in Figure 1, they are not quite clear. Data with time series info are also welcomed. Furthermore, several python packages help to draw Europe Map, and might make this part more vivid.\\n2. It is better to provide a figure to explain the structure of the network. The authors surely already gave some details in page 2, including the input layer, activation function info. The hyper parameter of the network could also be provided.\\n3. It is lacking of comparison of the current NN with some other NN structure. How would one single experiment derive convincing result without baseline methods or intrinsic evaluation? This is a core question I would like to raise here for this research.\\n4. I am thinking of a possibility of splitting the Twitter data in terms of weeks, and take time series consideration into the current research paradigm. A sentiment-time curve plot might lead to some instructive hypothesis, if the research take a more sophisticated experiment design.\\n',\n",
       "    'rating': '6: Marginally above acceptance threshold',\n",
       "    'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'},\n",
       "   'signatures': ['aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer1'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer1']},\n",
       "  {'id': 'kAPKEJYRLfM',\n",
       "   'original': None,\n",
       "   'number': 1,\n",
       "   'cdate': 1593827509247,\n",
       "   'ddate': None,\n",
       "   'tcdate': 1593827509247,\n",
       "   'tmdate': 1593827702431,\n",
       "   'tddate': None,\n",
       "   'forum': 'VvRbhkiAwR',\n",
       "   'replyto': 'VvRbhkiAwR',\n",
       "   'invitation': 'aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/-/Official_Review',\n",
       "   'content': {'title': 'Review',\n",
       "    'review': 'This is a mostly well-written overview of an exercise to assign a sentiment label to the European-country generated tweets during the period December’19-May’20. \\n\\nThe authors describe how they differentiate and identify the country, how they assign the sentiment level (positive, neutral, negative), how they use emojis, and how they use the deep learning neural model which presumably can adjust this label assignment regardless of what language the tweet is originally written. The authors report a 0.82 accuracy of their system. The rest of the paper is a recognition of the limitations, and a description and plotting of the sentiment level for various European countries. \\n\\nUnfortunately, these results do not contribute to adding new knowledge.  The study could use more work.  \\n\\nSuggestions: \\n\\nCould the authors provide a breakdown by language of the tweets that they process? Are we to assume that all tweet originated from Italy are in Italian and those originating in Germany are in German? \\n\\nIs this data publicly available?\\n\\nHas the 0.82 accuracy been manually validated? Is there a difference in accuracy depending on the language? The authors claim that one of the contributions of their study is this tagged dataset (geotagged, and sentiment-tagged). It seems there is no further evaluation on how well the tagging has been applied. \\n\\nAnd while it is visibly clear that we see a global fall in sentiment that correlates with governments issuing lock-down protective measures, and this result could be a start that this labelling of the data is good, is there anything else we can say, is there any other way we can analyze this data and identify common topics in the similar sentiment groups? Something that can be actually useful to the COVID-19 researchers…\\n',\n",
       "    'rating': '6: Marginally above acceptance threshold',\n",
       "    'confidence': '5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature'},\n",
       "   'signatures': ['aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer3'],\n",
       "   'readers': ['everyone'],\n",
       "   'nonreaders': [],\n",
       "   'writers': ['aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer3']}],\n",
       " 'latex': '\\n\\\\documentclass[11pt,a4paper]{article}\\n\\\\usepackage[hyperref]{acl2020}\\n\\\\usepackage{times}\\n\\\\usepackage{latexsym}\\n\\\\renewcommand{\\\\UrlFont}{\\\\ttfamily\\\\small}\\n\\\\usepackage{graphicx}\\n\\\\usepackage{caption}\\n\\\\usepackage{url}\\n\\\\usepackage[utf8]{inputenc}\\n\\\\usepackage{microtype}\\n\\n\\\\aclfinalcopy %\\n\\n\\\\setlength\\\\titlebox{10cm}\\n\\n\\\\newcommand\\\\BibTeX{B\\\\textsc{ib}\\\\TeX}\\n\\\\title{Cross-language sentiment analysis of European Twitter messages during the COVID-19 pandemic}\\n\\n\\\\author{Anna Kruspe \\\\\\\\\\n  German Aerospace Center (DLR) \\\\\\\\\\n  Institute of Data Science \\\\\\\\\\n  Jena, Germany \\\\\\\\\\n  \\\\texttt{anna.kruspe@dlr.de} \\\\\\\\\\\\And\\n  Matthias H\\\\\"aberle \\\\\\\\\\n  Technical University of Munich (TUM) \\\\\\\\\\n  Signal Processing in Earth Observation (SiPEO) \\\\\\\\\\n  Munich, Germany \\\\\\\\\\n  \\\\texttt{matthias.haeberle@tum.de} \\\\\\\\\\\\AND\\n  Iona Kuhn \\\\\\\\\\n  German Aerospace Center (DLR) \\\\\\\\\\n  Institute of Data Science \\\\\\\\\\n  Jena, Germany \\\\\\\\ \\n  \\\\texttt{iona.kuhn@dlr.de} \\\\\\\\\\\\And \\n  Xiao Xiang Zhu \\\\\\\\\\n  German Aerospace Center (DLR) \\\\\\\\\\n  Remote Sensing Technology Institute (IMF) \\\\\\\\\\n  Oberpfaffenhofen, Germany \\\\\\\\\\n  \\\\texttt{xiaoxiang.zhu@dlr.de}}\\n\\n\\\\date{}\\n\\n\\\\begin{document}\\n\\\\maketitle\\n\\\\begin{abstract}\\nSocial media data can be a very salient source of information during crises. User-generated messages provide a window into people\\'s minds during such times, allowing us insights about their moods and opinions. Due to the vast amounts of such messages, a large-scale analysis of population-wide developments becomes possible.\\\\\\\\\\nIn this paper, we analyze Twitter messages (tweets) collected during the first months of the COVID-19 pandemic in Europe with regard to their sentiment. This is implemented with a neural network for sentiment analysis using multilingual sentence embeddings. We separate the results by country of origin, and correlate their temporal development with events in those countries. This allows us to study the effect of the situation on people\\'s moods. We see, for example, that lockdown announcements correlate with a deterioration of mood in almost all surveyed countries, which recovers within a short time span.\\n\\\\end{abstract}\\n\\\\section{Introduction}\\nThe COVID-19 pandemic has led to a worldwide situation with a large number of unknowns. Many heretofore unseen events occurred within a short time span, and governments have had to make quick decisions for containing the spread of the disease. Due to the extreme novelty of the situation, the outcomes of many of these events have not been studied well so far. This is true with regards to their medical effect, as well as the effect on people\\'s perceptions and moods.\\\\\\\\\\nFirst studies about the effect the pandemic has on people\\'s lives are being published at the moment \\\\citep[e.g.][]{uni_erfurt}, mainly focusing on surveys and polls. Naturally, such studies are limited to relatively small numbers of participants and focus on specific regions (e.g. countries).\\\\\\\\\\nIn contrast, social media provides a large amount of user-created messages reflective of those users\\' moods and opinions. The issue with this data source is the difficulty of analysis - social media messages are extremely noisy and idiosyncratic, and the amount of incoming data is much too large to analyze manually. We therefore need automatic methods to extract meaningful insights.\\\\\\\\\\nIn this paper, we describe a data set collected from Twitter during the months of December 2019 through April 2020, and present an automatic method for determining the sentiments contained in these messages. We then calculate the development of these sentiments over time, segment the results by country, and correlate them with events that took place in each country during those five months.\\n\\n\\\\vspace{-5pt}\\n\\\\section{Related work}\\nSince the pandemic outbreak and lockdown measures, numerous studies have been published to investigate the impact of the corona pandemic on Twitter. \\n\\\\citet{feng2020working} analyzed tweets from the US on a state and county level. First, they could detect differences in temporal tweeting patterns and found that people tweeting more about COVID-19 during working hours as the pandemic progressed. Furthermore, they conducted a sentiment analysis over time including an event specific subtask reporting negative sentiment when the 1000th death was announced and positive when the lockdown measures were eased in the states.   \\n\\n\\\\citet{lyu2020sense} looked into US-tweets which contained the terms \"Chinese-virus\" or \"Wuhan-virus\" referring to the COVID-19 pandemic to perform a user characterization. They compared the results to users that did not make use of such controversial vocabulary. The findings suggest that there are noticeable differences in age group, geo-location, or followed politicians.\\n\\n\\\\citet{chen2020eyes} focused on sentiment analysis and topic modelling on COVID-19 tweets containing the term \"Chinese-virus\" (controversial) and contrasted them against tweets without such terms (non-controversial). Tweets containing \"Chinese-virus\" discussing more topics which are related to China whereas tweets without such words stressing how to defend the virus. The sentiment analysis revealed for both groups negative sentiment, yet with a slightly more positive and analytical tone for the non-controversial tweets. Furthermore, they accent more the future and what the group itself can do to fight the disease. In contrast, the controversial group aiming more on the past and concentrate on what others should do.\\n\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.8\\\\textwidth]{fig/treemap_countries.pdf}}\\n\\t\\\\caption{Treemap of Twitter activity in Europe during the time period of December 2019 to April 2020.}\\n\\t\\\\label{fig:treemap_countries}\\n\\\\end{figure*}\\n\\\\section{Data collection}\\\\label{sec:data_collection}\\nFor our study, we used the freely available Twitter API to collect the tweets from December 2019 to April 2020. The free API allows streaming of 1\\\\% of the total tweet amount. To cover the largest possible area, we used a bounding box which includes the entire world. From this data, we sub-sampled 4,683,226 geo-referenced tweets in 60 languages located in the Europe. To create the Europe sample, we downloaded a shapefile of the earth\\\\footnote{\\\\url{https://www.naturalearthdata.com/downloads/10m-cultural-vectors/10m-admin-0-countries/}}, then we filtered by country  performing a point in polygon test using the Python package \\\\textit{Shapely}\\\\footnote{\\\\url{https://pypi.org/project/Shapely/}}. Figure \\\\ref{fig:treemap_countries} depicts the Europe Twitter activity in total numbers. Most tweets come from the U.K. Tweets are not filtered by topic, i.e. many of them are going to be about other topics than COVID-19. This is by design. As we will describe later, we also apply a simple keyword filter to detect tweets that are probably COVID-19-related for further analysis.\\n\\\\begin{figure}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.4\\\\textwidth]{fig/model.png}}\\n\\t\\\\caption{Architecture of the sentiment analysis model.}\\n\\t\\\\label{fig:model}\\n\\\\end{figure}\\n\\n\\\\section{Analysis method}\\nWe now describe how the automatic sentiment analysis was performed, and the considerations involved in this method.\\n\\n\\\\begin{figure}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.5\\\\textwidth]{fig/embedding_comp.png}}\\n\\t\\\\caption{MSE for different models on the \\\\textit{Sentiment140} test dataset.}\\n\\t\\\\label{fig:embedding_comp}\\n\\\\end{figure}\\n\\n\\\\subsection{Sentiment modeling}\\nIn order to analyze these large amounts of data, we focus on an automatic method for sentiment analysis. We train a neural network for sentiment analysis on tweets. The text input layer of the network is followed by a pre-trained word or sentence embedding.\\nThe resulting  embedding vectors are fed into a 128-dimensional fully-connected ReLU layer with 50\\\\% dropout, followed by a regression output layer with sigmoid activation. Mean squared error is used as loss. The model is visualized in figure \\\\ref{fig:model}.\\\\\\\\\\nThis network is trained on the \\\\textit{Sentiment140} dataset \\\\cite{go}. This dataset contains around 1.5 million tweets collected through keyword search, and then annotated automatically by detecting emoticons. Tweets are determined to have positive, neutral, or negative sentiment. We map these sentiments to the values 1.0, 0.5, and 0.0 for the regression. Sentiment for unseen tweets is then represented on a continuous scale at the output.\\\\\\\\\\nWe test variants of the model using the following pre-trained word- and sentence-level embeddings:\\n\\\\begin{itemize}\\n    \\\\item A skip-gram version of \\\\textit{word2vec} \\\\citep{mikolov} trained on the English-language Wikipedia\\\\footnote{\\\\url{https://tfhub.dev/google/Wiki-words-250/2}}\\n    \\\\item A multilingual version of BERT \\\\citep{bert} trained on Wikipedia data\\\\footnote{\\\\url{https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2}}\\n    \\\\item A multilingual version of BERT trained on 160 million tweets containing COVID-19 keywords\\\\footnote{\\\\url{https://tfhub.dev/digitalepidemiologylab/covid-twitter-bert/1}} \\\\citep{covidtwitterbert}\\n    \\\\item An ELMO model \\\\cite{elmo} trained on the 1 Billion Word Benchmark dataset\\\\footnote{\\\\url{https://tfhub.dev/google/elmo/3}}\\n    \\\\item The Multilingual Universal Sentence Encoder (MUSE)\\\\footnote{\\\\url{https://tfhub.dev/google/universal-sentence-encoder-multilingual/3}} \\\\citep{yang}\\n\\\\end{itemize}\\nWe train each sentiment analysis model on the \\\\textit{Sentiment140} dataset for 10 epochs. Mean squared error results on the unseen test portion of the same dataset are shown in figure \\\\ref{fig:embedding_comp}. For comparison, we also include an analysis conducted by VADER which is a rule-based sentiment reasoner designed for social media messages \\\\cite{vader}.\\\\\\\\ %\\nInterestingly, most neural network results are in the range of the rule-based approach. BERT delivers better results than the \\\\textit{word2vec} model, with ELMO and the COVID-19-specific version also leading to improvements. However, the best result is achieved with the pre-trained multilingual USE model, which can embed whole sentences rather than (contextualized) words. We therefore perform the subsequent sentiment analysis with the MUSE-based model.\\\\\\\\\\nAn interesting side note here is that the dataset only contains English-language tweets, but the sentence embedding is multilingual (for 16 languages). We freeze the embedding weights to prevent them from over-adapting to English. Due to the cross-lingual semantic representation capabilities of the pre-trained embedding, we expect the model to be able to detect sentiment in other languages just as well.\\\\\\\\\\nWith the created model, we perform sentiment analysis on the 4.6 million tweets collected from December to April, and then aggregate the results over time. This provides us with a representation of the development of Twitter messages\\' average sentiment over time. We specifically consider all collected tweets rather than just those determined to be topically related to COVID-19 because we are interested in the effect on people\\'s moods in general, not just with regards to the pandemic. Additionally, we also filter the tweets by COVID-19-associated keywords, and analyze their sentiments as well. %\\nThe chosen keywords are listed in figure \\\\ref{fig:keywords}.\\\\\\\\\\n\\n\\\\subsection{Considerations}\\nThere are some assumptions implicit in this analysis method that we want to address here. First of all, we only consider tweets containing a geolocation. This applies to less than 1\\\\% of the whole tweet stream, but according to \\\\citet{sloan}, the amount of geolocated tweets closely follows the geographic population distribution. According to \\\\citet{graham}, there probably are factors determining which users share their locations and which ones do not, but there is no systematic study of these.\\\\\\\\\\nOther assumptions arise from the analysis method itself. For one, we assume that the model is able to extract meaningful sentiment values from the data. However, sentiment is subjective, and the model may be failing for certain constructs (e.g. negations, sarcasm). Additionally, modeling sentiment on a binary scale does not tell the whole story. ``Positive\\'\\' sentiment encompasses, for example, happy or hopeful tweets, ``negative\\'\\' angry or sad tweets, and ``neutral\\'\\' tweets can be news tweets, for example. A more finegrained analysis would be of interest in the future.\\\\\\\\\\nWe also assume a somewhat similar perception of sentiment across languages. Finally, we assume that the detected sentiments as a whole are reflective of the mood within the community; on the other hand, mood is not quantifiable in the first place. All of these assumptions can be called into question. Nevertheless, while they may not be applicable for every single tweet, we hope to detect interesting effects on a large scale. When analyzing thousands of tweets within each time frame, random fluctuations become less likely. We believe that this analysis can provide useful insights into people\\'s thoughts, and form an interesting basis for future studies from psychological or sociological perspectives.\\n\\n\\\\begin{figure}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.4\\\\textwidth]{fig/keywords.png}}\\n\\t\\\\caption{Keywords used for filtering the tweets (not case sensitive).}\\n\\t\\\\label{fig:keywords}\\n\\\\end{figure}\\n\\n\\\\section{Results}\\nIn the following, we present the detected sentiment developments over time over-all and for select countries, and correlate them with events that took place within these months. Results for some other countries would have been interesting as well, but were not included because the main spoken language is not covered by MUSE (e.g. Sweden, Denmark). Others were excluded because there was not enough material available; we only analyze countries with at least 300,000 recorded tweets. As described in section \\\\ref{sec:data_collection}, tweets are filtered geographically, not by language (i.e. Italian tweets may also be in other languages than Italian).\\n\\n\\\\subsection{Over-all}\\\\label{subsec:res_overall}\\nIn total, we analyzed around 4.6 million tweets, of which around 79,000 contained at least one COVID-19 keyword. Figure \\\\ref{fig:sentiment_kw_count_all} shows the development of the sentiment over time for all tweets and for those with keywords, as well as the development of the number of keyworded tweets. The sentiment results are smoothed on a weekly basis (otherwise, we would be seeing a lot of movement during the week, e.g. an increase on the weekends). For the average over all tweets, we see a slight decrease in sentiment over time, indicating possibly that users\\' moods deteriorated over the last few months. There are some side effects that need to be considered here. For example, the curve rises slightly for holidays like Christmas and Easter (April 12). Interestingly, we see a clear dip around mid-March. Most European countries started implementing strong social distancing measures around this time. We will talk about this in more detail in the next sections.\\\\\\\\\\nWe see that keywords were used very rarely before mid-January, and only saw a massive increase in usage around the beginning of March. Lately, usage has been decreasing again, indicating a loss of interest over time. Consequently, the sentiment analysis for keyword tweets is not expressive in the beginning. Starting with the more frequent usage in February, the associated sentiment drops massively, indicating that these tweets are now used in relation with the pandemic. Interestingly, the sentiment recovers with the increased use in March - it is possible that users were starting to think about the risks and handling of the situation in a more relaxed way over time. Still, the sentiment curve for keyword tweets lies significantly below the average one, which is to be expected for this all-around rather negative topic.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_all.png}}\\n\\t\\\\caption{Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_all}\\n\\\\end{figure*}\\n\\n\\\\subsection{Analysis by country}\\nWe next aggregated the tweets by country as described in section \\\\ref{sec:data_collection} and performed the same analysis by country. The country-wise curves are shown jointly in figure \\\\ref{fig:sentiment_by_country}. Comparing the absolute average sentiment values between countries is difficult as they may be influenced by the languages or cultural factors. However, the relative development is interesting. We see that all curves progress in a relatively similar fashion, with peaks around Christmas and Easter, a strong dip in the middle of March, and a general slow decrease in sentiment. In the following, we will have a closer look at each country\\'s development. (Note that the keyword-only curves are cut of in the beginning for some countries due to a low number of keyword tweets).\\n\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_by_country.png}}\\n\\t\\\\caption{Development of average sentiment over time by country (all tweets).}\\n\\t\\\\label{fig:sentiment_by_country}\\n\\\\end{figure*}\\n\\n\\\\subsubsection{Italy}\\nFigure \\\\ref{fig:sentiment_kw_count_italy} shows the average sentiment for all Italian tweets and all Italian keyword tweets, as well as the development of keyword tweets in Italy. In total, around 400,000 Italian tweets are contained in the data set, of which around 12,000 have a keyword. Similar to the over-all curves described in section \\\\ref{subsec:res_overall}, the sentiment curve slowly decreases over time, keywords are not used frequently before the end of January, when the first cases in Italy were confirmed. Sentiment in the keyword tweets starts out very negative and then increases again. Interestingly, we see a dip in sentiment on March 9, which is exactly when the Italian lockdown was announced. Keywords were also used most frequently during that week. The dip is not visible in the keyword-only sentiment curve, suggesting that the negative sentiment was actually caused by the higher prevalence of coronavirus-related tweets.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_italy_mod.png}}\\n\\t\\\\caption{Italy: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_italy}\\n\\\\end{figure*}\\n\\n\\\\subsubsection{Spain}\\nFor Spain, around 780,000 tweets were collected in total with around 14,000 keyword tweets. The curves are shown in figure \\\\ref{fig:sentiment_kw_count_spain}. The heavier usage of keywords starts around the same time as in Italy, where the first domestic cases were publicized at the same time. The spike in keyword-only sentiment in mid-February is actually an artifact of the low number of keyworded tweets in combination with the fact that ``corona\\'\\' is a word with other meanings in Spanish (in contrast to the other languages). With more keyword mentions, the sentiment drops as in other countries.\\\\\\\\\\nFrom there onwards, the virus progressed somewhat slower in Spain, which is reflected in the curves as well. A lockdown was announced in Spain on March 14, corresponding to a dip in the sentiment curve. As with the Italian data, this dip is not present in the keyword-only sentiments.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_spain.png}}\\n\\t\\\\caption{Spain: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_spain}\\n\\\\end{figure*}\\n\\n\\\\subsubsection{France}\\nAnalyses for the data from France are shown in figure \\\\ref{fig:sentiment_kw_count_france}. For France, around 309,000 tweets and around 4,600 keyword tweets were collected. Due to the lower number of data points, the curves are somewhat less smooth. Despite the first European COVID-19 case being detected in France in January, cases did not increase significantly until the end of February, which once again is also seen in the start of increased keyword usage here. The French lockdown was announced on March 16 and extended on April 13, both reflected in dips in the sentiment curve. Towards the end of the considered period, keyword-only sentiment actually starts to increase, which is also seen in Italy and Germany. This could indicate a shift to a more hopeful outlook with regards to the pandemic.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_france_mod.png}}\\n\\t\\\\caption{France: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_france}\\n\\\\end{figure*}\\n\\\\subsubsection{Germany}\\nFor Germany, around 415,000 tweets and around 5,900 keyword tweets were collected. The analysis results are shown in figure \\\\ref{fig:sentiment_kw_count_germany}. After very few first cases at the end of January, Germany\\'s case count did not increase significantly until early March, which is again when keyword usage increased. The decrease in the sentiment curve actually arrives around the same time as in France and Spain, which is a little surprising because social distancing measures were not introduced by the government until March 22 (extended on March 29). German users were likely influenced by the situation in their neighboring countries here. In general, the curve is flatter than in other countries. One possible reason for this might be the lower severity of measures in Germany, e.g. there were no strict curfews.\\\\\\\\\\nIn contrast to all other considered countries, the keyword-only sentiment curve is not significantly below the sentiment curve for all tweets in Germany after the beginning of March. There are some possible explanations for this. For one, governmental response to the situation was generally applauded in Germany \\\\cite{uni_erfurt}, and, as mentioned above, was not as strict as in other countries, possibly not impacting people as much. On the other hand, the over-all German curve is lower than its counterparts from other countries, i.e. German tweets have lower average sentiment values in general, possibly caused by cultural factors.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_germany_mod.png}}\\n\\t\\\\caption{Germany: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_germany}\\n\\\\end{figure*}\\n\\\\subsubsection{United Kingdom}\\n\\nCurves for the United Kingdom are shown in figure \\\\ref{fig:sentiment_kw_count_uk}, calculated on around 1,380,000 tweets including around 22,000 keyword tweets. Higher keyword usage starts somewhat earlier here than expected in February, whereas a significant increase in cases did not occur until March. Once again, keyword-only sentiment starts out very negative and then increases over time.\\\\\\\\\\nThe British government handled the situation somewhat differently. In early March, only recommendations were given, and a lockdown was explicitly avoided to prevent economic consequences. This may be a cause for the sentiment peak seen at this time. However, the curve falls until mid-March, when other European countries did implement lockdowns. The government finally did announce a lockdown starting on March 26. This did not lead to a significant change in average sentiment anymore, but in contrast with other countries, the curve does not swing back to a significantly more positive level in the considered period, and actually decreases towards the end.\\n\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_uk_mod.png}}\\n\\t\\\\caption{United Kingdom: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_uk}\\n\\\\end{figure*}\\n\\\\section{Conclusion}\\n\\\\vspace{-5pt}\\n\\nIn this paper, we presented the results of a sentiment analysis of 4.6 million geotagged Twitter messages collected during the months of December 2019 through April 2020. This analysis was performed with a neural network trained on an unrelated Twitter sentiment data set. The tweets were then tagged with sentiment on a scale from 0 to 1 using this network. The results were aggregated by country, and averaged over time. Additionally, the sentiments of tweets containing COVID-19-related keywords were aggregated separately.\\\\\\\\\\nWe find several interesting results in the data. First of all, there is a general downward trend in sentiment in the last few months corresponding to the COVID-19 pandemic, with clear dips at times of lockdown announcements and a slow recovery in the following weeks in most countries. COVID-19 keywords were used rarely before February, and correlate with a rise in cases in each country. The sentiment of keyworded tweets starts out very negative at the beginning of increased keyword usage, and becomes more positive over time. However, it remains significantly below the average sentiment in all countries except Germany. Interestingly, there is a slight upward development in sentiment in most countries towards the end of the considered period.\\\\\\\\\\n\\n\\\\vspace{-10pt}\\n\\n\\\\section{Future work}\\n\\\\vspace{-5pt}\\n\\nWe will continue this study by also analyzing the development in the weeks since May 1st and the coming months. More countries will also be added. It will be very interesting to compare the shown European results to those of countries like China, South Korea, Japan, New Zealand, or even individual US states, which were impacted by the pandemic at different times and in different ways, and where the governmental and societal response was different from that of Europe.\\\\\\\\ \\nThere are also many other interesting research questions that could be answered on a large scale with this data - for example, regarding people\\'s trust in published COVID-19 information, their concrete opinions on containment measures, or their situation during an infection. Other data sets have also been published in the meantime, including ones that contains hundreds of millions of tweets at the time of writing \\\\cite[e.g.][]{geocov,banda_juan_m_2020_3757272}. These data sets are much larger because collection was not restricted to geotagged tweets. In \\\\citet{geocov}, geolocations were instead completed from outside sources.\\\\\\\\\\nThese studies could also be extended to elucidate more detailed factors in each country. One possibility here is an analysis of Twitter usage and tweet content by country. Another, as mentioned above, lies in moving from the binary sentiment scale to a more complex model.\\n\\n\\\\newpage\\n\\\\bibliography{anthology,acl2020}\\n\\\\bibliographystyle{acl_natbib}\\n\\n\\\\appendix\\n\\\\end{document}\\n'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_dataset = []\n",
    "for dataset_item in dataset:\n",
    "    for item in dataset_item[\"reviews\"]:\n",
    "        # print(item)\n",
    "        title = item[\"content\"].get(\"title\", \"\").strip()\n",
    "        review = item[\"content\"].get(\"review\", \"\").strip()\n",
    "        rating = item[\"content\"].get(\"rating\", \"\").strip()\n",
    "        confidence = item[\"content\"].get(\"confidence\", \"\").strip()\n",
    "        \n",
    "        if rating != \"\":\n",
    "            rating = \"Rating: \" + rating\n",
    "        if confidence != \"\":\n",
    "            confidence = \"Confidence: \" + confidence\n",
    "\n",
    "        full_review = f\"{title}\\n{review}\\n{rating}\\n{confidence}\"\n",
    "        # print(full_review)\n",
    "        # print(\"=\" * 100)\n",
    "        prompts_dataset.append({\n",
    "            \"full_review\":  full_review,\n",
    "            \"latex\": dataset_item['latex'],\n",
    "            'paper_url': dataset_item['paper_url'],\n",
    "            'arxiv_url': dataset_item['arxiv_link']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review</th>\n",
       "      <th>latex</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>arxiv_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review of \"Cross-language sentiment analysis o...</td>\n",
       "      <td>\\n\\documentclass[11pt,a4paper]{article}\\n\\usep...</td>\n",
       "      <td>https://openreview.net/forum?id=VvRbhkiAwR</td>\n",
       "      <td>https://arxiv.org/abs/2008.12172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review on \"Cross-language sentiment analysis o...</td>\n",
       "      <td>\\n\\documentclass[11pt,a4paper]{article}\\n\\usep...</td>\n",
       "      <td>https://openreview.net/forum?id=VvRbhkiAwR</td>\n",
       "      <td>https://arxiv.org/abs/2008.12172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review\\nThis is a mostly well-written overview...</td>\n",
       "      <td>\\n\\documentclass[11pt,a4paper]{article}\\n\\usep...</td>\n",
       "      <td>https://openreview.net/forum?id=VvRbhkiAwR</td>\n",
       "      <td>https://arxiv.org/abs/2008.12172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent description of a critical COVID-19 d...</td>\n",
       "      <td>\\n\\documentclass[11pt,a4paper]{article}\\n\\Pass...</td>\n",
       "      <td>https://openreview.net/forum?id=0gLzHrE_t3z</td>\n",
       "      <td>https://arxiv.org/abs/2004.10706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overview of a highly important Covid-19 datase...</td>\n",
       "      <td>\\n\\documentclass[11pt,a4paper]{article}\\n\\Pass...</td>\n",
       "      <td>https://openreview.net/forum?id=0gLzHrE_t3z</td>\n",
       "      <td>https://arxiv.org/abs/2004.10706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2nd Place Scheme on Action Recognition Track o...</td>\n",
       "      <td>\\n\\documentclass[runningheads]{llncs}\\n\\usepac...</td>\n",
       "      <td>https://openreview.net/forum?id=R6YWiPVOQBo</td>\n",
       "      <td>https://arxiv.org/abs/2008.03996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Interesting method, unclear explanation\\n#### ...</td>\n",
       "      <td>\\n\\documentclass[runningheads]{llncs}\\n\\usepac...</td>\n",
       "      <td>https://openreview.net/forum?id=R6YWiPVOQBo</td>\n",
       "      <td>https://arxiv.org/abs/2008.03996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>The proposed method is somehow novel, but it l...</td>\n",
       "      <td>\\n\\documentclass[manuscript]{acmart}\\n\\n\\usepa...</td>\n",
       "      <td>https://openreview.net/forum?id=atWaELmguNj7</td>\n",
       "      <td>https://arxiv.org/abs/2208.12133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>The evaluation and sub-materials show good res...</td>\n",
       "      <td>\\n\\documentclass[manuscript]{acmart}\\n\\n\\usepa...</td>\n",
       "      <td>https://openreview.net/forum?id=atWaELmguNj7</td>\n",
       "      <td>https://arxiv.org/abs/2208.12133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Novel and interesting paper with a little uncl...</td>\n",
       "      <td>\\n\\documentclass[manuscript]{acmart}\\n\\n\\usepa...</td>\n",
       "      <td>https://openreview.net/forum?id=atWaELmguNj7</td>\n",
       "      <td>https://arxiv.org/abs/2208.12133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_review  \\\n",
       "0    Review of \"Cross-language sentiment analysis o...   \n",
       "1    Review on \"Cross-language sentiment analysis o...   \n",
       "2    Review\\nThis is a mostly well-written overview...   \n",
       "3    Excellent description of a critical COVID-19 d...   \n",
       "4    Overview of a highly important Covid-19 datase...   \n",
       "..                                                 ...   \n",
       "145  2nd Place Scheme on Action Recognition Track o...   \n",
       "146  Interesting method, unclear explanation\\n#### ...   \n",
       "147  The proposed method is somehow novel, but it l...   \n",
       "148  The evaluation and sub-materials show good res...   \n",
       "149  Novel and interesting paper with a little uncl...   \n",
       "\n",
       "                                                 latex  \\\n",
       "0    \\n\\documentclass[11pt,a4paper]{article}\\n\\usep...   \n",
       "1    \\n\\documentclass[11pt,a4paper]{article}\\n\\usep...   \n",
       "2    \\n\\documentclass[11pt,a4paper]{article}\\n\\usep...   \n",
       "3    \\n\\documentclass[11pt,a4paper]{article}\\n\\Pass...   \n",
       "4    \\n\\documentclass[11pt,a4paper]{article}\\n\\Pass...   \n",
       "..                                                 ...   \n",
       "145  \\n\\documentclass[runningheads]{llncs}\\n\\usepac...   \n",
       "146  \\n\\documentclass[runningheads]{llncs}\\n\\usepac...   \n",
       "147  \\n\\documentclass[manuscript]{acmart}\\n\\n\\usepa...   \n",
       "148  \\n\\documentclass[manuscript]{acmart}\\n\\n\\usepa...   \n",
       "149  \\n\\documentclass[manuscript]{acmart}\\n\\n\\usepa...   \n",
       "\n",
       "                                        paper_url  \\\n",
       "0      https://openreview.net/forum?id=VvRbhkiAwR   \n",
       "1      https://openreview.net/forum?id=VvRbhkiAwR   \n",
       "2      https://openreview.net/forum?id=VvRbhkiAwR   \n",
       "3     https://openreview.net/forum?id=0gLzHrE_t3z   \n",
       "4     https://openreview.net/forum?id=0gLzHrE_t3z   \n",
       "..                                            ...   \n",
       "145   https://openreview.net/forum?id=R6YWiPVOQBo   \n",
       "146   https://openreview.net/forum?id=R6YWiPVOQBo   \n",
       "147  https://openreview.net/forum?id=atWaELmguNj7   \n",
       "148  https://openreview.net/forum?id=atWaELmguNj7   \n",
       "149  https://openreview.net/forum?id=atWaELmguNj7   \n",
       "\n",
       "                            arxiv_url  \n",
       "0    https://arxiv.org/abs/2008.12172  \n",
       "1    https://arxiv.org/abs/2008.12172  \n",
       "2    https://arxiv.org/abs/2008.12172  \n",
       "3    https://arxiv.org/abs/2004.10706  \n",
       "4    https://arxiv.org/abs/2004.10706  \n",
       "..                                ...  \n",
       "145  https://arxiv.org/abs/2008.03996  \n",
       "146  https://arxiv.org/abs/2008.03996  \n",
       "147  https://arxiv.org/abs/2208.12133  \n",
       "148  https://arxiv.org/abs/2208.12133  \n",
       "149  https://arxiv.org/abs/2208.12133  \n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts_dataset)\n",
    "# pd.DataFrame(prompts_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# dataset = Dataset.from_list(dataset)\n",
    "dataset = Dataset.from_list(prompts_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.19ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]\n",
      "Updating downloaded metadata with the new split.\n"
     ]
    }
   ],
   "source": [
    "# dataset.push_to_hub(\"dim/openreview_raw_65\")\n",
    "dataset.push_to_hub(\"dim/openreview_prompts_65\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 357/357 [00:00<00:00, 3.25MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/kosenko/.cache/huggingface/datasets/dim___parquet/dim--openreview_prompts_65-197d25d8f8ef4f49/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 1.49M/1.49M [00:00<00:00, 3.29MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 645.38it/s]\n",
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/kosenko/.cache/huggingface/datasets/dim___parquet/dim--openreview_prompts_65-197d25d8f8ef4f49/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 750.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"dim/openreview_prompts_65\")\n",
    "dataset = dataset[\"train\"]\n",
    "dataset = dataset.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_review': 'Review of \"Cross-language sentiment analysis of European Twitter messages\"  -- interesting trends analysis but some more approach comparisons and tables for the data would be good.\\nThe authors present an interesting, important and relevant trend analysis of sentiment across languages in several locales during the Covid-19 pandemic, using geo-tagged European Twitter data and pre-trained cross-lingual embeddings within a neural model.\\n\\nThe main contributions of the paper are: 1) the geo-tagged European Twitter dataset of 4.6 million tweets between Dec 2019 and Apr 2020, where some of these contain Covid19-specific keywords (it would be nice to see some percentage breakdown stats by language here), and 2) the important trends by country in terms of dip and recovery of sentiment over this period, including the overall trends across the board.\\n\\nIn terms of sentiment modeling, they use a pre-trained neural model trained on the Sentiment140 dataset of Go et al, which is English-only, hence they freeze the weights to prevent over-adapting to English. They use cross-lingual MUSE embeddings to train this network to better generalize sentiment prediction to multi-lingual data for each country. There is no novelty in the modeling approach itself, which works for the purposes of trend analysis being performed. However, there is no comparison being presented of results of experimentation with different approaches, to corroborate or contrast their current trends results. E.g. a simple baseline approach could have been to run Average and Polarity sentiment values using a standard python text processing package such as `textblob` to obtain sentiment predictions. Other experiments could have been done to use different pre-trained embeddings such regular GloVE or Multi-lingual BERT to provide a comparison or take the average of the approaches to get a more generalized picture of sentiment trends. Also the authors should make it clear that the model has really been used in perhaps inference mode only to obtain the final sentiment predictions for each tweet.\\n\\nThe treemap visualization gives a good overall picture of tweet stats, but a table providing the individual dataset statistics including keywords chosen by locale would be really helpful.\\n\\nSome notable trends are how the sentiment generally dips in all locales right around the time of lockdown announcements, and recovers relatively soon after, except for Germany where it dips at the same time as neighboring countries despite lockdown being started here much later, and UK, where sentiment stays low. It is also interesting to note the spikes and fluctuations in Covid19-related sentiment for Spain, and the overall trend for average sentiment by country for \"all\" tweets (including Covid19-related ones) tracking similarly over the time period considered.\\n\\nHowever, one trend it would be good to see some discussion on is how the histogram of keywords correlate with the sentiment for the keyworded tweets, as it appears interesting that heightened use of Covid-19 keywords in tweets tracks with more positive sentiment in most of the plots. Perhaps it would be helpful to have a separate discussion section for the overall trend analysis at the end.\\n\\nOverall the paper is well-motivated and in its current form provides perhaps the intended insights, and presents lot of scope to perform useful extended analyses with more meaningful comparisons for additional time spans and across countries where governmental and societal response were different than in Europe. Perhaps the authors could consider a more interpretable predictive sentiment model in future with some hand-crafted features such as geotag metadata, unigram and bi-gram features, binary features for government measures, and Covid19-specific keyword features by locale, which could provide more insight into why sentiment predictions trend a certain way during a specific period for a given locale.\\nRating: 6: Marginally above acceptance threshold\\nConfidence: 3: The reviewer is fairly confident that the evaluation is correct',\n",
       " 'latex': '\\n\\\\documentclass[11pt,a4paper]{article}\\n\\\\usepackage[hyperref]{acl2020}\\n\\\\usepackage{times}\\n\\\\usepackage{latexsym}\\n\\\\renewcommand{\\\\UrlFont}{\\\\ttfamily\\\\small}\\n\\\\usepackage{graphicx}\\n\\\\usepackage{caption}\\n\\\\usepackage{url}\\n\\\\usepackage[utf8]{inputenc}\\n\\\\usepackage{microtype}\\n\\n\\\\aclfinalcopy %\\n\\n\\\\setlength\\\\titlebox{10cm}\\n\\n\\\\newcommand\\\\BibTeX{B\\\\textsc{ib}\\\\TeX}\\n\\\\title{Cross-language sentiment analysis of European Twitter messages during the COVID-19 pandemic}\\n\\n\\\\author{Anna Kruspe \\\\\\\\\\n  German Aerospace Center (DLR) \\\\\\\\\\n  Institute of Data Science \\\\\\\\\\n  Jena, Germany \\\\\\\\\\n  \\\\texttt{anna.kruspe@dlr.de} \\\\\\\\\\\\And\\n  Matthias H\\\\\"aberle \\\\\\\\\\n  Technical University of Munich (TUM) \\\\\\\\\\n  Signal Processing in Earth Observation (SiPEO) \\\\\\\\\\n  Munich, Germany \\\\\\\\\\n  \\\\texttt{matthias.haeberle@tum.de} \\\\\\\\\\\\AND\\n  Iona Kuhn \\\\\\\\\\n  German Aerospace Center (DLR) \\\\\\\\\\n  Institute of Data Science \\\\\\\\\\n  Jena, Germany \\\\\\\\ \\n  \\\\texttt{iona.kuhn@dlr.de} \\\\\\\\\\\\And \\n  Xiao Xiang Zhu \\\\\\\\\\n  German Aerospace Center (DLR) \\\\\\\\\\n  Remote Sensing Technology Institute (IMF) \\\\\\\\\\n  Oberpfaffenhofen, Germany \\\\\\\\\\n  \\\\texttt{xiaoxiang.zhu@dlr.de}}\\n\\n\\\\date{}\\n\\n\\\\begin{document}\\n\\\\maketitle\\n\\\\begin{abstract}\\nSocial media data can be a very salient source of information during crises. User-generated messages provide a window into people\\'s minds during such times, allowing us insights about their moods and opinions. Due to the vast amounts of such messages, a large-scale analysis of population-wide developments becomes possible.\\\\\\\\\\nIn this paper, we analyze Twitter messages (tweets) collected during the first months of the COVID-19 pandemic in Europe with regard to their sentiment. This is implemented with a neural network for sentiment analysis using multilingual sentence embeddings. We separate the results by country of origin, and correlate their temporal development with events in those countries. This allows us to study the effect of the situation on people\\'s moods. We see, for example, that lockdown announcements correlate with a deterioration of mood in almost all surveyed countries, which recovers within a short time span.\\n\\\\end{abstract}\\n\\\\section{Introduction}\\nThe COVID-19 pandemic has led to a worldwide situation with a large number of unknowns. Many heretofore unseen events occurred within a short time span, and governments have had to make quick decisions for containing the spread of the disease. Due to the extreme novelty of the situation, the outcomes of many of these events have not been studied well so far. This is true with regards to their medical effect, as well as the effect on people\\'s perceptions and moods.\\\\\\\\\\nFirst studies about the effect the pandemic has on people\\'s lives are being published at the moment \\\\citep[e.g.][]{uni_erfurt}, mainly focusing on surveys and polls. Naturally, such studies are limited to relatively small numbers of participants and focus on specific regions (e.g. countries).\\\\\\\\\\nIn contrast, social media provides a large amount of user-created messages reflective of those users\\' moods and opinions. The issue with this data source is the difficulty of analysis - social media messages are extremely noisy and idiosyncratic, and the amount of incoming data is much too large to analyze manually. We therefore need automatic methods to extract meaningful insights.\\\\\\\\\\nIn this paper, we describe a data set collected from Twitter during the months of December 2019 through April 2020, and present an automatic method for determining the sentiments contained in these messages. We then calculate the development of these sentiments over time, segment the results by country, and correlate them with events that took place in each country during those five months.\\n\\n\\\\vspace{-5pt}\\n\\\\section{Related work}\\nSince the pandemic outbreak and lockdown measures, numerous studies have been published to investigate the impact of the corona pandemic on Twitter. \\n\\\\citet{feng2020working} analyzed tweets from the US on a state and county level. First, they could detect differences in temporal tweeting patterns and found that people tweeting more about COVID-19 during working hours as the pandemic progressed. Furthermore, they conducted a sentiment analysis over time including an event specific subtask reporting negative sentiment when the 1000th death was announced and positive when the lockdown measures were eased in the states.   \\n\\n\\\\citet{lyu2020sense} looked into US-tweets which contained the terms \"Chinese-virus\" or \"Wuhan-virus\" referring to the COVID-19 pandemic to perform a user characterization. They compared the results to users that did not make use of such controversial vocabulary. The findings suggest that there are noticeable differences in age group, geo-location, or followed politicians.\\n\\n\\\\citet{chen2020eyes} focused on sentiment analysis and topic modelling on COVID-19 tweets containing the term \"Chinese-virus\" (controversial) and contrasted them against tweets without such terms (non-controversial). Tweets containing \"Chinese-virus\" discussing more topics which are related to China whereas tweets without such words stressing how to defend the virus. The sentiment analysis revealed for both groups negative sentiment, yet with a slightly more positive and analytical tone for the non-controversial tweets. Furthermore, they accent more the future and what the group itself can do to fight the disease. In contrast, the controversial group aiming more on the past and concentrate on what others should do.\\n\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.8\\\\textwidth]{fig/treemap_countries.pdf}}\\n\\t\\\\caption{Treemap of Twitter activity in Europe during the time period of December 2019 to April 2020.}\\n\\t\\\\label{fig:treemap_countries}\\n\\\\end{figure*}\\n\\\\section{Data collection}\\\\label{sec:data_collection}\\nFor our study, we used the freely available Twitter API to collect the tweets from December 2019 to April 2020. The free API allows streaming of 1\\\\% of the total tweet amount. To cover the largest possible area, we used a bounding box which includes the entire world. From this data, we sub-sampled 4,683,226 geo-referenced tweets in 60 languages located in the Europe. To create the Europe sample, we downloaded a shapefile of the earth\\\\footnote{\\\\url{https://www.naturalearthdata.com/downloads/10m-cultural-vectors/10m-admin-0-countries/}}, then we filtered by country  performing a point in polygon test using the Python package \\\\textit{Shapely}\\\\footnote{\\\\url{https://pypi.org/project/Shapely/}}. Figure \\\\ref{fig:treemap_countries} depicts the Europe Twitter activity in total numbers. Most tweets come from the U.K. Tweets are not filtered by topic, i.e. many of them are going to be about other topics than COVID-19. This is by design. As we will describe later, we also apply a simple keyword filter to detect tweets that are probably COVID-19-related for further analysis.\\n\\\\begin{figure}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.4\\\\textwidth]{fig/model.png}}\\n\\t\\\\caption{Architecture of the sentiment analysis model.}\\n\\t\\\\label{fig:model}\\n\\\\end{figure}\\n\\n\\\\section{Analysis method}\\nWe now describe how the automatic sentiment analysis was performed, and the considerations involved in this method.\\n\\n\\\\begin{figure}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.5\\\\textwidth]{fig/embedding_comp.png}}\\n\\t\\\\caption{MSE for different models on the \\\\textit{Sentiment140} test dataset.}\\n\\t\\\\label{fig:embedding_comp}\\n\\\\end{figure}\\n\\n\\\\subsection{Sentiment modeling}\\nIn order to analyze these large amounts of data, we focus on an automatic method for sentiment analysis. We train a neural network for sentiment analysis on tweets. The text input layer of the network is followed by a pre-trained word or sentence embedding.\\nThe resulting  embedding vectors are fed into a 128-dimensional fully-connected ReLU layer with 50\\\\% dropout, followed by a regression output layer with sigmoid activation. Mean squared error is used as loss. The model is visualized in figure \\\\ref{fig:model}.\\\\\\\\\\nThis network is trained on the \\\\textit{Sentiment140} dataset \\\\cite{go}. This dataset contains around 1.5 million tweets collected through keyword search, and then annotated automatically by detecting emoticons. Tweets are determined to have positive, neutral, or negative sentiment. We map these sentiments to the values 1.0, 0.5, and 0.0 for the regression. Sentiment for unseen tweets is then represented on a continuous scale at the output.\\\\\\\\\\nWe test variants of the model using the following pre-trained word- and sentence-level embeddings:\\n\\\\begin{itemize}\\n    \\\\item A skip-gram version of \\\\textit{word2vec} \\\\citep{mikolov} trained on the English-language Wikipedia\\\\footnote{\\\\url{https://tfhub.dev/google/Wiki-words-250/2}}\\n    \\\\item A multilingual version of BERT \\\\citep{bert} trained on Wikipedia data\\\\footnote{\\\\url{https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2}}\\n    \\\\item A multilingual version of BERT trained on 160 million tweets containing COVID-19 keywords\\\\footnote{\\\\url{https://tfhub.dev/digitalepidemiologylab/covid-twitter-bert/1}} \\\\citep{covidtwitterbert}\\n    \\\\item An ELMO model \\\\cite{elmo} trained on the 1 Billion Word Benchmark dataset\\\\footnote{\\\\url{https://tfhub.dev/google/elmo/3}}\\n    \\\\item The Multilingual Universal Sentence Encoder (MUSE)\\\\footnote{\\\\url{https://tfhub.dev/google/universal-sentence-encoder-multilingual/3}} \\\\citep{yang}\\n\\\\end{itemize}\\nWe train each sentiment analysis model on the \\\\textit{Sentiment140} dataset for 10 epochs. Mean squared error results on the unseen test portion of the same dataset are shown in figure \\\\ref{fig:embedding_comp}. For comparison, we also include an analysis conducted by VADER which is a rule-based sentiment reasoner designed for social media messages \\\\cite{vader}.\\\\\\\\ %\\nInterestingly, most neural network results are in the range of the rule-based approach. BERT delivers better results than the \\\\textit{word2vec} model, with ELMO and the COVID-19-specific version also leading to improvements. However, the best result is achieved with the pre-trained multilingual USE model, which can embed whole sentences rather than (contextualized) words. We therefore perform the subsequent sentiment analysis with the MUSE-based model.\\\\\\\\\\nAn interesting side note here is that the dataset only contains English-language tweets, but the sentence embedding is multilingual (for 16 languages). We freeze the embedding weights to prevent them from over-adapting to English. Due to the cross-lingual semantic representation capabilities of the pre-trained embedding, we expect the model to be able to detect sentiment in other languages just as well.\\\\\\\\\\nWith the created model, we perform sentiment analysis on the 4.6 million tweets collected from December to April, and then aggregate the results over time. This provides us with a representation of the development of Twitter messages\\' average sentiment over time. We specifically consider all collected tweets rather than just those determined to be topically related to COVID-19 because we are interested in the effect on people\\'s moods in general, not just with regards to the pandemic. Additionally, we also filter the tweets by COVID-19-associated keywords, and analyze their sentiments as well. %\\nThe chosen keywords are listed in figure \\\\ref{fig:keywords}.\\\\\\\\\\n\\n\\\\subsection{Considerations}\\nThere are some assumptions implicit in this analysis method that we want to address here. First of all, we only consider tweets containing a geolocation. This applies to less than 1\\\\% of the whole tweet stream, but according to \\\\citet{sloan}, the amount of geolocated tweets closely follows the geographic population distribution. According to \\\\citet{graham}, there probably are factors determining which users share their locations and which ones do not, but there is no systematic study of these.\\\\\\\\\\nOther assumptions arise from the analysis method itself. For one, we assume that the model is able to extract meaningful sentiment values from the data. However, sentiment is subjective, and the model may be failing for certain constructs (e.g. negations, sarcasm). Additionally, modeling sentiment on a binary scale does not tell the whole story. ``Positive\\'\\' sentiment encompasses, for example, happy or hopeful tweets, ``negative\\'\\' angry or sad tweets, and ``neutral\\'\\' tweets can be news tweets, for example. A more finegrained analysis would be of interest in the future.\\\\\\\\\\nWe also assume a somewhat similar perception of sentiment across languages. Finally, we assume that the detected sentiments as a whole are reflective of the mood within the community; on the other hand, mood is not quantifiable in the first place. All of these assumptions can be called into question. Nevertheless, while they may not be applicable for every single tweet, we hope to detect interesting effects on a large scale. When analyzing thousands of tweets within each time frame, random fluctuations become less likely. We believe that this analysis can provide useful insights into people\\'s thoughts, and form an interesting basis for future studies from psychological or sociological perspectives.\\n\\n\\\\begin{figure}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.4\\\\textwidth]{fig/keywords.png}}\\n\\t\\\\caption{Keywords used for filtering the tweets (not case sensitive).}\\n\\t\\\\label{fig:keywords}\\n\\\\end{figure}\\n\\n\\\\section{Results}\\nIn the following, we present the detected sentiment developments over time over-all and for select countries, and correlate them with events that took place within these months. Results for some other countries would have been interesting as well, but were not included because the main spoken language is not covered by MUSE (e.g. Sweden, Denmark). Others were excluded because there was not enough material available; we only analyze countries with at least 300,000 recorded tweets. As described in section \\\\ref{sec:data_collection}, tweets are filtered geographically, not by language (i.e. Italian tweets may also be in other languages than Italian).\\n\\n\\\\subsection{Over-all}\\\\label{subsec:res_overall}\\nIn total, we analyzed around 4.6 million tweets, of which around 79,000 contained at least one COVID-19 keyword. Figure \\\\ref{fig:sentiment_kw_count_all} shows the development of the sentiment over time for all tweets and for those with keywords, as well as the development of the number of keyworded tweets. The sentiment results are smoothed on a weekly basis (otherwise, we would be seeing a lot of movement during the week, e.g. an increase on the weekends). For the average over all tweets, we see a slight decrease in sentiment over time, indicating possibly that users\\' moods deteriorated over the last few months. There are some side effects that need to be considered here. For example, the curve rises slightly for holidays like Christmas and Easter (April 12). Interestingly, we see a clear dip around mid-March. Most European countries started implementing strong social distancing measures around this time. We will talk about this in more detail in the next sections.\\\\\\\\\\nWe see that keywords were used very rarely before mid-January, and only saw a massive increase in usage around the beginning of March. Lately, usage has been decreasing again, indicating a loss of interest over time. Consequently, the sentiment analysis for keyword tweets is not expressive in the beginning. Starting with the more frequent usage in February, the associated sentiment drops massively, indicating that these tweets are now used in relation with the pandemic. Interestingly, the sentiment recovers with the increased use in March - it is possible that users were starting to think about the risks and handling of the situation in a more relaxed way over time. Still, the sentiment curve for keyword tweets lies significantly below the average one, which is to be expected for this all-around rather negative topic.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_all.png}}\\n\\t\\\\caption{Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_all}\\n\\\\end{figure*}\\n\\n\\\\subsection{Analysis by country}\\nWe next aggregated the tweets by country as described in section \\\\ref{sec:data_collection} and performed the same analysis by country. The country-wise curves are shown jointly in figure \\\\ref{fig:sentiment_by_country}. Comparing the absolute average sentiment values between countries is difficult as they may be influenced by the languages or cultural factors. However, the relative development is interesting. We see that all curves progress in a relatively similar fashion, with peaks around Christmas and Easter, a strong dip in the middle of March, and a general slow decrease in sentiment. In the following, we will have a closer look at each country\\'s development. (Note that the keyword-only curves are cut of in the beginning for some countries due to a low number of keyword tweets).\\n\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_by_country.png}}\\n\\t\\\\caption{Development of average sentiment over time by country (all tweets).}\\n\\t\\\\label{fig:sentiment_by_country}\\n\\\\end{figure*}\\n\\n\\\\subsubsection{Italy}\\nFigure \\\\ref{fig:sentiment_kw_count_italy} shows the average sentiment for all Italian tweets and all Italian keyword tweets, as well as the development of keyword tweets in Italy. In total, around 400,000 Italian tweets are contained in the data set, of which around 12,000 have a keyword. Similar to the over-all curves described in section \\\\ref{subsec:res_overall}, the sentiment curve slowly decreases over time, keywords are not used frequently before the end of January, when the first cases in Italy were confirmed. Sentiment in the keyword tweets starts out very negative and then increases again. Interestingly, we see a dip in sentiment on March 9, which is exactly when the Italian lockdown was announced. Keywords were also used most frequently during that week. The dip is not visible in the keyword-only sentiment curve, suggesting that the negative sentiment was actually caused by the higher prevalence of coronavirus-related tweets.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_italy_mod.png}}\\n\\t\\\\caption{Italy: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_italy}\\n\\\\end{figure*}\\n\\n\\\\subsubsection{Spain}\\nFor Spain, around 780,000 tweets were collected in total with around 14,000 keyword tweets. The curves are shown in figure \\\\ref{fig:sentiment_kw_count_spain}. The heavier usage of keywords starts around the same time as in Italy, where the first domestic cases were publicized at the same time. The spike in keyword-only sentiment in mid-February is actually an artifact of the low number of keyworded tweets in combination with the fact that ``corona\\'\\' is a word with other meanings in Spanish (in contrast to the other languages). With more keyword mentions, the sentiment drops as in other countries.\\\\\\\\\\nFrom there onwards, the virus progressed somewhat slower in Spain, which is reflected in the curves as well. A lockdown was announced in Spain on March 14, corresponding to a dip in the sentiment curve. As with the Italian data, this dip is not present in the keyword-only sentiments.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_spain.png}}\\n\\t\\\\caption{Spain: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_spain}\\n\\\\end{figure*}\\n\\n\\\\subsubsection{France}\\nAnalyses for the data from France are shown in figure \\\\ref{fig:sentiment_kw_count_france}. For France, around 309,000 tweets and around 4,600 keyword tweets were collected. Due to the lower number of data points, the curves are somewhat less smooth. Despite the first European COVID-19 case being detected in France in January, cases did not increase significantly until the end of February, which once again is also seen in the start of increased keyword usage here. The French lockdown was announced on March 16 and extended on April 13, both reflected in dips in the sentiment curve. Towards the end of the considered period, keyword-only sentiment actually starts to increase, which is also seen in Italy and Germany. This could indicate a shift to a more hopeful outlook with regards to the pandemic.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_france_mod.png}}\\n\\t\\\\caption{France: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_france}\\n\\\\end{figure*}\\n\\\\subsubsection{Germany}\\nFor Germany, around 415,000 tweets and around 5,900 keyword tweets were collected. The analysis results are shown in figure \\\\ref{fig:sentiment_kw_count_germany}. After very few first cases at the end of January, Germany\\'s case count did not increase significantly until early March, which is again when keyword usage increased. The decrease in the sentiment curve actually arrives around the same time as in France and Spain, which is a little surprising because social distancing measures were not introduced by the government until March 22 (extended on March 29). German users were likely influenced by the situation in their neighboring countries here. In general, the curve is flatter than in other countries. One possible reason for this might be the lower severity of measures in Germany, e.g. there were no strict curfews.\\\\\\\\\\nIn contrast to all other considered countries, the keyword-only sentiment curve is not significantly below the sentiment curve for all tweets in Germany after the beginning of March. There are some possible explanations for this. For one, governmental response to the situation was generally applauded in Germany \\\\cite{uni_erfurt}, and, as mentioned above, was not as strict as in other countries, possibly not impacting people as much. On the other hand, the over-all German curve is lower than its counterparts from other countries, i.e. German tweets have lower average sentiment values in general, possibly caused by cultural factors.\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_germany_mod.png}}\\n\\t\\\\caption{Germany: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_germany}\\n\\\\end{figure*}\\n\\\\subsubsection{United Kingdom}\\n\\nCurves for the United Kingdom are shown in figure \\\\ref{fig:sentiment_kw_count_uk}, calculated on around 1,380,000 tweets including around 22,000 keyword tweets. Higher keyword usage starts somewhat earlier here than expected in February, whereas a significant increase in cases did not occur until March. Once again, keyword-only sentiment starts out very negative and then increases over time.\\\\\\\\\\nThe British government handled the situation somewhat differently. In early March, only recommendations were given, and a lockdown was explicitly avoided to prevent economic consequences. This may be a cause for the sentiment peak seen at this time. However, the curve falls until mid-March, when other European countries did implement lockdowns. The government finally did announce a lockdown starting on March 26. This did not lead to a significant change in average sentiment anymore, but in contrast with other countries, the curve does not swing back to a significantly more positive level in the considered period, and actually decreases towards the end.\\n\\n\\\\begin{figure*}[htbp]\\n\\t\\\\centerline{\\\\includegraphics[width=.9\\\\textwidth]{fig/sentiment_kw_count_uk_mod.png}}\\n\\t\\\\caption{United Kingdom: Development of average sentiment for all tweets and for tweets containing COVID-19 keywords, and development of number of tweets containing COVID-19 keywords.}\\n\\t\\\\label{fig:sentiment_kw_count_uk}\\n\\\\end{figure*}\\n\\\\section{Conclusion}\\n\\\\vspace{-5pt}\\n\\nIn this paper, we presented the results of a sentiment analysis of 4.6 million geotagged Twitter messages collected during the months of December 2019 through April 2020. This analysis was performed with a neural network trained on an unrelated Twitter sentiment data set. The tweets were then tagged with sentiment on a scale from 0 to 1 using this network. The results were aggregated by country, and averaged over time. Additionally, the sentiments of tweets containing COVID-19-related keywords were aggregated separately.\\\\\\\\\\nWe find several interesting results in the data. First of all, there is a general downward trend in sentiment in the last few months corresponding to the COVID-19 pandemic, with clear dips at times of lockdown announcements and a slow recovery in the following weeks in most countries. COVID-19 keywords were used rarely before February, and correlate with a rise in cases in each country. The sentiment of keyworded tweets starts out very negative at the beginning of increased keyword usage, and becomes more positive over time. However, it remains significantly below the average sentiment in all countries except Germany. Interestingly, there is a slight upward development in sentiment in most countries towards the end of the considered period.\\\\\\\\\\n\\n\\\\vspace{-10pt}\\n\\n\\\\section{Future work}\\n\\\\vspace{-5pt}\\n\\nWe will continue this study by also analyzing the development in the weeks since May 1st and the coming months. More countries will also be added. It will be very interesting to compare the shown European results to those of countries like China, South Korea, Japan, New Zealand, or even individual US states, which were impacted by the pandemic at different times and in different ways, and where the governmental and societal response was different from that of Europe.\\\\\\\\ \\nThere are also many other interesting research questions that could be answered on a large scale with this data - for example, regarding people\\'s trust in published COVID-19 information, their concrete opinions on containment measures, or their situation during an infection. Other data sets have also been published in the meantime, including ones that contains hundreds of millions of tweets at the time of writing \\\\cite[e.g.][]{geocov,banda_juan_m_2020_3757272}. These data sets are much larger because collection was not restricted to geotagged tweets. In \\\\citet{geocov}, geolocations were instead completed from outside sources.\\\\\\\\\\nThese studies could also be extended to elucidate more detailed factors in each country. One possibility here is an analysis of Twitter usage and tweet content by country. Another, as mentioned above, lies in moving from the binary sentiment scale to a more complex model.\\n\\n\\\\newpage\\n\\\\bibliography{anthology,acl2020}\\n\\\\bibliographystyle{acl_natbib}\\n\\n\\\\appendix\\n\\\\end{document}\\n',\n",
       " 'paper_url': 'https://openreview.net/forum?id=VvRbhkiAwR',\n",
       " 'arxiv_url': 'https://arxiv.org/abs/2008.12172',\n",
       " 'help_prompt': 'Please evaluate the paper based on the provided evaluation, focusing on the approach comparisons, data breakdown, and the potential for extended analyses and future improvements.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate prompts using chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai.api_key = open(\"./chat_gpt_token\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "def chat_with_chatgpt(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    chat_completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    return chat_completion[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "\n",
    "user_prompt = \"Hello world.\"\n",
    "chatbot_response = chat_with_chatgpt(user_prompt)\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: Overview of a highly important Covid-19 dataset\n",
      "This is a paper that describes an important research dataset that has been produced during the Covid-19 epidemic. The CORD-19 collection is used for much research and some challenge evaluations. Even though this paper does not report any research results per se, and the paper is posted on the ArXiv preprint server, this version will give a citable description of the collection that will likely be widely referenced.\n",
      "\n",
      "The authors describe well the process of dealing not only with the technical issues of processing heterogeneous scientific papers but also the non-technical issues, such as copyright and licensing.\n",
      "\n",
      "The authors do not make any unreasonable claims, although I do question the value of this collection for non-computational researchers and clinicians. As the authors note, the collection is not complete, which is essential for clinical researchers and certainly for clinicians (who do not typically read primary research papers anyways, and tend to focus more on summations). But the dataset is of tremendous value to computational and informatics researchers, and that should be pronounced.\n",
      "\n",
      "I appreciate the Discussion that points out the limitations of how scientific information is currently published, and how it could be improved. One other concern that could be addressed is how long the Allen Institute for AI, which is to be commended for this work, will continue to maintain this tremendously valuable resource.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "\n",
      "Imagine you are user who only has text of own paper.\n",
      "write a prompt based on'Evaluation' that asks to evaluate your paper. Answer only prompt. Don't mention and use any part information from 'Evaluation' section.\n",
      "Write prompt in one or maximum two sentences.\n",
      "\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Please evaluate the significance and value of the dataset presented in my paper, considering its potential impact on computational and informatics researchers.\n"
     ]
    }
   ],
   "source": [
    "num = 4\n",
    "full_review = dataset[num][\"full_review\"]\n",
    "\n",
    "input_text = f\"\"\"\n",
    "Evaluation: {full_review}\n",
    "\n",
    "Imagine you are user who only has text of own paper.\n",
    "write a prompt based on'Evaluation' that asks to evaluate your paper. Answer only prompt. Don't mention and use any part information from 'Evaluation' section.\n",
    "Write prompt in one or maximum two sentences.\n",
    "\"\"\"\n",
    "print(input_text)\n",
    "chatbot_response = chat_with_chatgpt(input_text, model='gpt-4')\n",
    "print(\"=\" * 100)\n",
    "print(\"=\" * 100)\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [02:13<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    full_review = dataset[i][\"full_review\"]\n",
    "\n",
    "    input_text = f\"\"\"\n",
    "    Evaluation: {full_review}\n",
    "\n",
    "    Imagine you are user who only has text of own paper.\n",
    "    write a prompt based on'Evaluation' that asks to evaluate your paper. Answer only prompt. Don't mention and use any part information from 'Evaluation' section.\n",
    "    Write prompt in one or maximum two sentences.\n",
    "    \"\"\"\n",
    "    chatbot_response = chat_with_chatgpt(input_text, model='gpt-4')\n",
    "    dataset[i]['help_prompt'] = chatbot_response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:00<00:00, 75837.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review of \"Cross-language sentiment analysis of European Twitter messages\"  -- interesting trends analysis but some more approach comparisons and tables for the data would be good.\n",
      "The authors present an interesting, important and relevant trend analysis of sentiment across languages in several locales during the Covid-19 pandemic, using geo-tagged European Twitter data and pre-trained cross-lingual embeddings within a neural model.\n",
      "\n",
      "The main contributions of the paper are: 1) the geo-tagged European Twitter dataset of 4.6 million tweets between Dec 2019 and Apr 2020, where some of these contain Covid19-specific keywords (it would be nice to see some percentage breakdown stats by language here), and 2) the important trends by country in terms of dip and recovery of sentiment over this period, including the overall trends across the board.\n",
      "\n",
      "In terms of sentiment modeling, they use a pre-trained neural model trained on the Sentiment140 dataset of Go et al, which is English-only, hence they freeze the weights to prevent over-adapting to English. They use cross-lingual MUSE embeddings to train this network to better generalize sentiment prediction to multi-lingual data for each country. There is no novelty in the modeling approach itself, which works for the purposes of trend analysis being performed. However, there is no comparison being presented of results of experimentation with different approaches, to corroborate or contrast their current trends results. E.g. a simple baseline approach could have been to run Average and Polarity sentiment values using a standard python text processing package such as `textblob` to obtain sentiment predictions. Other experiments could have been done to use different pre-trained embeddings such regular GloVE or Multi-lingual BERT to provide a comparison or take the average of the approaches to get a more generalized picture of sentiment trends. Also the authors should make it clear that the model has really been used in perhaps inference mode only to obtain the final sentiment predictions for each tweet.\n",
      "\n",
      "The treemap visualization gives a good overall picture of tweet stats, but a table providing the individual dataset statistics including keywords chosen by locale would be really helpful.\n",
      "\n",
      "Some notable trends are how the sentiment generally dips in all locales right around the time of lockdown announcements, and recovers relatively soon after, except for Germany where it dips at the same time as neighboring countries despite lockdown being started here much later, and UK, where sentiment stays low. It is also interesting to note the spikes and fluctuations in Covid19-related sentiment for Spain, and the overall trend for average sentiment by country for \"all\" tweets (including Covid19-related ones) tracking similarly over the time period considered.\n",
      "\n",
      "However, one trend it would be good to see some discussion on is how the histogram of keywords correlate with the sentiment for the keyworded tweets, as it appears interesting that heightened use of Covid-19 keywords in tweets tracks with more positive sentiment in most of the plots. Perhaps it would be helpful to have a separate discussion section for the overall trend analysis at the end.\n",
      "\n",
      "Overall the paper is well-motivated and in its current form provides perhaps the intended insights, and presents lot of scope to perform useful extended analyses with more meaningful comparisons for additional time spans and across countries where governmental and societal response were different than in Europe. Perhaps the authors could consider a more interpretable predictive sentiment model in future with some hand-crafted features such as geotag metadata, unigram and bi-gram features, binary features for government measures, and Covid19-specific keyword features by locale, which could provide more insight into why sentiment predictions trend a certain way during a specific period for a given locale.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the provided evaluation, focusing on the approach comparisons, data breakdown, and the potential for extended analyses and future improvements.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review on \"Cross-language sentiment analysis of European Twitter messages during the COVID-19 pandemic\"\n",
      "The authors carried on a deep learning pipeline to analyze the sentiment of Twitter texts, and propose a complete research. The presentation and language part of this submission is good.\n",
      "\n",
      " However, the research mainly use the routine DL methodology and the analysis method is not contributive.  In general, the novelty and contribution of this research do not reach the level of publication as a ACL workshop paper. Here comes some comments and suggestions.\n",
      "\n",
      "1. The data statistics is missing. Though we found a rough number list in Figure 1, they are not quite clear. Data with time series info are also welcomed. Furthermore, several python packages help to draw Europe Map, and might make this part more vivid.\n",
      "2. It is better to provide a figure to explain the structure of the network. The authors surely already gave some details in page 2, including the input layer, activation function info. The hyper parameter of the network could also be provided.\n",
      "3. It is lacking of comparison of the current NN with some other NN structure. How would one single experiment derive convincing result without baseline methods or intrinsic evaluation? This is a core question I would like to raise here for this research.\n",
      "4. I am thinking of a possibility of splitting the Twitter data in terms of weeks, and take time series consideration into the current research paradigm. A sentiment-time curve plot might lead to some instructive hypothesis, if the research take a more sophisticated experiment design.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its methodology, novelty, and contribution, providing specific feedback on the data statistics, network structure, comparison with other methods, and potential for time series analysis.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review\n",
      "This is a mostly well-written overview of an exercise to assign a sentiment label to the European-country generated tweets during the period December’19-May’20. \n",
      "\n",
      "The authors describe how they differentiate and identify the country, how they assign the sentiment level (positive, neutral, negative), how they use emojis, and how they use the deep learning neural model which presumably can adjust this label assignment regardless of what language the tweet is originally written. The authors report a 0.82 accuracy of their system. The rest of the paper is a recognition of the limitations, and a description and plotting of the sentiment level for various European countries. \n",
      "\n",
      "Unfortunately, these results do not contribute to adding new knowledge.  The study could use more work.  \n",
      "\n",
      "Suggestions: \n",
      "\n",
      "Could the authors provide a breakdown by language of the tweets that they process? Are we to assume that all tweet originated from Italy are in Italian and those originating in Germany are in German? \n",
      "\n",
      "Is this data publicly available?\n",
      "\n",
      "Has the 0.82 accuracy been manually validated? Is there a difference in accuracy depending on the language? The authors claim that one of the contributions of their study is this tagged dataset (geotagged, and sentiment-tagged). It seems there is no further evaluation on how well the tagging has been applied. \n",
      "\n",
      "And while it is visibly clear that we see a global fall in sentiment that correlates with governments issuing lock-down protective measures, and this result could be a start that this labelling of the data is good, is there anything else we can say, is there any other way we can analyze this data and identify common topics in the similar sentiment groups? Something that can be actually useful to the COVID-19 researchers…\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the methodology used to assign sentiment labels to European-country generated tweets during the period December'19-May'20, including the accuracy of the system and any limitations or potential improvements.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Excellent description of a critical COVID-19 dataset, some questions remaining\n",
      "This manuscript describes an exemplary effort to address COVID-19 by bringing together much of the relevant literature into one corpus, CORD-19, and increasing its accessibility by providing a harmonized and standardized format convenient for use by automated tools. CORD-19 has been - and is likely to continue being - a critical resource for the scientific community to address COVID-19, and this manuscript not only reflects that importance, but also gives insight into the approach used, the design decisions taken, challenges encountered, use cases, shared tasks, and various discussion points. The manuscript is well-organized and readable, and (overall) an excellent case study in corpus creation. This manuscript is not only important for understanding the CORD-19 corpus and its enabling effect on current COVID-19 efforts, but is possibly also a historically important example of joint scientific efforts to address COVID-19.\n",
      "\n",
      "Despite the critical importance of this dataset, there are several questions left unanswered by this manuscript, and it would be unfortunate to not address these before publication.\n",
      "\n",
      "It would be useful to have a very clear statement of the purpose for CORD-19. The inclusion of SARS and MERS makes intuitive sense, but it is less clear why other coronaviruses that infect humans (e.g. HCoV-OC43) are not explicitly included - I am not a virologist, but neither will be most of the audience for this manuscript. While many of the articles that discuss these lesser known cornaviruses would be included anyway because they would also mention \"coronavirus\", this is not guaranteed. \n",
      "\n",
      "While it seems appropriate for document inclusion to be query-based, it is important to consider the coverage of the query. The number of name variants in the literature for COVID-19 or SARS-CoV-2 is rather large, and not all of these documents will include other terms that will match, such as \"coronavirus\". For example, how would a document that mentions \"SARS CoV-2\" but none of the query terms listed be handled? This is not a theoretical case: the title and abstract for PMID 32584542 have this issue, and I was unable to locate this document in CORD-19. In addition to minor variations such as this, there are many examples of significant variations such as \"HCoV-19\", \"nCoV-19\" or even \"COIVD\". Are these cases worth considering? If not, can we quantify how much is lost? And if we can't quantify it, this is a limitation.\n",
      "\n",
      "How is the following situation handled: querying source A returns a document (e.g. the source has full text and that matches), but the version in source B does not return it (e.g. the source only has title & abstract, and they do not match). From the description, I would assume that the version from source A is used and the version from source B is ignored; is any reasonably useful data lost by not explicitly querying source B for its version?\n",
      "\n",
      "There are other efforts to provide a repository of scientific articles related to COVID-19, and it would be appropriate to mention these, if only to indicate why CORD-19 has unique value. I am aware of LitCovid (Chen Q, Allot A, Lu Z. Keep up with the latest coronavirus research. Nature. 2020;579(7798):193), are there others?\n",
      "\n",
      "There are also non-COVID-19 efforts to provide a large percentage of the literature in formats appropriate for text mining or other processing. One is (Comeau, Donald C., et al. \"PMC text mining subset in BioC: about three million full-text articles and growing.\" Bioinformatics 35.18 (2019): 3533-3535.), which not only provides the full text of a large percentage of the articles in PubMed Central, but it is also kept up-to-date and converts all documents into a straightforward standardized XML format appropriate for text mining. While this effort is single-source, it specifically addresses some of the issues encountered in the creation of CORD-19 and the representation aspect of the \"Call to Action\".\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the clarity and comprehensiveness of my paper, specifically addressing the purpose of my research, the coverage of the literature, and any potential limitations or gaps in the dataset used.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Overview of a highly important Covid-19 dataset\n",
      "This is a paper that describes an important research dataset that has been produced during the Covid-19 epidemic. The CORD-19 collection is used for much research and some challenge evaluations. Even though this paper does not report any research results per se, and the paper is posted on the ArXiv preprint server, this version will give a citable description of the collection that will likely be widely referenced.\n",
      "\n",
      "The authors describe well the process of dealing not only with the technical issues of processing heterogeneous scientific papers but also the non-technical issues, such as copyright and licensing.\n",
      "\n",
      "The authors do not make any unreasonable claims, although I do question the value of this collection for non-computational researchers and clinicians. As the authors note, the collection is not complete, which is essential for clinical researchers and certainly for clinicians (who do not typically read primary research papers anyways, and tend to focus more on summations). But the dataset is of tremendous value to computational and informatics researchers, and that should be pronounced.\n",
      "\n",
      "I appreciate the Discussion that points out the limitations of how scientific information is currently published, and how it could be improved. One other concern that could be addressed is how long the Allen Institute for AI, which is to be commended for this work, will continue to maintain this tremendously valuable resource.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the significance and value of the dataset described in this paper for researchers and clinicians in the field of Covid-19.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "CORD-19 is an excellent resource with an impressive integration work for the research community to fight COVID-19.\n",
      "The authors present the CORD-19 data set and describe how it has been developed and continues to be developed. The CORD-19 data set is a valuable resource that provides access to the latest literature about COVID-19 and coronaviruses and it is updated daily with over 200k downloads. The generation of the CORD-19 requires a coordinated integration and processing effort that is significant. The contribution of this corpus is of high significance and will have a strong impact on the biomedical domain and support the development, for instance, of COVID-19 vaccines. The manuscript is clearly written and it is easy to understand.\n",
      "\n",
      "The effort in providing a version of the latest literature in formats that can be processed by text analytics methods is excellent, using the latest of the available technology to do so. In the paper, it is mentioned in the manuscript that there are some problems in turning tables into structured format and the authors provide examples of issues that they have found. Table processing is done by IBM, who has as well a method for table processing that seems to be resilient to the problems mentioned and would be relevant to consider it for table processing (https://arxiv.org/abs/1911.10683).\n",
      "\n",
      "The authors give an example of conflict from which it can be inferred that the same DOI might be linked to two different PubMed identifiers, the reviewer is curious why this might be the case and if an example could be provided.\n",
      "\n",
      "When you mention “Classification of CORD-19 papers to Microsoft Academic Graph”, is this classification done by a method provided by the authors? is this classification provided as meta-data?\n",
      "\n",
      "During my review the only typo I could find is:\n",
      "* “other research activity.” —> “other research activities.”?\n",
      "* “by not allowing republication of **an** paper”, an —> a\n",
      "\n",
      "Please consider the following guideline for NLM trademarks: https://www.nlm.nih.gov/about/trademarks.html\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its description and development of the CORD-19 data set, its impact on the biomedical domain, and its potential to support the development of COVID-19 vaccines.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "nice application to new data set to be made available\n",
      "This paper explores gender differences in linguistic productions between two groups of Redditors who self-identify as either \"male\" or \"female\". It examines a corpus of covid-19 pandemic threads in relation to two areas: emotion analysis (employing a VAD lexicon and word embedding representations); and topic analysis (employing the tool MALLET).\n",
      "\n",
      "The paper's novelty is in the application of an established method to a new corpus that the authors have developed pertaining to covid-19 threads. As expected, the language usage for covid-19 posts had a lower Valence when compared to language used in a baseline corpus. There is also a general trend for the language used in the female sub-corpus scoring slightly higher in the Valence scale than male sub-corpus. The trends are reversed when Arousal and Dominance were examined: overall higher for men, and when comparing baseline to the covid-19 posts, the baselines score slightly lower for both male and female data.\n",
      "\n",
      "To compare and contrast the different topics covered between the male and female authored posts, topic modelling was applied to each sub-corpus and the topics with the highest coherence scores were presented. However, applying topic modelling to the corpus as a whole and analysing the topic allocation of the male and female posts would give a better indication of similarities and differences of the topics covered in the sub-corpora. However, two different topic models for each sub-corpus were developed and the most cohesive topics were presented.\n",
      "\n",
      "In general the VAD study is interesting, although unsurprsing. The goal of discovering if different or similar topics were covered in the two sub-corpora may be best approached by discovering the topics covered by the corpus as a whole and analysing the topic allocation of the sub-corpora.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its exploration of gender differences in linguistic productions in relation to emotion analysis and topic analysis in a corpus of covid-19 pandemic threads.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Overall the paper is okay but fails to provide the significance of the work.\n",
      "This paper aims to understand the difference between male and female discourse in social media looking at a manually annotated set of Reddit threads related to Covid-19 compared to a baseline set. They confirm existing results about male and female discourse on the VAD scale.\n",
      "\n",
      "The paper is clear and well-written and seems to be an interesting analysis, but fails to provide the significance of the work. Further the only novelty of the work is the application to Covid-19, otherwise all methods are utilizing previous work. This is not to say the authors should re-invent the wheel. \n",
      "\n",
      "\n",
      "Pros:\n",
      "- An interesting exploration of gender differences that confirms previous results.\n",
      "- A good use of previous work on a new corpus. \n",
      "\n",
      "Cons:\n",
      "- Missing the overall significance for researchers, clinicians, epidemiologists, etc.\n",
      "- It is unclear why Reddit specifically is used. They mention it is the 19th most visited site world. What about the other ones that are more visited? Is Reddit truly representative of the population at large? A description of the basic characteristics of Reddit users and posts would be helpful. \n",
      "- There is also a large imbalance between male and female posts (2:1 ratio). \n",
      "- This is very heteronormative.\n",
      "- The dataset is pulled from 15 weeks starting from Feb 1 to June 1, which was a rapidly changing time. The paper would benefit from a discussion of the different topics discussed over that time in comparison to the topics pulled out by the models. Currently we are in a new \"normal\" and I think that would be reflected during the different weeks.\n",
      "- The baseline is pulled from the same time period of Covid-19. An explanation of why the baseline should be the same time frame would be helpful to understand why the baseline is not from before Covid-19 when males and females were posting \"normal\" stuff. \n",
      "- The overall results in table 1 are confusing in what is being compared and what is statistically significant. The difference between males and females for the VAD criteria may be statistically significant but it is a minor increase (< 0.2). It is unclear how important this is and what implications it has.\n",
      "- A more in depth discussion on the relevance of the most coherent topics for males and females would be helpful.\n",
      "Rating: 4: Ok but not good enough - rejection\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the significance and novelty of the paper, as well as the clarity of the results and their implications for researchers and practitioners in the field.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Overall the paper is well written, contains re-usable data, and describes clear results.\n",
      "Quality:\n",
      "Overall the paper is well written, contains re-usable data, and describes clear results.\n",
      "\n",
      "Clarity:\n",
      "Authors aims of analysis were clearly stated, as were the methods employed. Results are elucidated clearly. The paper is well written, concise, and easy to follow logically.\n",
      "\n",
      "Originality:\n",
      "Given the findings corroborate already established patterns of F / M speech, the exact findings that those patterns persist in covid-related speech is not particularly original. However, within the context of studying phenomena amidst a completely novel world event, covid, the findings regarding how people talk about said event are original. Combination of methodologies to perform analysis are somewhat original.\n",
      "\n",
      "Significance:\n",
      "Mohammed's VAD showed low inter-annotator agreement for A & D types. This may reduce the impact of any findings, distinctions, or variances (even if statistically significant) between the genders in these categories. Even if statistically significant, the cohen-d effect sizes between F & M are still very small (< .2 in all categories). What is the _human significance_ (not mathematical significance) of the analyzed differences? \n",
      "\n",
      "Editing suggestions: \n",
      "  Clarify Fig1 caption by including \"re covid\" or something to that effect\n",
      "  Typo in sentence, missing \"of\" :  \"COVID-related data trends (Figure 2) show comparatively low scores for valence and high scores\n",
      "for arousal in the early weeks [OF] our analysis (February to mid-March)\". \n",
      "  This sentence comes off as sexist: \"women tend to use more positive language, while men score higher on arousal and dominance.\" Use similar terms to describe characteristics for both genders instead of saying what women do and what men score, e.g, \"Women score higher in use of positive language, while men score ...\"\n",
      "\n",
      "pros\n",
      "  Straightforward, solid results that established F / M speech patterns persist in novel corpus.\n",
      "  Probably a decent baseline paper to use in further research on gender differences re covid speech or other domains.\n",
      "  \n",
      "cons\n",
      "  Statistical significance does not explain human importance of findings.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper\n",
      "====================================================================================================\n",
      "Please evaluate the overall quality, clarity, originality, and significance of my paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "timely contribution, could be better positioned with regard to previous work\n",
      "This paper presents a dataset of 1700 questions related to covid which\n",
      "are hand labeled and divided into 15 general categories and 207\n",
      "clusters of semantic equivalence. The value is potentially useful for\n",
      "general question classification, for semantic similarity, with\n",
      "particular application to reducing load on question answerers by\n",
      "removing redundancy, The data set is on the small side and some\n",
      "important details about how the data was collection are omitted. The\n",
      "authors make a number of factual errors. All of these could be easily\n",
      "corrected and the data set is a useful resource.\n",
      "\n",
      "\n",
      "\"we scraped questions about covid\". how is a 'question about covid'\n",
      "determined? Are keywords used? If so what keywords? Additionally how\n",
      "were questions that had location/time-specific versions vs. questions\n",
      "with only one version determined? There are number of ways this could\n",
      "be done, some noisier than others, some more scalable than others.\n",
      "\n",
      "What are all the 'synonymous ways of saying COVID?'\n",
      "\n",
      "same answer -> same question cluster. \"In which country is SARS-CoV-2\n",
      "believed to have originated\" and \"Which country manufactures the most\n",
      "face masks\" have the same answer but are not the same question nor are\n",
      "even related. Plenty of useful questions do not have an answer (yet);\n",
      "how are these to be clustered?\n",
      "\n",
      "\"there are fewer ways to ask how long COVID will last than ways to\n",
      "write a positive movie review\" -- I would argue both are countably\n",
      "infinite. \n",
      "\n",
      "The cluster classification task was oddly formed. This is ultimately a\n",
      "sentence similarity task or a coreference/nil clustering task. One\n",
      "could use the data to pose the binary question \"are these two\n",
      "sentences asking the same question?\" One could also posit the far more\n",
      "useful \"is this a question that has already been asked [and if so\n",
      "which one] or is this a novel question?\" task of coref/nil\n",
      "clustering. Static assignment to clusters seems wrong for that kind of\n",
      "data. By specifically excluding clusters with a small number of\n",
      "questions you specifically skirt the issue you would have to deal with\n",
      "in real application of this data.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its dataset of hand-labeled questions related to COVID-19, considering its potential usefulness for question classification, semantic similarity, and reducing redundancy in question answering.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A good dataset paper - some clarification and statement of limitation\n",
      "The paper presents a dataset of questions related to COVID-19; included are annotations mapping questions to specific categories and classes.\n",
      "\n",
      "It's always good to see papers that contribute datasets to the research community, particularly if they require significant efforts in annotation as this one does.\n",
      "\n",
      "I think that some changes are needed in terms of positioning of this paper to make clear the contributions and benefits. The other reviewer, I believe, also struggled a little with this. I suggest an explicit \"who would use this data\" and \"how would this dataset be used\" section. I think limiting it to just people who want to train an QA IR system is a mistake. First, not all question have answers (Table 1); second, it's not obvious how the classes and categories focus, which are a large part of the paper, is core to training a QA IR system. Instead, I think the classes and categories can be used a lot more in the query intent / query understanding area of research. Pitching the paper more broadly - and being explicit on areas - would help to clarify and strengthen the contributions.\n",
      "\n",
      "On the methodology of annotation:\n",
      "- The paper rests on the technical soundness of the manual annotation process so the authors should really focus on ensuring the methodology / rigour is clear - especially as all the annotation work was done by the authors themselves. \n",
      "- Categories were made up by the author. How subjective and context specific was this? What are the limitations?\n",
      "- Seems like one question is mapped to one class and one category - what about overlapping questions? Surely there are questions that fall in multiple - and if there are not in this dataset then there will certainly be out in the wild. The paper, at leasts, needs to address this.\n",
      "- Categories may remain static (i.e., new questions about covid-19 would likely map to existing categories). But classes will be ever evolving. For example, if a vaccine is developed then a whole host of new question classes will arise. Having these static list of classes, at this snapshot in time, risks them becoming out-of-date very quickly in a rapidly changing environment.\n",
      "- Figure 2 - questions/class highly skewed. So is it actually worth having the classes? How valuable are they?\n",
      "- Having an explicit limitation section at the end of the paper will really help with the above points.\n",
      "\n",
      "\n",
      "Some changes in presentation could really elevate the paper:\n",
      "- The definition and difference between categories and classes was not clear at the beginning of the paper. In the middle section 2, the definition finally becomes clear. A definition of both is really needed earlier in the intro. \n",
      "- I found “classes” not really the best term. What about question “topics” or even question “clusters” since they are essential groups of duplicate questions. When classes are introduced, there needs to be a better justification for their purpose. It comes clearer much later but I think is needed earlier.\n",
      "- Matched vs. unmatched is confusing. It’s not that they were not matched, it’s just that they were classes with only one question, right? Can a better term found? Also Table 1 presents matched/unmatched without any reference / definition - only much later in the paper do you find out.\n",
      "- At some point, the paper suddenly starts talking about “labels” - it’s not clear whether this is classes or categories or both - why not just use the actual terms.\n",
      "\n",
      "On the classifier / experiments\n",
      "- The contribution of the paper is the dataset and not the ML methods. As stated, in the response to the review, the performance is merely an indication of how well current methods do on this task. The fact that the performance is good or bad does not really change the papers worth. However, insights from the experiments are part of the contribution; and these could be improved: e.g., were certain categories much harder than others? where two categories often confused for each other? \n",
      "\n",
      "Overall, this paper provided a good dataset for the community. But it needs to be much more explicit and clear about how people might use the dataset rather than a generic reference to training QA IR system. Addressing the presentation issues and directly addressing a number of limitations will greatly improve the paper.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the clarity and explicitness of the contributions and potential uses of the dataset presented in the paper, as well as the methodology of annotation and any limitations addressed.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Preliminary work, limited significance\n",
      "This paper presents a corpus of 1690 documents about COVID-19 manually annotated with questions classes, along with basic question classification algorithms.\n",
      "\n",
      "Pros\n",
      "- in scope for the conference\n",
      "- dataset is publicly available\n",
      "- technical details are kept to a minimum\n",
      "- accessible to a large audience\n",
      "\n",
      "Cons\n",
      "- no clear statement of objectives\n",
      "- no clear statement of specific contribution\n",
      "- no explicit annotation guidelines (making it difficult to reproduce this effort)\n",
      "- ad hoc categories (not modeled after general types of questions)\n",
      "- no justification for the selection of documents\n",
      "- mediocre performance of the basic question classification algorithms\n",
      "- no discussion (the so-called discussion section is merely a summary)\n",
      "- the claim that this dataset can help train QA systems is unwarranted at this stage\n",
      "\n",
      "Overall\n",
      "The significance of this preliminary work is extremely limited\n",
      "\n",
      "Other comments\n",
      "- the presentation of figure 2 is unnecessarily confusing\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the significance and contribution of this paper, as well as the performance of the question classification algorithms and the potential usefulness of the dataset for training QA systems.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Valuable resource\n",
      "The paper describes a novel dataset containing answers to a survey that asked participants to describe in short and long text their emotional states and rate their levels of  anger, anxiety, desire, disgust, fear, happiness, relaxation, and sadness. The dataset includes responses from 2500 UK residents collected during a critical period of the cover-19 pandemic.\n",
      "\n",
      "The paper also investigated the predictive performance of lexicon-based and supervised classifiers. Preliminary analyses of the data showed significant correlations between the respondents emotional ratings and the scores inferred by LIWC for the same emotions. However, these correlations are much higher for longer texts, which is not surprising since LIWC was not created for microblog style content and longer text has more words that can match with the lexicon. Similar trends were observed with a supervised model trained to predict the emotional ratings given the text answers. Finally, topic analysis of the data showed that the main topics expressed in shorter text are different than in longer text. \n",
      "\n",
      "The paper is well written, well scoped and well executed. The dataset is very interesting and it will be useful for the NLP community not only from the standpoint of understanding how people respond to global crises but also to better understand how the characteristics of social media might influence what kinds of information people decide to share. The cautionary tale about using Twitter to study the public's reactions to these kinds of events is worth a closer look. I am not sure how much we can extrapolate from this, given that in real life people can post more than one tweet about a subject, and they do so spontaneously which is different from being asked to post about something specific on a survey.  Some \"experimenter effect” might be at play here.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its methodology, dataset, and potential contributions to the NLP community.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Good first steps toward understanding the UK public's emotional response toward covid19\n",
      "The focus of this manuscript is to 1) describe a corpus of long and short lengthened emotional responses to the covid19 pandemic by the public, 2) identify meaningful associations between linguistic measures and emotional responses, and 3) develop prediction models for automatically classifying unseen texts according to their emotional response categories.\n",
      "\n",
      "Quality: The usage of LIWC lexicon to identify topical/linguistic information is a good start. I'm interested in how differently tools like empath (https://github.com/Ejhfast/empath-client) would perform in identifying pre-configured and new topics on this corpus and what additional insights could be drawn from it. \n",
      "\n",
      "The correlation values appear low, but I'm wondering if that's due to out of vocabulary terms. Perhaps, a quick manual review of LIWC term coverage and a lexicon enrichment might help identify a stronger signal. \n",
      "\n",
      "Some emotions seem a little hard to tease out or have close relationships e.g., worry, anxiety, fear, etc. It would be interesting to understand commonalities and distinguishing characteristics in terms of linguistic measures of related/close categories. \n",
      "\n",
      "Clarity: A few points should be clarified or explained: 1) did you collect any additional meta-data about the participants e.g., sex, gender, age, race, professions (essential vs. non-essential workers), etc. that could be useful to contextualize or identify particular worries among groups? 2) did these \"texts\" also include emoticons that could be used to convey emotional response and topical information? \n",
      "\n",
      "It would also be interesting to sample more than 2 days. I wonder how the topics will shift as the pandemic unfolds. \n",
      "\n",
      "Also, I would recommend revisiting the corpus title as its very UK-centric and covers a broad range of emotions. What about \"UK COVID19 Public Emotional Response dataset\"?\n",
      "\n",
      "Originality: The coupling of the open survey with traditional linguistic and topic modeling approaches for examining the global threat has some originality. The predictive model serves as an initial baseline. It would be interesting to evaluate other traditional machine learning classifiers to establish reasonable baseline performance.  \n",
      "\n",
      "Significance: The topic is certainly significant and a nice first attempt at obtaining self-reported emotional concerns of the public. This is also a great tool that if deployed more broadly could capture insights across regions, countries, and continents.\n",
      "\n",
      "Thank you for making this invaluable resource publicly available to researchers!\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its description of a corpus of emotional responses to the COVID-19 pandemic, the identification of linguistic measures associated with these responses, and the development of prediction models for classifying unseen texts.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Useful dataset\n",
      "Summary: The paper introduces a self-reported dataset of 2500 short and long (each) texts about emotions of people during the COVID-19 pandemic. The paper then analyses the dataset in terms of LIWC properties, output of a topic model (most probable topics) and a linear regression model to predict emotion based on TFIDF and POS-based features. The dataset will certainly be useful. The fact that it is self-reported and has both short and long texts are noteworthy.\n",
      "\n",
      "Suggestions:\n",
      "1) Short and long texts by the same participant do not necessarily have to be 'parallel'/'analogous', it seems. If this is indeed the case, I would suggest mentioning so.\n",
      "\n",
      "2) It would be good to know the reason behind picking worry as the key emotion. (In other words, the choice of calling this a 'worry dataset' and not an 'emotion dataset' is not clear). The question asked to the participants (when they draft their text) does not mention 'worry' explicitly. They are asked to rate how worried they feel. However, in addition, the participants are also asked to record other emotions.\n",
      "\n",
      "3a) Section 2.2: The description accompanying worry clubs it with 'anxiety'. However, table 1 shows that only 55% participants reported anxiety.\n",
      "\n",
      "3b) Please elaborate \"The participants’ self-reported ability to express their feelings in the long text\". Was it a part of the form?\n",
      "\n",
      "4) It is not clear if the number of tokens is the same as vocabulary. It would be useful to know the vocabulary sizes of the datasets.\n",
      "\n",
      "5) The github repo also includes LIWC statistics of the texts. This could also potentially be useful.\n",
      "\n",
      "6) There is a low correlation between the 'concerns' (work, money, death?) and worry. In contrast, the top topics from the model include job and family. Is it surprising?\n",
      "\n",
      "7) It would be useful to add statistics on how frequently the participants reported using Twitter. This would be helpful to understand the quality of the short text.\n",
      "\n",
      "8) Observation: The classifier is not state-of-the-art. It would be useful to add citations to papers which use linear regression for emotion analysis.\n",
      "\n",
      "9) Was the linear regression model also trained using spaCy?\n",
      "\n",
      "10) Is the low MAE for worry related to the fact that worry was central to the annotation? Could there have been a bias in the annotations? The stdev for worry is also the lowest (as shown in Table 1).\n",
      "\n",
      "The dataset would certainly be useful for future work. The analysis of the dataset (LIWC, topic models) is very interesting. The paper is easy to follow as well.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the usefulness and clarity of my paper, which introduces a self-reported dataset of short and long texts about emotions during the COVID-19 pandemic and analyzes the dataset using LIWC properties, topic modeling, and a linear regression model.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting correlation, but not actionable and not clear\n",
      "This paper analyzes the correlation between Covid19 cases (as reported by JHU) and relevant tweets, on a per-country based granularity.\n",
      "The results are remarkable, showing a very strong correlation (Table 2) for a model trained on Italian data. Moreover, using modern multi-lingual embeddings, the trained regression carries over to other languages; although the correlation there is very variable (and sometimes negative).\n",
      "The results are intriguing and show once more how expressions on social media reflect physical reality. \n",
      "\n",
      "I have however two major concerns:\n",
      "\n",
      "1/ Why is this useful?\n",
      "Not in the sense of what could public health officials do with such models (although I have no clue what they could do). It seems to me (and please correct me if I am wrong) that you are using the tweets of day D to predict number of cases of day D. If that is the case, then the causality is the other way round (cases => tweets). It would be much more interesting to try to predict number of cases at day D+1, or even better at day D+n.\n",
      " \n",
      "2/ Reproducibility \n",
      "There are lots of things that are not clear. Those are not fundamental issues, but I cannot recommend acceptance in the current state, as I could not understand exactly what the authors did, much less would I be able to reproduce it\n",
      "Filtering: \n",
      "  - why do you remove tweets with hyperlinks?\n",
      " - \"we remove [...] tweets discussing countries other than Italy\". What does this mean?\n",
      " - \"We further filter Italy’s tweets for a balanced representation of tweet embeddings.\" What does this mean?\n",
      "Model:  what exactly is a model? Is it the embedding + the total frequency of the selected words? Could you enumerate all the \"models\" (feature set) you used and - maybe in the appendix - the values for all of them?\n",
      "Evaluation: Why do you not report mean error? The correlation itself is not very actionable, the predicted value would be\n",
      "\n",
      "Also, there is a confusion between language and country, which is conflated. The given argument is that the chosen languages have a majority country, but for rigourousity I would recommend replacing country everywhere by language as it is misleading.\n",
      "\n",
      "Fig 1 seems to be done with the number of tweets before the filtering of Sect 2.5. Why?\n",
      "\n",
      "Finally, I am not sure if I understand how the transfer is done. Is it correct to say that you use the same regression and provide as feature the Japanese/Indonesian/etc tweets after putting them through the multi-lingual embedding?\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the usefulness of the correlation between Covid19 cases and relevant tweets, as well as the clarity and reproducibility of the methods used.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Good idea but some methodological concerns\n",
      "The following paper hypothesizes that tweets can be used to model COVID-19 outbreaks in across countries. The paper does this by using cross-lingual sentence embeddings from mBERT and LASER to predict case-counts.\n",
      "\n",
      "Although this is a good idea and Figure 1 is particularly compelling, I find that the paper is at best a work in progress and at worst intentionally misleading. I'd recommend substantially more work before it is ready for publication. \n",
      "\n",
      "My biggest concern is that the way the tweets are filtered and the time-chunks are specified, I have no reason to believe that this model is using tweets to actually predict an outbreak, as the authors imply (NB the authors are careful to say they are \"aligning\", not \"predicting\", although I think this intentionality is rather muddy). It seems to me that they are simply capturing the response to an outbreak already occurring -- I'm unclear what the value of this is to social scientists and policymakers.\n",
      "\n",
      "The authors explicitly filter for words such as \"lockdown\", \"quarantine\", \"social distancing\", \"epidemic\", and \"outbreak\", to perform their alignment, which to me seem to describe tweet-responses to policy rather than tweet-responses to sickness. I think the authors' hypothesis would be better served by choosing words, topics or other indicators that are more personal and health-related -- words like \"fever\", \"cough\" or \"lack of smell\" -- to avoid such confounding.\n",
      "\n",
      "Further, the authors utilized fixed time-periods to explore their regression, which is a little confusing to me. I think the authors should use date-ranges in each country relative to the kth case in that country. Since their date-ranges are so wide, I worry that the date-ranges are simply capturing the full policy response of a government that has already predicted an outbreak.\n",
      "\n",
      "Why is spearman's correlation the only metric used? If the authors are conducting a regression experiment, there are other more compelling and interpretable metrics. Why aren't significance-values included for the correlation?\n",
      "\n",
      "Why do the authors say that they observe \"right-skewed Gaussians\"? This is clearly more of a point process (i.e. a Hawkes process.)\n",
      "\n",
      "Additionally, I would urge a more serious consideration of other confounders as well. I'm not sure what the best ones to use would be, but I think some policy analysis is necessary -- when did each country actually institute a lockdown? Do lockdowns effect overall non-COVID tweet-volume as well? I'm sure there are confounders in the literature.\n",
      "\n",
      "If this is not possible, then I urge a reframing of the paper. The authors need to be clearer about what they are actually purporting to do, and not hide behind words like \"align\".\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the methodology and findings of our paper on using tweets to model COVID-19 outbreaks across countries, including any concerns or suggestions for improvement.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review of: Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment\n",
      "# [REVIEW] Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment\n",
      "\n",
      "10th June 2020\n",
      "\n",
      "## SUMMARY\n",
      "This short paper describes work on cross-lingual transfer learning to track COVID-19 cases across Italy, Thailand, Japan, Turkey, and Indonesia (i.e. languages that are largely spoken in a single country).  Using case statistics derived from Johns Hopkins COVID dashboard, the researchers aim to determine (a) if the number of COVID-related tweets is associated with case numbers (good correlations were achieved for this), and (b) can this training be applied to other countries that may be at a slightly different point in their COVID trajectory i.e. cross-lingual transfer learning (a range of correlations with JHU data were achieved ranging from -.316 to 0.859, indicating that the approach has some utility — but see caveats below).  \n",
      "\n",
      "It is difficulty for me to assess the quality of this paper relative to other submissions, but I suspect that this use of cross-lingual transfer learning is sufficiently interesting to justify a short paper.\n",
      "\n",
      "## MAJOR COMMENTS\n",
      "1.  There is a major methodological issue not related to the NLP and not something you can be reasonably expected to do anything about — but I think it’s important to point it out as a limitation:  The international ground truth data for COVID is  not very reliable regarding underlying prevalence/incidence of COVID-19.  Even in the US, there have been stark differences in approaches to testing, and the criteria for testing. International comparisons are even more difficult. This undermines the evaluation somewhat.\n",
      "\n",
      "## MINOR COMMENTS [NITPICKING]\n",
      "1.  [p1c1] “With globalization, it is intuitive that countries have followed earlier affected regions in patterns of outbreaks and measures to contain to them (Cuffe and Jeavans, 2020).” Consider rephrasing this to emphasise that it is the increased travel associated with globalization that is important, rather than globalisation per se.\n",
      "2.  [p3c1] “Bert as service” probably requires a few words of  explanation (at least for this reviewer - I had to google it)\n",
      "3.  [p3c2] “When measuring against new daily cases, the correlations are not as significant in time II”  suggest avoiding using the word significance here, unless you are referring to statistical significance.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the quality and significance of the paper on \"Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment\" based on the reviewer's comments.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Useful resources collected and introduced\n",
      "This work is an introduction to a suite of resources and their corresponding ideas revolving around the COVID data provided by the Allen institute. Authors in particular provide Neural Covidex which allows exploration of information retrieval and NLP techniques over the COVID dataset.\n",
      "\n",
      "The positives of this manuscript is as it also says gathering all the information and resources one would need to start exploring this dataset and further the techniques without having to spend weeks to put them all together. It is significant effort to get this far and of course authors are relying on their previous work over many years. There are some good pointers for some of the recent work in biomedical IR that is useful to know. I personally learnt from the content and enjoyed reading it.\n",
      "\n",
      "This work however is written in haste (as it was needed due to the time limit of the current situation) and it is lacking the formal language of a scientific paper and of course evaluation. Obviously evaluation on this particular dataset is not straightforward given for example TREC is only starting on that effort. However though some initial analysis of the dataset could strengthen it. I was half expecting to see the discussion on evaluation metrics be a bit more mature and be given a separate section at least. This work as it stands, while very useful for the IR/NLP community it needs some reworking of the content to get to the state of publication in an ACL workshop.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the content and structure of my paper, specifically focusing on the clarity of language, inclusion of evaluation metrics, and overall usefulness for the IR/NLP community.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Laudable effort, but currently more preprint material\n",
      "This paper describes the rapid deployment of an IR system for the CORD-19 dataset. The system borrows state-of-the-art pieces, such as T5 and BioBERT, with training on MS MARCO. A search interface is shown that includes potential answer highlighting. Absent hard evaluation data, the authors provide more of a narrative of the system development, from initial conceptualization, early builds, deployment, and social media advertisement.\n",
      "\n",
      "First and foremost, the authors are to be congratulated for this work. The effort is most laudable.\n",
      "\n",
      "The style and tenor of the paper should be described as somewhere between a Medium post and a work-in-progress preprint. While normally this would be out of place, it is less out of place in a workshop such as this one. The casual language is fine and almost cute, while the frankness is quite welcome, but the other preprint-like or web post-like aspects of the paper are more problematic.\n",
      "\n",
      "Let's start with the lack of evaluation, which the authors acknowledge that \"It is, of course, expected that papers today have an evaluation section that attempts to empirically quantify the effectiveness of their proposed techniques\". Of course, this empirical validation is what makes it science, as opposed to engineering/marketing. I certainly understand that the resource commitment to a TREC-style evaluation is beyond one group's ability under a pandemic situation. But the authors present the solution within their own paper: from footnote 14 it appears that the TREC-style evaluation is underway, and that should have preliminary results available well before this workshop's deadline. So why not simply issue this as a preprint to flagplant their admittedly laudable effort, then wait until some empirical results are available and submit *that* paper to the workshop?  If the authors plan to submit a work with results as a separate publication, this should be made more clear and a more compelling argument needs to be made for the scientific usefulness of the \"behind the scenes\" story of this search engine.\n",
      "\n",
      "The authors make the claim that instead of the importance of search result ranking (despite Section 3 being about how great the system is at ranking on other tasks), that instead what is really important are the interface improvements that increase the usability of the system. However, every real-world IR evaluation has come to exactly this conclusion: experts always request various bells and whistles. First, note that users can't see the relevant articles that were missed, so they have little choice but to comment on the interface. But more importantly, good ranking != good usability, this is no novel claim. But usability evaluation is a well-honed science, and the authors do not perform any kind of usability evaluation either. These are less resource-intensive as well, typically requiring just an IRB protocol and some experts willing to provide feedback.\n",
      "\n",
      "My main stylistic issue is that in many places this paper comes across as a brag-fest for the accomplishments of the group. These accomplishments are beyond doubt, of course, which is all the more reason why the authors can avoid tangents to cite unnecessary prior work (e.g., most of the BERT stuff in the first paragraph of Section 3.3, as this is not even used in the system).  The implications in Section 5 that the authors' group's \"culture\" and use of good software practices, unlike other poor-coding researchers, is also unnecessary (why is a \"faculty advisor\" reference even there?). One can extol the virtues of good culture and software engineering without coming across as bragging, so I would recommend a re-write of those parts of this paper to take a more scientific tone.\n",
      "\n",
      "Minor:\n",
      "- In Section 3.1 it is unclear what the \"1\" in \"n+1\" comes from. Do the authors also include a document that is just the title/abstract without the paragraphs?\n",
      "- \"who are engage in\" -> \"who are engaged in\"\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its content and presentation, providing feedback on its strengths and weaknesses.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Evaluation of a rapidly deployed search system for the CORD-19 data set\n",
      "The authors have quickly stood up a conventional and neural search system based on the CORD-19 dataset, which is a commendable task given the global crisis caused by the Covid-19 pandemic. However, this paper is just a description of their system and design decisions, with some additional discussion of why a conventional TREC system-oriented retrieval evaluation would be limited. I agree with the authors on that point.\n",
      "\n",
      "However, it would be helpful to have some sort of evaluation of their system to gauge whether their approach offers any novelty beyond the multiple other systems that been stood up and linked to from the Allen Institute site where the data is housed.\n",
      "\n",
      "While I agree that a system-oriented evaluation approach would be limited, it would also be helpful to, say, compare the baseline and neural approaches. The first round of the TREC-COVID challenge evaluation is being conducted as I write this, and the first set of results will be available by late April or early May. I believe a better approach would be to include these results and then discuss their limitations.\n",
      "\n",
      "If the authors do not believe the system-oriented results are important, they can explain why. They could provide some usage statistics for their system and describe other real-world use. They can also propose better evaluation studies, including those that involve users as they allude to in their paper.\n",
      "\n",
      "Overall this is good work, but it could be much better, and we will hopefully learn more as the system is used, the test collection grows, and more complex tasks beyond ad hoc retrieval are evaluated with it.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness and novelty of the search system described in our paper, specifically in comparison to other systems that have been developed for the CORD-19 dataset.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A novel method of empirical attacks and defenses using semantic transformations\n",
      "This paper proposed novel defense and attack methods using image transformations. The random transformation defense is designed by averaging the scores of results under random transformations. This paper proposed to use Bayesian optimization to select the most informative transformation parameters. The authors also re-implemented and evaluate BaRT attacks and improve their performance.\n",
      "\n",
      "The experimental results and solid and significant so I recommend a clear acceptance.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed defense and attack methods in our paper, which utilize image transformations and Bayesian optimization, and provide your recommendation for acceptance.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A more reliable evaluation of robustness for random transformation defenses\n",
      "The authors show that backward-pass differentiable approximation struggles to approximate some transformations accurately, and non-differentiable transformation can’t guarantee robustness. Furthermore, the authors propose a novel attack method to evaluate random transformation defenses. This work provides a more reliable evaluation of robustness for random transformation defenses.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the robustness evaluation method proposed in our paper and provide feedback on its reliability in assessing the effectiveness of random transformation defenses.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Convergence Analysis of No-Regret Learning Algorithms in Min-Max Stackelberg Games\n",
      "This paper provides a convergence proof of no-regret learning algorithms in min-max Stackelberg games. Under certain assumptions, the authors prove that the no-regret learning algorithms will converge to a equilibrium after $T$ iterations in pessimistic and optimistic settings (with Lagrangian regret). The author then apply above theorems to OMD and derive $O(\\frac{1}{\\epsilon^2})$ convergence rate for those algorithms. Finally, the authors study the dynamic Stackelberg games and give theoretical proof for independent strategy sets.\n",
      "One interesting question is: can these analyses be applied to two-player zero-sum games modeled by Markov Decision Process, which might be a more practical and challenging question to be considered.\n",
      "\n",
      "Also some drawbacks must be addressed in terms of writing. Some inline functions can be adjusted for better reading, and grammar mistakes should be corrected before submission.\n",
      "\n",
      "the average of the players’ strategies converge to a Stackelberg equilibrium. -> converges to\n",
      "\n",
      "in average iterates. -> in average iterations.\n",
      "\n",
      "We provide a review of related work in Appendix BThis paper is organized as follows. -> Appendix B. This\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its convergence analysis of no-regret learning algorithms in min-max Stackelberg games, including its application to OMD and the study of dynamic Stackelberg games.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A novel work for Min-Max Stackelberg Games\n",
      "This work considers min-max Stackelberg games. For two special settings of this problem, this paper proposes no-regret algorithms with convergence guarantee. Moreover, this work provides the theoretical analysis as well as expereimetal results of the algorithms' robustness.\n",
      "\n",
      "However, the connection between this work and adversarial mechine learning is relatively weak. Moreover, it's better to adjust the format of some equations, like the equation in the bottom of page 2 and in the top of page 3, the Lipschitz-continuous condition in the final of sec 2,  “vanilla” regret in page 4, the objective in Example 4.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed algorithms for min-max Stackelberg games, their convergence guarantee, theoretical analysis, and experimental results, while also considering the connection to adversarial machine learning and the formatting of equations and objectives.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "An adversarial detector based on multiple model representations\n",
      "This paper proposes two approaches using multiple model representations to detect adversarial examples. The authors conducted ablation studies to verify the contribution of the number of underlying models. The major weakness is that comparisons with other adversarial detectors are lacking.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed approaches in our paper that utilize multiple model representations for detecting adversarial examples, considering their effectiveness and any potential weaknesses.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting idea of ensembling models to detect adversarial instances\n",
      "This paper proposed to detect adversarial instances by ensembling the deep representations of multiple models in two ways ---- model-wise or unit-wise. The experiments is conducted on CIFAR-10 with the attack methods of FGSM, BIM and CW. The results show that with the incremental number of ensemble models or units, the detection accuracy will increase.\n",
      "\n",
      "Strengths:\n",
      "* The paper is well-written and the figures clearly convey the main ideas.\n",
      "* The idea of incorporating the representations from multiple models to detect adversarial instances is straightforward yet effective.\n",
      "\n",
      "Weaknesses:\n",
      "* Comparison with existing adversarial example detection methods should be given.\n",
      "* Experiments on other datasets can be further conducted.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed method of ensembling deep representations from multiple models to detect adversarial instances, including its strengths and weaknesses.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Good Approach and Extensive Evaluation\n",
      "**Summary**:\n",
      "\n",
      "In this work, the authors have described a novel approach towards detecting adversarial perturbations in images. The approach uses conditional VAEs trained on clean (non-perturbed) images, and leverages that adversarial perturbed examples actually come from a different distribution than the predicted class and hence will have a higher reconstruction error. The authors evaluate their approach over several known black-box and white-box methods. \n",
      "\n",
      "**PROS**:\n",
      "\n",
      "1. The authors address the distinction between random noise and adversarial perturbation, which is important since not all random noise will be adversarial. \n",
      "2. The authors extensively evaluate their approach over known attacks, which shows that the CVAE based method can be of practical significance. \n",
      "3. The approach leverages correctly the fundamental characteristics of autoencoders -- that since adversarial examples will cause only imperceptible distribution shifts in the feature space, the reconstruction error is high. In other words, the tradeoff between classification label and adversarial perturbation is leveraged. \n",
      "\n",
      "**CONS**\n",
      "1. In the introduction, the authors explain drawbacks of statistical, network-based and distribution methods such as domain-dependency and non-transferability. It would be also good to address whether the CVAE approach overcomes any of these issues, and if so, how.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the approach and evaluation presented in the paper, focusing on the effectiveness of the proposed method in detecting adversarial perturbations in images.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review of Paper 23\n",
      "This paper propose to use CVAE to detect adversarial examples, while avoid be sensitive on random noisy samples. The experiments are done on MNIST and CIFAR-10, under different attacks and threat models.\n",
      "\n",
      "The idea of exploiting the information of predicted labels is reasonable, and the authors also evaluate the method under white-box attacks (i.e., adaptive attacks). However, recent work [1] find that many detection-based defenses may over-claim their performance, so it would be more convinced if the authors can convert their reported results into classification-based defenses and do a sanity check along with [1].\n",
      "\n",
      "[1] Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method of using CVAE to detect adversarial examples, while avoiding sensitivity to random noisy samples, and provide feedback on the experimental results and the potential for over-claiming performance.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A novel method for diferentiating a bilevel programming solver\n",
      "This paper proposed a novel method for calculating gradients of a bilevel programming solver. This problem has a wide range of applications like adversarial training, GAN, and combinatorial optimization problems. \n",
      "\n",
      "Pros\n",
      "The method is novel and interesting and it can easily be embedded into a neural network as a layer. The author also implements it in several examples like linear and non-linear inequality constraints.\n",
      "\n",
      "Cons\n",
      "I think the author could provide more examples or applications about adversarial learning. For example, adversarial training (AT) is also a bilevel optimization problem. Can your method be used in AT?\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed method for calculating gradients in a bilevel programming solver, considering its potential applications in areas such as adversarial training, GAN, and combinatorial optimization problems.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "An ensemble training method for robustness\n",
      "This paper proposes an ensemble training method to enhance the robustness. The ensemble training is implemented by training a super-net called random gated network (RGN). An interesting block called random gated blocks (RGB) is proposed to diversify the vulnerability of different paths through the RGN. Extensive experiments demonstrate the effectiveness of RGN. \n",
      "\n",
      "Weakness:\n",
      "There are too many typos in this paper. Please correct them. For example, “Pan et. al. treat the distribution” in Page 3 (should be Pang et. al.); Algorithm 1 (incorrect line numbers, redundant right bracket, meaningless “=0” in last line)\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness and quality of the proposed ensemble training method in enhancing the robustness of your paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "An simple yet efficient ensemble training method.\n",
      "Pros:\n",
      "1, The proposed ensemble training method is simple yet efficient. Compared with conventional methods, this method is easier to scale up and faster.\n",
      "2, The paper is easy to follow.\n",
      "3, Most of the experiments are convincing.\n",
      "\n",
      "Cons:\n",
      "1, Though one advantage of the proposed method is easy-to-scale-up. However, it is also admitted that the scaling-up in the method brings no benefit, which is disappointing.\n",
      "2, Since one contribution is minimal computational overhead, the paper should offer the comparison on training speed with other methods.\n",
      "3, The proposed method cannot support the ensemble of models in different architectures.\n",
      "4, The algorithm 1 is not formal.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed ensemble training method in terms of its simplicity, efficiency, scalability, and experimental results.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Novel method for network verification\n",
      "The author proposed a polytope traversing algorithm for network verification within a certain region. For Relu networks, the function is piecewise linear and decision regions are partitioned by many polytopes. By traversing these polytopes using a specific algorithm, we can verify a sample within a given region. I also have some concerns. What's the complexity of the method? Is it possible to scale it to larger datasets like ImageNet? I think the scalability is the major drawback of these deterministic verification approaches compared with probabilistic approaches like Randomized Smoothing. If this method can be further extended to larger-scale datasets, I think it will be a breakthrough.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed polytope traversing algorithm for network verification in terms of its complexity and scalability, particularly in relation to larger datasets such as ImageNet.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A novel work for proposing polytope traversing algorithm\n",
      "This paper points out that ReLU NNs will divide the input domain into many local polytopes. Based on this observation, this work develop a polytope traversing algorithm via BFS and apply in many aspects like local adversarial attacks. The idea is novel and exactly makes sense. \n",
      "\n",
      "However, I have some concerns about how this work can be applied to larger and more real tasks like image classification. First, the dimension of images is large, which may significantly increase the computational complexity of this algorithm. Second, since the sizes of different local polytopes may vary a lot, directly search polytopes via BFS may not find the optimal solution in some application like generating adversarial noises. Maybe the authors can attempt to test their methods in some image dataset like MNIST.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed polytope traversing algorithm and its potential application in larger tasks such as image classification, considering factors such as computational complexity and the effectiveness of the algorithm in finding optimal solutions.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "An instresting work.\n",
      "This paper studies robustness indicators of deep models with the goal of better estimating robustness on \"unknown\" datasets.  The authors argue that fixed test sets (e.g., ImageNet-C) are only able to capture a small portion of possible data variations and are limited and prone to generate new overfitted solutions.  Towards this end, the authors proposed a novel method to estimate the robustness behaviour of trained models by analyzing the learned feature-space structure. \n",
      "\n",
      "What I really like about this work is taking an empirical approach to understanding the robustness of the models' inner feature space and providing experimental observations.  Overall this paper is generally well written and focuses on an important direction of understanding the models' robustness on unknown datasets.\n",
      "\n",
      "## Strength\n",
      "1). The overall presentation of the paper is clear and easy to follow.\n",
      "\n",
      "2). In addition to the empirical experiments, the paper also provides some theoretical analysis.\n",
      "\n",
      "3). Interesting intuition around the concept of robustness.\n",
      "\n",
      "## Weakness\n",
      "1). Motivation for using clustering methods as a robustness indicator is not well explained.\n",
      "\n",
      "2). More datasets should be incorporated.  ImageNet-P perturbations are not included in the paper.  Another important recent benchmark not mentioned in the paper is ImageNet-A ). If the authors want to make their claims more reliable, I would encourage them to consider these datasets (in addition to ImageNet and ImageNet-C).\n",
      "\n",
      "3). Some experimental results are not explained. For example, in Figure 7,  when epsilon increases,  the correlation becomes weaker.  This seems to be a conflict against the main contribution of this method.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its empirical approach to understanding the robustness of deep models' inner feature space and its focus on estimating robustness on \"unknown\" datasets.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A new perspective for assessing robustness from the clustering performance of the model's latent space.\n",
      "**Pros:**\n",
      "Generally this paper proposes a new indicator for the model's robustness based on the clustering performance of the model's latent space. Also, vast experiments demonstrate the correlation between the indicator and the model's robustness under corrupted inputs, and proposed indicator clearly overperforms the naive baseline, i.e. the class overlap in the latent space.\n",
      "\n",
      "**Cons:**\n",
      "However, some doubts still need to be addressed:\n",
      "- It seems that the clustering performance highly depends on latent space samples, so one question is: will the robustness indicator still work when the latent space samples are derived from a different dataset other than the training dataset?\n",
      "- Considering the adversarial robustness, acquiring adversarial examples of a known model using methods like FGSM or PGD is neither complex nor time-consuming. Therefore, I don't quite understand why we need to explore the latent space features from the samples with clustering, it seems to require more time and computation resources.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed indicator for assessing the robustness of our model based on the clustering performance of the latent space, and provide your thoughts on its effectiveness compared to existing methods.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Lacks Novelty\n",
      "**Summary**: \n",
      "\n",
      "The paper talks about how adversarial perturbations can affect the performance of OOD detectors. They present a unified framework to study both adversarial attacks on in-distribution as well as OOD inputs (ie attacks which aim to increase both FP and FN). An algorithm called ALOE is presented that trains the model with perturbed inputs and improves robustness towards such attacks. \n",
      "\n",
      "\n",
      "**PROS**\n",
      "\n",
      "1. OOD detection is an important problem due to adversarial attacks and data drift in the real world, hence the problem is pertinent. \n",
      "2. Evaluation is detailed and compares against well-known methods. \n",
      "\n",
      "\n",
      "**CONS**\n",
      "\n",
      "1. To me, the paper lacks innovation and novelty. Reduced to the basic version, the proposed approach is simply adversarial training with some minor tweaks. Exposing the model to perturbed inputs to improve robustness has been done previously, see [1] and [2] for examples. The only difference is the domain; while previous experiments were on classifiers, these are on OOD detectors (which are also fundamentally, classifiers). \n",
      "2. The authors claim that one of the contributions is that they 'show that state-of-the-art OOD detectors can fail to distinguish between in-distribution examples and OOD examples under small adversarial perturbations'; however, this is not surprising, see [3].\n",
      "3. Finally, the attacks presented are _white box_ which seems improbable. OOD detectors are generally not exposed as an endpoint, and most users do not even perceive that there is an OOD detector at work here. Therefore, I believe that white box attacks against OOD detectors are not of practical signifiance.\n",
      "\n",
      "\n",
      "**References**\n",
      "\n",
      "[1] Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. \"Explaining and harnessing adversarial examples.\" arXiv preprint arXiv:1412.6572 (2014).\n",
      "\n",
      "[2] Wang, Y., Ma, X., Bailey, J., Yi, J., Zhou, B., & Gu, Q. (2019, June). On the Convergence and Robustness of Adversarial Training. In ICML (Vol. 1, p. 2).\n",
      "\n",
      "[3] Sehwag, V., Bhagoji, A. N., Song, L., Sitawarin, C., Cullina, D., Chiang, M., & Mittal, P. (2019, November). Analyzing the robustness of open-world machine learning. In Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security (pp. 105-116).\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the novelty and contribution of our paper in the context of adversarial perturbations and their impact on the performance of out-of-distribution (OOD) detectors.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review\n",
      "**Summary of the paper:**\n",
      "\n",
      "This paper extensively studies the problem of robust OOD detection on common OOD detection approaches and shows that existing OOD detection algorithms can be easily attacked to produce mistaken OOD prediction by adding small perturbations to the in-distribution and OOD inputs. To address the challenge, the authors propose an effective method to improve the robust OOD detection performance. Moreover, the authors show that the proposed method can improve the robust OOD detection performance by up to 58.4% compared to the previous state-of-the-art method on several benchmark datasets.\n",
      "\n",
      "**Detailed comments:**\n",
      "\n",
      "a.) This paper studies the problem of _Robust Out-of-Distribution Detection_ and shows that state-of-the-art OOD detectors can be easily fooled by adding small perturbations to the in-distribution and OOD inputs. The related analysis and conclusion are interesting and valuable if there is no similar analysis in the past.\n",
      "\n",
      "b.) The proposed method performs robust training by exposing the model to both adversarially crafted inlier and outlier examples, which is simple yet effective and works well for a wide range of datasets.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of the proposed method in improving robust out-of-distribution detection performance compared to existing state-of-the-art methods, based on the evaluation results presented in the paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review of Paper4\n",
      "**Summary of the paper:**\n",
      "\n",
      "The authors propose a novel diversity-promoting learning approach for the deep ensembles to overcome the shared vulnerabilities in its members. Experiments on  MNIST, Fashion-MNIST, and CIFAR-10 are conducted to demonstrate the efficacy of the proposed methods.\n",
      "\n",
      "**Main Review:**\n",
      "\n",
      "Strength:\n",
      "* The proposed method is simple and achieves the goal of improving the adversarial robustness of deep ensembles. \n",
      "* Several ablation studies are presented to illustrate the proposed method.\n",
      "Weakness:\n",
      "* The saliency diversification learning objective may damage the interpretability of the DNNs.\n",
      "* Why not take the large-scale data set (ImageNet) into consideration to evaluate the effectiveness of the proposed method.\n",
      "* In Table. 1, the experiments on CIFAR-10 may show that the efficacy of the proposed method is limited. \n",
      "* You can make an ablation study on CIFAR-10 compared with adversarial training (with small perturbation like $\\epsilon=2/255$). Maybe adversarial training performs better on vanilla accuracy and robust accuracy.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of the proposed method in improving the adversarial robustness of deep ensembles, considering its simplicity and the results presented in the experiments.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Saliency Diversified Deep Ensemble for Robustness to Adversaries\n",
      "This paper proposes a diversity-promoting learning approach for the deep ensembles, which promotes saliency map diversity (SMD) on ensemble members to prevent the attacker from targeting all ensemble members by introducing an additional term. Thus it can improve ensemble robustness to adversaries. However, some concerns are also listed as follows:\n",
      "\n",
      "Adversarial training is a currently popular and effective method. What is the effect of this method on CIFAR-10 under adversarial training? And what are the corresponding time-consuming results? Besides, AutoAttack[1] can be involved in this paper for white-box evaluation.\n",
      "\n",
      "[1] Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed approach in the paper for promoting saliency map diversity in deep ensembles to improve robustness to adversaries.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A new normalization method.\n",
      "The paper introduces a new normalization method named pixel-wise tensor normalization which improves both accuracy and robustness of the model. However, the results shows somewhat improvement, but not significant. Also, I think the paper is not providing enough theoretical backups for the claimed algorithm, and it prevents me from being completely convinced. Also, the paper does not seem to be a complete draft - there are many points that seem to be incomplete. The paper still needs further polishment and is not ready for publication at the moment.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness and theoretical support of the proposed normalization method in my paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review of paper \"Tensor Normalization and Full Distribution Training\"\n",
      "This paper proposes two techniques including tensor normalization and full distribution training to improve model robustness. These two techniques are easy to understand, and bring improved robustness compared with the baseline. Here are some suggestions for the authors.\n",
      "\n",
      "- Can the proposed methods be integrated with adversarial training? And how about the results?\n",
      "- Do the proposed methods have other advantages beyond adversarial robustness, such as natural robustness evaluated by CIFAR-C.\n",
      "\n",
      "Hope the authors can further improve this paper.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed techniques of tensor normalization and full distribution training in terms of their integration with adversarial training and potential advantages beyond adversarial robustness.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Meta Adversarial Perturbations\n",
      "This paper proposes a meta adversarial perturbation (MAP) and obtains a better initialization that causes natural images to be misclassified with high probability, which is only updated through a one-step gradient ascent update.\n",
      "\n",
      "Experimental performance can be demonstrated that the method can better mislead adversarial example classifiers and achieve better performance. \n",
      "\n",
      "The weakness is also listed as follows:\n",
      "\n",
      "1.\tThe authors are encouraged to evaluate the performance on more datasets, such as ImageNet.\n",
      "\n",
      "2.\tMore baselines should be introduced for comparison, such as DIM[1] and TIM[2].\n",
      "\n",
      "\n",
      "[1] Xie et al. Improving transferability of adversarial examples with input diversity\n",
      "\n",
      "[2] Dong et al. Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate our paper by considering its performance on various datasets, such as ImageNet, and comparing it to other baselines like DIM and TIM.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A good work for improving the robustness against unauthorized replication attacks\n",
      "This work proposes Constrained Randomization of Policy (CRoP) as a deep reinforcement learning defence method against unauthorized replication attacks. Though the theoretical part needs to be organized better, the extensive experiments show the effectiveness of CRoP.\n",
      "\n",
      "Some suggestions:\n",
      "\n",
      "1. It's better and more clear to first define the attack objective as well as the defence objective. \n",
      "\n",
      "2. Some symbols can be more concise, e.g. in eq(1), $\\!\\exists \\hat{a}\\in\\hat{A}$ may be replaced with $\\hat{A} = \\emptyset$.\n",
      "\n",
      "3. It's better to define the meaning of the symbol before it's first used, e.g. $m_n$.\n",
      "\n",
      "4. Some theoretical results need more careful discussion, e.g. eq(9) provides an upper bound, what's the connection with defence?\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of the proposed Constrained Randomization of Policy (CRoP) method in improving the robustness against unauthorized replication attacks in the paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review of paper \"Is AutoAttack/AutoBench a suitable Benchmark for Adversarial Robustness?\"\n",
      "This paper discusses several limitations of AutoAttack and RobustBench for robustness evaluation. It points out two limitations: 1) The adversarial examples generated by AutoAttack can be easily detected. 2) AutoAttack does not generalize well to datasets with higher resolutions. This paper provides excessive experiments to validate these two findings.\n",
      "\n",
      "Overall, it is interesting to see such discussions on AutoAttack, which is the most popular benchmark to evaluate adversarial robustness. The findings are insightful and could be useful for future research. The authors are encouraged to further complete their paper to a long version.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper \"Is AutoAttack/AutoBench a suitable Benchmark for Adversarial Robustness?\" based on its findings and experiments.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "An Adversarial Benchmark for Fake News Detection Models\n",
      "This paper proposes an adversarial benchmark for fake news detection, which is designed to evaluate models’ ability to reason about real-world facts. And some findings can strengthen the need for fake news classification models.\n",
      "\n",
      "However, the author is also expected to make more analysis and experiments for a benchmark. A clearer discussion and definition should be also considered.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed benchmark for fake news detection in terms of its ability to assess models' reasoning about real-world facts and its potential to strengthen the need for fake news classification models.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Timely research with exciting results, more details of computational gain would make the work stronger\n",
      "The paper proposes an operator learning approach to learn a mapping between initial and final states of the droplet coalescence process to enable rapid and accurate part-scale build simulation. Authors compare this approach to previous work and show the impressive acceleration and reduction of the required data for learning. This is very timely research that can have considerable implications for quality control in additive manufacturing. \n",
      "\n",
      "The paper contains preliminary results for deposition settings and reports the computational gain. However, I would like to see a more detailed analysis beyond the demonstration of the two cases. For example, the authors state that only 729 pairs were used for training with the proposed approach. How were these 729 pairs selected is unclear.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its demonstration of the operator learning approach for rapid and accurate part-scale build simulation, including the analysis of computational gain and the selection process for training data.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The paper presents a new Fourier Neural Operator (FNO) approach to accelerate manufacturing simulations\n",
      "The paper presents a new Fourier Neural Operator (FNO) approach to accelerate metal jet droplet deposition manufacturing simulations. The proposed approach is an order of magnitude faster than the existing state-of-the-art reduced-order simulation approach. The preliminary results show that the FNO approach works better for large spacing between droplets but might need further training for smaller droplet spacings. Overall the results look promising.\n",
      "\n",
      "I have some minor comments. A more detailed timing and accuracy results would make the advantages of the FNO approach more clear. The quality of the figures could be improved to use vector graphics. Finally, as a possible extension of the work, it might be interesting to understand the effect of the FNO architecture on the results.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed Fourier Neural Operator (FNO) approach for accelerating metal jet droplet deposition manufacturing simulations, including its advantages, limitations, and potential areas for further investigation.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The paper presents a Generative Adversarial Network-based design methodology which allows uncertainty quantification (UQ) of geometric variability. The main idea is to learn a low-D representation of possibly high-D nominal design spaces, and quantify the uncertainty through the learning of a conditional posterior distribution of the fabricated designs given any nominal design. The framework has been demonstrated on two design examples – airfoil design and optical metasurace absorber design.\n",
      "•\tThe idea of using GANs to simultaneously learn the reduced design space and the conditional distribution quantifying the manufacturing uncertainty is novel.\n",
      "\n",
      "•\tCould you elaborate on the distinction between the variabilities present in the parent and the child latent space?\n",
      "\n",
      "•\tIn some sense, the fabricated design space for a given nominal design involves heuristics in how the fabricated space is created (which is expected to be so – each problem is different). But it would be helpful to understand the effect of noise in creating the fabricated design space. For example, what happens when the standard deviation of the Gaussian noise is increased from 0.02 in the airfoil design fabricated space? What effect does it have in the optimization cycle in terms of evaluations/data requirement? If it is beyond the scope of this paper for a demonstration, it would be helpful to have some comments regarding this. \n",
      "\n",
      "•\tAny comments on how the initial samples were selected for the Bayesian optimization (BO) phase? As we know that BO results can be strongly influenced by the initial design. Also, what was the criterion for stopping the BO loop ?\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its novel use of Generative Adversarial Networks (GANs) to learn a reduced design space and quantify manufacturing uncertainty, and provide insights on the effect of noise in creating the fabricated design space and the selection criteria for initial samples in the Bayesian optimization phase.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A novel approach to Robust Design leveraging conditional generative models\n",
      "This paper addresses the use of generative models for design under uncertainty, such as in the case where manufacturing variability may affect a design's performance or feasibility. The key idea of the paper is that rather than modeling design under uncertainty as a sequence of bounds or independent random variables, you can use a generative model to model the high dimensional covariance among the design parameters, and thus more accurately estimate the likely uncertainty. The other key idea in the paper, which I found quite compelling and novel, is to model this uncertainty as a conditional distribution over a given nominal design—that is, that one can directly learn how manufacturing (or other) variability is likely to arise given a target (i.e., nominal) design. This is a natural way of model uncertainty, since it goes directly from the \"as designed\" part to the \"as made\" part, and the properties of the generator can be usefully interrogated.\n",
      "\n",
      "The paper itself uses a standard InfoGAN setup with a proposed weight sharing scheme for the \"nominal\" and \"fabricated\" shapes, and then uses the trained generators for Bayesian Optimization in both the standard and robust setting. It tests the model on airfoil and metasurface design examples, showing that, perhaps as expected, the robust designs possess higher performance than standard designs when subjected to manufacturing certainty. In addition, the paper provides a dataset of comparisons designs (nominal, fabricated) that can spur further developments along these lines for the community. The paper is well executed in the target scope for the workshop and has clear relevance to the workshop outcomes and goals; thus I think this is a good fit for this venue. One minor concern that the authors can consider as they move this work forward after the workshop is that, as written, the figures only compare the results in the standard and robust conditions for the *proposed GAN model* and not with respect to another compelling alternative (perhaps simpler) model or existing approaches to robust design. For this to be of wider archival use, you would need those comparisons, though for workshop discussion I think the scope and relevance of the workshop paper is fine as is.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its approach to using generative models for design under uncertainty and its novel idea of modeling uncertainty as a conditional distribution over a given nominal design.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Well written paper for GP based system ID for optical fiber communication networks\n",
      "This paper presents a GP approach to create a data-driven emulatorof a detailed physics optical fiber communication network simulator. The GP approach naturally accounts for parameter uncertainty and serves as a robust surrogate model that can be used for parameter estimation based on observations. This is well-motivated problem. \n",
      "Some suggestions/clarifications:-         \n",
      "- Clarification on how expensive the SSFM approach is to create the dataset\n",
      "- Impact of synthetic noise on parameter estimation, specifically comment on the trade-off between dataset size and the maximum underlying noise that the estimator can handle.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper on GP based system identification for optical fiber communication networks, specifically addressing the clarity of the SSFM approach's computational cost in creating the dataset and the impact of synthetic noise on parameter estimation.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review of Gaussian Process-Driven History Matching for Physical Layer Parameter Estimation in Optical Fiber Communication Networks\n",
      "This paper has demonstrated a GP-driven history matching (HM) approach for parameter estimation/calibration at the physical layer of a optical fiber comm network. The authors have laid out the motivation of this problem well and they have shown that this approach can yield a high accuracy in estimation with a low data requirement. \n",
      "Pros: a suitable application of GP-based HM in parameter estimation; algorithms are clearly described in detail for reproduction by a practitioner. \n",
      "Cons: Generally GP-based approach fails to scale with dimension. It is not clear from the paper how this approach would perform regarding accuracy and data requirement when the parameter space is high dimensional.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper on Gaussian Process-Driven History Matching for Physical Layer Parameter Estimation in Optical Fiber Communication Networks, focusing on its suitability for parameter estimation, clarity of algorithms, scalability with dimension, and performance in high-dimensional parameter spaces.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting work\n",
      "The paper proposes a new Grassmanian manifold based shape representation for airfoils. The authors suggest that such a representation may be more conducive to AI/ML algorithms. They also show the advantages of Grassmanian representations over CST, the current state of art representations for airfoils.\n",
      "\n",
      "Pros:\n",
      "1. The proposed representation is intuitive and well motivated for airfoil shape representation.\n",
      "2. Fig.3b shows that the compressed representation shows that Grassmanian representations are similar to a mixture of Gaussians whereas the prevailing CST representations are more discrete spaces. This shows some advantages of the representations for gradient based optimization. \n",
      "3. The paper is well written and presents useful comparisons to illustrate the advantage of the proposed model.\n",
      "\n",
      "Cons:\n",
      "1. The paper could do with a clear application of an AI/ML task to evidence the claims.\n",
      "\n",
      "In summary, the paper appears to be a good addition to the workshop and will be of interest to the community.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed Grassmanian manifold based shape representation for airfoils, its comparison to the current state of the art representation, and its potential advantages for AI/ML algorithms.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review for the novel Grassmannian Shape Representations of Aerodynamic Applications\n",
      "Summary: this paper presents a novel airfoil shape design method based on data-driven techniques. Specifically, the authors proposed a novel representation of shapes which decouples affine-style deformations from a rich set of data-driven deformations over a submanifold of the Grassmannian. By comparing the principal geodesic deformations and consistent blade deformations with the traditional affine deformations, data-driven techniques show the critical efforts on representations and parameterizations of airfoil design problems in aerospace domain. This proposed method is very interesting to apply data-driven techniques for complex airfoil shape design. This work can provide some useful insights to the aerospace area on the airfoil shape design. The work is easy to follow and well written. While I have a couple concerns in mind. First, though data-driven techniques may provide better solutions, how practical is it when these are applied to real design problems? Since affine transformations are simple and easy to be implemented in practice. The author should discuss the difference in the paper. Second, how complex is the Grassmannian shape representations in theory? Though the author have shown clearly the derivation in the work, it would be better to see some complexity analysis in the paper.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the practicality and complexity of applying data-driven techniques for airfoil shape design in the aerospace domain, as presented in our paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The authors have presented a GAN-based cloning strategy that helps in reducing the probability estimation variance for rare events. An optimization problem is solved to control the disturbance induced by cloning on the density function.\n",
      "The advantages of GAN-based cloning strategies over random cloning have been clearly demonstrated, which is a strong point of novelty and significance of this work.\n",
      "\n",
      "Some comments/questions regarding the approach:\n",
      "1) Could you elaborate on how the hyperparameter of the swarm optimization are chosen that ensures the proximity of the clones to the parent realizations?\n",
      "2) The authors have noted the large data requirement for the generative model. In case the generative model is not well trained under data limitations, what effect does that have on the optimization step? Is there a way to update the generative model sequentially during the optimization for an iterative improvement?\n",
      "\n",
      "Overall, the work is of high quality and has great potential for growth and significance in the field.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate our paper, specifically addressing the effectiveness of our GAN-based cloning strategy in reducing probability estimation variance for rare events and any potential limitations or suggestions for improvement.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A GAN based improved on rare event estimation methods.\n",
      "This paper primarily concerns methods for reducing the variance in importance splitting-based probability estimators in the context of rare events. The paper argues that the standard strategy in Genealogical importance splitting—random splitting—can fail in cases where the probability distribution has the type of degeneracies seen in rare event distributions. To get around this, the paper proposes generating perturbations instead via a GAN. Specifically, the method builds upon Genealogical adaptive multilevel splitting (GAMS) which samples small perturbations from a normal distribution ($\\eta$). This paper instead substitutes $\\eta$ with conditional GAN-generated samples. \n",
      "\n",
      "Overall, this paper fits the scope of the workshop and presents some interesting ideas that could benefit discussion at the workshop. The background and motivation were well explained and the experiments were sound and easily reproducible using known examples. My only concerns, though these are minor for a workshop paper and are just suggestions for if the authors take this work further forward are: (1) It would have been nice to see this applied to a more design or manufacturing-oriented example, rather than the KSE example given, and (2) the paper only compared the KSE and KSE+GANISP method—are there other competing approaches that this method would be benchmarked well against?\n",
      "One minor technical notes of possible future interest to the authors: The optimization is Equation 7 uses PSO to match samples in the latent space coordinates. You could consider in future work either (a) backpropagating directly through the generator to minimize Eqn. 7 or (b) investigating bi-directional maps between $z$ and $\\xi_{parent}$ such as normalizing flows or autoencoder type models.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed method of using a GAN to improve rare event estimation methods, including its background, motivation, experimental results, and potential applications.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Nice new method for developing deep surrogate PDE solvers in a data-efficient manner\n",
      "The paper proposes a natural approach for improving sample (data) efficiency in deep surrogate PDE solvers. The high level idea is to use two spatial scales (first train a \"low-fidelity\" model and use its outputs as side information for a final, high fidelity model); this in combination with an active learning strategy leads to data reductions of upto 10x.\n",
      "\n",
      "The paper is nicely written and the topic is timely.\n",
      "\n",
      "Points of feedback: a) consider validating on more challenging complex systems. b) why only 2 scales? is there room for an extension to a hierarchy of coarse-to-fine mappings (analogous to multiresolution analysis).\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method for developing deep surrogate PDE solvers in terms of its sample efficiency and potential for extension to a hierarchy of coarse-to-fine mappings.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Coarse-to-fine physics informed mapping, promising results\n",
      "This paper presents a method (PEDS) to construct physics informed surrogate model using a coarse to fine framework where a NN is used to map the fine input to a 'generated' coarse input which is then combined with a coarse version of the fine input and fed to a coarse physics based solver. The NN + combination weights is trained end-to-end with the coarse solver. The method, though similar to neural and coarse-to-fine space mapping methods (except for combination of generated coarse and coarse version of input, which can have different dimensionalities), is shown to perform significantly better, especially when coupled with active learning. \n",
      "\n",
      "The results would be strengthened if the comparison to SM was with a dimension 1100, the same dimension that is learnt by the NN since PEDS with generator only gets pretty close to PEDS as per Table 1 (perhaps within error bars?), so the improvement could just be larger embedding dimension. Also, section numbers are missing in reference to appendix.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the presented method of constructing a physics informed surrogate model using a coarse to fine framework and its performance compared to other methods.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Solid paper\n",
      "The paper proposes a method for anomaly segmentation - a problem widely observed in manufacturing. For that purpose, they leverage hard augmentation, self-supervised learning for generation, and a discriminator for anomaly detection. Anoseg provides promising results when compared to existing methods. \n",
      "\n",
      "Overall, the paper is clearly written. However, the full end-to-end flow of the pipeline is hard to follow from the figures and the main text. I personally found the abstract provides a clear overview of the entire flow. I would suggest authors to include/reiterate the training/testing flow in the main text, as well as to expand figure captions,  to make the paper easier to follow.\n",
      "\n",
      "Authors should include recent relevant works on novelty detection/generation/anomaly segmentation using deep generative models,  for example (1) \"RaPP: Novelty Detection with Reconstruction along Projection Pathway\", ICLR 2020; (2) \"Toward A Neuro-inspired Creative Decoder\", IJCAI 2020; (3)\"DFR: Deep Feature Reconstruction for Unsupervised Anomaly Segmentation\", arXiv:2012.07122.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the clarity and comprehensibility of the paper, including the flow of the proposed method and the inclusion of relevant works in the field of anomaly segmentation using deep generative models.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Conceptually clear paper with convincing results. Additional details will make paper easier to follow\n",
      "This paper discusses a method for anomaly segmentation using ideas from multiple fields, including hard augmentation to generate artificial data with anomalies, adversarial training for improved generalization, and coordinate channel concatenation to learn positional features. The authors compared their results to several state-of-the-art methods on a benchmark dataset and demonstrated that their methods outperformed other baselines and were significantly more robust to various thresholding values. The overall concept is clearly presented at a high level and the results shown are also convincing and would be significant, since the challenge of obtaining sparse anomalous data, can be circumvented. A couple of things which can be improved upon are:\n",
      "\n",
      "The section on coordinate concatenation is not very clear and Figure 4 is not very informative as well. Additional descriptions on this section (maybe in the appendix) will make the paper easier to follow\n",
      "\n",
      "It is also not clear to me what the discriminator during the training phase and the anomaly detector during the testing phase takes as input. During the testing phase, how is the fake data generated? Is it using the generator? Overall, a more descriptive section detailing the flow of data during training and testing will be helpful.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the clarity and comprehensiveness of the paper, including the presentation of the concept and the results.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Differential property prediction\n",
      "Authors use XGBoost and MLP to predict property differences for different material pairs. While the paper is for most part well written, I am not convinced of the motivation, novelty, and experimental setting. The current problem can be handled using a learning to rank model, for which one can use simple (such as logistic regression) to complex (DNN) model) - an area that has been widely studied. Second, it is not clear how many samples were used for training/testing and what is input dimension. The number of training/test samples are 15/5 as reported. Then the paper states \"Material properties were measured for samples obtained from (on average) 10 locations along the length of an ex- truded tube.\" Does that mean that for each experiment there were 10 samples generated? Even then,  it is not clear how authors ensure that the XGBoost or a 3 layer MLP does not overfit and how do they handle curse of dimensionality.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the motivation, novelty, and experimental setting of our paper, specifically addressing the use of XGBoost and MLP for predicting property differences in different material pairs, the potential use of learning to rank models, the number of training/test samples, and how we handle overfitting and the curse of dimensionality.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Not fully convinced of the motivation of the approach, but well-written paper.\n",
      "This paper provides the differential property classification framework (DPC), which converts the regression into a classification problem. The author proposes labeling three different classes based on the difference of two input processing parameters and verifying their method on AA7075 tube properties. \n",
      "\n",
      "The main concern of this paper is their justification of converting into a DPC model rather than a naive regression problem. The authors claim that \"classification problems often require fewer data to achieve an acceptable level of accuracy than regression problems do\"; however, this statement has no guarantee by just considering the dataset following basic linear models. Furthermore, the author will need to provide more systematic approach to support their argument since this is the primary motivation for leveraging the DPC model. \n",
      "\n",
      "Furthermore, in the section \"the DPC Framework and Model,\" the authors give an example \"if two samples have a max load of 1739.4kg and 1739.9kg respectively, we might not consider them different from the standpoint of this material property\" to support to use DPC. However, if the choice of $t$ needs to be large enough as a hyperparameter, I do not see the apparent motivation of converting the regression problem to a classification problem again. \n",
      "\n",
      "Still, I see the paper's topic fits into the workshop, and I give the rating marginally above the acceptance threshold.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the justification for converting the regression problem into a classification problem using the differential property classification framework (DPC).\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Meta-review\n",
      "The paper presents the system description of Team ÚFAL for the CMCL 2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior. The authors present a range of model comparisons for eye-tracking prediction. As pointed out by the reviewers, the paper has potential but requires some improvements. The descriptions should be more precise, especially regarding the motivation of the chosen model architectures and the discussion/analysis of the results.\n",
      "\n",
      "We urge the authors to take the feedback from the reviewers into account and to improve their paper for the camera-ready deadline.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its system description for the CMCL 2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior, focusing on the clarity of the model architectures and the analysis of the results.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "High potential, but further work is needed\n",
      "The paper describes the system proposed for the CMCL2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior, and the different architectures implemented and compared by the Team ÚFAL.\n",
      "\n",
      "**Pros**:\n",
      "interesting approach, the different results of the various systems implemented and compared have a high potential in explaining both possible psycholinguistic insights and the computational models' natures.\n",
      "\n",
      "**Cons**:\n",
      "the paper is generally not precise enough. In particular: 1) no reason for the different architectures is provided, 2) the results are only reported, but not analyzed deep enough (i.e., the study lacks attempt in finding psycholinguistic-related explanations for the different performances)\n",
      "\n",
      "**General suggestions**:\n",
      "1) Give a justification for each different system (i.e., sys1, sys2, CWR, classifier, whole, first, mean, sum), that is, why you tried and compared these approaches.\n",
      "2) collect the tables in an Appendix to have more space for results discussion\n",
      "\n",
      "\n",
      "Minor\n",
      "\n",
      "Introduction:\n",
      " - “have also shown state-of-the-art performance on cross-lingual understanding tasks”, insert at least one reference to a shared task or a study on cross-lingual understanding.\n",
      "- reference to Huggingface\n",
      "\n",
      "Experiments:\n",
      "- “All systems under the System-1/2 label were further trained as a BERT (bert) based system or a XLM (xlm)”: labelS\n",
      "\n",
      "Results:\n",
      "- 4.1: “However, it should be noted than 12 out of the first 20 best performing models”: noted THAT\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the provided information, focusing on the justification for the different system architectures and the depth of analysis in the results section.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Potentially informative contribution, but missing discussion of results\n",
      "This paper presents the system description for a contribution to the CMCL 2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior. The authors propose to tackle to task using pretrained language models and performed a systematic study of the effects of model (mBERT vs. XLM), context information, input representation, lexical features, and fine-tuning.\n",
      "\n",
      "# Pros\n",
      "\n",
      "- The authors carried out a systematic study of a range of different model configurations for the task\n",
      "- Different contributions to final performance are analyzed using an exhaustive grid-search\n",
      "\n",
      "# Cons\n",
      "\n",
      "- Figure 3, 4, 5: The x-axis label and ticks are not very informative. What are the different models? All possible model configurations? If yes, which configuration is which index? This information is crucial in order to allow the reader are more fine-grained interpretation of the results.\n",
      "\n",
      "- The results should analyzed for statistical significance. This is especially important for cases with only marginal differences, as for example the comparison between BERT and XLM (Section 4.2): Here, the difference in MAE is probably not significant.\n",
      "\n",
      "- The results are not discussed in relation to previous approaches for the task (especially regarding work on the challenge from 2021). In order to highlight the significance of the work, the authors should point out which results agree with previous findings, and which are novel.\n",
      " \n",
      "- The performance of the best model is only marginally better than the mean baseline as reported in the challenge (MAE 5.72 vs. 5.73) and substantially worse than the mean baseline taking into account the target language (MAE 4.27). The authors do not discuss the performance of their models with respect to this baseline. It would be interesting to analyze why even the best of all 48 different models perform that poorly. Is it because of the high variance of feature values between the languages? Would these models perform better if they were trained and evaluated only on one language?\n",
      "\n",
      "## Minor\n",
      "\n",
      "### Abstract\n",
      "- effects: affects\n",
      "- lesser: smaller\n",
      "\n",
      "### Introduction:\n",
      "- Missing reference for “Huggingface”\n",
      "\n",
      "### Results:\n",
      "- Table 2 &3: Wouldn’t it be more infromative to report scores for the best performing model, instead of average over all tested models?\n",
      "- The results presented in Figure 1 and 2 could be presented in Tables, as they show only 4 and 2 data points. This would save space and make the results more readable.\n",
      "\n",
      "- Tables 6, 7, 8, and 10 are not at all mentioned in the text. If the results are not relevant, they can probably be removed?\n",
      "Rating: 4: Ok but not good enough - rejection\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the strengths and weaknesses of our paper on the system description for the CMCL 2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior, focusing on the systematic study of different model configurations and the analysis of contributions to performance.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Very well described details of the working system\n",
      "## Summary\n",
      "\n",
      "This paper describes the system of NU-HLT for the CMCL 2022 shared task. The system, inspired by previous works in speech recognition, uses a novel preprocessing step involving the transformation of words to a global vector space using IPA. Next fourteen features were then extracted from the transcriptions. The features included features like length and frequency of words and language-model based features in the form of different n-gram based statistics. Psychologically-motivated features in the form of imageability and concreteness were also extracted. Finally, information theoretic features in the form of surprisal was extracted for the systems. Using WEKA, four ML algorithms ( Linear regression, MLP, Random Forest and k-NN) were used to train the systems for predicting FFDAvg and TRTAvg features. Additionally, top 50% of the predictors are identified using their correlation with FFDAvg and TRTAvg.\n",
      "\n",
      "## Reasons to accept \n",
      "\n",
      "* The system description is very clear, concise and informative. All the details about the features, experiments and hyperparameters are mentioned.\n",
      "* The idea of transforming the raw words into IPA is novel.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the clarity and informativeness of the system description in my paper, as well as the novelty of the idea of transforming raw words into IPA.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Good descriptions of a working system\n",
      "### Summary\n",
      "This paper describes the NU-HLT system in CMCL 2022 shared task. This system is inspired by both classical and recent previous works in speech recognition systems. First, the raw terms are transformed into a global shared space using IPA. Then, some features, including the frequency, length, N-gram, and information-theoretic features are extracted. Specifically, there are two psycholinguistically-motivated features: imageability and concreteness. Four ML algorithms from WEKA (LinReg, MLP, RF, kNN) are used to train to predict the FFDAvg and TRTAvg scores. Additionally, top predictor features with their correlation coefficients are identified.\n",
      "\n",
      "### Reasons to accept\n",
      "- The description of the system is clear. The hyperparameters including learning rate and the number of iterations are reported, allowing easy reproduction of the results.\n",
      "- The idea of transforming into IPA turns out to be novel and effective for predicting the FFDAvg and TRTAvg tasks.\n",
      "\n",
      "### Reasons to reject\n",
      "I see no serious issues with this paper.\n",
      "\n",
      "### Comments\n",
      "- The reporting of some results could be improved. E.g., in Table 1, there are many mentions of `k`, `m`. What do they mean?  \n",
      "- Table 2: highest correlation coefficients. Do you mean \"highest absolute correlation coefficients\"? Some numbers are negative there.  \n",
      "- Probably an additional feature selection procedure can be useful for further improving the predicting performance.\n",
      "- Reference: Some entries have urls, but the remaining do not. Recommend adding (or removing) urls to all entries to keep the style consistent.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the clarity of the system description, the novelty and effectiveness of the IPA transformation, and the reporting of results and correlations.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting idea and reasonable experiment results\n",
      "This paper proposed an interesting idea to learn the Tokenizer/Vocabulary for federated language models. The previous word-level tokenizer/vocabulary can be potentially generated by the following methods: (1) use a public dataset, which may have distribution shift compared to the targeting task; (2) directly collect from target task, which may cause privacy concern; (3) use private heavy hitter to directly collect from target task, which does not seem to provide desirable privacy utility tradeoff. This paper proposed to train a sub-word language model with differentially private federated learning from the targeting task, and then use the trained model to generate/sample words to build the word-level tokenizer. Experiments on stackoverflow, reddits with wiki data as extra public dataset show the effectiveness  of the proposed method. \n",
      "\n",
      "In general, I think the idea is interesting. The paper is well written, technically solid, and the experiments seem to make sense. I think the draft can be further improved by clarifying the following\n",
      "(1) Why do we still want to sample a word-level tokenizer if we can train good models with sub-word tokenizer?\n",
      "(2) I cannot get the intuition why the proposed method can be better than private heavy hitters. Could the authors provide more intuition and highlight it in experiments?\n",
      "\n",
      "The authors may also be interested in the following paper and blogpost that show how to get DP in FL in practice:\n",
      "Practical and Private (Deep) Learning without Sampling or Shuffling https://arxiv.org/abs/2103.00039\n",
      "Federated Learning with Formal Differential Privacy Guarantees https://ai.googleblog.com/2022/02/federated-learning-with-formal.html\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method for learning the Tokenizer/Vocabulary for federated language models and its experimental results.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review\n",
      "This paper proposes a federated learning framework to train a tokenizer while it does not require additional privacy budget in differential privacy. Training the tokenizer is an important part of learning a language model (e.g., Transformer and BERT), but to my best knowledge, it is the first work to study how to train the tokenizer in federated learning setting. \n",
      "Although the first two contributions (i.e., 1) performance degradation from training with a different distribution and 2) sub-word tokenizer eliminates the out-of-vocabulary problem) are quite obvious, I appreciate this work and advocate accepting the article in this workshop to discuss further. Here are some of my concerns:\n",
      "1.\tI am confused about the system and privacy model, especially how public (Wiki) and private (Reddit or StackOverflow) dataset is distributed over the server/clients. The authors assume that stale tokenizer is trained with the public dataset with a certain privacy budget. However, if the public dataset is utilized to train the model, why should differential privacy be applied? In addition, who generates dataset by utilizing the stale (or old) tokenizer and who update the model embeddings? Clarification about these questions from the FL perspective can improve the paper.\n",
      "2.\tIn experiments, it would be better to highlight the paper’s contribution if comparing the two settings in the same privacy budget: 1) proposed scheme (i.e., train old tokenizer with DP and train the new tokenizer without additional privacy budget) and 2) directly train the tokenizer based on private dataset in private FL with the same privacy budget.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed federated learning framework for training a tokenizer in the context of language models, specifically addressing the system and privacy model, as well as comparing the proposed scheme to directly training the tokenizer based on private dataset in private federated learning.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review\n",
      "This paper provides a novel method on training a tokenizer along with the language model privately in a federated learning setting. By utilizing the post-processing theorem of differential privacy, the authors claim that the proposed method satisfies DP without additional privacy cost on training the tokenizer. Empirical results show that the proposed method outperforms heavy-hitters algorithm both in terms of privacy and utility.\n",
      "\n",
      "In general this paper is well written, with enough background knowledge explained for readers to understand. The motivation is also clear and the algorithm description makes sense. Here are some comments I have to improve the work:\n",
      "- The authors should clearly clarify what type of privacy the proposed method is protecting. It seems that client-level privacy is enforced and a trustworthy server is assumed. I feel it is important to explicitly state this so that it is clear where the clipping and noise is happening in the FL algorithm.\n",
      "- It seems from that the proposed method outperforms heavy hitters algorithm even omitting the extra privacy budget induced by the latter. Could the authors provide the exact \\epsilon and \\delta for the heavy hitters algorithm? Alternatively, could the authors show the utility performance difference given the same privacy budget, including the separate privacy budget, in order to see how much the proposed method outperforms the former.\n",
      "- There are two minor questions during training a sub-word tokenizer: 1. How does it encode the word when there are multiple sub word combinations? Does it simply search for the one that appears earliest in the dictionary? 2. When updating model embeddings with sub-words, it doesn't seem to be a bijection: different combinations of subwords could result in the same summation, causing words with different semantic meanings to be mapped to the same embedding. Could the authors explain whether this will cause problem to the proposed method?\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the clarity of the privacy protection measures and the utility performance of the proposed method in training a tokenizer along with a language model in a federated learning setting, compared to the heavy-hitters algorithm.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Reasonable idea, good results, but more work needs to be done before this can be used in practice\n",
      "Thanks for the submission! I enjoyed reading this paper. The goal of this paper is to improve the tokenizer using the samples matching the real distribution of the data without incurring an additional PFL budget. The basic idea is to start with a tokenized from a public dataset, which might not match real data, and then improve that tokenizer using samples obtained from the trained model. After that, replace the old tokenizer with the new one and repeat this process. Evaluations show good results on Reddit and StackOverflow datasets. \n",
      "\n",
      "1. To apply it to real-world use cases, it’s a bit unclear when we should start sampling the trained model and using the new tokenizer. Experiments shown in Section 5.4 seem to suggest that there is no easy answer, and it might depend on the underlying dataset and algorithm. Given that, any suggestions on how ML practitioners can adopt this? I assume they cannot try multiple options and pick the best one because that would require an additional budget?\n",
      "2. The experiments seem to be conducted with a fixed budget. I am curious to learn how the proposed algorithm compares with baselines if we got the chance to increase the budget to hit a target perplexity?\n",
      "3. The evaluation results look good. I am curious if the improvements can also be proven in theory as well. And is it possible to quantify the improvements before training? \n",
      "4. Are there any limitations of the proposed algorithm?\n",
      "5. IIUC, before replacing the old tokenizer with the new one, we will need to pause the current process, and use samples from the model to train the new tokenizer. In practice, how long does it take to bring the new tokenizer to a reasonable state, and will this delay be an issue? \n",
      "6. Is it viable to allocate some dedicated budget to train the tokenizer, say 20%? Is there any estimation of how the proposed algorithm compares to that?\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper\n",
      "====================================================================================================\n",
      "Please evaluate the proposed algorithm in terms of its practical applicability, potential limitations, and the impact it may have on training time and overall performance.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The authors propose a method to train a 'matched' tokenizer alongside the decentralized and private federated learning of an NLP model over the client data.\n",
      "The authors propose a method to train a 'matched' tokenizer alongside the decentralized and private federated learning of an NLP model over the client data. In particular, the authors consider the problem of having tokenizer for the NLP model that is reflective of the data on the clients that participate in the decentralized federated learning process. When the tokenizer is not matched with the private client, such as when the tokenizer is trained on a public dataset, the authors demonstrate a significant drop in accuracy of the trained model, compared to when using an oracle tokenizer i.e. when the tokenizer is trained on the client data itself. While having a matched tokenizer is essential, training tokenizer on the private client is quite challenging and can potentially cause additional privacy leakage over the existing leakage from DP based FL. Hence, the authors propose a new protocol that samples new datasets for tokenizer up dation using the language model trained using the DP based FL itself. This additional step is integrated into the existing federated learning protocol, and the authors claim that there is no additional privacy leakage. Experiments with many settings are provided that demonstrate that the proposed schemes can match the language model performance of the federated training with oracle tokenizer.\n",
      "\n",
      "While the problem considered is interesting and relevant, and the algorithm also has some novelty, the claim that there is no additional privacy leakage is not proved formally. In particular, when the tokenizer is modified during the private federated learning, it essentially splits the training into different stages with their own DP guarantees. I don't think the post-processing guarantee of DP applies in such a scenario. A composition analysis to bound the DP privacy budget is needed.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method for training a 'matched' tokenizer alongside decentralized and private federated learning of an NLP model, specifically in terms of its effectiveness in maintaining accuracy while preserving privacy.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Adapting intrinsic gradient compression in federated settings\n",
      "Summary:\n",
      "A gradient compression technique for federated settings based on the intrinsic dimension concept is proposed. Three variations of the technique are implemented and their tradeoffs in terms of parameter exploration, federation performance and uplink and downlink cost are presented.\n",
      "\n",
      "Strong and Weak Points:\n",
      "\n",
      "(S1) Interesting adaptation of intrinsic dimension in federated learning settings for compressing clients' (local) gradients.\n",
      "(S2) Extensive empirical evaluation against different baselines and on multiple domains.\n",
      "(S3) Promising insights to employ intrinsic gradient compression techniques against inference attacks.\n",
      "\n",
      "(W1) Presentation of preliminaries, background, gradient compression and approximation, and algorithms can be improved.\n",
      "\n",
      "Detailed comments:\n",
      "(W1) In section 1, it would be better to cite the original intrinsic dimension work the first time it is discussed. In section 2 it would be better to create a table with all the notations you use throughout your work for faster notation indexing. Section 2.2 \"the data is averaged\", please change to \"gradients or weights are averaged\". Related Work: Federated Learning, please add some discussion on recent works on weight and gradient pruning in federated settings (e.g., [1], [2]). Please elaborate more on the concept of reconciliation; it is not clear what it is and what its challenges are (maybe pointing to specific lines of the algorithm will be helpful). In your time-varying gradient compression it is not clear why we need twice the bandwidth for downlink and where do the $\\theta^{final}$ stems from. For the choice of the compression matrix, why do you need an entire Dxd matrix and not consider the model parameters as a collection of smaller dense matrices? Figures 1 and 2 need to come before table 2 since they are discussed first in the paper. Also you compare against LocalTop-K but you never presented or discussed the technique in the paper.\n",
      "\n",
      "Please be consistent with your notation, for instance in the static intrinsic gradient compression algorithm why use $\\mathcal{L}$ as loss. In section 2.1 wouldn't it be more appropriate to replace $\\theta_2$ with $\\theta^\\prime$; also does it hold that $T < L$? Moreover, why refer to $\\ell$ as a task when it has already been defined as loss, maybe another symbol could resolve this. A couple notations and concepts used in algorithm 1 are never presented in the paper (e.g., $A(\\sum_{t-1}$) - no need for parenthesis, $z_j$, sketches). In section 3, shouldn't be $A\\theta^\\prime + \\theta_0$ instead of $A\\theta^\\prime$ in the subscript of function f in the first line of equations? Also, how did you derive the A transpose multiplied with the gradient transpose from the previous line and in equation (5) why is $A\\theta_{t+1}^\\prime$ equal to $\\theta_{t+1}$?\n",
      "\n",
      "\n",
      "[1] Jiang, Yuang, Shiqiang Wang, Victor Valls, Bong Jun Ko, Wei-Han Lee, Kin K. Leung, and Leandros Tassiulas. \"Model pruning enables efficient federated learning on edge devices.\" arXiv preprint arXiv:1909.12326 (2019).\n",
      "\n",
      "[2] Bibikar, Sameer, Haris Vikalo, Zhangyang Wang, and Xiaohan Chen. \"Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better.\" arXiv preprint arXiv:2112.09824 (2021).\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the proposed gradient compression technique for federated settings based on the concept of intrinsic dimension, considering its strengths and weaknesses, empirical evaluation against baselines, and potential applications in defending against inference attacks.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Adopting a classical sketching idea into federated learning applications\n",
      "This paper proposes to use a classical sketching idea in federated SGD-like algorithms to improve the communication efficiency of federated learning algorithms. The proposed method has been used widely in centralized distributed SGD with good efficiency. Thus I am a bit concerned about the novelty of the paper.\n",
      "\n",
      "Conceptually, I believe the sketching idea can also be adopted on top of federated averaging, i.e., conduct $A^\\top A$ over the model updates instead of gradient updates. How does that variant work? Moreover, the error feedback scheme seems to be always helpful for gradient/model compression, does it also help the proposed method?\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method of adopting a classical sketching idea in federated learning algorithms to improve communication efficiency, considering its potential novelty and the possibility of applying the sketching idea on top of federated averaging. Additionally, discuss the potential impact of the error feedback scheme on gradient/model compression in the proposed method.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The authors propose a set of communication-efficient federated learning algorithms that are based on the prior idea of intrinsic dimension in theoretical machine learning.\n",
      "The authors propose a set of communication-efficient federated learning algorithms that are based on the prior idea of intrinsic dimension in theoretical machine learning. Essentially, it has been known in theoretical ML that in the overall parameter space of the ML model, there is an intrinsic subspace, with potentially much smaller dimension than the model parameter space, where optimization can be carried out. Exploiting this concept and related ideas on intrinsic dimension, the authors propose a set of three novel strategies that enables compression of updates communicated between the FL server and clients, reducing the communication load dramatically. The underlying idea is to use a projection matrix for compression at the clients/decompression at the server, so that both training and global update can be done in the model parameter space while communications can be done in the lower dimensional space. The first algorithm considers the projection matrix to be fixed throughout training, the other two consider different versions of variable projection matrices. Multiple experiments for NLP and vision tasks have been presented that demonstrate reasonable drop in accuracy even for very high (>1000x) compression rates.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed communication-efficient federated learning algorithms in our paper, specifically focusing on their effectiveness in reducing communication load and the impact on accuracy for NLP and vision tasks.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review of the paper\n",
      "This paper considers an important and timely problem in federated learning on knowledge graphs (KGs), especially developing an attack model which incurs privacy leakage in an existing work, named FedE, and proposing a new privacy-preserving embedding aggregation framework to protect the privacy against the attack.\n",
      "\n",
      "This paper proposed the attack model which can reconstruct original entities and relations of individual client based on the local embedding matrix, which is an important finding in Federated Knowledge Graph Completion from the privacy perspective. It empirically demonstrates the effectiveness of the attack with a simple 3 clients-model. Then, this paper proposed a relation embedding aggregation framework to reduce the privacy leakage while it also reduces the required bandwidth to achieve the target MRR.\n",
      "\n",
      "It is worth to discuss the proposed attack model and defense mechanism even though the reviewer has the following concerns. \n",
      "1.\tThis paper does not contain the system model of FedE and attack model in the main body. Before reading the Appendix C and D, I cannot capture the which information is communicated between the server and clients, which information is known to the server and colluding client, and how to reconstruct the private local information. It would be helpful to provide the system model (including definition of entity/relation embeddings and  local/global update equation, and … etc)\n",
      "2.\tIn addition to 1, it is unclear what is the global update equation based on the local relation embeddings in the proposed framework, FedR.\n",
      "3.\tThere are minor typos such as: 1) there is (?) in Appendix A 2) paris => pairs in Algorithm 1 in Appendix C.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed attack model and defense mechanism in the context of federated learning on knowledge graphs, and provide feedback on the clarity of the system model, the global update equation, and any minor typos or errors you may have noticed.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review\n",
      "This paper proposed a novel reconstruction attack method to infer the client's data utilizing the model updates in a knowledge graph setting. The proposed method achieves strong attacking accuracy on previous baselines. To overcome this, the authors further proposed a new method called FedR robust to the proposed reconstruction attack method. \n",
      "\n",
      "The method is interesting. The idea of sharing relation embedding rather than head/tail embedding for aggregation is novel and seems to effectively prevent exact inference of the user data. The experimental results seem strong and significantly outperform prior work on multiple benchmarks. Here are some of my concerns:\n",
      "- Rather than saying the proposed FedR is 'privacy-preserving', it seems that FedR is only robust to the proposed attacking method. There are a couple of things missing here: 1. How does the success rate of the attacking method transfer to the privacy level of the randomized algorithm to train KG? Could it transfer to any formal differential privacy guarantee? 2. How to evaluate the optimality of the attack evaluated in this work? Could there be stronger, defense-aware attack that could similarly break FedR? It would be great if the authors could provide additional details for these points.\n",
      "- Could the authors add a related work/background section to list relevant work on reconstruction attacks/FL on KG?\n",
      "- Could the authors add a clear algorithm description on FedR?\n",
      "- In the description of experiment, the authors claim each dataset is randomly split among clients? Does that mean the data are homogeneous among all the clients? In a typical FL setting, data are heterogeneous on each client. Could the authors add experiments on experiments under heterogenous data?\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate our paper, specifically addressing the following points: 1. How does the success rate of the proposed reconstruction attack method impact the privacy level of the randomized algorithm used in training the knowledge graph? 2. Can you assess the optimality of the attack evaluated in this work and discuss the possibility of stronger, defense-aware attacks that could break our proposed method?\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Good idea, but some inaccuracies\n",
      "I think overall, this paper would be interesting for the workshop, and authors have proposed an interesting approach. There are issues in presentation and claims which can be improved and fixed. Hopefully, discussions at the workshop can help authors gather more feedback and continue their work.\n",
      "\n",
      "\n",
      "Below are some comments which I hope authors will find useful to improve their work.\n",
      "\n",
      "It seems that authors are proposing to modify the FL setting, by assuming that server might collude with the clients. This is a modified definition of privacy for FL which is fine and interesting. However, in the abstract and introduction, authors seem to claim that they have found a severe privacy leakage for FedE method and they want to address that severe shortcoming. Contribution of this paper can be explained more clearly starting with the assumptions used in FL literature, FedE method, and authors' method.\n",
      "\n",
      "Statements like \"FedE is not privacy-preserving\" are meaningless without proper definition of \"privacy\". From authors' point of view, how many of the methods in FL literature can be considered \"privacy-preserving\"?\n",
      "\n",
      "Phrases like \"much more\" for communication efficiency seem to be overly vague.\n",
      "\n",
      "Function f(h,r,t) is not defined properly.\n",
      "\n",
      "It is not clear what authors mean by \"honest-but-curious\" server. If the server is honest why should we go through all these trouble to hide the data? Authors have to define what they mean by \"honest\" and how that affects their formulation.\n",
      "\n",
      "If a client is a traitor and shares the data with the server, why would it share only a percentage of its data and not all of it?\n",
      "\n",
      "Method is not presented in a coherent way. First, it is mentioned that \"To guarantee the data privacy in the FedE, FEDR adopts two main strategies\". Despite this guarantee, a paragraph later, it is mentioned that \"the server still can roughly infer the relation by comparing the uploaded relation embedding with the one stored...\". It is not clear what \"roughly\" entails here and how it can combine with the statements before. It sounds like authors do not have a clear definition of privacy in mind, are they are putting bandaids on various shortcomings that they consider. The word \"guarantee\" seem to lose its meaning.\n",
      "\n",
      "Figure 4 which provides the comparison with other methods does not depict the performance of proposed method. In the legend, proposed method is shown as a solid black line, but in the plot, there is no such line.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the reviewer's feedback, focusing on the clarity of the proposed approach, the definition of privacy, and the coherence of the method presentation.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review on \"Efficient Federated Learning on knowledge Graphs via Privacy-Preserving Relation Embedding Aggregation\"\n",
      "This work presents an extension of FedE, a recently proposed knowledge graph aggregation scheme in Federated Learning. Specifically, the authors tackle the privacy issue by aggregating relation embedding instead of directly aggregating the entity embedding.\n",
      "\n",
      "Although the idea is quite simple, it effectively addresses the privacy issue while maintaining the model performance. I appreciate this idea and advocate accepting the article in this workshop. I see a few things that can be improved as follows.\n",
      "\n",
      "1. The experimental settings can be improved. The number of clients is obviously too small. Federated Learning is a large-scale distributed learning paradigm. Considering the total number of entities in the benchmark datasets, the dataset can be distributed to more than 20 clients. If the number of clients is hundreds for example, would similar performance benefits still be available?\n",
      "\n",
      "2. Although FedE is the recently proposed representative work, comparing FedR to this single work does not provide useful insights. Additional comparisons to other works (especially referenced in FedE paper) will significantly strengthen the paper.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the experimental settings and the comparison to other related works, and provide a rating and confidence level for your evaluation.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Overall nice work analyzing different ways to scale federated training of transformers\n",
      "## Summary\n",
      "This paper primarily studies the effect of partial variable training, quantization, and their combinations to enable training large language models in a federated setup. These techniques allow training large language models in cross-device federated configurations. They show that quantizing the models before uploading and downloading can reduce training costs with marginal drops in performance. \n",
      "\n",
      "### Main Observations:\n",
      "- Model quantization before uploading from local learners is more effective than quantizing before downloading to the local learner.  \n",
      "- Partial variable training combined with quantization further reduces the training and communication load.\n",
      "- Transfer learning or pretraining can speed up federated training.\n",
      "\n",
      "## Suggestions:\n",
      "Overall, I like the paper's analysis of different options available for scaling up federated training for language models and the paper is well-written. However, it still lacks comparison with prior works and baselines. For example, an alternative approach to PVT could be model pruning. So, it would be nice to compare with model pruning baselines such as TPrune ([https://dl.acm.org/doi/10.1145/3446640](https://dl.acm.org/doi/10.1145/3446640)). \n",
      "\n",
      "Also, please clarify the following in writing:\n",
      "- How was tokenization done for federated experiments --- centralized or federated? Please clarify. \n",
      "- Do you exchange model parameters or the changes in parameters for upload and download? While this may be a minor detail, it could affect quantization performance.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the paper's analysis of different techniques for scaling up federated training of language models, including partial variable training and quantization, and provide suggestions for improvement.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Official Review\n",
      "**Summary Of The Paper:** This paper leverages several techniques for mitigating the communication and computation bottlenecks to train a Transformer in cross-device federated learning. They systematically evaluate partial model training, quantization, efficient transfer learning, and communication-efficient optimizers,\n",
      "\n",
      "**Strengths.**\n",
      "- This paper is easy to read and has good structure, and is complete and coherent.\n",
      "- The topic is interesting and important because the large transformer model has become mainstream in the NLP community. It is necessary to consider how to deploy this kind of large model in the client.\n",
      "- The design of experiments is sufficient and comprehensive.\n",
      "\n",
      "**Weaknesses.** \n",
      "- All the methods are general so it would be better to design a novel method. However, I think it is okay for an analytical paper.\n",
      "\n",
      "Overall, in my view, this is a high-quality paper.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper, focusing on its readability, structure, and the comprehensiveness of the experimental design.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "review\n",
      "**Summary**\n",
      "The paper studies cross-device federated learning for the problem of language modelling. The paper conducts a series of empirical studies to show that large and high-performing language models can be trained in the cross-device setting, with large Transformers partially fine-tuned through federated updates and quantized communication achieving very good performance. \n",
      "\n",
      "**Overall comments**\n",
      "The paper conducts a careful empirical study on how high-performing language models can be trained in the cross-device setting. While the techniques and methods employed in the paper already exist in the literature, the empirical results demonstrated in the paper has high practical value (and would therefore be considered as significant) to practitioners. The paper is therefore of high quality. The paper is also written clearly. I therefore recommend acceptance.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper on cross-device federated learning for language modelling, specifically focusing on the empirical results and their practical value.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Simple idea, strong empirical performance. Rigorous evaluation including interesting ablation analysis.\n",
      "## Strengths\n",
      "- Simple approach, trivial to implement\n",
      "- Strong empirical performance\n",
      "- Thorough empirical evaluation: multiple benchmarks (including skewed version of Sent140), ablation over token lengths and types of user-ids, performance of unseen users\n",
      "- Privacy preserving. Rand.All can be implemented locally with no privacy loss (Def. and Num. cannot, but they don't work as well)\n",
      "\n",
      "## Weaknesses\n",
      "- No comparison against some other popular FL personalization schemes (like Ditto). UserAdapter is the only comparison, while something like Ditto or pFedMe are more established\n",
      "- It is not clear why trainable user embeddings perform worse (it is very unintuitive, at least to me). Authors mention that \"coupling learning problems in both domains is useful\", but a deeper analysis might help. \n",
      "- Their intuition on why UserIdentifier outperforms UserAdapter (collaborative learning and personalization is happening simultaneously). I don't understand how UserIdentifier performs any collaborative learning. Assume UserA and UserB behave \"similarly\", and a method that does collaborative learning might learn this and exploit it. In UserIdentifier, A and B would get random ids - so no collaborative learning would happen\n",
      "- Large, over-parameterized models like RoBERTa-base or BERT-base are not practical in FL (on-device constraints). Would their scheme work in smaller models, where the embeddings are smaller and less over-parameterized?\n",
      "\n",
      "## Suggestions\n",
      "- Consider expanding to harder FL-NLP problems outside of sentiment classification (e.g, LM)\n",
      "- Does this scale to a large #users, say millions? As the #users increase, almost all token embeddings will be modified by some user?\n",
      "- An interesting setting would be running UserIdentifier in the same setting as UserAdapter: personalization as a separate task after global training\n",
      "- On 'unseen' users: Another interesting setting would be to run local run train + eval on unseen users (instead of just eval, as you do)\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its simple approach, strong empirical performance, thorough evaluation, and privacy-preserving nature.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "\n",
      "## Summary\n",
      "\n",
      "This paper proposes learning a personalized sentiment analysis model from the text by appending or prepending a user-specific string (termed \"UserIdentifier\") to the input text. Then a single transformer model is finetuned on data from all the individuals. Incorporating user identifiers help learn a better and more personalized model for each individual. The proposed method is compared with three other approaches --- finetuning with original data, finetuning with original data followed by prefix-tuning, and finetuning with trainable user identifiers. The authors justified their choice of selecting user-identifiers by appropriate ablation experiments. The \"UserIdentifier\" approach outperforms other baselines on Yelp, Sent140, and IMDB datasets. \n",
      "\n",
      "## Strengths:\n",
      "- Although the solution builds upon recent findings that demonstrate parameter efficient finetuning/few-shot learning by prompting with task-specific texts or introducing trainable input embeddings, the idea of introducing user-specific strings is interesting. \n",
      "- I appreciate that the authors discussed different ways to assign user-identifiers and tried to partially explain the best choice in Sec A.3 and 4.3.\n",
      "- The paper also studied generalization to new users briefly. Interestingly, the model performance is almost similar to finetuning with no user-identifiers (though slightly lower), thus providing personalization without hurting. \n",
      "\n",
      "\n",
      "## Scope for Improvement:\n",
      "- **Federated vs. Centralized Setups**: \n",
      "Since we are eventually interested in a federated setup and personalized models, one of the baselines would be training a model per user, which is missing. While this may not be parameter efficient, each user will train its model on their local machine saving massive communication costs and maybe using similar or compute. The authors should discuss this scenario in the paper at least.  \n",
      "- **Writing**:\n",
      "     - a. The main paper is mainly motivated by federated learning & need for personalized models, but the experiments are performed in a centralized setup which is ok. However, this is not clarified until sec 4. It would be nice to have this clarified in the introduction. \n",
      "     - b. Sec 4.3 last paragraph ignores the L parameter in the discussion. The overlap will be much less even with just L=2 and sample space=400.\n",
      "Minor: Table 4 is in the appendix. Either use a different numbering convention or add a small note in brackets that it is in the appendix. \n",
      "- **Trainable Embeddings**:\n",
      "It is counterintuitive that fixed prefixes outperform trainable embeddings, as Li & Liang (2021) and Hambardzumyan et al. (2021) show that it outperforms fixed prefixes. Even though the above references are not in the same context, ideally, more flexibility should help improve the model training. This raises the question if this can be explained by overfitting? Did the author compare training performance for these models? \n",
      "The authors argue in the paper that simultaneous adaptation of parameters hurts learning. Would further \"embedding only training\" of the \"UserIdentifier\" approach improve or maintain performance? \n",
      "\n",
      "### Refs:\n",
      "- WARP: Word-level Adversarial ReProgramming (Hambardzumyan et al., ACL 2021)\n",
      "- Prefix-Tuning: Optimizing Continuous Prompts for Generation (Li & Liang, ACL 2021)\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method by comparing it with other baselines and discussing the strengths and weaknesses of the approach.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "review\n",
      "**Summary**\n",
      "\n",
      "The paper proposes a data augmentation method to handle personalized prediction for text classification problems. \n",
      "\n",
      "**Overall comments**\n",
      "\n",
      "The method is simple and seems to work well on the toy problems studied in the paper. The experiments are adequate for a workshop paper (but can be improved to provide more insight into the performance). The writing is clear. The paper is on topic. I list drawbacks below.\n",
      "\n",
      "**Cons**\n",
      "- The paper compares different methods on simple datasets for the task of sentiment classification. To make the empirical study more compelling, one may consider additional tasks (language generation) and datasets (GLUE, table2text, dialog, summarization).\n",
      "- It's unclear how the method improves upon baselines with better pre-trained models, e.g., Roberta*-large*. \n",
      "\n",
      "**Other suggestions**\n",
      "- The method could be combined with federated learning. \n",
      "- The paper explores different ways to create the user-identifier in text format, but one could easily imagine the user-identifier being prompt embeddings directly -- randomly sample high-dimensional gaussians for each user as their prompt embedding.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please provide your evaluation of the paper and its proposed method for personalized prediction in text classification.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Effective method for conducting backdoor attack of federated NLP tasks\n",
      "This paper introduces a practical approach for injecting backdoor attacks into a federated learned model. The attackers only manipulate the embedding layers of a model for injecting the backdoor. Compared to the previously proposed backdoor attack on language models (where the attacker manipulates to change all layers' weights), the proposed attack is easier to inject and is harder to detect by the central server.\n",
      "\n",
      "Extensive experimental results indicate that the proposed attack is effective under various NLP tasks and transformer models. I'm convinced that the proposed attack is effective given the scales of the experiments.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of the proposed method for conducting backdoor attacks on federated NLP tasks in terms of its ease of injection and difficulty of detection compared to previous approaches.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting topic and the method can be further improved\n",
      "This work proposes a practical backdoor attack against NLP models in the Federate Learning scenarios by inserting malicious tokens in the word embeddings. The author demonstrates its effectiveness through many practical scenarios, e.g., large trigger tokens, etc. It would be better to explore inserting backdoor triggers in a more stealth manner, e.g., inserting incontinuous or dynamic backdoor triggers, inserting backdoor triggers without adding too many tokens besides the benign tokens. Since the attack method is adapted from CV methods, the robustness of the proposed method against potential defense mechanisms adapted from Image Classification tasks [1,2] should also be discussed.\n",
      "\n",
      "[1] Wang, Bolun, et al. \"Neural cleanse: Identifying and mitigating backdoor attacks in neural networks.\" 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019.\n",
      "\n",
      "[2] Guo, Junfeng, Ang Li, and Cong Liu. \"AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis.\" ICLR (2022).\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness and potential improvements of the proposed backdoor attack method in the context of Federated Learning for NLP models, considering factors such as the stealthiness of the backdoor triggers and the robustness against potential defense mechanisms.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "review\n",
      "The paper presents a new attack extension of the embedding attack on NLP models to FL. Instead of training to optimize the whole model the attacker only focuses on a small single embedding of an unpopular token. \n",
      "\n",
      "I really liked the idea and think that it has a good potential impact, however I have a couple of concerns:\n",
      "\n",
      "1. Motivation -- FL in NLP is motivated by a smart keyboard application and therefore language generation task. I did not understand motivation under seq2seq tasks, neither summarization nor translation seem like would be good candidates for FL as there are no privacy constraints. I can understand classification, but not on the news dataset (which is hardly private) but rather some toxicity dataset.\n",
      "\n",
      "2. Experiments -- some details on seq2seq task would be great otherwise it's unclear what task exactly gets evaluated (I assume it's a summarization task as it uses ROUGE but still not clear). \"Trigger range\" discussion is also complex as it wasn't introduced before. \n",
      "\n",
      "3. Novelty -- the backdoor attacks on embeddings exist in literature as well as backdoor attacks on FL. Seems like it's a trivial operation to apply one to another. I cannot see why 3.3 is novel as it's the core assumption in all other backdoor FL papers -- other participants contributions can be ignored when computing backdoored model update.\n",
      "\n",
      "In my opinion the key interesting part of the paper is that it can possibly evade norm-bound detection by modifying only a small model's embedding vector, however it has a very trivial way to defend -- simply check for norm updates of each embedding vector. \n",
      "\n",
      "Overall, I really like the idea but it needs more solid motivation and exploration.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper, focusing on the motivation, experiments, novelty, and potential impact of the proposed attack extension on Federated Learning for NLP models.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Simple and elegant approach to post-hoc error correction\n",
      "### Paper Summary:\n",
      "\n",
      "This paper focuses on improving GPT-3's performance post-deployment, without any retraining, via a growing repository of interactive user feedback. Through correcting GPT-3's misunderstanding of question intent via a key-value store of user questions and corrective feedback, the authors develop a system to edit prompts through such feedback from previously-asked, similar questions.\n",
      "\n",
      "Evaluating on 4 tasks (lexical relations, word scrambling, and 2 variations of ethics reasoning), the authors show that their method of maintaining a growing memory store coupled with dynamically injecting feedback into prompts is useful in improving GPT-3's accuracy over time.\n",
      "\n",
      "\n",
      "### Paper Strengths:\n",
      "\n",
      "This paper takes a simple but effective step towards post-deployment error correction. Given that retraining (or, sometimes even large scale finetuning) may not always be tractable, the authors' conceptual framework of a lookup table for previously committed errors is straightforward and task-independent. \n",
      "\n",
      "In addition, incorporating direct user feedback in future model interactions helps to improve interpretability of model output and the model's usability, given that small errors in intent understanding can be corrected post-hoc.\n",
      "\n",
      "\n",
      "### Paper Weaknesses:\n",
      "\n",
      "1. Evaluation of feedback: Given that the prompt is directly edited using feedback provided by users, it would be helpful to understand the model's sensitivity to the user feedback. For example, analysis of lexical sensitivity, robustness to noise in feedback, or other such analysis of user-provided feedback that did not aid accuracy/performance would help to understand the practical implications of using this framework with GPT-3. \n",
      "2. Evaluation of \"u\": Likewise, for more complex questions or tasks, it seems like a more thorough evaluation of the generated question intent (via something like a human evaluation study) would be useful. Given that this approach is using humans in the loop, robust evaluation of the model's “understanding” of the task and the sensitivity/role of user feedback would help contextualize the limitations or practical applications of the approach.\n",
      "3. Scalability: The key-value store (and thus the retrieval component) plays an instrumental role in the performance of the overall system design, but, to my knowledge, the paper does not include a discussion of the scalability of their approach. Given that the memory is simply expected to accumulate over time, this feels like an important dimension of analysis or discussion.\n",
      "\n",
      "\n",
      "### Overall assessment\n",
      "\n",
      "Overall, I think this paper is a nice step towards post-hoc correction of models with humans in the loop, and could be incredibly effective in certain practical settings.\n",
      "\n",
      "### Typos\n",
      "\n",
      "1. Line 176: add \"than the\"\n",
      "2. Line 428: \"improves\" --> \"improve\"\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness and contribution of the paper in improving GPT-3's performance post-deployment without retraining.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Solid paper with small writing issues.\n",
      "### Pros\n",
      "\n",
      "* The paper presents a simple method that works.\n",
      "* The proposed method does not require model re-training which would be expensive.\n",
      "* The proposed method supports a natural user-machine interaction.\n",
      "\n",
      "### Cons\n",
      "\n",
      "* One downside of the paper is that it only studies the GPT-3 model. It would have been interesting to see if the results apply to the open-source equivalents: GPTNeo and GPTJ.\n",
      "\n",
      "### Minor things\n",
      "\n",
      "* Lines 127, 163: The citations should not be in parenthesis, as the authors' names are part of the discourse.\n",
      "* Line 428: \"Does pairing GPT-3 with MEM-PROMPT improves\" - Typo. It should say \"improve\".\n",
      "\n",
      "### Issues with the references \n",
      "\n",
      "* When possible, please add URLs to the references as the template uses them.\n",
      "* Johnson et al. (2017) – Cites preprint instead of the article's peer-reviewed version.\n",
      "* Liu et al. (2021a) and Liu et al. (2021b) are duplicates of each other.\n",
      "* Liu et al. (2021c) is missing the ArXiv ID.\n",
      "* Marcus (2021) is missing the URL and the title is not clickable. The web page's URL should appear.\n",
      "* Mitchell et al. (2021) is missing the ArXiv ID.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the strengths and weaknesses of my paper, focusing on its methodology and contributions.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A generally strong paper with some weaknesses to be addressed\n",
      "The presented work proposes a straight-forward method for improving the performance of pre-trained LMs (PLMs) on a variety of tasks through corrective feedback. The feedback is first supplied by a (simulated) user and stored in a memory component. In the main experiments, such feedback contains information that is intended to correct the model's faulty reasoning, e.g. by elaborating on or clarifying the task that the user is expecting the model to perform. The feedback memory can subsequently be used as a source of additional information for new queries to the model, whereby corrective feedback is retrieved from the memory that was previously provided for queries that are most similar to the current one. The query and the retrieved feedback are subsequently combined with the task-specific prompt and given to the PLM as input, which has empirically been found to outperform baselines that either do no utilize the corrective memory at all, or employ a non-selective memory module. The experimental section includes lexical as well as ethical reasoning tasks, although the authors also describe the application of the proposed method to code-switched question answering and question answering with label feedback (as opposed to natural language corrections).\n",
      "\n",
      "Overall. the proposed method is compelling, easy to implement, and effective according to the provided experimental evaluation. The corrective feedback memory is a neat idea for leveraging and re-using user feedback in an efficient manner and could potentially be applied to many diverse tasks.\n",
      "\n",
      "There are some minor issues with the paper that should be corrected:\n",
      "- Line 180: The notation is confusing  - does x_i/j represent the input or the error? \n",
      "- Line 308: It would be appropriate to provide citation for Social Chemistry 101, as well.\n",
      "- Figure 3: Some of the example questions / templates are oddly phrased, e.g. \"on the lines of\" which should probably be either \"in the vein of\" or \"along the lines of\"? Could the authors clarify?\n",
      "- Line 379: I assume this should be \"cosine similarity\" rather than \"cosine distance\", as the latter with a threshold of 0.9 would be extremely permissive.\n",
      "- Line 385: Concatenation is not a gating function (while gating may be explored in the future, it is not part of the presented approach); relatedly, the breakdown of the approach in section 3.1. makes it sound more complex than it actually is and is detrimental to the paper's clarity (e.g. both the \"prompter\" and the \"combiner\" are simple concatenation steps and don't really need extra terminology attached to them).\n",
      "- Line 428: improves -> improve\n",
      "- Table 2: Should be positioned under 4.1.1 header and does not have to include the GROW-PROMPT row. \n",
      "- Figure 4: Should get a better caption, e.g. one that explains that the legend denotes the likelihood of feedback being drawn from memory, as it does not to be explicitly stated anywhere else.\n",
      "- Figure 5: The authors should address why feedback retrieval likelihood of 0.5 performs similar to or better than 1.0.\n",
      "- Figure 6, caption: Should be \"for GROW-PROMPT and MEM-PROMPT\".\n",
      "\n",
      "In closing, I think this paper is really neat, fits well within the body of commonsense reasoning research, and would be a worthy addition to the workshop.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed method for improving the performance of pre-trained language models through corrective feedback and the experimental evaluation provided.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review of the paper\n",
      "# Summary\n",
      "This work investigates the augmentation of pretrained language models (LMs) with knowledge graphs (KGs) for the cause-effect relation classification and commonsense causal reasoning tasks. They verbalize the ATOMC-2020 KG triples into natural language which they use to continually pretrain BERT. Their results show that the continually pretrained LM outperforms non-continually pretrained ones on two commonsense causal reasoning benchmarks, COPA and BCOPA-CE, and a Temporal and Causal Reasoning (TCR) dataset.\n",
      "\n",
      "# Contributions\n",
      "1. They study pretrained LMs augmented with the ATOMIC-2020 knowledge graph in the commonsense reasoning domain.\n",
      "2. They perform experiments to show that these augmented LMs can outperform non-continually pretrained ones and other baselines on the cause-effect relation classification and commonsense causal reasoning tasks.\n",
      "\n",
      "# Pros\n",
      "1. The writing is generally very clear, which makes the paper easy to follow.\n",
      "2. The result on the TCR task looks very good!\n",
      "3. Approach the (causal) commonsense reasoning task, which is very important.\n",
      "\n",
      "# Cons\n",
      "1. The framework of continually pertaining LMs using verbalized KG triples is something that has been done previously [1]. The only things that are different in this paper is to apply this technique to a different KG (ATOMIC-2020) and to fine-tune on a few different tasks and benchmarks. So there is a lack of novelty.\n",
      "2. I find the result in Table 4 unsatisfactory. First, what is the b-l-reg baseline and why does the ATOMIC-BERT model underperform that baseline? Second, the fact that using all the categories for ATOMIC-2020 actually hurt performance but only using the event ones does not fit well with the claim of the paper that general commonsense knowledge helps the causal commonsense reasoning task. It may just be the case that the event triples in ATOMIC-2020 is in a closer domain to the BCOPA-CE and it is actually the in-domain further pertaining that is helping. Third, why not just try using the causal relations in ATOMIC-2020 (\"cause\", \"effect\" etc)?\n",
      "3. The standard deviations are not reported for all the experimental results.\n",
      "4. I know it is not a fair comparison to compare ATOMIC-BERT and T5 and DeBERTa, but looking at the latter two's numbers on the COPA-test, the task seems a solved one. I am not sure how significant/useful it is to continue working on this benchmark.\n",
      "\n",
      "# Other comments and questions\n",
      "1. An ablation study in the effect of different ways to verbalize the KG triples and e.g. whether the grammar correction step is necessary can be useful and interesting.\n",
      "2. Which split of ATOMIC-2020 is used?\n",
      "\n",
      "# References\n",
      "1. Guan, Jian, et al. \"A knowledge-enhanced pretraining model for commonsense story generation.\" Transactions of the Association for Computational Linguistics 8 (2020): 93-108.\n",
      "Rating: 4: Ok but not good enough - rejection\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its contributions in studying pretrained language models augmented with knowledge graphs for commonsense reasoning tasks, and its experimental results on cause-effect relation classification and commonsense causal reasoning benchmarks.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Unique limited contribution of cause-effect models created by knowledge-augmented LM pretraining\n",
      "This paper proposes a method for knowledge-augmented LM pretraining with cause-effect information. The method is targetted towards causal reasoning benchmarks (TCR, COPA, and BCOPA-CE). The method performs better than vanilla and existing system baselines on TCR, and below some baselines on the COPA/BCOPA-CE tasks.\n",
      "\n",
      "The paper is overall interesting. Its novelty is limited as the method is already known in the literature, but the evaluation is unique which may be enough for a workshop paper.\n",
      "\n",
      "Weaknesses:\n",
      "* It is unclear how the citations in paragraph 1 of section 1 relate to the statement that PLMs have been leveraged in for understanding causality in language.\n",
      "* The statement that model performance is very dependent on the domain and downstream tasks is reasonable, but it is broad, and it is unclear how this paper addresses this challenge.\n",
      "* The evaluation contains various benchmark-specific adaptations which are not anticipated in the experimental setup, and feel like hacks to improve performance ad hoc. It would be good to give these configurations a better structure in the paper, ideally by stating them within the method description or within the experimental setup. Moreover, it would be good to clarify how each of these configurations relates to the research question investigated in this paper.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method for knowledge-augmented LM pretraining with cause-effect information in terms of its novelty, clarity of citations, addressing the challenge of domain and downstream tasks, and the structure of the evaluation with benchmark-specific adaptations.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Review\n",
      "Summary\n",
      "- The technique of continually pretraining language models on commonsense knowledge graph triples has been shown useful for some downstream tasks, but it may depend on the specific domain and tasks. This work investigates the effect of this technique on the task of cause-effect relation classification. The authors verbalize the ATOMIC2020 knowledge graph and continue to pretrain BERT-large on it. The authors show that this simple method can boost the performance in cause-effect classification. \n",
      "\n",
      "Reasons to Accept:\n",
      "- The effect of commonsense knowledge graphs for cause-effect relation classification is an interesting topic, but has not been studied systematically. This work performs an interesting investigation into this research question.\n",
      "- The paper is clear and well-written overall. \n",
      "- The authors will publicly release the knowledge graph verbalization codes and the trained models\n",
      "\n",
      "Weakness and questions:\n",
      "- Overall, I think that the experiments/analyses could be polished a bit more. Below are s few suggestions.\n",
      "- ATOMIC-BERT-large (Event, Physical, Social relations) underperforms the baseline BERT-large on two datasets (Table 2, 4). It'd be great if the authors could investigate more into why this is the case. Do Physical/Social relations have very different distributions of knowledge than the tasks of interest (i.e. cause-effect prediction)? Even though ATOMIC-BERT-large (Event) outperforms the baseline, it is a bit concerning that in order for the proposed method to work, it needs to identify what kinds of relations within ATOMIC2020 is useful or hurting for the task and remove the hurting relations. It'd be ideal if the authors could think about a bit more elegant method to address this issue.\n",
      "- Additionally, it is not clear why adding prompt helps for BCOPA-CE but hurts for COPA task. It'd be great if the authors could conduct more in-depth analysis for their results. \n",
      "\n",
      "Typos/grammar:\n",
      "- L184: redundant parenthesis in \"(MLM)\"?\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of our paper in investigating the impact of pretraining language models on commonsense knowledge graphs for cause-effect relation classification, including any weaknesses or areas for improvement that you may have identified.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "a good benchmark paper overall\n",
      "The paper proposes CIKQA, a commonsense benchmark, which unifies several commonsense task into QA format and associates them with relevant knowledge. Experiments shows that models can better learn inference and generalize across tasks with proposed formulation and usage of knowledge.\n",
      "\n",
      "Strength:\n",
      "1. the proposed benchmark can be a useful resource for the field. \n",
      "2. the experiments and analysis are comprehensive and give interesting insights. \n",
      "3. the writing is clear and easy to follow.\n",
      "\n",
      "Weakness:\n",
      "1. the coverage of proposed benchmark is limited, it doesn't include any physical or social commonsense tasks, like PIQA or SocialIQA.\n",
      "2. the idea isn't entire novel - unified task formulation and knowledge injection have already been well-studied in QA domain. \n",
      "3. missing related works: \n",
      "[1] Liu, Jiachen et al. “Generated Knowledge Prompting for Commonsense Reasoning.” ArXiv abs/2110.08387 (2021): n. pag.\n",
      "[2] Shwartz, Vered et al. “Unsupervised Commonsense Question Answering with Self-Talk.” ArXiv abs/2004.05483 (2020): n. pag.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed benchmark, experiments, and analysis, and provide your overall assessment.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Commonsense benchmark paper - simple and well-presented\n",
      "Overall the paper seems comparatively complete and solid to me. The authors propose the benchmark CIKQA with a clear task formulation and detailed steps on how to extract supporting knowledge, as well as a strong baseline that takes advantage of its format. Experiments are also well-executed to answer the authors' questions regarding leveraging provided knowledge, distinguishing gold knowledge, and model generalization ability on different tasks.\n",
      "\n",
      "Here are my comments:\n",
      "- It is a bit overclaimed to me that CIKQA can focus on learning to do the inference with the current task setting. \n",
      "- The related work discussion seems a bit sparse to me.\n",
      "- I am a bit concerned about the novelty as the unified format and injecting knowledge have all been discussed widely.\n",
      "- From Table 1, there are only 3,007 instances with gold knowledge, but for experiment results in Figure 3, even models with the suffix `_gold` could still be trained with $10^4$ training instances. Hope the authors could address the issue there.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its completeness, clarity of task formulation, steps for extracting supporting knowledge, baseline performance, experimental design, and novelty of the proposed benchmark CIKQA.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "review\n",
      "The authors propose a reformulation of commonsense reasoning QA tasks\n",
      "that attempts to separate knowledge (e.g., facts as specified by a KG)\n",
      "from inference (i.e., reasoning over a given set of facts). Their\n",
      "setup is to pair a small knowledge graph with each question that\n",
      "contains the relevant knowledge to answer the question. They report\n",
      "experimental results in this setting, showing that their model,\n",
      "JointI, 1) effectively incorporates the knowledge graph information in\n",
      "a fewer-shot setting (e.g., 100-1000 points); and 2) transfers between\n",
      "tasks better than if the model didn't have explicit knowledge handed\n",
      "to it.\n",
      "\n",
      "I commend the authors for their attempt to solve a difficult problem:\n",
      "indeed, the distinction between factual knowledge and inference over\n",
      "that knowledge is rather illspecified in the commonsense domain.  The\n",
      "proposed approach: converting and then augmenting existing QA datasets\n",
      "with all the knowledge the might need gives a potentially nice\n",
      "solution to this problem: i.e., by conditioning on \"all of the\n",
      "knowledge\", the algorithms can focus entirely on inference; similarly,\n",
      "by retrieving knowledge as a first step. I also think the results here\n",
      "regarding generalization are quite interesting! Because we expect that\n",
      "the inference required for commonsense reasoning tasks may be shared,\n",
      "the transfer results suggest that, moreso than a model without\n",
      "explicit knowledge provided, an inference-focused model may generalize\n",
      "better.\n",
      "\n",
      "My biggest concern is that I'm not entirely convinced that this setup,\n",
      "as the authors claim, fully separates the knowledge versus inference\n",
      "question. While the approach makes sense in theory (i.e., conditioning\n",
      "on all needed knowledge), 1) there are still pieces of commonsense\n",
      "knowledge required to, e.g., interpret the small KGs that are paired\n",
      "with each question. To take the example in Figure 2: one simple case:\n",
      "an algorithm must know that sleeping is a type of resting. And 2)\n",
      "models could simply ignore the given knowledge graph in this setup,\n",
      "e.g., if one was to use a pretrained language model that was already\n",
      "imparted with both knowledge and inferential capacity. The authors do\n",
      "use BERT-Small in some experiments and performance improves when the\n",
      "graph is included in the input, but, I suspect that if more powerful\n",
      "pretrained models were used the large performance gaps presented\n",
      "between Table 2 (a) vs. Table 2 (b) might vanish.\n",
      "\n",
      "Overall, the authors report some interesting results for their new\n",
      "setup, which may have practical promise for few-shot learning with\n",
      "small models. However, I do worry that CIKQA has limitations that need\n",
      "to be addressed if larger models were to be applied to such a task.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed reformulation of commonsense reasoning QA tasks that separates knowledge from inference and incorporates a small knowledge graph with each question, based on the experimental results and the potential limitations mentioned in the review.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Insightful Analysis on CCI\n",
      "The authors present analysis on contextual commonsense inference (CCI) using GLUCOSE, a story dataset annotated with commonsense explanations. They argue that the conflation of CCI with language generation (used in original GLUCOSE task) hinders model performance and the evaluation protocol also has issues. They propose to separate CCI from NLG by proposing CIS^2 and show improvement.\n",
      "\n",
      "Strength:\n",
      "- It's always good to see (and enjoyable to read!) analysis papers that tackle a previously studied problem from a new angle and provide insights. CIS^2 looks at the CCI problem and critiques a previous task formulation which I think provides important reflections for other researchers working on this problem.\n",
      "- The experiment design is well-reasoned and thoroughly described. I really like the different diagnosis task settings trying to disentangle different factors that might influence CCI performance.\n",
      "- The analysis on evaluation metrics also provides interesting insights\n",
      "\n",
      "Places to improbe:\n",
      "- I do not have major weaknesses to point out, but I think some parts of the writings can be much more concise. Especially Section 3 where the authors spent 2 pages on reviewing and introducing a previous work's data and task (I know it's crucial background but think could be shortened)\n",
      "- Significance tests would be beneficial to be included for Table 4 and others.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its analysis of contextual commonsense inference (CCI) and the proposed CIS^2 model, focusing on the strengths and areas for improvement.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting hypothesis \"Contextual Commonsense Inference should not be conflated with NLG as in GLUCOSE\" but not much evidence.\n",
      "What the paper is about: The paper argues that for contextual commonsense inference (commonsense understanding in some story), the GLUCOSE task conflates a different skill of natural language generation, which also brings in the ills of BLEU metrics. They propose the task of CIS2 which instead of asking the model to generate a commonsense inference, merely asks it to pick/classify the correct sentence prediction. They compare with different diagnostics/ablations of the original GLUCOSE task by removing parts of the input. They find that models trained on these ablations of GLUCOSE-Original perform worse than one trained on CIS2 (note that all these variants are based on the same GLUCOSE dataset) -- when evaluating on CIS2 metric of classification.\n",
      "\n",
      "Key Shortcoming: There is no independent evidence that shows a classification task is better than generation task in training for \"contextual commonsense inference.\" The only evidence is on the same metric of CIS2 which seems biased. The argument sounds like \"Standardized Tests are not good benchmarks of creativity, so we propose instead teaching/testing students the skill of playing chess. We find that students preparing for different standardized tests are worse than students preparing for chess -- when evaluated on chess.\" The core hypothesis remains untested: whether chess playing (CIS2) is a better metric and task for creativity (commonsense contextual inference) than standardized testing (generation). Some ways that this could have been evaluated are:\n",
      "1. human studies - do annotators find one model to exhibit more commonsense than others in some way?\n",
      "2. independent downstream task - does the model trained on CIS2 outperform those trained on generation on some third task?\n",
      "Rating: 4: Ok but not good enough - rejection\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of our paper in proposing the CIS2 task as a better metric and task for contextual commonsense inference compared to the GLUCOSE task, providing evidence and potential alternative evaluation methods.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The paper pinpointed a valid issue with the existing CCI task formulation. However, the findings are somewhat obvious, and the newly designed task might not generalize to settings where the CS inference is implicit and not part of the given story.\n",
      "This paper critiques existing methods on Contextual Commonsense Inference (CCI), which conflates generation and reasoning tasks. The authors propose reframing the CCI task as a classification task (called Cis2) to isolate commonsense reasoning from the generation. This helps in evaluating the commonsense inference ability of a model irrespective of its generation performance. For this, they convert story sentences into output tags which avoids a partial match between input and output sequences. The model is then required to generate an abstracted output which contains story sentences' tags instead of full sequences. \n",
      "\n",
      "Pros:\n",
      "* It is important to evaluate the reasoning abilities of models in isolation from their generation abilities and the author pinpointed a valid issue with original GLUCOSE task formulation.\n",
      "\n",
      "\n",
      "Cons:\n",
      "* Most of the findings from the diagnostic tests are obvious and expected (see comments). \n",
      "* Too much content is provided about Mostafazadeh et al. 2020 which could be easily skipped and referred to the original paper.\n",
      "* It is not clear how the newly designed task formulation handles cases where the inference output Y is not explicitly stated in the given story.\n",
      "\n",
      "Comments:\n",
      "1- How does your task reformulation handle cases where the inference output Y is not explicitly stated in the story? As the authors mention in Line 196, the CS inference Y might or might not be part of the story. And example from the original GLUCOSE paper is:\n",
      "“Gage wants safety” Causes/Enables “Gage turned his bike”, while “Gage wants safety” is never stated in the story and should be inferred thus can not be replaced by a tag from the story.\n",
      "\n",
      "2- Line 259: while I agree with the authors that the original task formulation suffers from conflation of CCI and language generation tasks, I think this can be solved mostly by 1) removing the selected sentence X from the output, and 2) including a better evaluation metrics that accounts for semantic similarity such as BertScore. \n",
      "\n",
      "3- Line 367-369: Isn't this obvious? if in the training data, output always copy/paraphrase X, it's expected that the model learns this pattern and consequently the BLEU score would be high. The issue is why the model should generate X in the first place. Without including X in the output (no matter if X is in the input or not) the evaluation using n-gram overlap would be less unreliable.\n",
      "\n",
      "4- Line 380: In my opinion copying is an easier task.\n",
      "\n",
      "5- The first 5.5 pages are allocated for background and related work and only on page 6 the author started to talk about their proposed task Cis2. \n",
      "\n",
      "6- It is helpful to explicitly mention somewhere in the paper that you are using a generative classifier where the model GENERATES one of the 100 possible output sequences (using T5) and it’s not a 100-way classification task.\n",
      "\n",
      "7- Line 449: For what portion of the original data could the authors find output Y explicitly mentioned in the input story? And why not discard those with very low similarity scores?\n",
      "\n",
      "Typo: \n",
      "\n",
      "Line 406: the The → The\n",
      "\n",
      "Line 407: footnote after punctuation.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the proposed task reformulation in the paper and discuss its potential limitations in handling cases where the inference output is not explicitly stated in the given story.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting and original work but the proposed method might need further development before the resulting CSKB can be used as a reliable resource\n",
      "This paper studies generating commonsense knowledge directly from pre-trained language models for two CSKBs - ConceptNet and Ascent++. The direction is interesting and original, and the paper is well written and easy to follow. However, \n",
      "\n",
      "1. The paper claims that \"up to now no materialized resource of commonsense knowledge generated via pre-trained language models is publicly available.\". However it's not true. West et al. (2021) construct AUTOTOMIC via GPT3 that's 10x larger than ATOMIC, and provide comprehensive and in-depth analysis and evaluation. \n",
      "2.  Lack of novelty: the proposed method directly applies previous COMET pipeline on two established CSKBs without further improvement or adaption. \n",
      "3. Evaluation shows a clear gap between proposed PLM generated CSKs and original human written CSKs. Without further filtering or purification, it's questionable whether the generated noisy CSKB can be used as a reliable resource. \n",
      "\n",
      "Citation:\n",
      "West, Peter et al. “Symbolic Knowledge Distillation: from General Language Models to Commonsense Models.” ArXiv abs/2110.07178 (2021): n. pag.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method for generating commonsense knowledge directly from pre-trained language models, specifically in terms of its novelty, reliability, and comparison to existing resources.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Strong paper that fills a gap in current commonsense knowledge extraction work\n",
      "This paper proposes to materialize neural commonsense predictions with COMET into concrete resources. The paper investigates two SotA knowledge bases (ConceptNet and ASCENT++) and two standard language models (GPT-2-XL and BART). The evaluation estimates the precision of the generated knowledge through salience and typicality, and the recall by comparison against a feature norms dataset, CSLB. The results indicate the promise of this approach, but also point to key obstacles in terms of redundancy, subject copying, and co-occurrence misreading.\n",
      "\n",
      "The paper is overall well-written, original, and the evaluation is solid. The pointed challenges are thought-provoking. \n",
      "\n",
      "The paper size is in between a short and a long paper, so it is unclear to me whether this paper qualifies as long of short. If this is meant to be a long paper, it would be good to include more discussion on how would the authors propose to circumvent the key challenges with this knowledge base generation method. These mitigation strategies are currently only briefly listed in the conclusion, which leaves many questions unanswered. Furthermore, some quantitative investigation of how would the downstream applications benefit from the created sources despite these challenges would be useful.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed approach of materializing neural commonsense predictions with COMET into concrete resources, including the investigation of knowledge bases and language models, and the evaluation of precision and recall.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Trained COMET models analyzed for precision+recall and used to generate new commonsense KGs -- but not clear why we need this resource?\n",
      "What the paper is about: The authors offer a new resource generated from COMET models trained on commonsense knowledge graphs like ConceptNet and Ascent++. They study not just plausibility but also the precision (typicality and saliency) as well as recall of the models' predictions. They analyze different base LMs and datasets on these metrics and offer insights. Finally, they demonstrate a web interface with wider customizations than the original one hosted by AI2.\n",
      "\n",
      "Key shortcoming: The authors call it a resource paper (L043). However, the benefit of the new \"generated\" commonsense knowledge graphs is not well established. Section 4.3 hints at some use cases like aggregation, joins, ranking, and text search. But the benefit of having a static set of predictions (this new resource) is not clear. (1) How are these better than the base KGs like ConceptNet and Ascent++? Perhaps they are bigger but not always more salient/typical/exhaustive than the original KGs (see Table 2). (2) How are these better than retaining the trained COMET model, which can generate such inferences and many more, on demand?\n",
      "\n",
      "Pros: good analysis + useful resource.\n",
      "Cons: usefulness of the resource not demonstrated.\n",
      "\n",
      "EDIT: Reviewer jbiB rightly points to a major missing related work, which further challenges the paper's claim to novelty.\n",
      "\n",
      "Minor:\n",
      "- Should you be referring to Untypical as Atypical instead? I was fairly confident that the latter is \"correct\" but words have no inherent meaning anyway so this is up to the authors.\n",
      "- Saliency vs Typicality could benefit from a formal definition (in English, not just in a formula) each. Do they differ in just values of k for top k extractions?\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the usefulness and benefits of the new resource generated from COMET models trained on commonsense knowledge graphs, as described in the paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Good paper that shows scientific significance, accept\n",
      "**Summary** \\\n",
      "This paper investigates the inductive bias in ViT and CNN models. The authors claim that the previous design of injecting convolution-like inductive bias into CNN models ignore that the optimal inductive bias depends on the data scale and fixed inductive bias may not be optimal. Experiments on different data scales of ImageNet illustrate that smaller data scale is needed for ViT to outperform CNN if more convolution-like inductive biases is included. The paper also proves that frequency characteristics can explain whether the inductive bias is closer to convolution or self-attention by conducting Fourier analysis. Then the authors show that the interpolation of inductive bias between CNN and ViT can be realized by adjusting the moment of reparameterization during training. Based on the above findings, a progressively reparameterization scheduling is proposed to make the front layers to act like convolution and the rear layer to act like self-attention. Experiments on CIFAR-100 show the effectiveness of PRS.\n",
      "\n",
      "\n",
      "\n",
      "**Strengths**\n",
      "- Investigating the inductive bias injected in CNN and ViT models is crucial and this paper presents a new idea of making the inductive bias flexible, which provides a new research direction.\n",
      "- The order of the paper and the logic in conducting this research is clear. The authors try to first understand the inductive bias by conducting the 'different data ratio' experiments and the Fourier analysis and then propose the scheduling strategy of reparameterization based on the previous findings.\n",
      "- The tables, equations and figures used to demonstrate the PRS is clear.\n",
      "- The paper is generally well-written. \n",
      "\n",
      "\n",
      "**Weaknesses**\n",
      "- The experiments used to verify the effectiveness of PRS is only conducted on CIFAR-100. It would be good if more datasets can be included.\n",
      "- The legend in Figure 3 is misleadings. The orange line should be Conv50, SA250?\n",
      "\n",
      "**Overall rating (1-10)** \\\n",
      "7\n",
      "\n",
      "**Justification of rating** \\\n",
      "The scientific significance of this paper.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the paper based on its scientific significance and overall quality.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting method, but concerns about motivating analysis\n",
      "**Summary**\n",
      "The authors use existing work that reparameterizes self-attention to be able to interpolate between self-attention and convolution, and propose a linear schedule that progressively switches over CNN modules to self-attention over training time. This method is motivated by a reproduction of the result that CNNs and ViT models with increased inductive biases are more data efficient than baseline ViT models, while ViT models can outperform CNNs at large data scales.\n",
      "\n",
      "**Strengths**\n",
      "- The proposed method is simple and easy to reproduce based on the paper.\n",
      "- The method is effective on CIFAR-100.\n",
      "\n",
      "**Weaknesses**\n",
      "- In my view, the analysis in sections 4 and 5 does not connect to the method. The relationship between the frequency response of convolution/self-attention and their inductive bias is not properly explained and not obvious to me. The cited work by Park et al. doesn’t directly connect the two either. The claim that the frequency response is indicative of inductive bias is therefore, in my opinion, not substantiated.\n",
      "- Regardless of the validity of the analysis in sections 4 and 5, in my opinion sections 4 and 5 are not necessary to argue that inductive bias aids data efficiency, as that is an established property of machine learning models. Specifically for convolutions and self-attention thee are many works to cite (see the related works in this work and the work of Park et al.). As such, the chapters distract from the main contributions.\n",
      "- The main motivation for the method is improved accuracy on CIFAR-100, but a thorough description of the hyperparameter of the method and baselines is missing, which does not inspire trust in the results.\n",
      "- The method is not evaluated for its claimed benefit of adjusting to the data scale. For example, the authors could have evaluated on the ImageNet subsets of sec 4.2.\n",
      "\n",
      "Rating: marginally below acceptance threshold\n",
      "\n",
      "**Justification**\n",
      "My leading principle for this review is if I believe the paper disseminates useful information for the field. In the current form, I do not believe sections 4 and 5 should be published, as I do not agree with the claims on the relationship between frequency response and inductive bias, and they will confuse and distract uninformed readers. I can however see the value of the proposed linear schedule method, and think it would be a good fit for this workshop or another similar venue otherwise. I recommend the authors revisit the way they motivate and analyze their method, and resubmit to a similar venue.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its analysis of the relationship between frequency response and inductive bias, as well as the effectiveness of the proposed linear schedule method on CIFAR-100.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Good paper! Accept without doubt.\n",
      "This paper first studies the inductive bias in convs and transformers using Fourier analysis. The amount of inductive bias is defined as the log-scale difference between the high and low frequencies. The observation seems to align with common sense that convs have much more bias thus being data-efficient, while transformers are the opposite.  Later, the authors study a progressive reparameterization schedule which allows a model to flexibly decide \"optimal\" the amount of bias needed during training by progressively converting convs to transformer blocks. In general, an interesting paper. \n",
      "\n",
      "However, I do have a concern about the lack of connection among frequencies, inductive biases, and data efficiency. The main argument is that MSA is low-pass while convs are high-pass. However, it is not clear how the high/low frequency contributes to data efficiency.  Is the frequency bias universal (applicable to other datasets/tasks)? Reviewer \"zxBu\" shares the same opinion, as indicated in \"The relationship between the frequency response of convolution/self-attention and their inductive bias is not properly explained and not obvious to me.\"  \n",
      "\n",
      "In general, I think the ProgressiveReparameterizationScheduling is an interesting idea and the experiments on cifar show some inspiring results.  Despite the concerns on the Fourier analysis, I would still vote for acceptance.\n",
      "\n",
      "line 388 typo\n",
      "line 389: how are the frequencies normalized to [-pi, pi]? linearly?\n",
      "line 396: what is the 'normalized depth'?\n",
      "is it possible to show some qualitative analysis/visual examples on low/high frequencies? what are the low/high frequencies exactly? How do they differ in early and later layers? It might be beneficial to understand the inductive bias.\n",
      "fig 3 why is the orange line has the same configuration as the light blue line? is this a mistake? I would assume it is orange - conv100, SA200?\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the reviewer's feedback, specifically addressing the concerns about the lack of connection between frequencies, inductive biases, and data efficiency, as well as the request for qualitative analysis or visual examples of low and high frequencies.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Preliminary work with interesting future extensions\n",
      "The paper describes an approach for developing resource-efficient Counterfactual Generative Networks (CGNs) through Knowledge Distillation (KD) from black-box pre-trained CGNs to smaller TinyGANS. The approach is then named by the authors Source-free\n",
      "Knowledge Distillation of Counterfactual Generative Networks (SKDCGN).\n",
      "The authors employ a TinyGAN for each of the independent mechanisms (i.e., shape, texture, background) in order to increase modularity and reduce the size of the overall model.\n",
      "\n",
      "Pros:\n",
      "\n",
      "- The paper is eligible for the workshop since the concept of “prior” is applicable both to 1) the knowledge transfer from the teacher CGN and 2) the built-in approach of CGNs that employ inductive biases (i.e., shape, texture, and background) to generate realistic images. \n",
      "\n",
      "- The paper tackles two critical problems of modern deep learning literature, i.e., 1) reducing the size of state-of-the-art GANs and 2) learning from large pre-trained models through black-box access.\n",
      "\n",
      "- The paper is well written and clearly presents the objectives, methodology, and qualitative results.\n",
      "\n",
      "- The related work section provides a good overview of the literature concerning this paper (i.e., CGNs and KD).\n",
      "\n",
      "\n",
      "Cons:\n",
      "\n",
      "- The paper employs and combines published techniques [3, 7] rather than proposing a novel method.\n",
      "\n",
      "- The evaluation of the approach is preliminary and needs extensions.\n",
      "\n",
      "  Section 4 mainly presents qualitative rather than quantitative results. It would be interesting to evaluate SKDCGN on Out-of-Domain (OOD) classification tasks as performed in [3]. The results would probably be less \n",
      "  compelling but still interesting to observe.\n",
      "\n",
      "  Furthermore, given that the objective of SKDCGN is to make current CGNs more lightweight, it would be better to report a plot/table in \n",
      "  which metrics quantify improvements. For instance, the reduction of the number of trainable parameters, GPU memory usage, etc.\n",
      "\n",
      "- As visible in Fig. 2, the texture mechanism is the one that suffers more from the reduction of size. Textures of Fig. 2 (b) generated by \n",
      "  SKDCGN are hardly distinguishable.\n",
      "  On the contrary, the shape and background mechanisms mimic quite well the original generations.\n",
      "  Future work should develop more on the texture generation mechanism. For instance, by including data augmentation or other \n",
      "  approaches that improve image synthesis for GANs.\n",
      " \n",
      "\n",
      "Minor issues:\n",
      "\n",
      "- The abstract is a bit lengthy and could probably be pruned.\n",
      "\n",
      "- Is the legend of Fig. 1 partially wrong? During inference, the TinyGANs should be “fixed” and during training “trainable”. Further, the composition mechanism is said to be untrainable by default.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its methodology, objectives, and qualitative results, and provide suggestions for future extensions and improvements.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A knowledge distillation method with limited novelty\n",
      "[Summary]\n",
      "This paper presents a method that trained three tinyGANs from the Counterfactual GAN (CGNs) for shape, background and texture independent components respectively. The main novelty of this paper is the combination of the TinyGANs [7] and CGNs [3]. The author shows it is feasible to train the proposed method in the knowledge distillation way. \n",
      "\n",
      "[Paper strength]\n",
      "- The paper contributes to the combination of the TinyGANs [7] and CGNs [3]. The TinyGANs[7] train the one TinyGANs from one BigGANs, and the CGNs trained three BigGANs [4] for object shape, texture and background respectively. The proposed method in this paper trained three TinyGANs (using the way in [7]) from three BigGANs in the CGNs [3].\n",
      "\n",
      "-  The secondary contribution is the author uses the KL divergence as the additional loss compared to [7]. In section 4.4, the author shows that using KL divergency could improve performance.\n",
      "\n",
      "- In the experiment, the author shows that the proposed method could generate reasonable results on ImageNet and MNIST datasets. \n",
      "\n",
      "[Paper weakness]\n",
      "- The novelty contribution is limited. The proposed method is to train the TinyGANs [3] from the CGANs [3] model. The proposed architecture shown in Fig. 1 is similar to [7] except it is for three separated models, and the three separated models are introduced by [3]. The loss terms 1 to 3 are from [7] with the exact same equation and adapted text, and the loss term 4 is from [21]. I did not find any interesting technical contribution. \n",
      "\n",
      "- The experiment is limited in terms of the error metric and conclusion. There are only qualitative results for the main experiments in sections 4.3 and 4.4. The comparison between the proposed method and baseline can only be judged subjectively. In the related works [7], there are other metrics such as FID to compare different methods. From these qualitative results, I can only judge that the proposed method can generate the somehow similar results to the baseline but for sure is worse than the baseline. Compared to the results achieved in [7], the TinyGAN in [7] has comparable results with the BigGAN model.\n",
      "\n",
      "- Inappropriate baseline. The baseline method is CGN but each BigGAN is replaced by a TinyGAN. However, the author motivates the proposed method that the BigGANs in the original CGN is over-parameterrized (line 45). I expected the author would compare their method to the original CGN,  too. If we can train the CGN with the TinyGAN, I think we do not have the over-parameterized networks problem.\n",
      "\n",
      "Other minor issues:\n",
      "- I do not find the necessarily of section 4.5.\n",
      "- Misuse of the supplementary material. The author refers to supplementary on improving the method in section D. However, according to the author guideline of ECCV (https://eccv2022.ecva.net/submission/call-for-papers/), \"Reviewers will be encouraged to look at it (supplementary), but are not obligated to do so\", and \"It may not include results obtained with an improved version of the method\".\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method in our paper, focusing on its novelty and contributions, as well as the experimental results and comparisons with baseline methods.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "This paper studies an interesting task: learning less parameterized models from the bigGAN teacher using knowledge distillation. However, the paper itseld lacks clarity, especially in the exps.\n",
      "This paper aims to learn lightweight models from the bigGAN teacher using knowledge distillation (KL loss at both pixel/feature levels). The Introduction, Related work, and Approach are easy to follow and well explained. \n",
      "\n",
      "Unfortunately, I find the exp part poorly written, making it extremely hard to understand: does the result support the claim? I lost track completely there. The same also happens in the appendix. Please add concrete conclusions or take-aways for each figure and re-write the exp part.\n",
      "\n",
      "Despite the fact the task/problem addressed in the paper is both theoretically and practically meaningful, I would still recommend 'reject' given the flaws in the writing, especially the exp part. \n",
      "\n",
      "\n",
      "\n",
      "Fig 1: left: are the modules in blue non-trainable? right: are the tinyGANs trainable during inference? Or there is a mistake in legend?\n",
      "line 223: Abuse of notation: \"S\" refers to the student model in eq2, while in eq4 it is defined as the generator\n",
      "\n",
      "line 344: what is the take-away from fig 2. I do not see a conclusion? It seems the SKDCGN generates less impressive results than the CGN.\n",
      "\n",
      "\n",
      "line 351: \"We realize that the student is as good as the teacher.\" where does this conclusion come from?\n",
      "\n",
      "line 356/358: Grammarly incorrect. I do not follow these claims. It seems this part (exp 4.4) is not in a good shape as a submission.\n",
      "\n",
      "Appendix B2/B3: It is unclear what the takeaways are in the figures? I find it hard to interpret\n",
      "\n",
      "appendix: line 226/227 typos.\n",
      "Rating: 4: Ok but not good enough - rejection\n",
      "Confidence: 2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper\n",
      "====================================================================================================\n",
      "Please evaluate the clarity and coherence of the experimental section in the paper, including the presentation of results and conclusions drawn from the figures.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      ".\n",
      "1) Summary:\n",
      "\n",
      "The paper reformulates Video Frame Interpolation (VFI) as a Continuous Image Transition task. The approach is based on Space Decoupled Learning (SDL) and it shows competitive results for VFI and for other CIT tasks.\n",
      "\n",
      "2) Strengths:\n",
      "- SDL simplifies VIF to a CIT problem without affecting performance and without requiring any human knowledge of the domain. Additionally, SDL works well for several CIT tasks.\n",
      "- Paper very well written.\n",
      "- Hypothesis supported by experiments.\n",
      "- In line with workshop.\n",
      "\n",
      "3) Weaknesses.\n",
      "- Figure 1 is usually an important figure in the paper. It seems a bit difficult to follow and to read.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its approach of reformulating Video Frame Interpolation as a Continuous Image Transition task using Space Decoupled Learning, and its competitive results for various tasks.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The SDL method introduced in the paper is a solid contribution as it can improve Continuous Image Transition (CIT) and be deployed for several CIT tasks. The paper seems technically correct, the experiments are exhaustive, the motivation is clear, the paper is well written. Because of this, I vote to accept the paper.\n",
      "Summary:\n",
      "\n",
      "- The paper aims to improve video frame interpolation (VFI) by reformulate as a continuous image transition (CIT) task. The authors propose a model based on Space Decoupled Learning (SDL) that can be used for multiple CIT tasks, including VFI. One of the advantages of SDL is that is does not require human knowledge of the data domain. Thorough experiments show that the proposed SDL achieves competitive results on a number of CIT tasks, including VFI, face ageing, face tonification, dog-to-dog morphing.\n",
      "\n",
      "\n",
      "\n",
      "Positive points:\n",
      "\n",
      "+ The Space Decoupled Learning (SDL) for Continuous Image Transition (CIT) proposed in the paper seems a solid contribution and can be effectively deployed for several tasks, including VFI, face ageing, face tonification, dog-to-dog morphing.\n",
      "+ The paper seem technically correct. Thorough experiments and ablation studies are performed to show the effectiveness of the proposed method. Experiments on four VFI datasets are included, on which SDL achieves competitive performance.\n",
      "+ The paper is easy to read, the motivation is clear and the literature review exhaustive.\n",
      "+ The proposed method is based on inductive priors which lead to decoupling the image space into tractable flow space and a non-tractable feature space, therefore this paper is a good fit for the VIPriors workshop.\n",
      "+ The paper seems reproducible. \n",
      "\n",
      "\n",
      "\n",
      "Negative points:\n",
      "- I did not find substantial flows in the paper.\n",
      "\n",
      "\n",
      "\n",
      "Per line comments:\n",
      "\n",
      "225-234: In figure 1, the font size is very small, which makes the text hardly readable. I think the figure and capture are currently not self explanatory. I would suggest adding an explanation on how to read the figure. \n",
      "\n",
      "315: In Table 1 the font size is very small. I suggest to increase it to make the table more readable.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the proposed Space Decoupled Learning (SDL) method for Continuous Image Transition (CIT), its technical correctness, thorough experiments, and its potential impact on various CIT tasks.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "In general, good work\n",
      "Quality: Good work, intensive experiments with three tasks with two major datasets\n",
      "\n",
      "Clarity: Clear problem statements, clear and tidy methodology by adding unsupervised k-means and corresponding loss\n",
      "\n",
      "Significance: the methodology could ease the stated problems to some extend (e.g., if new unseen samples are far away from any local experts, so in this situation the hyper parameter K will be related with the performance. How can you determine this K? And what is the influence? Is there any optimal option on choosing K in general?)\n",
      "\n",
      "Questions: \n",
      "\n",
      "1. In Fig. 6 \\& 7 right side, the mAP performance dropped with the large \\lambda (the rightmost square and star). And the caption for that is 'the method is stable regardless the choice of the parameters over various tasks'. Could you please give me some explanation on those two points? I think the trend of dropping of mAP with large \\lambda is clear. Do you still think it is stable?\n",
      "\n",
      "2. I find some typos or grammar mistakes, please check them. Line 66, 'evcaluate'. Line 112, 'where early on in the training'. Line 236, 'Thereof'. Line 493. 'both both'.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the reviewer's comments, specifically addressing the stability of the method with large lambda values and any typos or grammar mistakes that may have been found.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A well written paper, with some interesting ideas. The results only show marginal improvement across different settings.\n",
      "Summary: \n",
      "The paper builds on the idea of Dynamic Routing (DR) in the context of mixture of experts. The authors propose an unsupervised DR approach (coined as DivDR) to train several local experts on subsets of a training dataset. The paper is well written and well structured, even though it can benefit from a proof read. The qualitative experimental results are promising and demonstrate the efficacy of the proposed approach in clustering of data subsets and assignment of correct local expats. The impact on the bottomline performance in different settings (object detection, semantic segmentation, and so) is rather marginal. The paper has a coherent story, but lacks solid theoretical deep dive into the mechanics of DivDR.\n",
      "\n",
      "Major Remarks:\n",
      "- Any theoretical guarantees, or intuitive analyses, on why the alternating between solving eq(3) and reclustering (3) would work? At least try to discuss this by drawing resemblance with similar approaches in literature. \n",
      "\n",
      "- Given that there is still enough space, I suggest summarizing the steps involved in Fig 2 and 3 (Subsection 3.2) in the algorithmic form. \n",
      "\n",
      "- $K$ seems to be an important parameter. How to optimize or tune on this parameter? In Table 3, rather contradicting results are reported. Is it better to increase, decrease or optimize $K$, and how? \n",
      "   \n",
      "- Looking at the result on semantic segmentation, the standard (no-DR based) baselines do not represent the state-of-the-art performance on Cityscapes. That said, the improvement offered by DivDR-X is rather marginal (within 1%). And, the reduction in computational complexity in FLOPS is also on the marginal side. Even though the proposed approach does well in metric learning in the $\\mathcal{A}()$ space, the impact on the bottom-line performance seems to be marginal. How would you justify adopting DivDR for semantic segmentation, e.g.? Same can be said about Object detection results, btw. \n",
      "\n",
      "Minor modifications:\n",
      "- Another proof read would help to fix typos such as: \"evcaluate\" (Lines 66-67), and \"on subsets on subsets\" (Lines 102-3), \"of of accuracy\" (Line 178)  and so on. \n",
      "\n",
      "- Please define the acronyms for the first time: NAS (being neural architecture search), etc. \n",
      "\n",
      "- What is $n$ in Line 167.\n",
      "\n",
      "-  Please use references here \"As shown earlier, learning local experts can benefit performance both in terms of accuracy and computational cost\"\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the provided evaluation, focusing on the theoretical analysis of the proposed approach, the impact on performance in different settings, and the optimization of the parameter K.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Nice new idea to process video with GCNs\n",
      "I can only recommend to accept this paper. It is highly related to the workshop due to many reasons.\n",
      "1) Authors propose GraphVid. A new idea based on GCN to process video in an efficient way. \n",
      "2) Apart from being a new and nice idea, it can offers state-of-the-art performance.\n",
      "3) GraphVid uses not only opt-flow as prior knowledge but also many new specific data augmentation methods to extract information from the data in the most efficient way possible.\n",
      "4) GraphVid allows to make a better use of the data and reduce the computational burden.\n",
      "5) All ideas are support by experiments.\n",
      "6) The paper is very easy to read.\n",
      "... Many others\n",
      "Rating: 10: Top 5% of accepted papers, seminal paper\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposal of GraphVid, a new approach using GCNs to process video efficiently, and its potential to offer state-of-the-art performance, supported by experiments and specific data augmentation methods.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The idea presented in the paper is simple but can effectively speed up action recognition, therefore the paper should be accepted.\n",
      "Summary:\n",
      "\n",
      "- The authors propose an efficient graph video representation, GraphVid, that can be used for action recognition with reduced time and memory requirements. GraphVid results in a large efficiency gain without decreasing the performance. \n",
      "\n",
      "\n",
      "Positive points:\n",
      "\n",
      "+ The idea presented in the paper is interesting and can facilitate future work on action recognition. \n",
      "+ Paper experiments 4 augmentation strategies to improve the model performance. \n",
      "+ Thorough experiments and ablation study show GraphVid effectiveness.\n",
      "+ Competitive results on two action recognition benchmarks, Kinetics-400 and Charades. \n",
      "\n",
      "\n",
      "Negative points:\n",
      "\n",
      "- Relevant related work is missing. GCN have been used for video modelling before.\n",
      "1) Yan, Sijie, Yuanjun Xiong, and Dahua Lin. \"Spatial temporal graph convolutional networks for skeleton-based action recognition.\" Thirty-second AAAI conference on artificial intelligence. 2018.\n",
      "2) Thakkar, Kalpit, and P. J. Narayanan. \"Part-based graph convolutional network for action recognition.\" arXiv preprint arXiv:1809.04983 (2018).\n",
      "3) Korban, Matthew, and Xin Li. \"Ddgcn: A dynamic directed graph convolutional network for action recognition.\" European Conference on Computer Vision. Springer, Cham, 2020.\n",
      "4) Papadopoulos, Konstantinos, et al. \"Vertex feature encoding and hierarchical temporal modeling in a spatial-temporal graph convolutional network for action recognition.\" arXiv preprint arXiv:1912.09745 (2019).\n",
      "...\n",
      "\n",
      "- Writing is sloppy and overly complex in places. The text can be simplified by removing sentences such as \"to be defined hereunder\" (line 207), \"The following is a description of how we utilize the superpixels to construct our video-graph representation.\" (line 202-203)...\n",
      "\n",
      "- Spatial edges and figure 5. It is unclear whether the spatial graph for each frame is complete. I do not see an explanation about edge selection, however, it seems that in figure 3 only \"neighbouring super pixels\" are connected. \n",
      "\n",
      "- Missing algorithm time complexity for graph generation (i.e. extraction of super pixels, graph construction).\n",
      "\n",
      "- Prior knowledge incorporation (line 369): I do not see how optical flow is currently encoded in the graph video representation, especially due to the absence of coordinates. For example, if an object moves fast within consecutive frames, the distance between the respective super pixels over time might be larger than d_proximity. This way, information about the object motion (direction) is lost completely. \n",
      "\n",
      "\n",
      "Justification:\n",
      "The idea of using super pixels in combination with GCNs is, to my knowledge, novel. The experiments are thorough and show the effectiveness of the method. The paper needs some fixes in the text as indicated above. My rate is weak accept.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its proposed method of using super pixels and graph convolutional networks for action recognition, considering its potential impact and the thoroughness of the experiments.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Dynamic Image for 3D MRI image Alzheimer's Disease classification\n",
      "Summary\n",
      "This paper addresses the problem of 3D MRI volume segmentation of images collected from patients with Alzheimer's disease. The motivation for the work comes from automating the classification task for assigning labels such as cognitive unimpaired (CU) and Alzheimer’s disease (AD) to each patient based on the 3D MRI volume. The authors approach the problem by  leveraging a 3D to 2D conversion using dynamic images according to https://openaccess.thecvf.com/content_cvpr_2015/papers/Fernando_Modeling_Video_Evolution_2015_CVPR_paper.pdf and https://www.egavves.com/data/cvpr2016bilen.pdf and introducing an attention module in a transfer model with pre-training on ImageNet dataset. The evaluations include (a) matching feature dimensionality of the features extracted from four well-established architectures and the features coming from the dynamic image based conversion, (b) optimizing the steps in feature extraction and AI-based classification, (c) analyzing inclusion/exclusion of skull, and (d) comparing execution times when 3D vs 2D raw data are used as inputs into classifiers.\n",
      "Strengths:\n",
      "The classification framework is very interesting.\n",
      "The introduction of dynamic image and attention module is novel\n",
      "\n",
      "Weaknesses:\n",
      "The experimental dataset is very limited.\n",
      "The theoretical description is not very clear.\n",
      "\n",
      "Comments:\n",
      "Is there any reason (e.g., based on visual inspection) to believe that the features of 2D dynamic images are of the same nature as the features extracted from ImageNet?\n",
      "Line 129: what do you refer to when mentioning the ImageNet resolution? \n",
      "Line 171: why did you choose three activation functions and 1x1 convolutional kernels? \n",
      "The section 3.3 also did not explain the details in Fig 3. For example, why do you have in Fig 3 the same blocks but the tensor sizes are HxWx512 -> HxWx256 -> HxWx64? Shouldn’t the last tensor size be HxWx128?\n",
      "What implementation did you use for the CAM attention module?\n",
      "What is the method in dynamic image based conversion that you are using to create 110 x 110 x 3 (i.e., 3 features)? The original paper in https://openaccess.thecvf.com/content_cvpr_2015/papers/Fernando_Modeling_Video_Evolution_2015_CVPR_paper.pdf refers to learning rank machines but your paper does not mention this important detail.\n",
      "\n",
      "\n",
      "Minor comments:\n",
      "Fig 1 caption: you have one row of pictures but the caption refers to two rows.\n",
      "Why applying dynamic image-based 3D to 2D conversion is preferred over z-axis? Is there any motivation to prefer one of the three possible planes, i.e., sagittal vs transversal vs coronal plane?\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the paper on 3D MRI image Alzheimer's Disease classification, focusing on the strengths and weaknesses of the classification framework, the introduction of dynamic images and attention module, and the limitations of the experimental dataset and theoretical description.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Simple and effective method to improve AD classification\n",
      "Summary\n",
      "-------\n",
      "\n",
      "This paper presents a method for Alzheimer's Disease (AD) classification from\n",
      "3D MRI scans. In contrast to earlier approaches, the 3D scans are first\n",
      "converted into a 2D dynamic image, which is then processed by a 2D\n",
      "convolutional neural network. The network consists of a pre-trained (and\n",
      "fine-tuned) feature extractor, an attention module, and subsequent fully\n",
      "connected layers for the final classification. Results on MRI scans with\n",
      "stripped skulls demonstrate a significant increase compared to fully 3D\n",
      "baselines, albeit using only 20% of the time needed for training.\n",
      "\n",
      "Quality and Clarity\n",
      "-------------------\n",
      "\n",
      "The introduction, motivation, and technical description are very well written\n",
      "and easy to follow. The provided figures are helpful to understand the method\n",
      "and show qualitative results of the dynamic image generation.\n",
      "\n",
      "Originality\n",
      "-----------\n",
      "\n",
      "Using 2D dynamic images instead of the full 3D scan is a compelling idea\n",
      "(although already explored in other medical domains). The main contribution of\n",
      "this paper lies therefore in the subsequent use of pre-trained 2D feature\n",
      "extractors, which are enabled by the 2D input images. Furthermore, the authors\n",
      "investigate the usefulness of an attention module between the feature\n",
      "extraction and classification network.\n",
      "\n",
      "Significance\n",
      "------------\n",
      "\n",
      "The results demonstrate consistent improvements over several baselines and\n",
      "variations of the proposed model. On top of those improvements, the proposed\n",
      "model trains faster and requires less resources for prediction.\n",
      "\n",
      "The authors mention that \"there is potential for mobile applications\" (line\n",
      "360). I am not sure what this could look like in a clinical setting and suggest\n",
      "the authors elaborate if they want to make this point convincingly.\n",
      "\n",
      "My main concern for a clinical application is that the improved results seem to\n",
      "be achieved only on \"skull stripped\" MRI scans. From the paper, it is unclear\n",
      "whether this is a manual, semi-automatic, or entirely automatic process. I\n",
      "would appreciate if the authors could discuss this point in more detail to\n",
      "provide context about the amount of manual labor needed in the proposed\n",
      "pipeline.\n",
      "\n",
      "Pros\n",
      "----\n",
      "\n",
      "* well written\n",
      "* elegant architecture\n",
      "* thorough comparison to baselines and model variations\n",
      "* significant accuracy improvement\n",
      "\n",
      "Cons\n",
      "----\n",
      "\n",
      "* unclear how much manual intervention is needed for \"skull stripping\"\n",
      "\n",
      "Minor Comments\n",
      "--------------\n",
      "\n",
      "* title: capitalize \"image\" and \"classification\"\n",
      "* line 56: \"We\" -> \"we\"\n",
      "* line 144: \"association\" -> \"associated\"\n",
      "* line 283: \"choice\" -> \"choose\"\n",
      "* line 335: \"decrease if\" -> \"decrease in\"\n",
      "* Equation 4: What is $i$ running over? According to the text, $l$ and $I$ are label and image of a single sample.\n",
      "* Figure 4: It would be helpful to see same (or similar) images without skull in the same figure.\n",
      "* notation: $\\mathcal{R}$ vs $R$\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of our proposed method for Alzheimer's Disease classification from 3D MRI scans, including its impact on accuracy, training time, and resource requirements.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "An interesting moslty solid contribution with some problematic unclear aspects.\n",
      "-----------------------------\n",
      "Summary\n",
      "-----------------------------\n",
      "The authors present a novel method for the diagnosis of Alzheimer's disease from MRI volumes.\n",
      "The first compress the 3D volume to a 2D 'dynamic' image, which is then fed into a pre-trained features extractor.\n",
      "Finally, the resulting feature vector is subject to an attention mechanism and processed by a fully connected MLP to predict a probability for the disease. \n",
      "The method is evaluated against various baselines and achieves competitive results.\n",
      "\n",
      "-----------------------------\n",
      "Strengths\n",
      "-----------------------------\n",
      "\n",
      "- The paper is for the most part clearly written and structured.\n",
      "- The method outperforms its baselines, which are adequatly choosen as far as I can tell.\n",
      "\n",
      "-----------------------------\n",
      "Weaknesses\n",
      "-----------------------------\n",
      "\n",
      "My main concern is the unclear explanation of the dynamic image compression.\n",
      "This would not be a big issue, since they say they are using an existing method [3].\n",
      "However, looking at [3], I am not sure the equation they give (Eq. 3) corresponds to what is presented in [3] and if it is really correct.\n",
      "To be more precise, Eq 3 computes simply an averaged image using fixed weights \\alpha_t. It does not even make use of the feature representation.\n",
      "In contrast, the method in [3] averages the computed feature representations, as far as I understand.\n",
      "I am really not sure if this is just a typo in Eq 3 or if the authors are simply averaging the images with fixed weights and overselling it as a more sophisticated method.\n",
      "\n",
      "The mathematical notation is not very clear.\n",
      "In line 140 'd' is used as the dimension of a feature vector. In line 143 it is itself a feature vector.\n",
      "In Section 3.2 the 'I' denotes an input image, but in Section 3.3  the same symbol is used for the feature image produced by the network.\n",
      "Throughout the paper, various symbols are used for the set of real numbers.\n",
      "\n",
      "-----------------------------\n",
      "Final Recommendation \n",
      "-----------------------------\n",
      "\n",
      "Even though the paper seems highly relevant and generally solid, I am really concerned about the computation of the dynamic image.\n",
      "I thus see the paper as borderline.\n",
      "However, as I am not an expert on dynamic images, it might be that I simply misunderstood this part or that it can be explained as a typo.\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the clarity and correctness of the explanation of the dynamic image compression method in our paper, specifically in relation to the equation provided.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A new approach for annotating 3D+T cell tracking data\n",
      "Cell tracking is an important but challenging step for many biological research. By combining VR and eye tracking, the authors developed a new method for tracking cells in 3D and time. With the help of the two devices, users can generate cell trajectories by simply looking at a cell in a 3D movie. In the manuscript, detailed usage and user study data are provided. From what described, this new approach appears to be a great addition and can potentially make cell tracking annotation faster and enjoyable as stated by the authors.\n",
      "\n",
      "Major comments:\n",
      "- The manuscript is well written with details that are necessary, the limitations are clearly stated. \n",
      "- Although it is hard to grasp the actual user experience without trying the device, the user study results seem promising and reflect a good overall experience.\n",
      "- Although the authors provide user estimation of a 10x speed up with the new approach, it would be more convincing to actually measure the time for conventional methods and compare them with the new.\n",
      "- Since the user can only look at one cell at a time with the new approach, this will likely limit the overall annotation throughput. Instead of focusing on generating trajectories cell-by-cell, I would encourage the authors to explore ways to use the new hardware to fix and curate trajectories generated by automated algorithms. Similar to what is mentioned in the end of the manuscript, it would be also interesting to see how this can be combined with machine-learning algorithms.\n",
      "\n",
      "Minor comments:\n",
      "- The provided supplementary video is quite helpful to the understanding of the approach, it would be helpful also to mention the video in the manuscript.\n",
      "- When describing the hardware, could you provide detailed information about the eye tracking resolution? For users who are not familiar with the device, it is better to get some feeling about how accurate the eye tracking device is.\n",
      "- Could you also discuss how the cell size impacts the tracking performance? When the cell is big, should the user look at the center of the cell? Is there an optimal display cell size for the device?\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the provided information, focusing on the user experience, potential impact, and suggestions for further improvement.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting direction for tracking of cells in time-lapse video based on eye-tracking, with a small but promising user study.\n",
      "### Summary\n",
      "- The paper proposes an approach for the “manual” tracking of 3d+t datasets of biological cells that is carried out in virtual reality and cells are tracked via eye. The approach, that the authors call Bionick Tracking, offers an alternative to the established method of manually tracking cells (and lineage trees) on a 2D screen with mouse click.\n",
      "\n",
      "- The authors investigate the question whether using eye gaze and the movement in virtual reality can facilitate cell tracking. In order to be able to infer the cell track from the tracked eye gaze, they propose to use a graph-based algorithm. They carry out a study with seven users to test their set-up with regards to usability and accuracy.\n",
      "\n",
      "- They find that all users overall had a positive tracking experience. The users also stated that they believe that tracking with Bionick Tracking speeds up the tracking process.\n",
      "\n",
      "### Major strengths of the paper\n",
      "- The paper is understandable with a clear line of thought; Limitations are clearly stated.\n",
      "- The authors set-up a pipeline for eye-tracking of cells in time-lapse videos with a focus on using commodity hardware. With this focus, chances are higher that the setup will actually be adapted by other labs.\n",
      "- The authors carried out a user study with promising results including very positive feedback from the users.\n",
      "- The approach is novel and addresses important challenges in the cell tracking community (visualization of 3D time-lapse videos and annotation of cell tracks).\n",
      "- The authors provide a video that nicely explains the usage of their setup and their algorithm, which facilitates the understanding of the entire paper.\n",
      "\n",
      "### Major weaknesses of the paper\n",
      "- The extraction of the path from the gaze involves smoothing, but how to handle real jumps or datasets that are difficult to register? In this context, the ground-truth path has to contain real jumps that would potentially be smoothed out by the algorithm that they propose in the paper.\n",
      "- The study is limited as they only tested their setup on seven users, but this limitation is clearly stated.\n",
      "- There is no quantitative comparison of annotation time of conventional methods versus their method. The observation that their method is faster in tracking cells than conventional methods is based on the user’s opinion. This is an important finding, but should be backed up with further quantitative experiments.\n",
      "\n",
      "### Language\n",
      "Some sentences use vague or colloquial language:\n",
      "  - “The initial setting for the scale of the dataset is to make it appear about 2m big.” (about 2m big)\n",
      "  - “and a kind of Midas touch problem [10] remains” (a kind)\n",
      "  - “At the moment, the calibration of the eye trackers can still be a bit problematic” (a bit)\n",
      "  - “One could imagine just having one or two eye tracking-enabled HMDs as an institute” (One could imagine just….)\n",
      "\n",
      "Unclear sentences and minor mistakes\n",
      "- Line 42: \"The 3D images the lineage trees are usually created based on fluorescence microscopy images.\"\n",
      "Unclear sentence;\n",
      "- Line 94: Unclear sentence, please split into two sentences.\n",
      "- Line 129: \"The occur when following a stimilus\" → They occur when following a stimulus\n",
      "- Line 391: \"This corresponds to distances larger than double the standard deviation of all distances the hedgehog.\"\n",
      "Unclear sentence\n",
      "- Line 539: \"Our method does not only accelerates the process, but makes\"; Incorrect grammar (--> Our method does not only accelerate the process …)\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the paper's approach for tracking cells in time-lapse videos using eye-tracking in virtual reality, and discuss the strengths and weaknesses of the study design and results.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Simple and effective U-Net feedback extension\n",
      "Summary\n",
      "-------\n",
      "\n",
      "This paper presents a feedback mechanism for U-Nets, which re-uses the output\n",
      "of the U-Net for a second round of processing. For the incorporation of the\n",
      "output into an earlier feature map of the U-Net, the authors propose two\n",
      "attention mechanisms (source-target-attention and self-attention). On an\n",
      "electron microscopy dataset of neural tissue, experiments demonstrate\n",
      "consistent improvements of the self-attention version of the proposed method\n",
      "over several baselines, including a vanilla U-Net and a feedback U-Net. In\n",
      "further ablation studies, the authors investigate the two proposed attention\n",
      "mechanisms, the choice of the injection point of the output, and the usefulness\n",
      "of the second round of processing.\n",
      "\n",
      "Quality and Clarity\n",
      "-------------------\n",
      "\n",
      "The technical description of the method is very clear and the provided figures\n",
      "helpful.\n",
      "\n",
      "Originality\n",
      "-----------\n",
      "\n",
      "Reusing the output of a U-Net for a second round of processing is not an\n",
      "entirely new idea (as acknowledged by the authors in the Related Work section).\n",
      "The main contribution here is therefore the addition of an attention mechanism\n",
      "and the re-use of the same weights for the second round of processing.\n",
      "\n",
      "Significance\n",
      "------------\n",
      "\n",
      "The experimental evaluation is thorough (albeit on only a single\n",
      "dataset) and addresses key questions about the proposed method. Qualitative\n",
      "results (especially the attention maps generated by the two proposed\n",
      "mechanisms) are helpful to understand the contributions of the method.\n",
      "\n",
      "Pros\n",
      "----\n",
      "\n",
      "* clear presentation\n",
      "* elegant architecture\n",
      "* convincing results\n",
      "* thorough analysis of method components in ablation study\n",
      "\n",
      "Cons\n",
      "----\n",
      "\n",
      "* evaluated on only one dataset\n",
      "\n",
      "Minor Comments\n",
      "--------------\n",
      "\n",
      "* line 44: \"cell image segmentation is a difficult task because [...] there is not regularity compared to other datasets such as automatic driving\" I would personally argue that the opposite is true\n",
      "* line 420: \"menbranes\" -> \"membranes\"\n",
      "* line 437: \"firrst\" -> \"first\"\n",
      "* line 487: \"We\" -> \"we\"\n",
      "* no \".\" after \"Equation\", \"Table\", or \"Figure\"\n",
      "* line 71: \"we evaluate the proposed method on two kinds of cell image datasets\" results are only presented on one dataset\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the proposed method in our paper, including the clarity of the technical description, the originality of the approach, the significance of the results, and any potential limitations or improvements.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Thoroughly-investigated addition of feedback attention to U-Net segmentation\n",
      "### Quality\n",
      "This work approaches the addition of a feedback attention mechanism into a U-Net based segmentation method with commendable rigour. While the authors only demonstrate their method on one dataset, they do so in a methodical manner whereby the carefully validate what sort of feedback works best, and also offer explanations as to why this is the case. The authors also validate which layers of the network work most effectively for their chosen network architecture, and that the improvement in segmentation performance is indeed due to the addition of feedback attention rather than just from running data through the U-Net twice.\n",
      "\n",
      "The figures are generally good quality. The attention maps in Figure 4 are particularly striking and are a good demonstration of the difference between the two proposed feedback attention methods introduced here.\n",
      "\n",
      "I would have been very interested to see the authors look closer at the attention maps and performance for the mitochondria and synapse classes, as these classes display the most striking segmentation accuracy improvement over the other methods compared. It would also have been interesting for the authors to have discussed cross-applicability of this approach to other microscopy modalities, for example digital pathology data.\n",
      "\n",
      "### Clarity\n",
      "It took me a few reads of the paper in order to sufficiently understand the method, and there are quite a lot of grammatical errors and typos throughout.\n",
      "\n",
      "I personally found that the Query/Key/Value terminology was quite clunky and detracted from my ability to understand section 3.2. For example, the phrase ‘the $i$th Query’s impact’ (line 255) threw me for a while, as I was unclear which dimension (C, H, W) $i$ was indexing. This may well be my own unfamiliarity with the field, but being slightly more explicit in the explanation of the indices would have helped me understand much quicker.\n",
      "\n",
      "It also felt like there was too much unnecessary repetition between the explanations of the Source-Target-Attention and Self-Attention methods. Again, if I understand correctly, the Source-Target-Attention and Self-Attention methods are identical except for the ‘Query’ being identical to the ‘Key’ in the latter case? If so, this could have been displayed in a more compact mathematical way.\n",
      "\n",
      "### Originality\n",
      "This work appears to be the first instance in which attention is integrated into a U-Net via a feedback mechanism. I am not an expert in this field, but a cursory literature search retrieved a [paper discussing the use of attention in medical image segmentation via attention gates](https://arxiv.org/abs/1804.03999) – perhaps this should have been mentioned as ‘Related Work’\n",
      "\n",
      "### Significance\n",
      "High-quality semantic segmentation is an undoubtedly significant and impactful challenge for microscopy. The technical merit of this work has been made clear, but I think that the authors could have expanded on the significance of the improved performance in the field of cell imaging. For example, the conclusion does not mention the application at all, and more dwells on further technical adaptations, which feels a little short-sighted. For that reason I also have concerns regarding deployment of this technique and ensuring that biologists are actual able to reap the benefits for their research.\n",
      "\n",
      "### Pros\n",
      "* Excellent technical rigour demonstrated in investigating novel method through ablation studies\n",
      "* Significant increase in segmentation performance achieved with this method\n",
      "\n",
      "### Cons\n",
      "* The sections describing the generation of attention maps were quite difficult to follow and understand\n",
      "* While the performance is very good, the authors do not discuss a route by which this method can actually be used for the benefit of the application demonstrated.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on the thorough investigation of adding feedback attention to a U-Net segmentation method, including the validation of different feedback methods and the analysis of the impact on segmentation performance.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting practical method but questionable concepts and results\n",
      "The paper addresses the problem of denoising of microscopy images and the fact that traditional methods as well as various recent supervised deep learning methods make assumptions about the noise statistics that may not hold. The authors advocate the use of self-supervised deep learning methods, as high-quality paired training data is often not available to properly train supervised methods. But they observe that self-supervised methods typically produce high-frequency artifacts and achieve inferior results compared to supervised methods. To remedy this, they propose to exploit the fact that the images are usually diffraction-limited, by adding a convolution with a point-spread function model to an existing self-supervised deep learning-based denoising method (Noise2Void) and training it accordingly. Experimental results on a range of microscopy images illustrate the potential of the proposed method.\n",
      "\n",
      "This paper is well written and the presentation is easy to follow. While the idea is interesting, I am not convinced it is theoretically sound. As explained (in Section 3.3 and also in Section 3.4), the Noise2Void method estimates the image s. Since s=z*h (Section 3.1), this makes it a denoising method, not a deconvolution method, and that is indeed how the method was designed. Thus, simply processing the estimated s by convolution with an assumed PSF model h (Figure 1 and Section 3.4) is questionable. Of course, doing so will force Noise2Void to behave more like it, and you can claim to \"view the direct output before the convolution as an estimate of the phantom image ... i.e. an attempt at deconvolution\" and get some visually pleasing results, but that does not make the approach theoretically right. Rather, it seems a practical trick that apparently happens to work to some extent.\n",
      "\n",
      "Other specific comments:\n",
      "\n",
      "- Section 4.1: Synthetic data is generated using a Gaussian PSF and pixel-wise additive Gaussian noise, but that is not realistic. As the authors admit elsewhere (multiple times), the dominant sources of noise are Poisson photon noise and Gaussian readout noise (Sections 1 and 3.1).\n",
      "\n",
      "- Section 4.2: \"Our implementation is based on the pytorch Noise2Void implementation from [10]. We use the exact same network architecture, with the only difference being the added convolution with the PSF at the end of the network.\" This, combined with the above major concern, make both the theoretical and the practical contribution of the paper rather limited.\n",
      "\n",
      "- In Section 2 many methods are discussed but the comparison in Figure 2 is limited to only N2V (and a variant). Are there really no available software implementations of other methods to compare with?\n",
      "\n",
      "- Section 4.3: The only quantitative measure used is PSNR. It is tricky to make the entire quantitative comparison hinge on a single measure that is known to be questionable. It would be good to also evaluate using other measures, such as SSIM.\n",
      "\n",
      "- The authors claim \"considerable visual improvements\" (Figure 2) and even \"stunning visual improvement (Section 4.4). These are subjective statements that in my opinion are not supported by the provided evidence.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the theoretical soundness, practical contribution, and visual improvements of our proposed method for denoising microscopy images using self-supervised deep learning and convolution with a point-spread function model.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Theoretically and conceptually very strong, but I have concerns regarding the performance\n",
      "In this work, the authors present an extension to the Noise2Void denoising framework that incorporates convolution with a point spread function in order to better approximate the image formation process in microscopy.\n",
      "\n",
      "### Quality\n",
      "The premise of the work is very solid and represents a shift towards making denoising approaches specific to bioimaging data rather than just the direct translation of computer vision techniques originally formulated for e.g. photographs, video data. This is an important conceptual advancement in the field.\n",
      "\n",
      "The performance of the new method is assessed in comparison to a selection of other denoising frameworks, and when measured by the PSNR metric is shown to out-perform comparable self-supervised methods. However, I find the general reliance on the PSNR as a performance assessment to be problematic, as this does not take into account the structural content of the images post-denoising. For example, in Fig. 2 there appears to be some structural discrepancies in the ‘Flywing’ data. While the ‘N2V (conv.)’ image has a lower PSNR than ‘ours’, the visual agreement between the N2V (conv.) and ground truth data appears better than that between ours and ground truth. As a sanity check for myself, I thresholded and skeletonised these images and while the N2V (conv.) and ground truth skeletons matched well, the ‘ours’ skeleton deviated substantially at the central junction. Apologies if this seems facetious, but I think it underlines the necessity for another measure of performance, especially as the ultimate goal of denoising microscopy images is to produce a better baseline from which quantitative measurements of structure can be made (rather than just a visually pleasing image).\n",
      "I would suggest that the authors remove the phrase ‘stunning visual improvement’ (line 443) as this is rather subjective – for example, using the positivity constraint in the mouse actin deconvolution does not improve the prevalence of patterned noise (which can be seen if the images are Fourier-transformed).\n",
      "\n",
      "Section 4.5, wherein the effects of the PSF size are investigated, seems a little abrupt. Although the PSF size parameter is clearly critical for the performance of the method, this section would have benefitted from additional discussion of e.g. a non-uniform PSF throughout the image or tolerance to the PSF deviating from a Gaussian function, as these are both relevant considerations in real-life microscopy applications.\n",
      "\n",
      "### Clarity\n",
      "The paper is overall incredibly clear and I managed to understand the majority of what was written on my first pass (in contrast to my general experience reading papers in this field).\n",
      "\n",
      "The repeated use of the phrase ‘diffraction-limited’ is somewhat misleading and may even be doing the work a disservice, This phrase is normally used in the context of referring to conventional widefield or confocal fluorescence imaging data; however there is no reason that the application of this method is limited to this regime. For example, given that the condition of a point spread function whose spatial distribution can be approximated by a Nyquist-sampled Gaussian distribution of known width, this approach could be readily applied to some super-resolution data such as STED images. For this reason, the authors may wish to reconsider the use of the phrase ‘diffraction-limited’ although this is just a suggestion.\n",
      "\n",
      "### Originality\n",
      "The work described here is a very similar concept to that described in [Kobayashi et al (2020)](https://arxiv.org/abs/2006.06156). However the authors acknowledge this work in their discussion and given that there was less than one month between the submission of the work by Kobayashi et al and the BIC submission deadline I do not see this as shortcoming in originality (rather, unfortunate timing). Setting aside the paper by Kobayashi et al, this paper displays interesting conceptual novelty. In comparison to the paper by Kobayashi et al, this work (in my opinion) is much better focused toward the application of fluorescence microscopy and is reported in such a way that I feel it is more likely that a microscopist would preferentially use the method presented here. \n",
      "\n",
      "### Significance\n",
      "The overall conceptual significance – integrating knowledge about the image formation process into the denoising method – is high, as I mentioned above. I am still not entirely convinced, however, that there is a *significant* increase in performance, as the PSNR values represent fairly marginal gains over to Noise2Void (alongside my above concerns regarding structural fidelity).\n",
      "\n",
      "### Pros\n",
      "* The paper is very well written, explained, and presented\n",
      "* The theoretical benefits of the approach are substantial, and again the explanation of these is well-integrated into the paper\n",
      "* The discussion of the paper shows that this work is a starting point and that the authors have thought about concrete ways to extend and improve it going forward. \n",
      "\n",
      "### Cons\n",
      "* The authors have not convinced me from a quantitative point of view that the results are superior to existing self-supervised methods.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the performance and significance of our paper, specifically in terms of its denoising method for microscopy images and its comparison to existing self-supervised methods.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "DenoiSeg: Joint Denoising and Segmentation\n",
      "Summary\n",
      "This paper addresses the problem of image segmentation and denoising when a very few training segmentation masks are available. The problem is motivated by the need to train neural networks with a high capacity (millions of coefficients) while having only tens of ground truth segmentation masks. The authors approach the problem by combining the self-supervised denoising task with the segmentation task in one neural network optimized using a joint loss. The joint loss is a weighted contribution of denoising and segmentation loss contributions. The authors develop the joint denoising and segmentation framework as an extension to the Noise2Void work accessible at https://openaccess.thecvf.com/content_CVPR_2019/papers/Krull_Noise2Void_-_Learning_Denoising_From_Single_Noisy_Images_CVPR_2019_paper.pdf\n",
      "\n",
      "Strengths:\n",
      "The practical value of training a segmentation model with very few ground truth segmentation masks is very high.\n",
      "The novelty lies in formulating a joint loss and delivering denoised images as well as segmentation masks.\n",
      "\n",
      " \n",
      "Weaknesses:\n",
      "The paper is missing an assumption paragraph which is misleading for a reader who would like to use this technique.  For example, one of the assumptions is the i.i.d. property of the noise. Another assumption is that the very few ground truth segmentation masks must be representative of the dataset. The authors showed the performance on three datasets that have spatially distributed very similar pattern/content and thus sampling is very easy. \n",
      "\n",
      "Comments:\n",
      "How did the authors decide on the size of the blind spot patches? The paper focused on Noise2Void is using patches of 64 x 64 pixels while this work is using patches of 128 x 128 pixels.\n",
      "Lines 249 – 257: The authors refer to patches and then to images. Please, verify the terminology\n",
      "Lines 314, 345-350: It is not clear how delta is computed. Is it AP(alpha=0.2) – AP(alpha=0.5) or AP(alpha=0.2) – AP(alpha=0.7) compared to AP(alpha=0.5)? Please, clarify. I could not follow the Figure 6 vertical axis (you might include an equation for delta).\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of our paper in addressing the problem of image segmentation and denoising with limited training segmentation masks, and provide feedback on any assumptions or clarifications that should be included.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Potentially VERY useful public dataset, some questions regarding neglected related work\n",
      "While the submitted manuscript is indeed aiming a a joint denoising and superres task, there is quite a body of work that was not included in the related work sections or in the comparative parts of the paper (CARE, N2V, PN2V, etc.).\n",
      "\n",
      "I have the feeling that the utility of the data should be valued higher than the incompleteness of comparisons, but if the camera-ready version could at least acknowledge the broader existing literature it would certainly be a positive.\n",
      "\n",
      "With respect to the data, it appears that the availability of it is still pending to some degree. From the GitHub repo of the paper:\n",
      "```\n",
      "To those who have cloned or forked our repository, we now removed the png data and are working with the raw data pre-processed only with a single global z-score normalization. All the consequent modifications are being made. The full raw data will be made public very soon, and pretrained models (with raw data) will be made available by mid July.\n",
      "```\n",
      "\n",
      "In my opinion it would be highly desirable to bring the work on this public dataset to completion together with the submission of the camera-ready version.\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the completeness of the related work section and the comparative analysis in the paper, and provide feedback on the availability of the dataset and the importance of making it public.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "An extensive new dataset and a new state-of-the-art algorithm for denoising and super-resolution.\n",
      "The authors address the problem of denoising and image resolution improvement in microscopy. A new public benchmark dataset is presented, much more extensive than the currently available alternatives.The authors perform a detailed evaluation of the existing denoising and super-resolution algorithms and finally propose their own which handles both tasks and out-performs the others. All code and data is available.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness and novelty of our paper, which introduces a new algorithm for denoising and super-resolution in microscopy, along with a comprehensive evaluation using a newly created benchmark dataset.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "What leads to generalization of object proposals?\n",
      "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      " In this paper, authors propose guidelines to build proper datasets for object proposals that can offer good generalization when training models on them. Concretely, the paper introduces the idea of prototypical classes as the sufficient and necessary classes to achieve good generalization. To proof this, they conduct a series of experiments on OIV4 and COCO datasets. As oracles, they choose Faster RCNN and RetinaNet. \n",
      "\n",
      "2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      " -\tThe paper is very well written. Story is very easy to follow.\n",
      " -\tGeneralization typically has been study from the model perspective. However, interpreting the problem from the data perspective is very interesting.\n",
      " -\tAlthough authors focus on data, they also offer a study of what is happening with the models to validate the results.\n",
      " -\tIn particular, prototypical classes seems pretty interesting.\n",
      "\n",
      "3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      " -\tThe effect of space granularity has a weird interpretation. The model used for this experiment is class specific Faster RCNN. Have the authors tried the class agnostic version?\n",
      " -\tVisual and Semantic diversity seems obvious. It would be interesting to study also the amount of samples, as well as how similar they are.\n",
      "\n",
      "\n",
      "4. [Overall rating] Paper rating.\n",
      "\n",
      " 7\n",
      "\n",
      "5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "\n",
      " The whole paper is interesting. Even more from the efficiency perspective. Prototype classes play an important role. \n",
      "\n",
      "6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the strengths and weaknesses of the paper, focusing on the significance of the proposed guidelines for building datasets that lead to good generalization of object proposals.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Prototype classes can be sufficient to localize in object detection\n",
      "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      "The authors propose to learn object localizations using only prototype classes. They explore what defines prototype classes and experiment with many ablations and hyperparameters to their method.\n",
      "\n",
      "[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      "Powerful idea; clear definitions; practical modeling choices for determining prototypical classes; extensive experimentation.\n",
      "\n",
      "[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      "Marginally related to visual inductive priors.\n",
      "\n",
      "[Overall rating] Paper rating: Accept\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the paper based on its proposal to use prototype classes for object localization, including the clarity of the definitions, practical modeling choices, and the extent of experimentation.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Unsupervised Image Classification for Deep Representation Learning\n",
      "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      "Authors in this paper described a modification of the embedding clustering method (DeepCluster) presented in [2]. Different from DeepCluster, this work proposes a unified pipeline, where clustering is directly performed using an image classification task. Experiments show first that their method achieves same or better performance than that of DeepCluster.\n",
      "\n",
      "2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      "The authors found out that the embedding clustering phase in the previous method DeepCluster [2] can be avoided and its two phases can directly be performed using a classification task.\n",
      "The method is pretty simple but it obtains state-of-the-art results.\n",
      "\n",
      "3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      "The paper seems a bit difficult to read. I found it a bit difficult to follow the story.\n",
      "The whole paper is built on top of the work of [2], when considering the results, it could be described as a contribution to the field by itself.\n",
      "Although authors propose to use different visual data augmentation (at the beginning only random crop and then further extending it with SimCLR techniques), and claim efficiency as they avoid storing embeddings, the work does not seem to be very much related to study visual inductive priors.\n",
      "\n",
      "4. [Overall rating] Paper rating.\n",
      "\n",
      "6.\n",
      "\n",
      "5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "\n",
      "With a simpler method, the paper shows good results. However, readability, structure and out of scope possibility lower the score. \n",
      "\n",
      "6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      "I suggest the authors to increase the size of Fig. 1, 2 and 4.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its clarity, contribution to the field, and the strength of its results.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Simple and effective method for unsupervised feature learning\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The paper proposes a simple method for unsupervised deep clustering by iteratively (1) generating pseudo-labels by performing a forward pass through a CNN and (2) training the CNN using the generated pseudo-labels. The method is evaluated on ImageNet and performs competitively with other unsupervised learning methods.\n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "* The method is surprisingly simple and seems to perform competitively with clustering in latent space, which is much more computationally expensive.\n",
      "* The paper is well written and easy to understand.\n",
      "* The performed experiments are sound and demonstrate the effectiveness of the method.\n",
      "\n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "* The bold numbers in Table 3 are rather misleading as they do not actually denote the best performance.\n",
      "\n",
      "#### 4. [Overall rating] Paper rating\n",
      "* 8: Top 50% of accepted papers, clear accept\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "The method is simple and effective and the paper is well written.\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the effectiveness and simplicity of our proposed method for unsupervised feature learning in comparison to other methods in the field.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Distilling Visual Priors from Self-Supervised Learning\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The method has two stages: (i) a teacher network is trained with contrastive learning to obtain feature representation, (ii) the knowledge of the teacher network is transferred to student network by distillation, in the meantime, the student network is also finetuned with labels. \n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "- 2-stage method\n",
      "- Using a margin to overcome the small bank size problem \n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "- No conclusion and discussion section.\n",
      "\n",
      "\n",
      "#### 4. [Overall rating] Paper rating\n",
      "7\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n",
      "\n",
      "\n",
      "#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      "- How is the margin value chosen? In the text, it is given as 0.6 but in the table, the value is 0.4.\n",
      "- Related works: Why is there any margin loss part?\n",
      "- Missing citations:\n",
      "\t> L.29:\".. simply memorize the dataset and can not generalize well to unseen data..\"\n",
      "\t> L.31:\"..some works..\" (only given one)\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Evaluate the paper on \"Distilling Visual Priors from Self-Supervised Learning\" based on its strengths and weaknesses.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting method, well-written paper\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The paper proposes to use contrastive pre-training to construct a visal prior (i.e. the model weights) and subsequently initializes both a teacher and student model with the pre-trained weights to finetune the student network on the dataset while  imposing an additional distillation loss between the frozen teacher and unfrozen student networks.\n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "* The paper is clear and is easy to understand\n",
      "* The method is interesting and seems to perform well\n",
      "* The ablation studies clealy show which portion of the performance gain can be accredited to the proposed method and which portion is due to additional tricks, such as data augmentation.\n",
      "\n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "* It would have been nice to include experiments on an additional (toy) dataset such as MNIST or SVHN to show that the method generalizes to other tasks.\n",
      "* Conclusion section is missing; the paper is ending rather abruptly.\n",
      "\n",
      "#### 4. [Overall rating] Paper rating\n",
      "8: Top 50% of accepted papers, clear accept\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "The method is interesting and seems to perform well. In addition, the paper is well-written. Please consider extending the paper with a \"Conclusion\" section.\n",
      "\n",
      "#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "* What is $\\tau$ in equation (1)?\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the paper based on its clarity, the strength of the proposed method, and the inclusion of ablation studies, and provide a rating and justification for the rating.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The paper proposes a method which constrains search space by using question type information as prior information and utilizes different attentions to obtain better results.\n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "- Search space constraints according to question types\n",
      "- Using multiple attention mechanisms\n",
      "- Performance and better attention maps\n",
      "\n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "- Question types are prior knowledge yet not visual prior knowledge.\n",
      "\n",
      "#### 4. [Overall rating] Paper rating\n",
      "7\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n",
      "\n",
      "\n",
      "#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      "- Fig.3: Some of the notations are not visible. In addition, you can show modules with dashed areas with different colors.\n",
      "- Table 4: Why did you make your results as bold?\n",
      "- The effectiveness of multi-hypothesis interaction learning proposed\n",
      "in Section 3.3: The explanation in the subsection makes confusion because the order of showing the results. It can be better to have a paragraph for each result (table).\n",
      "\n",
      "- Limitations and failing cases.\n",
      "- Time and memory usage\n",
      "- Will you share the code and models?\n",
      "Typos:\n",
      "- L80: constraint\n",
      "- L.436: not fitting in the line\n",
      "- L.590:modality\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Evaluate the paper on \"Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering\" based on its strengths and weaknesses.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "An ensemble of VQA methods with prior knowledge on question types\n",
      "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      "The authors propose a VQA method that jointly optimizes question answering and answer type classification using an ensemble of existing attention-based VQA methods. Prior information about the answer types is integrated into a weighted loss. Modalities are fused by first merging visual and linguistic features, then merging in question type features.\n",
      "\n",
      "[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      "The authors use prior information on answer types while allowing the model to account for outlier questions. The authors perform extensive experiments to show all aspects of their works.\n",
      "\n",
      "[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      "It is not clear how significant the individual performance increases of each contribution are. Crucial design choices for the VQA loss are not motivated (e.g. where to integrate awareness matrix). Presentation needs work (typos, grammar, typesetting).\n",
      "\n",
      "[Overall rating] Paper rating: Accept (tentative rating, subject to revision until deadline)\n",
      "\n",
      "[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      "- Please review the paper for typos, incorrect grammar and typesetting. Specifically lines 40 (grammar), 114, 178, 260 \"constraints\", 264, 287 (capitalizing VQA), 389 \"standardly\", 436 end of line, 590 \"modaality\"\n",
      "- Table 4: your method is not the highest (LXMERT is), so please do not use bold numbers. See also the claim on line 594.\n",
      "- Algorithm 1 should be expressed in math, like the other equations.\n",
      "- Source for claim on line 153\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate our paper on an ensemble of VQA methods with prior knowledge on question types, focusing on the strengths and weaknesses of our approach.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Simple, effective and very well discussed\n",
      "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      " This paper proposes to adapt several data-level augmentation techniques from image field to videos. To study the effects of such techniques, authors conduct experiments on the action recognition topic. Results showcase that some of the proposed techniques helps improve the performance. Additionally, they described their participation in the 1st VIPriors Action Recognition Challenge.\n",
      "\n",
      "2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      " -\tRegarding the results, the paper is really well motivated and clearly understandable. The story is clear and is very easy to follow.\n",
      " -\tAuthors clearly described how they have adapted all the techniques to video.\n",
      " -\tThe results are marginal (or even worse than baseline) in some situations. However, I like the fact that authors recognise it and discuss it in Section 4.6, suggesting some interesting reasons.\n",
      "\n",
      "3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      " -\tResults are marginal (or even worse than baseline) for some augmentation techniques.\n",
      " -\tAuthors talk always about temporal distortions. However, it seems that basically they apply frame distortions during a concrete temporal window. For me, this is not a temporal distortion. Authors can check the paper “Learning Temporal Action Proposals With Fewer Labels”. In this paper, data augmentation on videos is performed by modifying the temporal information accumulated by the features. Concretely, they use time warping and Time masking. \n",
      "\n",
      "4. [Overall rating] Paper rating.\n",
      "\n",
      " 7\n",
      "\n",
      "5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "\n",
      " Despite weaknesses, the paper is well written, and very well discussed.\n",
      "\n",
      "6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      " - Line 198: augmentation operation(s).\n",
      " - Line 350: consists (of)\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the strengths and weaknesses of the paper, providing justification for your rating.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Good execution of a simple idea\n",
      "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      "The authors extend popular data augmentation methods to the temporal domain in a straightforward manner. Experiments show minor improvements over the spatial data augmentations.\n",
      "\n",
      "[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      "Simple, powerful idea; simple implementations; clear explanations; self-critical in analyzing the magnitude of their contribution; extensive evaluations.\n",
      "\n",
      "[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      "Marginally related to workshop topic.\n",
      "\n",
      "[Overall rating] Paper rating: Strong accept\n",
      "\n",
      "[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      "- Grammar: lines 40, 254, 521 (whole paragraph needs revision)\n",
      "- Typos: line 130 \"squre\", 141 \"researches\"\n",
      "- Figure 2 could have been pseudocode\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the strengths and weaknesses of our paper, focusing on the execution of our simple idea and its significance, as well as any potential improvements or revisions you would suggest for the camera-ready version.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Injecting Prior Knowledge into Image Caption Generation\n",
      "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      " The paper tries to mitigate overfitting and generating easy captions by introducing prior knowledge from the dataset during training. To this end, authors propose to add visual-semantic relation prior knowledge by defining a series of Latent Topics, and semantic prior knowledge by training a Seq2seq module with the text. While the former is introduced in the training procedure as a self-attention with image region features, the latter is utilized to remove visual biased on semantic structures. Apart from increasing results of state-of-the-art approaches, they demonstrate that with their approach, image captioning models can rely on less data when training.\n",
      "\n",
      "2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      " -\tThe paper is easy to read. Ideas are easy to follow.\n",
      " -\tIt is very well motivated.\n",
      " -\tBenefits of both modules (CLTA and SAE Regularizer) are clearly demonstrated in the experiments.\n",
      " -\tThe implementation is very well explained in detail.\n",
      " -\tThe benefits of adding prior knowledge (visual and semantic) is showed.\n",
      " -\tAdditionally, authors demonstrate the relevance of prior knowledge as it allows to train models with less data.\n",
      "\n",
      "3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      " -\tAlthough the improvement exists, in some situations it is marginal.\n",
      "\n",
      "4. [Overall rating] Paper rating.\n",
      "\n",
      " 9\n",
      "\n",
      "5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "\n",
      " Good paper. Well written, well motivated, simple method and positive results. On top of that, very much in line with the workshop.\n",
      "\n",
      "6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate our paper on injecting prior knowledge into image caption generation, focusing on the clarity of the ideas, the significance of the experiments, and the overall strength of the paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Powerful implementation of prior knowledge into image captioning models\n",
      "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      "The authors propose two adding to prior knowledge based modules to image captioning models. One module uses prior knowledge on the association of keywords to image regions. The other module regularizes generated captions to be more realistic.\n",
      "\n",
      "[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      "Simple but powerful ideas; clear methods; topical submission; excellent writing.\n",
      "\n",
      "[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      "By nature of the method experimental settings are complex; \n",
      "\n",
      "[Overall rating] Paper rating: Strong accept\n",
      "\n",
      "[Confidence] 4/5\n",
      "\n",
      "[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      "- Grammar: lines 40, 189\n",
      "- Formatting: line 221\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the paper based on its implementation of prior knowledge into image captioning models, including the strengths and weaknesses of the approach.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting and novel idea\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The paper proposes a novel, computationally efficient artificial \"strong neuron\" for sparse neural networks that combines low-level features through AND and OR operations and a corresponding training strategy. The resulting networks are evaluated on the GTSRB (German traffic sign) and SVHN datasets and show competitive results in both classification error and adversarial stability.\n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "* The proposed \"strong neurons\" are definitely a novel and interesting idea and the motivation is clearly explained through Figure 1.\n",
      "* The method seems effective on the evaluated datasets.\n",
      "* The paper is generally well written and easy to follow.\n",
      "* Code is made available which will hopefully spark interest for research into alternatives to traditional CNNs.\n",
      "\n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "* The optimization method is based on a lot of heuristics to simplify the otherwise intractable brute force approach. Although the optimization method seems effective (based on the performance), it is hard to evaluate the possible negative effects of these simplifications on the model performance.\n",
      "* The training strategy not allowing to use mini-batches seems like a major drawback for training on large-scale or high resolution datasets like ImageNet or CityScapes.\n",
      "\n",
      "#### 4. [Overall rating] Paper rating\n",
      "* 8. Top 50% of accepted papers, clear accept\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "The authors have proposed a novel and interesting alternative to traditional CNNs and have shown its effectiveness.\n",
      "\n",
      "#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "* Combine multiple references into same brackets, i.e. ([1], [2], [3]) should be [1,2,3].\n",
      "* What do $k$ and $i$ represent in equation (1) and line 125/126?\n",
      "* The paper would be easier to read if a conclusion would be included in the image captions (i.e. what point is the image trying to make).\n",
      "Rating: 8: Top 50% of accepted papers, clear accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the paper based on its novel and interesting idea of using \"strong neurons\" for sparse neural networks, its effectiveness on the evaluated datasets, and the potential drawbacks of the optimization method and training strategy.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "A novel approach to counter recognition\n",
      "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      "The authors propose a new type of neuron designed for contour recognition. They detail an extensive algorithm for training these neurons without back-propagation. They show their method can outperform convolutional methods in low FLOWs regime and is more robust against adversarial attacks.\n",
      "\n",
      "[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      "Creative approach to a hard problem (replacing the convolutional neuron); builds on related work where possible; solid experiments.\n",
      "\n",
      "[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      "Many heuristics are needed to optimize the strong neuron, while the effect of the heuristics are not analyzed or explored. In the same vein, an ablation study, including the effects of the unsupervised backbone, would have helped to make the work more solid.\n",
      "\n",
      "[Overall rating] Paper rating: Accept\n",
      "\n",
      "[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      "- Lines 156-157, 189-190 are unclear to me\n",
      "- Section 7.1 addresses the reader as \"you\". Use of more formal \"one\" would be advised.\n",
      "- Change brackets to separate sentences (e.g. lines 370-371)\n",
      "- Minor typos: lines 490 \"shalow\"\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the strengths and weaknesses of the paper, including any suggestions for improvement or clarification.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Unsupervised Learning of Video Representations via Dense Trajectory Clustering\n",
      "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      "This paper addresses the task of unsupervised learning of video representations for action recognition. Following current trend for image representation learning, authors propose first to adapt [46] and [49] for video instance recognition and local aggregation respectively. Since results prove that these methods do not capture motion, which is clearly important for action recognition, they proposed to force a 3D ConvNet to learn embeddings from IDTs. Experiment results justifies their framework.\n",
      "\n",
      "2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      "The whole paper is well written and motivations are very well stated.\n",
      "Although authors obtained promising results by correctly adapting [46] and [49], they went further and analyzed errors.\n",
      "\n",
      "3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      "A strong hypothesis of the paper is that motion is important to recognize actions in videos. And current 3D convnets models cannot learn it, while they tend to only learn appearance. For this reason, authors use IDTs.\n",
      "This hypothesis seems unfair since 3D convs can be trained with flow, or even two-stream.\n",
      "Have authors try their Video IR and Video LA using directly optical flow, or introducing a two-stream model? (C3D, I3D, R(2+1), TSN,…)\n",
      "\n",
      "4. [Overall rating] Paper rating.\n",
      "\n",
      "6\n",
      "\n",
      "5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "\n",
      "Good research story, good experimental set-up but arguable assumption.\n",
      "\n",
      "6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      "Do authors plan to release supplementary material they claim to have in the paper?\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 3: The reviewer is fairly confident that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the strengths and weaknesses of our paper, specifically focusing on the hypothesis that motion is important for action recognition and whether or not we have explored alternative methods such as using optical flow or a two-stream model.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Unsupervised Learning of Video Representations via Dense Trajectory Clustering\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The paper proposes a method which uses IDT descriptor and 3DConvNet to obtain action clusters and learns the unsupervised video representation.\n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "- Using IDT as prior knowledge\n",
      "- Effective motion capturing\n",
      "- Performance\n",
      "- Extensive related works and ablation study\n",
      "\n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "- It requires training with other big dataset.\n",
      "- Do the authors have any evidence of the performance without the usage of any other dataset?\n",
      "\n",
      "#### 4. [Overall rating] Paper rating\n",
      "9\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n",
      "The paper has nice analyses and the proposed method outperforms other methods by using IDT descriptors and 3DConvNet.\n",
      "\n",
      "#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "- L.318: Can you elaborate with the fine-tuning stage?\n",
      "- Can you please clarify for the Table 3 if you train your network with Kinetics-400 or 600? Most of the methods (DPC, 3D-Puzzle, PMAS) in the table use Kinetics-400 for self supervised training.\n",
      "- What are the limitations?\n",
      "- Do you have any memory usage and time analyses?\n",
      "\n",
      "Typos:\n",
      "- L.406: first\n",
      "- L.507: Kinetics\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Please evaluate the strengths and weaknesses of the paper, focusing on the proposed method's use of IDT descriptors and 3DConvNet for unsupervised video representation learning.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "EfficientSeg: An Efficient Semantic Segmentation Network\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The paper proposes new U-Net architecture which uses MobileNetV3 blocks.\n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "- New Unet\n",
      "\n",
      "\n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "- Only changing the architecture and no prior rather than generic data augmentation\n",
      "- It is more like technical report.\n",
      "#### 4. [Overall rating] Paper rating\n",
      "4\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n",
      "\n",
      "\n",
      "#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "- Why the 'related works' are related to the paper is missing.\n",
      "- L.32: Is any meaningful pretraining available for medical data?\n",
      "- Simple present tense instead of past tense\n",
      "- Fig.1 image resolution\n",
      "Typos:\n",
      "- L.173: 10 at .\n",
      "Missing citations:\n",
      "- L.24: \"..appoaches..\" (only one is given.)\n",
      "- L.26: \"..various problems..\"\n",
      "- L.34: \"..newly emerging..\". What are those fields?\n",
      "- L.57: classifying objects[?,?,?], detecting objects[?,?,?], estimating pose[?,?,?]\n",
      "- L.72: easy-to-access applications[?,?,?]\n",
      "- L.61: offline[?,?,?].., real-time[?,?,?]\n",
      "Rating: 4: Ok but not good enough - rejection\n",
      "Confidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n",
      "====================================================================================================\n",
      "Evaluate the paper based on its strengths and weaknesses, and provide an overall rating for the paper.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Effective method, out of scope\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The paper proposes a novel CNN architecture for semantic segmentation based on U-Net and MobileNetV3 blocks. The proposed architecture is applied on the MiniCity dataset and performance improvements are shown.\n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "* Clarity: the paper is clear and easy to read.\n",
      "* Effectiveness: the method seems effective on small-size datasets.\n",
      "\n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "* Scope: The proposed architecture change is motivated by computational efficiency and parameter reduction rather than incorporating prior knowledge. Prior knowledge is only considered to motivate the techniques used for data augmentation, which are generic and widely used techniques.\n",
      "\n",
      "#### 4. [Overall rating] Paper rating\n",
      "* 5. Marginally below acceptance threshold\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "Despite being effective, the proposed architecture is not motivated by incorporating prior knowledge but rather by computational efficiency and therefore the paper falls outside of the intended scope of this workshop.\n",
      "\n",
      "#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "(line 173) \"We divide the learning rate by 10 at . \"\n",
      "Missing word.\n",
      "(line 177) \"poll\" --> pole\n",
      "Rating: 5: Marginally below acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the effectiveness and strengths of the proposed method in the paper, considering its clarity and performance on small-size datasets.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "2nd Place Scheme on Action Recognition Track of ECCV 2020 VIPriors Challenges: An Efficient Optical Flow Stream Guided Framework\n",
      "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "\n",
      " This paper introduces a data-efficient pipeline to address the problem of action recognition. It is based on a two-stream model that utilizes an enhanced C3D network. The convolutions in the C3D are modified to include a 3D Temporal Central Difference Convolution term. Instead of working with RGB, authors proposed to use Rank Pooling guided with Optical Flow. Additionally, this work is ranked 2nd in de VIPriors Action Recognition Challenge.\n",
      "\n",
      "2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "\n",
      " -\tModification of the convolution, integrating a new term.\n",
      " -\t2nd Position in the challenge.\n",
      "\n",
      "3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "\n",
      " -\tThe paper feels more like a technical report than a proper paper.\n",
      " -\tThe introduction needs more motivation.\n",
      " -\tExperiments are very much focused on the challenge. Only modifying the convolution would need more justification. A deeper study.\n",
      "\n",
      "\n",
      "4. [Overall rating] Paper rating.\n",
      "\n",
      " 4\n",
      "\n",
      "5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "\n",
      " Weaknesses of point 3 justify the rating.\n",
      "\n",
      "6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "\n",
      " Please, include Rank Pooling citation, it seems is introduced by the authors.\n",
      "Rating: 4: Ok but not good enough - rejection\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the paper on \"An Efficient Optical Flow Stream Guided Framework for Action Recognition\" based on its strengths and weaknesses.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Interesting method, unclear explanation\n",
      "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n",
      "The paper proposes a new temporal convolution operator (3D TCDC), that combines a vanilla 3D convolution operator with a \"Temporal Central Difference\" term, and an optical flow guided Rank Pooling operation to compress the raw RGB input stream to a more compact single vector. A two stream network leverages both optical flow and the rank pooling representation to perform the task of action recognition. The method is evaluated on the VIPriors action recognition dataset and significant performance improvements are shown.\n",
      "\n",
      "#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n",
      "* I like that the authors propose 3D TCDC as a new fundamental building block for 3D CNNs; the method seems interesting.\n",
      "* The method seems effective on the dataset it has been evaluated on.\n",
      "\n",
      "#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n",
      "* The paper is too compact and omits some prerequisites that would make the method much more easy to understand. Especially section 3 would benefit from a more detailed explanation:\n",
      " * What does the temporal CD term in equation (1) do and what is the motivation behind it? It would have helped to provide a short recap of [13].\n",
      " * Similarly for the Rank Pooling operation: what is the motivation behind equation (2)? Which variable is optimized and what does the optimization represent? What are $\\omega$, $\\delta$, $\\xi$? The authors could have at least referred to previous work on rank pooling.\n",
      " * How are the two streams fused, i.e. what is \"Probability fusion\" in Fig. 1?\n",
      "* It would have been nice if the method would have been evaluated on multiple datasets. \n",
      "\n",
      "#### 4. [Overall rating] Paper rating\n",
      "* 6. Marginally above acceptance threshold\n",
      "\n",
      "#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n",
      "The proposed method seems interesting and effective. However, the paper provides too little explanation on the method. Nevertheless, I'm willing to accept the paper in the hope that the authors can further elaborate on the for the camera-ready version.\n",
      "\n",
      "#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n",
      "* The abbreviation \"C3D\" is never explained.\n",
      "* (line 202) \"We assume it’s caused by the irrelevant features with local optima.\"   \n",
      " Unclear explanation.\n",
      "* See 3. for additional comments.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Evaluate the strengths and weaknesses of the paper, focusing on the clarity of the method explanation and the effectiveness of the proposed approach.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The proposed method is somehow novel, but it lacks of ablation studies to validate the effects of using single modalities and cross-modality subspaces.\n",
      "This paper presents a speech-driven gesture generation method based on multimodal representation learning. Each modality is projected to two distinct subspaces: modality-invariant and modality-specific. Gradient reversal layer based adversarial classifier and modality reconstruction decoders are used during training.\n",
      "Average human-likeness ratings below 50% have been achieved, indicating that the proposed approach was not enough to generate natural gesture motions.\n",
      "\n",
      "Ablation studies should be included to show the effects of modality-invariant only, or modality-specific only.\n",
      "The video sample in the anonymous webpage shows an example of the generated motion.\n",
      "I'm not aware of how the other dialogue segments used in the evaluation are, but in the sample, the target speaker is basically in listening mode, so that the instants the co-speech gestures are generated are very short.\n",
      "Rating: 6: Marginally above acceptance threshold\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the effectiveness of our proposed speech-driven gesture generation method and provide feedback on whether the generated gesture motions appear natural.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "The evaluation and sub-materials show good results.\n",
      "The paper proposed a gesture generation method by incorporating representation learning into previously proposed network architectures. Six representations for audio, text, gesture (two per modality) are used. The method takes audio, text, and seed gestures as input and output is a sequence of gesture.\n",
      "\n",
      "The paper is well organized and written but it is easier to read if put new lines after sub-sub-section titles. \n",
      "\n",
      "The technical descriptions are well written and the experiments would be reproducible.\n",
      "\n",
      "Some research, such as [10], have already addressed the importance of the audio or human-pose representations for gesture generation. So, the contribution is incremental, but having modality-mixed representations is somewhat novel.\n",
      "\n",
      "The evaluation and sub-materials show good results. Having ablation study, also, help us to better understand the effects of proposed method. However, the effects of proposed representations were not very significant.\n",
      "Rating: 9: Top 15% of accepted papers, strong accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed gesture generation method in terms of its organization, reproducibility, novelty, and the significance of the proposed representations.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Novel and interesting paper with a little unclarity.\n",
      "The paper proposes a novel deterministic speech to gesture generation model by learning a modal-invariant and modal-specific features for different modalities used as inputs, i.e., audio, text, and seed poses. Ablation study showed that this method could improve the accuracy of the generated gestures.\n",
      "\n",
      "Strengths:\n",
      "1. Although the paper was not the best among proposed systems, the ablation study showed that the separation for modal-invariant feature and modal-specific feature were helpful to the accuracy of the generated gestures, i.e., a lower Hellinger distance and FGD on raw data space. This indicates that the proposed method is more effective to determine the gesture shape than purely mixing different modality features.\n",
      "2. The using of WavLM, as a pre-trained neural network for audio feature extraction, improves the jerk and acceleration of the generated gestures, even though the pitch, energy and volume were used at the same time. This shows that prosodic features of audio, i.e., pitch and energy, are not enough for predicting the rhythmic movements in the gestures.\n",
      "\n",
      "Potential issue:\n",
      "The paper uses an autoencoder-like training scheme to help learn the hidden feature space. However, the reconstruction error was computed on the reconstructed results and the output of one of the hidden layers, whose parameters are being updated when training. This could lead to an undesired behavior that the encoder and decoder agree with each other while not considering the original input at all. A more common approach for training an autoencoder is to compute the reconstruction error on the original input or a transformation of the original input.\n",
      "\n",
      "Weaknesses:\n",
      "1. More details are necessary for understanding the domain learning. While the authors propose to extract modal-invariant features from modalities as in [5], they did not use the original similarity loss for these features. Instead, they propose to use domain learning to reach this goal. Although this could be one of the originalities of this paper, the authors did not thoroughly explain how domain learning works and how it can achieve a similar effect as central moment discrepancy (CMD) loss, or its potential advantages and disadvantages compared with CMD.\n",
      "2. The authors claims that the reconstruction loss is used to ensure the hidden representations to capture the details. However, no ablation was provided for this. Thus, it is unclear that how much or if this loss is useful.\n",
      "3. The authors did not use traditional feature extraction method on the audio such as mel-spectrogram, which is more common in the literature. The difference between using WavLM and basic features is unknown.\n",
      "\n",
      "Questions:\n",
      "1. The scales of coefficients for different loss terms ranges widely, e.g., alpha is 300 and epsilon is 0.1 in equation (5). How did the authors adjust the hyper-parameters and reach such a different scale?\n",
      "2. Why did the author choose 3 seconds as the length for generation? Any reference for this?\n",
      "Rating: 7: Good paper, accept\n",
      "Confidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n",
      "====================================================================================================\n",
      "Please evaluate the proposed speech to gesture generation model in terms of its novelty, clarity, and effectiveness in improving the accuracy of generated gestures.\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    full_review = dataset[i][\"full_review\"]\n",
    "    print(full_review)\n",
    "    print(\"=\"*100)\n",
    "    prompt = dataset[i][\"help_prompt\"]\n",
    "    print(prompt)\n",
    "    print(\"=\"*100)\n",
    "    print(\"=\"*100)\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 92.09ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]\n",
      "Updating downloaded metadata with the new split.\n"
     ]
    }
   ],
   "source": [
    "Dataset.from_list(dataset).push_to_hub(\"dim/openreview_prompts_65\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
