[{"paper_url": "https://openreview.net/forum?id=VvRbhkiAwR", "paper_id": "VvRbhkiAwR", "reviews": [{"id": "1cp_MEsz_cI", "original": null, "number": 3, "cdate": 1594023893979, "ddate": null, "tcdate": 1594023893979, "tmdate": 1594023893979, "tddate": null, "forum": "VvRbhkiAwR", "replyto": "VvRbhkiAwR", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/-/Official_Review", "content": {"title": "Review of \"Cross-language sentiment analysis of European Twitter messages\"  -- interesting trends analysis but some more approach comparisons and tables for the data would be good.", "review": "The authors present an interesting, important and relevant trend analysis of sentiment across languages in several locales during the Covid-19 pandemic, using geo-tagged European Twitter data and pre-trained cross-lingual embeddings within a neural model.\n\nThe main contributions of the paper are: 1) the geo-tagged European Twitter dataset of 4.6 million tweets between Dec 2019 and Apr 2020, where some of these contain Covid19-specific keywords (it would be nice to see some percentage breakdown stats by language here), and 2) the important trends by country in terms of dip and recovery of sentiment over this period, including the overall trends across the board.\n\nIn terms of sentiment modeling, they use a pre-trained neural model trained on the Sentiment140 dataset of Go et al, which is English-only, hence they freeze the weights to prevent over-adapting to English. They use cross-lingual MUSE embeddings to train this network to better generalize sentiment prediction to multi-lingual data for each country. There is no novelty in the modeling approach itself, which works for the purposes of trend analysis being performed. However, there is no comparison being presented of results of experimentation with different approaches, to corroborate or contrast their current trends results. E.g. a simple baseline approach could have been to run Average and Polarity sentiment values using a standard python text processing package such as `textblob` to obtain sentiment predictions. Other experiments could have been done to use different pre-trained embeddings such regular GloVE or Multi-lingual BERT to provide a comparison or take the average of the approaches to get a more generalized picture of sentiment trends. Also the authors should make it clear that the model has really been used in perhaps inference mode only to obtain the final sentiment predictions for each tweet.\n\nThe treemap visualization gives a good overall picture of tweet stats, but a table providing the individual dataset statistics including keywords chosen by locale would be really helpful.\n\nSome notable trends are how the sentiment generally dips in all locales right around the time of lockdown announcements, and recovers relatively soon after, except for Germany where it dips at the same time as neighboring countries despite lockdown being started here much later, and UK, where sentiment stays low. It is also interesting to note the spikes and fluctuations in Covid19-related sentiment for Spain, and the overall trend for average sentiment by country for \"all\" tweets (including Covid19-related ones) tracking similarly over the time period considered.\n\nHowever, one trend it would be good to see some discussion on is how the histogram of keywords correlate with the sentiment for the keyworded tweets, as it appears interesting that heightened use of Covid-19 keywords in tweets tracks with more positive sentiment in most of the plots. Perhaps it would be helpful to have a separate discussion section for the overall trend analysis at the end.\n\nOverall the paper is well-motivated and in its current form provides perhaps the intended insights, and presents lot of scope to perform useful extended analyses with more meaningful comparisons for additional time spans and across countries where governmental and societal response were different than in Europe. Perhaps the authors could consider a more interpretable predictive sentiment model in future with some hand-crafted features such as geotag metadata, unigram and bi-gram features, binary features for government measures, and Covid19-specific keyword features by locale, which could provide more insight into why sentiment predictions trend a certain way during a specific period for a given locale.\n\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer2"]}, {"id": "sr6Pz8LrNmZ", "original": null, "number": 2, "cdate": 1593834884476, "ddate": null, "tcdate": 1593834884476, "tmdate": 1593834884476, "tddate": null, "forum": "VvRbhkiAwR", "replyto": "VvRbhkiAwR", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/-/Official_Review", "content": {"title": "Review on \"Cross-language sentiment analysis of European Twitter messages during the COVID-19 pandemic\"", "review": "The authors carried on a deep learning pipeline to analyze the sentiment of Twitter texts, and propose a complete research. The presentation and language part of this submission is good.\n\n However, the research mainly use the routine DL methodology and the analysis method is not contributive.  In general, the novelty and contribution of this research do not reach the level of publication as a ACL workshop paper. Here comes some comments and suggestions.\n\n1. The data statistics is missing. Though we found a rough number list in Figure 1, they are not quite clear. Data with time series info are also welcomed. Furthermore, several python packages help to draw Europe Map, and might make this part more vivid.\n2. It is better to provide a figure to explain the structure of the network. The authors surely already gave some details in page 2, including the input layer, activation function info. The hyper parameter of the network could also be provided.\n3. It is lacking of comparison of the current NN with some other NN structure. How would one single experiment derive convincing result without baseline methods or intrinsic evaluation? This is a core question I would like to raise here for this research.\n4. I am thinking of a possibility of splitting the Twitter data in terms of weeks, and take time series consideration into the current research paradigm. A sentiment-time curve plot might lead to some instructive hypothesis, if the research take a more sophisticated experiment design.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer1"]}, {"id": "kAPKEJYRLfM", "original": null, "number": 1, "cdate": 1593827509247, "ddate": null, "tcdate": 1593827509247, "tmdate": 1593827702431, "tddate": null, "forum": "VvRbhkiAwR", "replyto": "VvRbhkiAwR", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/-/Official_Review", "content": {"title": "Review", "review": "This is a mostly well-written overview of an exercise to assign a sentiment label to the European-country generated tweets during the period December\u201919-May\u201920. \n\nThe authors describe how they differentiate and identify the country, how they assign the sentiment level (positive, neutral, negative), how they use emojis, and how they use the deep learning neural model which presumably can adjust this label assignment regardless of what language the tweet is originally written. The authors report a 0.82 accuracy of their system. The rest of the paper is a recognition of the limitations, and a description and plotting of the sentiment level for various European countries. \n\nUnfortunately, these results do not contribute to adding new knowledge.  The study could use more work.  \n\nSuggestions: \n\nCould the authors provide a breakdown by language of the tweets that they process? Are we to assume that all tweet originated from Italy are in Italian and those originating in Germany are in German? \n\nIs this data publicly available?\n\nHas the 0.82 accuracy been manually validated? Is there a difference in accuracy depending on the language? The authors claim that one of the contributions of their study is this tagged dataset (geotagged, and sentiment-tagged). It seems there is no further evaluation on how well the tagging has been applied. \n\nAnd while it is visibly clear that we see a global fall in sentiment that correlates with governments issuing lock-down protective measures, and this result could be a start that this labelling of the data is good, is there anything else we can say, is there any other way we can analyze this data and identify common topics in the similar sentiment groups? Something that can be actually useful to the COVID-19 researchers\u2026\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper25/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=0gLzHrE_t3z", "paper_id": "0gLzHrE_t3z", "reviews": [{"id": "awuj7QVR2cj", "original": null, "number": 3, "cdate": 1593935756291, "ddate": null, "tcdate": 1593935756291, "tmdate": 1593935756291, "tddate": null, "forum": "0gLzHrE_t3z", "replyto": "0gLzHrE_t3z", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/-/Official_Review", "content": {"title": "Excellent description of a critical COVID-19 dataset, some questions remaining", "review": "This manuscript describes an exemplary effort to address COVID-19 by bringing together much of the relevant literature into one corpus, CORD-19, and increasing its accessibility by providing a harmonized and standardized format convenient for use by automated tools. CORD-19 has been - and is likely to continue being - a critical resource for the scientific community to address COVID-19, and this manuscript not only reflects that importance, but also gives insight into the approach used, the design decisions taken, challenges encountered, use cases, shared tasks, and various discussion points. The manuscript is well-organized and readable, and (overall) an excellent case study in corpus creation. This manuscript is not only important for understanding the CORD-19 corpus and its enabling effect on current COVID-19 efforts, but is possibly also a historically important example of joint scientific efforts to address COVID-19.\n\nDespite the critical importance of this dataset, there are several questions left unanswered by this manuscript, and it would be unfortunate to not address these before publication.\n\nIt would be useful to have a very clear statement of the purpose for CORD-19. The inclusion of SARS and MERS makes intuitive sense, but it is less clear why other coronaviruses that infect humans (e.g. HCoV-OC43) are not explicitly included - I am not a virologist, but neither will be most of the audience for this manuscript. While many of the articles that discuss these lesser known cornaviruses would be included anyway because they would also mention \"coronavirus\", this is not guaranteed. \n\nWhile it seems appropriate for document inclusion to be query-based, it is important to consider the coverage of the query. The number of name variants in the literature for COVID-19 or SARS-CoV-2 is rather large, and not all of these documents will include other terms that will match, such as \"coronavirus\". For example, how would a document that mentions \"SARS CoV-2\" but none of the query terms listed be handled? This is not a theoretical case: the title and abstract for PMID 32584542 have this issue, and I was unable to locate this document in CORD-19. In addition to minor variations such as this, there are many examples of significant variations such as \"HCoV-19\", \"nCoV-19\" or even \"COIVD\". Are these cases worth considering? If not, can we quantify how much is lost? And if we can't quantify it, this is a limitation.\n\nHow is the following situation handled: querying source A returns a document (e.g. the source has full text and that matches), but the version in source B does not return it (e.g. the source only has title & abstract, and they do not match). From the description, I would assume that the version from source A is used and the version from source B is ignored; is any reasonably useful data lost by not explicitly querying source B for its version?\n\nThere are other efforts to provide a repository of scientific articles related to COVID-19, and it would be appropriate to mention these, if only to indicate why CORD-19 has unique value. I am aware of LitCovid (Chen Q, Allot A, Lu Z. Keep up with the latest coronavirus research. Nature. 2020;579(7798):193), are there others?\n\nThere are also non-COVID-19 efforts to provide a large percentage of the literature in formats appropriate for text mining or other processing. One is (Comeau, Donald C., et al. \"PMC text mining subset in BioC: about three million full-text articles and growing.\" Bioinformatics 35.18 (2019): 3533-3535.), which not only provides the full text of a large percentage of the articles in PubMed Central, but it is also kept up-to-date and converts all documents into a straightforward standardized XML format appropriate for text mining. While this effort is single-source, it specifically addresses some of the issues encountered in the creation of CORD-19 and the representation aspect of the \"Call to Action\".\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/AnonReviewer1"]}, {"id": "9nXCz8yAKmY", "original": null, "number": 2, "cdate": 1593869977289, "ddate": null, "tcdate": 1593869977289, "tmdate": 1593869977289, "tddate": null, "forum": "0gLzHrE_t3z", "replyto": "0gLzHrE_t3z", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/-/Official_Review", "content": {"title": "Overview of a highly important Covid-19 dataset", "review": "This is a paper that describes an important research dataset that has been produced during the Covid-19 epidemic. The CORD-19 collection is used for much research and some challenge evaluations. Even though this paper does not report any research results per se, and the paper is posted on the ArXiv preprint server, this version will give a citable description of the collection that will likely be widely referenced.\n\nThe authors describe well the process of dealing not only with the technical issues of processing heterogeneous scientific papers but also the non-technical issues, such as copyright and licensing.\n\nThe authors do not make any unreasonable claims, although I do question the value of this collection for non-computational researchers and clinicians. As the authors note, the collection is not complete, which is essential for clinical researchers and certainly for clinicians (who do not typically read primary research papers anyways, and tend to focus more on summations). But the dataset is of tremendous value to computational and informatics researchers, and that should be pronounced.\n\nI appreciate the Discussion that points out the limitations of how scientific information is currently published, and how it could be improved. One other concern that could be addressed is how long the Allen Institute for AI, which is to be commended for this work, will continue to maintain this tremendously valuable resource.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/AnonReviewer3"]}, {"id": "QSKmsC8qzKu", "original": null, "number": 1, "cdate": 1593851275369, "ddate": null, "tcdate": 1593851275369, "tmdate": 1593851275369, "tddate": null, "forum": "0gLzHrE_t3z", "replyto": "0gLzHrE_t3z", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/-/Official_Review", "content": {"title": "CORD-19 is an excellent resource with an impressive integration work for the research community to fight COVID-19.", "review": "The authors present the CORD-19 data set and describe how it has been developed and continues to be developed. The CORD-19 data set is a valuable resource that provides access to the latest literature about COVID-19 and coronaviruses and it is updated daily with over 200k downloads. The generation of the CORD-19 requires a coordinated integration and processing effort that is significant. The contribution of this corpus is of high significance and will have a strong impact on the biomedical domain and support the development, for instance, of COVID-19 vaccines. The manuscript is clearly written and it is easy to understand.\n\nThe effort in providing a version of the latest literature in formats that can be processed by text analytics methods is excellent, using the latest of the available technology to do so. In the paper, it is mentioned in the manuscript that there are some problems in turning tables into structured format and the authors provide examples of issues that they have found. Table processing is done by IBM, who has as well a method for table processing that seems to be resilient to the problems mentioned and would be relevant to consider it for table processing (https://arxiv.org/abs/1911.10683).\n\nThe authors give an example of conflict from which it can be inferred that the same DOI might be linked to two different PubMed identifiers, the reviewer is curious why this might be the case and if an example could be provided.\n\nWhen you mention \u201cClassification of CORD-19 papers to Microsoft Academic Graph\u201d, is this classification done by a method provided by the authors? is this classification provided as meta-data?\n\nDuring my review the only typo I could find is:\n* \u201cother research activity.\u201d \u2014> \u201cother research activities.\u201d?\n* \u201cby not allowing republication of **an** paper\u201d, an \u2014> a\n\nPlease consider the following guideline for NLM trademarks: https://www.nlm.nih.gov/about/trademarks.html", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper24/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=ZQ_HvBxcdCv", "paper_id": "ZQ_HvBxcdCv", "reviews": [{"id": "WL_4KHfBioO", "original": null, "number": 3, "cdate": 1594092952959, "ddate": null, "tcdate": 1594092952959, "tmdate": 1594092952959, "tddate": null, "forum": "ZQ_HvBxcdCv", "replyto": "ZQ_HvBxcdCv", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/-/Official_Review", "content": {"title": "fairly straightforward, but apparently useful and tested on a large scale", "review": "This paper presents a rule-based NLP system for identifying COVID-19 cases from clinical narratives with application to 17 million documents.\n\nPros\n- in scope for the conference\n- real-life, large scale deployment\n- apparent usefulness\n- fairly straightforward system: the paper is accessible to a large audience\n\nCons\n- fairly straightforward system: limited technical innovation\n- ad hoc system: no/weak justification for the choice of approaches and technologies; not generalizable\n- more technology than science\n\nOverall\nThe significance of this work essentially comes from the practical utility of the system rather than from its originality or the innovation it brings. This work is reportable nonetheless.\n\nAdditional comments\nAssuming this is the case, it would be worth emphasizing that 36.1% of confirmed positive cases in a VA surveillance system were ***solely*** identified using this capability. This is not entirely clear from the abstract or the conclusion.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/AnonReviewer2"]}, {"id": "v68BiMgJjSo", "original": null, "number": 2, "cdate": 1593530563073, "ddate": null, "tcdate": 1593530563073, "tmdate": 1593530563073, "tddate": null, "forum": "ZQ_HvBxcdCv", "replyto": "ZQ_HvBxcdCv", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/-/Official_Review", "content": {"title": "straightforward but interesting case study in building NLP system from scratch for covid-19", "review": "This paper describes the creation of a system from scratch for processing clinical text at the VA to detect positive Covid-19 cases. While lab tests done at the VA will be in structured data, patients who may get some care elsewhere would have positive Covid results from other care recorded only in the free text, and the authors want to be able to capture those cases.\n\nThe challenges are that there was no existing data to build training sets for machine learning, there are many mentions of Covid and related terms in contexts that do not represent positive cases (negative test results, family members, describing the reason for a televisit).\n\nThe authors of this work created an NLP pipeline built on Spacy, including Context for negation/uncertainty/experiencer, sectionizer, etc. In the end, the decision of positive/negative was made based on finding a target term that was not uncertain, negated, or experienced by someone besides the patient, and that did have a positive modifier, occur in a diagnosis section, or was used to modify another condition (\"Covid-19 pneumonia\").\n\nSince this is an IR-like problem it is difficult to evaluate recall but straightforward to evaluate precision. For recall what they do is evaluate at the patient level on the subset of patients for whom they do have lab results they can use as a gold standard.\n\nWhile the NLP described here is fairly straightforward rule-based methods, this is an interesting use case of bootstrapping an NLP system from nothing for a new problem where there is no retrospective data available to build ML systems. The authors tease at the end that now that they've done this bootstrapping work they have essentially a labeled dataset that could be used for an ML system. A little more focus on this aspect would've been interesting to this reviewer, even if there are no ML results to report yet.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/AnonReviewer3"]}, {"id": "XrOi0ykupUQ", "original": null, "number": 1, "cdate": 1593410605765, "ddate": null, "tcdate": 1593410605765, "tmdate": 1593410605765, "tddate": null, "forum": "ZQ_HvBxcdCv", "replyto": "ZQ_HvBxcdCv", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/-/Official_Review", "content": {"title": "A Natural Language Processing System for National COVID-19 Surveillance in the US Department of Veterans Affairs", "review": "The paper proposes a natural language processing pipeline for identifying positively diagnosed COVID19 patients, which has been deployed as part of the VA national response to COVID19. The objective of the NLP system is to simply detect if a clinical document contains a positive COVID19 case. \n\nThe paper is very USA-specific. One of the motivations of the study is the fact that community-level testing and drive-through testing are often not counted in numbers derived from healthcare systems. Thus, the authors propose an approach that detects these cases from clinical texts within the Department of VA. The motivation could be made stronger by including numbers of people whose COVID19 status are encoded in free text only. What percentage of the patients may potentially be missed by laboratory-based surveillance methods?\nIt is unclear if the problem of not counting certain positive cases also applies to the VA. Do VA health networks not report laboratory test based COVID19?\n\nPreprocessor: \u2018remove problematic template text\u2019 and \u2018normalize lexical variants\u2019 are very vague descriptions of what is actually being done. Normalizing lexical variants can be as simple as simply stemming and as complex as mappings multi-word variants to standard IDs (which of course is a very hard problem).\nTarget matcher: Is exact matching used? What is the rate of misspellings within the clinical notes (i.e., how many misspellings per number of tokens?)\nDocument Classifier: what are the positive modifiers? How many of them are there? How often can it capture actual expressions of the diagnoses. \nIn Document Processing, how many keywords are actually used? How many times are these not spelled correctly?\n\nWhat are the actual sections (incl. number of sections)?\n\nThe number of patients without laboratory evidence but with evidence only in clinical notes is quite large\u2014and it justifies the development of such a pipeline. \n\nThe causes for the false negatives are quite straightforward and can be easily addressed. It would be good to ascertain how precision/recall would change if these simple issues (e..g, new lines) were fixed during the preprocessing phase. \n\nIt appears as though the authors did not consider inexact machine and/or semantic matching (e.g., via word2vec-type vectors). Recent research has shown that lexical similarity and semantic similarity based measures can generate data-centric variations/misspellings of noisy texts (e.g., from EHRs and social media), and such approaches have the potential to significantly improving performance\u2014and they will not require machine learning (which would require large amounts of training data). \n\nSince the test results for a very large number of patients already available, it would be pretty straightforward to just use those in a supervised learning framework. ", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper23/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=M4wgkxaPcyj", "paper_id": "M4wgkxaPcyj", "reviews": [{"id": "ptdqB4CFzS", "original": null, "number": 3, "cdate": 1593978247737, "ddate": null, "tcdate": 1593978247737, "tmdate": 1593978247737, "tddate": null, "forum": "M4wgkxaPcyj", "replyto": "M4wgkxaPcyj", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/-/Official_Review", "content": {"title": "A review of \"NLP-based Feature Extraction for the Detection of COVID-19 Misinformation Videos on YouTube\"", "review": "The paper describes a method for using YouTube video comments to classify video content, with the aim to separate videos into those describing Covid-19 conspiracy theories (misinformation) and those not (factual). An annotated video corpus is created by searching for videos on social media, downloading them from YouTube and annotating them, resulting in a dataset of 113 misinformation and 67 factual examples.\n\nThese videos have a total of 151,567 attached comments, which are further annotated as agreeing and/or conspiratorial, with manual annotation for the first 10% followed by automated propagation using a BERT-based neural network model. Finally, different classifiers are trained using the video description and comment label proportions to classify the video itself, and a feature analysis is performed to detect tokens important for this classification.\n\nThe paper is well written and the overall approach is well designed. The results are presented clearly and their significance is analysed thoroughly. The authors show that using attached comments as additional information can improve video classification, although since both the dataset and the method are new, it's not possible to compare or contrast the performance improvement with previous work. However, the authors have already published their dataset so further research and validation of the results is possible. Licence information (preferably Creative Commons for the dataset) should be added to the GitHub repository.\n\nThe paper follows a well-established approach of using contextual text as a proxy for audiovisual content classification. The current work in Covid-19 misinformation detection is a special case of this larger research area, and while the authors briefly mention this in citing Momeni et. al. (2013), the current work should be more extensively connected to this related work. For example, there appear to be at least two well known publications already from 2010-2011 that describe textual proxies for video classification [1,2] and it is commonly known that e.g. Google image search uses contextual text for visual content classification (https://support.google.com/webmasters/answer/114016) and has been doing so for a long time.\n\nAs a technical issue there may be something odd about how the parameters for the various classifiers are optimized. For example, the authors mention that \"For both SVM and random forest, we performed a grid search to obtain the best hyperparameters. In each run, we performed 10-fold cross-validation and report the mean accuracy in Table 2.\" This sounds like hyper-parameters were first optimized on the full data on which the final results were later generated, which sounds concerning, and should be clarified.\n\nFinally, it is not clear how much of this classification approach is already used by YouTube itself, which most likely uses contextual text in its video classification algorithms. The authors mention that \"In the case of Covid-19 misinformation, a large share of conspiratorial contents remain online on YouTube and other platforms, influencing the public, despite content moderation practices\", but then go on to state that \"We decided not to use YouTube\u2019s search function as previous studies found few conspiratorial content on the top results\". Doesn't this indicate that YouTube can already detect these conspiratorial videos, reflected by their low ranking in the search results, even if they have not been outright removed?\n\nAs a very minor issue, there appears to be a typo in \"the percentage of conspiracy comments feature is based on _an_ aggregated _classifications_.\"\n\n[1] Huang, C., Fu, T., & Chen, H. (2010). Text\u2010based video content classification for online video\u2010sharing sites. Journal of the American Society for Information Science and Technology, 61(5), 891-906.\n\n[2] Filippova, K., & Hall, K. B. (2011, July). Improved video categorization from text metadata and user comments. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval (pp. 835-842).", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/AnonReviewer3"]}, {"id": "d-P-yvO5mzL", "original": null, "number": 2, "cdate": 1593956478466, "ddate": null, "tcdate": 1593956478466, "tmdate": 1593956478466, "tddate": null, "forum": "M4wgkxaPcyj", "replyto": "M4wgkxaPcyj", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/-/Official_Review", "content": {"title": "An elegant approach and a great effort in data labelling but the authors need to address several questions ", "review": "The study explores how user comments can be utilised to detect false information in Youtube videos related to COVID-19 origination. The authors did a great job reviewing and manually labelling a large number of videos and the corresponding comments. First, a model is created to detect user comments that convey agreement or amplify misinformation, referred to as conspiracy comments. Next, the percentage of conspiracy comments under each video is calculated and used along with video titles and raw comments to predict if a video contains conspiratorial content. This two-step approach allows the authors to avoid dealing with computationally-expensive video processing and efficiently detect COVID-19-related misinformation in Youtube videos. \n\nPros: \n- A great effort in putting together the dataset of videos and comments;\n- The paper is well-written and the ideas are clearly explained\n\nAreas for improvement:\n- I suggest clarifying in point 2 of the introductory section that other features (titles, raw comments) were used along with the percentage of conspiracy comments to detect COVID-19-related misinformation.\n- There is a typo in \u201cPushshift Reddit API\u201d\n- It is said that conspiracy and agreement comments share 19.4% of their vocabulary and that only 1.95% of the vocabulary has more than four occurrences. Do you mean 1.95% of the shared vocabulary? Consider providing absolute numbers or restructuring the sentence to clarify the differences between the two collections. \n- Did you use cross-validation to report the training F1 scores (Table 1)? Did you change the threshold after analysing the precision-recall curves (Figure 1)?\n- I suggest changing non-misinformation to factual in the legend for consistency (Figure 2).\n- Please clarify how the data was split for the development of the second model, there should be a hold-out set to test the performance of the final model. It would be great if the authors could provide a confusion matrix for the final model and analyse the false-positives/-negatives. Given the dataset is slightly imbalanced, reporting the F1 score instead of the accuracy would also be more appropriate.\n- In Table 2, it would be good to provide the results for title + comments for benchmarking.\n- Please comment on why you chose exactly 10 most relevant words for Bayesian modelling. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/AnonReviewer4"]}, {"id": "cWdTrBsSGy7", "original": null, "number": 1, "cdate": 1593203859328, "ddate": null, "tcdate": 1593203859328, "tmdate": 1593417829387, "tddate": null, "forum": "M4wgkxaPcyj", "replyto": "M4wgkxaPcyj", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/-/Official_Review", "content": {"title": "Simple but effective method to detect COVID-19-related videos containing misinformation", "review": "This work proposes a simple but effective method to detect COVID-19 misinformation YouTube videos by using the percentage of conspiracy comments. While the authors did not examine video contents at all, the classification accuracy reached 82.2 by considering video title and the percentage of conspiracy comments only.\n\npros:\n- The approach is simple but works well.\n- The complete YouTube comments dataset and the Colab notebook file are publicly available.\n- Great efforts were made to construct COVID-19-related misinformation video datasets. \n\ncons:\n- While I have some minor concerns/suggestions, none of them are serious flaws. \n\ncomments:\n- Details in the labeling process should be added: For video labeling, did two authors independently label videos, and were all the labels agreed? For comments labeling, more explanations on the actual labeling process are required. For example, how many labels are collected per comment? \n- Comparison with a bag-of-words model: As the authors already have all the text of comments, building a bag-of-words model based on the first 100 comments (videos with less than 100 comments were easy to predict) is not super hard but will make the author\u2019s approach more concrete by adding another baseline. As there are several attempts to infer the political leaning of news articles based on their comments, bag-of-words models employing comments could be a solid baseline in this case as well. \n- Agree & Conspiracy labels in Table 1: drawing 2x2 table might be helpful to understand the characteristics of Agree and Conspiracy as the authors mentioned \u2018their different linguistic properties.\u2019 \n- Crowdtangle\u2019s historical data of public Facebook posts (Section 3.1): citations should be added.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper20/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=mlmwkAdIeK", "paper_id": "mlmwkAdIeK", "reviews": [{"id": "2Aa131i9-Qi", "original": null, "number": 3, "cdate": 1593931332484, "ddate": null, "tcdate": 1593931332484, "tmdate": 1593931332484, "tddate": null, "forum": "mlmwkAdIeK", "replyto": "mlmwkAdIeK", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/-/Official_Review", "content": {"title": "nice application to new data set to be made available", "review": "This paper explores gender differences in linguistic productions between two groups of Redditors who self-identify as either \"male\" or \"female\". It examines a corpus of covid-19 pandemic threads in relation to two areas: emotion analysis (employing a VAD lexicon and word embedding representations); and topic analysis (employing the tool MALLET).\n\nThe paper's novelty is in the application of an established method to a new corpus that the authors have developed pertaining to covid-19 threads. As expected, the language usage for covid-19 posts had a lower Valence when compared to language used in a baseline corpus. There is also a general trend for the language used in the female sub-corpus scoring slightly higher in the Valence scale than male sub-corpus. The trends are reversed when Arousal and Dominance were examined: overall higher for men, and when comparing baseline to the covid-19 posts, the baselines score slightly lower for both male and female data.\n\nTo compare and contrast the different topics covered between the male and female authored posts, topic modelling was applied to each sub-corpus and the topics with the highest coherence scores were presented. However, applying topic modelling to the corpus as a whole and analysing the topic allocation of the male and female posts would give a better indication of similarities and differences of the topics covered in the sub-corpora. However, two different topic models for each sub-corpus were developed and the most cohesive topics were presented.\n\nIn general the VAD study is interesting, although unsurprsing. The goal of discovering if different or similar topics were covered in the two sub-corpora may be best approached by discovering the topics covered by the corpus as a whole and analysing the topic allocation of the sub-corpora.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/AnonReviewer1"]}, {"id": "Z6sH6FO5-Ai", "original": null, "number": 2, "cdate": 1593797932016, "ddate": null, "tcdate": 1593797932016, "tmdate": 1593797932016, "tddate": null, "forum": "mlmwkAdIeK", "replyto": "mlmwkAdIeK", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/-/Official_Review", "content": {"title": "Overall the paper is okay but fails to provide the significance of the work.", "review": "This paper aims to understand the difference between male and female discourse in social media looking at a manually annotated set of Reddit threads related to Covid-19 compared to a baseline set. They confirm existing results about male and female discourse on the VAD scale.\n\nThe paper is clear and well-written and seems to be an interesting analysis, but fails to provide the significance of the work. Further the only novelty of the work is the application to Covid-19, otherwise all methods are utilizing previous work. This is not to say the authors should re-invent the wheel. \n\n\nPros:\n- An interesting exploration of gender differences that confirms previous results.\n- A good use of previous work on a new corpus. \n\nCons:\n- Missing the overall significance for researchers, clinicians, epidemiologists, etc.\n- It is unclear why Reddit specifically is used. They mention it is the 19th most visited site world. What about the other ones that are more visited? Is Reddit truly representative of the population at large? A description of the basic characteristics of Reddit users and posts would be helpful. \n- There is also a large imbalance between male and female posts (2:1 ratio). \n- This is very heteronormative.\n- The dataset is pulled from 15 weeks starting from Feb 1 to June 1, which was a rapidly changing time. The paper would benefit from a discussion of the different topics discussed over that time in comparison to the topics pulled out by the models. Currently we are in a new \"normal\" and I think that would be reflected during the different weeks.\n- The baseline is pulled from the same time period of Covid-19. An explanation of why the baseline should be the same time frame would be helpful to understand why the baseline is not from before Covid-19 when males and females were posting \"normal\" stuff. \n- The overall results in table 1 are confusing in what is being compared and what is statistically significant. The difference between males and females for the VAD criteria may be statistically significant but it is a minor increase (< 0.2). It is unclear how important this is and what implications it has.\n- A more in depth discussion on the relevance of the most coherent topics for males and females would be helpful. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/AnonReviewer3"]}, {"id": "2sY3by5pJW", "original": null, "number": 1, "cdate": 1593146492366, "ddate": null, "tcdate": 1593146492366, "tmdate": 1593146492366, "tddate": null, "forum": "mlmwkAdIeK", "replyto": "mlmwkAdIeK", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/-/Official_Review", "content": {"title": "Overall the paper is well written, contains re-usable data, and describes clear results.", "review": "Quality:\nOverall the paper is well written, contains re-usable data, and describes clear results.\n\nClarity:\nAuthors aims of analysis were clearly stated, as were the methods employed. Results are elucidated clearly. The paper is well written, concise, and easy to follow logically.\n\nOriginality:\nGiven the findings corroborate already established patterns of F / M speech, the exact findings that those patterns persist in covid-related speech is not particularly original. However, within the context of studying phenomena amidst a completely novel world event, covid, the findings regarding how people talk about said event are original. Combination of methodologies to perform analysis are somewhat original.\n\nSignificance:\nMohammed's VAD showed low inter-annotator agreement for A & D types. This may reduce the impact of any findings, distinctions, or variances (even if statistically significant) between the genders in these categories. Even if statistically significant, the cohen-d effect sizes between F & M are still very small (< .2 in all categories). What is the _human significance_ (not mathematical significance) of the analyzed differences? \n\nEditing suggestions: \n  Clarify Fig1 caption by including \"re covid\" or something to that effect\n  Typo in sentence, missing \"of\" :  \"COVID-related data trends (Figure 2) show comparatively low scores for valence and high scores\nfor arousal in the early weeks [OF] our analysis (February to mid-March)\". \n  This sentence comes off as sexist: \"women tend to use more positive language, while men score higher on arousal and dominance.\" Use similar terms to describe characteristics for both genders instead of saying what women do and what men score, e.g, \"Women score higher in use of positive language, while men score ...\"\n\npros\n  Straightforward, solid results that established F / M speech patterns persist in novel corpus.\n  Probably a decent baseline paper to use in further research on gender differences re covid speech or other domains.\n  \ncons\n  Statistical significance does not explain human importance of findings. \n  ", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper19/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=v8ioFR4fqpr", "paper_id": "v8ioFR4fqpr", "reviews": [{"id": "i3iCN61omXs", "original": null, "number": 3, "cdate": 1593120292977, "ddate": null, "tcdate": 1593120292977, "tmdate": 1593120292977, "tddate": null, "forum": "v8ioFR4fqpr", "replyto": "v8ioFR4fqpr", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/-/Official_Review", "content": {"title": "Good analysis of co-training, but several open questions", "review": "This paper presents a task of policy labeling related to COVID-19 in two different domains, government announcements and Twitter discussions. The authors study the use of two classifiers (logistic regression and a pretrained language model) in a transfer learning setup, where data is augmented by co-training. Event extraction is used to obtain features that would act as a bridge between the two domains. Results are presented for the classifiers with and without co-training, and some benefits are seen when co-training on tweets with the pre-trained language model.\n\nRemarks:\n\nThe assumption that event extraction will separate opinionated text from the content could be supported with some evidence and additional analysis. It is difficult to gauge whether the difference of 0.1 in median subjectivity is a little or a lot. \n\nIn trying to understand why the event information almost never helps, it would be good to know how precisely the event features are included into classifiers. What is their form, are these just extracted event phrases? Are events represented with some other labels? \n\nWhen filtering policy-related tweets, cosine similarity over BOW representations is used to decide about policy relatedness. I was wondering whether the authors tried to first identify content words, as matching with cosine may largely be accounting for function words and words not related to policy (even in policy-related tweets). Also, BOW matching would likely not work well if the style (e.g. word forms, the use of tense) differs between the two domains. As the authors show, the use of tense indeed differs considerably between the domains, which could be affecting the filtering of the tweets based on word forms alone.\n\nAlthough the authors generally do a good job in presenting the results (including graphically), I would also recommend showing confusion matrices, which could shed more light on where mistakes happen and how \u201cproblematic\u201d the uneven distribution of labels is. As a reader, I am still left wondering whether the presented task is difficult, and what are some challenges remaining. For this, an error analysis is needed.\n\nAs another reviewer observed, I am also missing a more detailed discussion about dataset creation. There is a mention of hierarchical labels, but only top-level categories seem to be used in the task. The role of hierarchical labels is unclear to me. The authors also mention they have considered using a rule-based approach but decided for a classification-based approach to identify top-level categories. It might help to state more precisely what is meant here. The identification of top-level categories during the creation of the dataset or the task itself? \n\nCo-training features prominently in the paper. The outcome appears to be that co-training can help somewhat when generalising to different corpora, especially when using RoBERTa and the event features. An analysis of salient word features of the LR classifier is presented, where\u2014with the number of iterations increasing\u2014more words from the target domain occur as salient features. This is a good sanity check to verify that co-training works (provided the domains really require different predictors for the same set of labels), but is not really surprising. I see co-training as the main contribution of the paper, and although its effects are in most scenarios quite marginal, I find the analysis nevertheless interesting.\n\nWhen augmenting data, 15 instances are added at each iteration (i*k) according to the caption of Figure 2, but earlier in section 3.2 the authors explain that k points are added for each class, which confused me (\u201cfor each view, we train a classifier, use it to label the top k most confident unlabeled datapoints for each class, and add them to the training set\u201d).\n\nI suggest proof-reading the paper again, there are several typos in Related works and Conclusion.\n\nMy overall impression is that although the paper does not present groundbreaking improvements with transfer learning, the pursued ideas (esp. around co-training) are interesting, the experiments sound and clearly presented. I believe the paper would fit this workshop venue well. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/AnonReviewer2"]}, {"id": "-T1hlFj9e2_", "original": null, "number": 2, "cdate": 1592955451501, "ddate": null, "tcdate": 1592955451501, "tmdate": 1592955483797, "tddate": null, "forum": "v8ioFR4fqpr", "replyto": "v8ioFR4fqpr", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/-/Official_Review", "content": {"title": "Interesting work; some questions could be addressed", "review": "Summary: The paper describes a topic classification task for policy announcements and tweets. The authors experiment with logistic regression and RoBERTa classifier. Co-training based on views based on events (indicated by a subset of words in the text) is used to increase the dataset size. This results in an improvement of 3% points in the F-score of the classification task for tweets. \n\nPros:\n1) The motivation of the problem is defined well in the paper. It certainly seems like an interesting problem.\n2) The experimental evaluation is in two parts: without co-training (with additional features based on events), and co-training (with events forming complementary views).\n\nCons:\nI struggled to understand some parts of the paper. It would be useful to address the following questions in the paper:\n0) It is not clear if co-training is useful as a transfer learning strategy. Without co-training, the RoBERTa classifier obtains an accuracy of 0.76 (figure 1b). With co-training, it is 0.77 (figure 3b).\n1) Is the classification task for tweets a Boolean task (policy-related or not) or a 6-class classification? Section 2.2 describes how tweets are labeled as policy-related. However, it is unclear how one of the six labels is determined for the tweets, if it is done for the dataset by Chen et al.\n2) Top 15 training instances are added at the end of every iteration. This may be substantial for the policy announcement dataset. Is it sufficient for the tweet dataset?\n3) How are events appended to the RoBERTa classifier in the case of 'Text & Events'? \n4) To the best of my understanding, the dataset by Chen et al, is a multilingual dataset that was collected based on words such as \"COVID\", \"Coronavirus\", and their translations in other languages. When determining the policy-relatedness of tweets, are any factors apart from their cosine similarity with a policy announcement taken into account?\n5) Since the labelled datasets are less than 1000 instances themselves, it is not clear if a percentage improvement of 3% is significant.\n6) Some graphs report values up to 8 iterations of co-training, while others only up to 4. If 15 instances are added at every step, is it only a small addition to the dataset?\n7) Event extraction is said to be performed because of the difference in relative subjective opinion. This connection is not clear to me.\n\nMinor:\n1) It may be useful to define the notation \"\\\" in \"Text \\ Events\" as text without events. This seems confusing because the paper also has \"Text & Events\" and \"Text / Events\" (in Figure 3b, which I believe is \"Text \\ Events\"\n\n[I have not yet read the already submitted review of the paper.]", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/AnonReviewer1"]}, {"id": "z9l91SEftfT", "original": null, "number": 1, "cdate": 1592911364829, "ddate": null, "tcdate": 1592911364829, "tmdate": 1592911364829, "tddate": null, "forum": "v8ioFR4fqpr", "replyto": "v8ioFR4fqpr", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/-/Official_Review", "content": {"title": "Interesting task sidelined in favour of underwhelming machine learning.", "review": "This paper introduces a text classification task, concerning six classes of COVID-19 related policies, and presents classifiers designed to make the most of the limited resources available when working in an emerging field such as COVID-19 policy.\n\nTwo corpora are presented - a manually annotated \"training corpus\" of official policy annoucements, and a \"transfer corpus\" from Twitter extracted from Twitter. The transfer corpus was constructed using a streamlined approach, using similarity to find relevant tweets - a small amount of manual assignment was needed to select an appropriate similarity threshold. The transfer corpus includes a manually annotated evaluation set, but no training set - the aim is to see how well models trained on the training corpus can be made to work on the transfer corpus. The corpus construction is not a major theme of paper - two pages worth out of nine are devoted to this and its context.\n\nThey present two baseline systems, using Logistic Regression - an old, well established technique, and RoBERTa - a state-of-the-art technique using a massive unlabelled corpus. Unsurprsingly, both systems do better on the training corpus, and the RoBERTa-based techniques outperform logistic regression. The abstract mentions an \"11% above a baseline\" - most of this 11% appears to be due to the use of RoBERTa. The gain from using RoBERTa looks similar on the training and transfer corpora.\n\nCo-training is heart of the paper and discussed in detail, it is mentioned in title whereas RoBERTa isn't. Co-training allows unlabelled data to be labelled for use as training data - this is potentially useful in poorly-resourced areas, and for transfer learning. It requires multiple \"views\" of the training data. Event extraction provides event-only and everything-but-event views of the data, and the authors show that these views are more useful than other views for co-training.\n\nCo-training appears to have the greatest effect when used on the transfer corpus, and with RoBERTa. There, it lifts F from .74 to .77 (a 3% improvement) - however an F score of .76 was reported earlier in the paper for that corpus. This makes the improvement look more like 1%.\n\nThe performance of systems is reported graphically, rather than as tables of results. Some individual scores are reported in the text, but not systematically. The abstract mentions \"11% above a baseline\" but the score for that baseline is never quoted in text. The graphical format does show some of the uncertainties in the results, but I feel that tables of results would be clearer and help with making comparisons.\n\nIn conclusion, this paper of two halves, and neither half feels strong enough on its own. The corpus construction - especially having two corpora from different domains - is potentially interesting but is not explored in depth. In the machine learning part, the gains from applying RoBERTa are substantial but the gains from other techniques are less so. There is an \"11% above a baseline\" quoted but the particular gains for the focus of the paper (the co-training and event extraction) are more like 3 or 1%. These are modest improvements, and do not feel particularly noteworthy. \n ", "rating": "5: Marginally below acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper16/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=yx-k0ukHzDR", "paper_id": "yx-k0ukHzDR", "reviews": [{"id": "POu9xsT9ZcF", "original": null, "number": 3, "cdate": 1593968981442, "ddate": null, "tcdate": 1593968981442, "tmdate": 1593968981442, "tddate": null, "forum": "yx-k0ukHzDR", "replyto": "yx-k0ukHzDR", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/-/Official_Review", "content": {"title": "Methodologically sound contribution notable for its focus on Arabic social media", "review": "# [REVIEW] COVID-19 and Arabic Twitter:  How can Arab World Governments and Public Health Organizations Learn from Social Media?\n\nACL COVID Workshop 2020 \n\n5th July 2020\n\n## SUMMARY\nThis paper describes work on processing 1 million Arabic language tweets from the Twitter API related to COVID-19 (i.e. containing the Arabic translations of the term \u201cCOVID\u201d).  Analysis consisted of 3 phases.  \nFirst, k-means cluster analysis using ngrams was used to identify broad topics (e.g. disease statistics, prayers, disease location).  Second, automatically detecting rumours.  Second, a top-down strategy was used annotate 2,000 tweets according to pre-determined rumours (e.g. hot weather kills covid) achieving an accuracy of 84% (logistic regression).  Third, a logistic regression model developed in a prior study was used to classify tweets by source (i.e. academic, media, government, health professional, and public).  This classifier was applied to the labelled data generated in step 2, when it was discovered that tweets containing false information and rumours, often adopt the language style of academics/official discourse, creating further challenges for health communication.  \n\nThis is a (generally) well-written, clear paper.  It is not methodologically innovative, but it is nicely executed, and the fact that it focuses specifically on Arabic language tweets makes it a valuable contribution.\n\n## COMMENTS\n\n* Why cluster analysis over, say, biterm topic modelling?\n* How was the appropriate number of clusters determined?  \n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/AnonReviewer4"]}, {"id": "d_Qsfz54Bg1", "original": null, "number": 2, "cdate": 1593924947391, "ddate": null, "tcdate": 1593924947391, "tmdate": 1594137999132, "tddate": null, "forum": "yx-k0ukHzDR", "replyto": "yx-k0ukHzDR", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/-/Official_Review", "content": {"title": "Much-needed study and findings with potential for health-policy decision making before, during, and after infectious disease for the Arabic-Speaking countries ", "review": "The paper is well-written with clear scope of research objective, methodology, hypotheses, findings, and implication.  Literature review is adequate and relevant.  The study was well conducted and clearly described.  It is also a much needed study for the Arabic-speaking countries to have machine-learning models to capture and analyze Arabic social media such as Twitter to discover important topics about COVID-19 and to classify the True information from False from reliable sources to influence the decision by the governments for public health.  The study, although small in terms of data sets, depth of classification, and different word-embedding models, sufficiently showed the value of and soundness of the approach to timely-information discovery from mining social media, especially for the Arabic language that presents different challenges from English social media.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/AnonReviewer3"]}, {"id": "KrTiiMUQMRv", "original": null, "number": 1, "cdate": 1592839306764, "ddate": null, "tcdate": 1592839306764, "tmdate": 1592839306764, "tddate": null, "forum": "yx-k0ukHzDR", "replyto": "yx-k0ukHzDR", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/-/Official_Review", "content": {"title": "Worthy paper of limited scope that does what it sets out to do successfully and usefully.", "review": "The paper is well-written and organized. It analyzes a refined dataset of Arabic language tweets and successfully extracts helpful information from them. The information is potentially of great value to public health organizations who might not otherwise be collecting this data.\n\nMy only reservation about the paper is that it confines itself to Tweets in Arabic script, thus eliminating the many Tweets in the Arabic chat alphabet across North Africa in particular, in the various dialects found there. These would be of equal value for analysis, though they would require much more unpacking owing to differences in dialect and chat alphabet preferences. So perhaps that is a task for another team.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper14/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=qd51R0JNLl", "paper_id": "qd51R0JNLl", "reviews": [{"id": "cO0SlRl0x2l", "original": null, "number": 2, "cdate": 1593448164581, "ddate": null, "tcdate": 1593448164581, "tmdate": 1593448164581, "tddate": null, "forum": "qd51R0JNLl", "replyto": "qd51R0JNLl", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/-/Official_Review", "content": {"title": "timely contribution, could be better positioned with regard to previous work", "review": "This paper presents a dataset of 1700 questions related to covid which\nare hand labeled and divided into 15 general categories and 207\nclusters of semantic equivalence. The value is potentially useful for\ngeneral question classification, for semantic similarity, with\nparticular application to reducing load on question answerers by\nremoving redundancy, The data set is on the small side and some\nimportant details about how the data was collection are omitted. The\nauthors make a number of factual errors. All of these could be easily\ncorrected and the data set is a useful resource.\n\n\n\"we scraped questions about covid\". how is a 'question about covid'\ndetermined? Are keywords used? If so what keywords? Additionally how\nwere questions that had location/time-specific versions vs. questions\nwith only one version determined? There are number of ways this could\nbe done, some noisier than others, some more scalable than others.\n\nWhat are all the 'synonymous ways of saying COVID?'\n\nsame answer -> same question cluster. \"In which country is SARS-CoV-2\nbelieved to have originated\" and \"Which country manufactures the most\nface masks\" have the same answer but are not the same question nor are\neven related. Plenty of useful questions do not have an answer (yet);\nhow are these to be clustered?\n\n\"there are fewer ways to ask how long COVID will last than ways to\nwrite a positive movie review\" -- I would argue both are countably\ninfinite. \n\nThe cluster classification task was oddly formed. This is ultimately a\nsentence similarity task or a coreference/nil clustering task. One\ncould use the data to pose the binary question \"are these two\nsentences asking the same question?\" One could also posit the far more\nuseful \"is this a question that has already been asked [and if so\nwhich one] or is this a novel question?\" task of coref/nil\nclustering. Static assignment to clusters seems wrong for that kind of\ndata. By specifically excluding clusters with a small number of\nquestions you specifically skirt the issue you would have to deal with\nin real application of this data.\n\n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/AnonReviewer2"]}, {"id": "aYbPwXjRoyA", "original": null, "number": 1, "cdate": 1591771125947, "ddate": null, "tcdate": 1591771125947, "tmdate": 1591771125947, "tddate": null, "forum": "qd51R0JNLl", "replyto": "qd51R0JNLl", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/-/Official_Review", "content": {"title": "A good dataset paper - some clarification and statement of limitation", "review": "The paper presents a dataset of questions related to COVID-19; included are annotations mapping questions to specific categories and classes.\n\nIt's always good to see papers that contribute datasets to the research community, particularly if they require significant efforts in annotation as this one does.\n\nI think that some changes are needed in terms of positioning of this paper to make clear the contributions and benefits. The other reviewer, I believe, also struggled a little with this. I suggest an explicit \"who would use this data\" and \"how would this dataset be used\" section. I think limiting it to just people who want to train an QA IR system is a mistake. First, not all question have answers (Table 1); second, it's not obvious how the classes and categories focus, which are a large part of the paper, is core to training a QA IR system. Instead, I think the classes and categories can be used a lot more in the query intent / query understanding area of research. Pitching the paper more broadly - and being explicit on areas - would help to clarify and strengthen the contributions.\n\nOn the methodology of annotation:\n- The paper rests on the technical soundness of the manual annotation process so the authors should really focus on ensuring the methodology / rigour is clear - especially as all the annotation work was done by the authors themselves. \n- Categories were made up by the author. How subjective and context specific was this? What are the limitations?\n- Seems like one question is mapped to one class and one category - what about overlapping questions? Surely there are questions that fall in multiple - and if there are not in this dataset then there will certainly be out in the wild. The paper, at leasts, needs to address this.\n- Categories may remain static (i.e., new questions about covid-19 would likely map to existing categories). But classes will be ever evolving. For example, if a vaccine is developed then a whole host of new question classes will arise. Having these static list of classes, at this snapshot in time, risks them becoming out-of-date very quickly in a rapidly changing environment.\n- Figure 2 - questions/class highly skewed. So is it actually worth having the classes? How valuable are they?\n- Having an explicit limitation section at the end of the paper will really help with the above points.\n\n\nSome changes in presentation could really elevate the paper:\n- The definition and difference between categories and classes was not clear at the beginning of the paper. In the middle section 2, the definition finally becomes clear. A definition of both is really needed earlier in the intro. \n- I found \u201cclasses\u201d not really the best term. What about question \u201ctopics\u201d or even question \u201cclusters\u201d since they are essential groups of duplicate questions. When classes are introduced, there needs to be a better justification for their purpose. It comes clearer much later but I think is needed earlier.\n- Matched vs. unmatched is confusing. It\u2019s not that they were not matched, it\u2019s just that they were classes with only one question, right? Can a better term found? Also Table 1 presents matched/unmatched without any reference / definition - only much later in the paper do you find out.\n- At some point, the paper suddenly starts talking about \u201clabels\u201d - it\u2019s not clear whether this is classes or categories or both - why not just use the actual terms.\n\nOn the classifier / experiments\n- The contribution of the paper is the dataset and not the ML methods. As stated, in the response to the review, the performance is merely an indication of how well current methods do on this task. The fact that the performance is good or bad does not really change the papers worth. However, insights from the experiments are part of the contribution; and these could be improved: e.g., were certain categories much harder than others? where two categories often confused for each other? \n\nOverall, this paper provided a good dataset for the community. But it needs to be much more explicit and clear about how people might use the dataset rather than a generic reference to training QA IR system. Addressing the presentation issues and directly addressing a number of limitations will greatly improve the paper.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/AnonReviewer1"]}, {"id": "-7scliZLDVP", "original": null, "number": 1, "cdate": 1591150995915, "ddate": null, "tcdate": 1591150995915, "tmdate": 1592494251628, "tddate": null, "forum": "qd51R0JNLl", "replyto": "qd51R0JNLl", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/-/Official_Review", "content": {"title": "Preliminary work, limited significance", "review": "This paper presents a corpus of 1690 documents about COVID-19 manually annotated with questions classes, along with basic question classification algorithms.\n\nPros\n- in scope for the conference\n- dataset is publicly available\n- technical details are kept to a minimum\n- accessible to a large audience\n\nCons\n- no clear statement of objectives\n- no clear statement of specific contribution\n- no explicit annotation guidelines (making it difficult to reproduce this effort)\n- ad hoc categories (not modeled after general types of questions)\n- no justification for the selection of documents\n- mediocre performance of the basic question classification algorithms\n- no discussion (the so-called discussion section is merely a summary)\n- the claim that this dataset can help train QA systems is unwarranted at this stage\n\nOverall\nThe significance of this preliminary work is extremely limited\n\nOther comments\n- the presentation of figure 2 is unnecessarily confusing", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper8/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=XOkm8xdns5R", "paper_id": "XOkm8xdns5R", "reviews": [{"id": "kc2wxJ4wLmZ", "original": null, "number": 2, "cdate": 1591682115643, "ddate": null, "tcdate": 1591682115643, "tmdate": 1591682395971, "tddate": null, "forum": "XOkm8xdns5R", "replyto": "XOkm8xdns5R", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper7/-/Official_Review", "content": {"title": "Fairly sound approach, but several serious concerns", "review": "This manuscript discusses the use of crowdsourcing to label sub-sentence segments with labels that look a lot like the ones used for structured abstracts.\n\nWith few exceptions, I found the manuscript to be clear. The task is a reasonably interesting one (though it would be a good idea to motivate it a bit more by showing what it could be used for) and the methods are reasonable and I am reasonably convinced that the approach described would produce the results shown. This paper is a pretty good example of the sort of work that can be done with crowdsourcing. I am not aware of other work approaching similar classification tasks with crowdsourcing, but I did not go looking. One very important point that seems to be buried is the fact that the annotation took 10 days. Every annotation project I have ever been involved with that used experts took months; this is a strong argument in favor of this approach.\n\nThere are quite a few things that concern me, however.\n\nFirst, the methods are all straightforward applications of fairly well known work. For the machine learning that is ok, but there are few insights in the crowdsourcing methods or the results that would not be strongly expected. In other words the authors need to make much more clear any claims to originality or significance. \n\nThe paper neglects to mention that many of the abstracts in CORD-19 are structured. For example, the abstract for document e9cgnhbq (PMID 20153051) has the following sections: Objective, Methods, Results, Conclusion. While the correlation may not be 1-to-1 to the annotation scheme, it seems that the mapping might be pretty high. How much does this help the crowd workers? Would it help the classifiers?\n\nThe claim that data sparsity is a challenge in general is of course true - there will never be enough annotated data to train a system to do every task we could want at near-human performance levels - but somewhat irrelevant. If there are no existing datasets that can be used to perform this task, then it is a challenge and the comments about the difficulty of annotating for other tasks is irrelevant. If there are existing datasets for the task needed, then the challenge is not lack of data but whether the dataset really does allow the task to be addressed. More likely, there are datasets that solve a similar task, and these should be evaluated and tested.\n\nWhich version of CORD-19 was used? A new version is released every week.\n\nWhile it is appropriate to provide compensation that roughly approximates 'fair', it is not mentioned how long each abstract took on average and therefore what the actual pay rate was. It would be useful to hear how long it took the experts as well. When I do annotation - admittedly for a more complex task - I almost always have to read the text multiple times.\n\nThis is essentially a text classification task, a task that multinomial Naive Bayes performs quite well on (probably not as well as BERT, but still). See:\nMcCallum, Andrew, and Kamal Nigam. \"A comparison of event models for naive bayes text classification.\" AAAI-98 workshop on learning for text categorization. Vol. 752. No. 1. 1998. \nTackling the poor assumptions of naive bayes text classifiers.\" Proceedings of the 20th international conference on machine learning (ICML-03). 2003.). \n\nThere is a strong but imperfect ordering of the sections: \"Background\" will almost always come before \"Method\". Note that at least one of the cited papers mentions this: Huang 2017. So why was that information not used in the classification models? The way to use it would be different for most of the models, but for naive bayes, the way to use it would be to switch to using a hidden markov model, which handles sequential information. \n\nStructured abstracts provide a great deal of information that is not being exploited here. In addition to being used as a feature directly, they could be used to train a second classifier that would serve as a feature: the structured abstracts will provide section labels and your existing TF-IDF vectorizer provides samples of vectors from segments. If these are run over a large corpus - not even necessarily covid-related - then a multinomial naive bayes model (or your favorite high dimensional instance classifier) could be created that predicts the section label from the TFIDF vector (importantly, this would work even if the abstract being predicted was not structured). There would be some section labels that are rare, these can simply be removed from the model. Then any TF-IDF vector for a segment could have section labels predicted, with that prediction fed as a feature for the classification of your annotation scheme.\n\nThere is no analysis provided to show whether 9x annotation is better than, say 5x annotation for this task. There is no analysis provided of how large the corpus needs to be, ie an ablation study with the classifiers. If the classifiers have the same performance on 11k abstracts that they would have on 5.5k abstracts, then maybe we don't need 11k. If 5x annotation of 5.5k abstracts provides close enough performance, then a sufficient corpus could have been created for 1/4 the cost.\n\nIt is not made clear why the annotation scheme will help fight COVID-19: what use cases do research aspects enable?\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper7/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper7/AnonReviewer2"]}, {"id": "CXBDlVvQfMk", "original": null, "number": 1, "cdate": 1591205402621, "ddate": null, "tcdate": 1591205402621, "tmdate": 1591205402621, "tddate": null, "forum": "XOkm8xdns5R", "replyto": "XOkm8xdns5R", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper7/-/Official_Review", "content": {"title": "Potentially important topic, but a number of questionable claims and an overall lack of contact with relevant literature detract from the paper quite a bit.", "review": "OVERALL\n\nThank you for the opportunity to review this interesting paper about annotation of abstracts from the CORD-19 corpus.  \n\nOVERALL STRENGTHS:\n\n1.The paper is written in the official language of the conference.\n\n2. The paper is within the page limits of the conference.\n\n3. The abstract accurately reflects the contents of the paper.\n\n4. The discussion of worker wages and total cost is very nice. The paper could do a better job of showing the reader why it is important by putting it into the context of Fort et al.\u2019s paper on the ethics of using AMT for NLP data (see the References section below), as well as Cohen et al.\u2019s paper on the relationship between Turker pay rates and actual Turker earnings (from that work, there appears not to be one).  Additionally, the paper mentions a target hourly wage, but does not report the ACTUAL hourly wage.  This seems like an omission.\n\n5. The data quality assessment is very nice.\n\nOVERALL AREAS FOR IMPROVEMENT:\n\nFor visibility, consider adding \u201cCOVID-19\u201d to the title of the paper.\n\nThe literature review is missing quite a bit of relevant work. This is an important gap in the paper because adequate coverage of related work would help in making the significance and innovation arguments.\n\nThere are a couple of claims in the Introduction that are either not relevant or not supportable, and coming in the Introduction, they reduce a reader\u2019s confidence in the paper as a whole. Specifics:\n\nThe statement that producing annotations for thousands of papers can be a prolonged process if only expert annotators are used and that their availability is limited is not connected with the rest of the paper.  There is also no evidence that it is true.  In fact due to the virus and attendant shutdown, expert annotators might have actually been MORE available at the time this work was done than at any time since the beginning of corpus annotation. I don\u2019t have data on that, but the paper doesn\u2019t present any data for the opposing hypothesis, either, and since there probably is none available, I would advise simply dropping any critique of manual annotation by experts.  If the authors feel that it must be included, then be balanced--point out the benefits of expert annotation (see, for example, Amber Stubbs\u2019s dissertation on the topic--sorry I couldn\u2019t find the reference for this one; I suggest contacting her directly).\n\nThe claim that data sparsity is a major challenge for biomedical text mining is not supported, and probably not supportable.  There is actually a LOT of data available for BioNLP research--that is why most people got into the field in the first place (see Cohen and Demner-Fushman\u2019s book \u201cBiomedical natural language processing)\u201d. Tons of projects have produced quite a bit of data--e.g., Cohen et al.\u2019s paper on multi-model annotation in the CRAFT corpus lists 25 (twenty-five) biomedical corpus constructions just in the five years before the publishing of that paper.\n\nThe scientific premises of the paper include the idea that the annotation task would typically be thought of as requiring expert knowledge; that is why the paper uses it to study the use of non-expert annotators.  The approach to such a research question is reasonable, but the data and the task are not suitable to answering the question.  The annotation scheme (Background/Purpose/etc.) does not seem like one that is necessarily difficult for non-experts, for example in the case where they are marked explicitly in abstracts. So, either demonstrate that they\u2019re not marked, or improve the argumentation with a reasoned claim that the task would EVER be thought of as requiring expert annotators.\n\nThe paper\u2019s description of the dataset is inadequate.  It samples the CORD-19 corpus, but the CORD-19 corpus has a number of versions (commercial, non-commercial, for example), and the paper does not tell us from which part the CODA corpus was sampled.\n\nIn Table 2, it is not clear to me that F1 is the right measure of agreement here.  Consider supporting an argument that it is.\n\nThe paper reports kappa, but does not say how P(e)n was calculated.  That makes it difficult to interpret the kappa score at all.\n\nThe result given at the end of Section 5 regarding which model gave the \u201cbest\u201d classification performance is not relevant.  The point of reporting classification scores in a paper on a corpus is as a measure of annotation quality and quantity--the argument would be that if a classifier can build a good model, then the annotations are probably consistent and the quantity of data is probably adequate (see the Pustejovsky and Stubbs reference).  Which model performs \u201cthe best\u201d is not actually well-evaluated in the paper, and it is not relevant to the paper, so I would strongly suggest removing that small paragraph altogether.\n\nAs academic courtesy if nothing else, I strongly recommend that you mention the classic work on crowdsourcing for production of NLP data.\n\nREFERENCES (sorry for all of the Cohen references--he has done a lot of work in this area)\n\nFort, Kar\u00ebn, Gilles Adda, and K. Bretonnel Cohen. \"Amazon mechanical turk: Gold mine or coal mine?.\" Computational Linguistics 37.2 (2011): 413-420.\n\nCohen, K. Bretonnel, et al. \"Ethical issues in corpus linguistics and annotation: Pay per hit does not affect effective hourly rate for linguistic resource development on amazon mechanical turk.\" LREC... \n\nInternational Conference on Language Resources & Evaluation:[proceedings]. International Conference on Language Resources and Evaluation. Vol. 2016. No. W40. NIH Public Access, 2016.\n\nCohen, Kevin Bretonnel, and Dina Demner-Fushman. Biomedical natural language processing. Vol. 11. John Benjamins Publishing Company, 2014.\n\nCohen, K. Bretonnel, Karin Verspoor, Kar\u00ebn Fort, Christopher Funk, Michael Bada, Martha Palmer, and Lawrence E. Hunter. \"The Colorado Richly Annotated Full Text (CRAFT) corpus: Multi-model annotation in the biomedical domain.\" In Handbook of Linguistic Annotation, pp. 1379-1394. Springer, Dordrecht, 2017.\n\nPustejovsky, James, and Amber Stubbs. Natural Language Annotation for Machine Learning: A guide to corpus-building for applications. \" O'Reilly Media, Inc.\", 2012.\n\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper7/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper7/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=2f70OXlGQMd", "paper_id": "2f70OXlGQMd", "reviews": [{"id": "sxt15yaDRfe", "original": null, "number": 3, "cdate": 1588431889250, "ddate": null, "tcdate": 1588431889250, "tmdate": 1588431889250, "tddate": null, "forum": "2f70OXlGQMd", "replyto": "2f70OXlGQMd", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/-/Official_Review", "content": {"title": "Worthwhile work and interesting discussion but a lot of technical detail missing.", "review": "This paper is about estimating the effect of COVID-19 on depression by using an LSTM to calculate depression from the language in Reddit users' posts at different periods prior to and during the pandemic and making comparisons. The paper has an interesting goal and I like the fact that it argues for a longitudinal analysis. However a lot of technical details are missing, including the task definition and the associated ground truth, and I would find it difficult to accept the paper in its current form.\n\nMajor comments\n--------------\nAt the moment this paper relies too heavily on information from a previous publication by the author from 2018. However, it should be possible to read the current paper as a standalone. Therefore I suggest that the following information is included here:\nSome more details about the off-topic depression dataset. What was the criterion for selection users and posts in this dataset and how was it annotated for depression? While I agree that most people posting on social media will not be explicit about depression or sad mood it is important to know how the ground truth for depression was established in the off-topic dataset. What is the available baseline being mentioned just before section 2.1.1?\n\nMethod: The paper doesn't actually describe anywhere the actual task that the LSTM is trained on and this is even more confusing as we don't know what the ground truth is and at what level it is assumed.\n\nDeep LSTM with fastText: it is totally unclear what is the task here. LSTM is trained on some users using what as the ground truth? What is the end goal? Is it the binary classification of a user as depressed or not depressed? Also, what is the input to the LSTM? Is a single post considered to be one time-step? Or is each word one time-stephere? Very little technical detail is provided and clarifications are needed before this work can be published.\n\nPandemic depression dataset:\nBefore the random selection of 20K users were there any other filtering criteria for candidate users (e.g. minimum threshold on number of posts etc). Are only the first six months of 2018, 2019 to make any seasonal effects as close to 2020 as possible?\n\nSection 3: What was the baseline by Wolohan et al 2018, also mentioned in Table 2?\nHow are the rates of depression determined?  Is this by aggregation the number of depressed users in a time period of the percentage of posts indicating depression?\n\nThe discussion is interesting but would be more useful if it was made clear what the prediction task was, what the input to the model was and how this information was aggregated to obtain rates of depression.\n\nMinor comments:\n-----------------\nThe following sentences are ungrammatical and needs rephrasing:\n\"The popular media is aware\nof the necessity for otherwise healthy emphasize\n\u201cself care\u201d\u2014small acts intended to maintain one\u2019s\nmental health or relieve stress\u2014during these uncertain\ntimes.\"\n\n\"The Pandemic Depression dataset contains 23 million\nwords aggregated up to 20,000 users(...)\"\n\nThe following could be shortened or removed if more space needs to be found:\n\"From this, it follows\nthat text classification approaches such as the\nuse of long short-term memory networks (Hochreiter\nand Schmidhuber, 1997) and word embeddings\n(Mikolov et al., 2013), such as fastText (Bojanowski\net al., 2017), can be used to classify people\u2019s\nmental health status based on their speech.\"\n\nSection 4.2 can also be shortened to make more space for necessary technical detail in earlier sections.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/AnonReviewer2"]}, {"id": "V-PnPZLcCF", "original": null, "number": 2, "cdate": 1587610132405, "ddate": null, "tcdate": 1587610132405, "tmdate": 1587610132405, "tddate": null, "forum": "2f70OXlGQMd", "replyto": "2f70OXlGQMd", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/-/Official_Review", "content": {"title": "Interesting and useful conclusion, but the method and analysis could improve.", "review": "This paper conducts an analysis of the depression rate of users posting in reddit before and after 2020. The results show a sharp increase of depression in 2020, which coincides with the start of COVID-19. The paper is worth publishing in that it shows a sharp increase of depression and this needs to be addressed. \n\nThe paper concludes that COVID-19 caused the increase of depression but the analysis conducted in the paper is not clear, only that there is a correlation.\n\nThe method used is OK and the system shows good results when evaluated on the development data, but it has some parts that can be improved, especially if the absolute numbers of depression reported are to be accurate, they might not be. But the increase of depression is clear based on their experiments.\n\nAdditional comments:\n\nThe system was trained on a separate training data using reddit, and then applied the system to the new collection of reddit posts. It was not clear to me whether there was an overlap of users/posts between the training and test data. The paper must say what they did to prevent/control this overlap. Still, this is just a minor comment. If there was any overlap, then the depression results in 2018 would be artificially high. Given that they are similar to those of 2019, it seems that there is little or no overlap between training and test data.\n\nThe paper gives a detailed explanation of the plausibility of such a high rate of depression in all years. What they say makes sense, but I noted that the training data has an artificially high number users with depression (from the cited paper: 4000 depressed vs 7000 control). It would be best to conduct some simple error analysis. For example, the system might have a high rate of false positives?\n\nThe highest value of depression found was in January 2020. If COVID-19 was the cause, why does the rate of depression declines slightly during 2020? Can the paper report on the geographical profile of the reddit users? If they are mostly Chinese, the high increase of depression in January would make sense. If they are mostly from USA, why isn't there higher depression in March? There could be confounding factors here.\n\nSomething to consider for further work: analyse the topics discussed in the posts, or at least analyse the frequency of covid-related posts among depressed and non-depressed users. This can help establish whether there is causation.\n\nSection 2.3 mentions that they analysed the same users for all periods but I do not see anywhere any analysis of how many users changed from not depression to depression (or otherwise). Is this possible?\n\nSome small comments/typos below:\n\n- Abstract: near the middle of the abstract, there is a line starting with a comma.\n\n- Page 1, introduction: \"for otherwise healthy emphasize\" -> \"for otherwise healthy to emphasize\"\n\n- Page 1, section 2.1: The reference should include the year 2018.\n\n- Page 4, beginning of col 2: \"Importantly, there are reasons\"\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/AnonReviewer3"]}, {"id": "pQJjfl_Fbsh", "original": null, "number": 1, "cdate": 1587348669579, "ddate": null, "tcdate": 1587348669579, "tmdate": 1587348669579, "tddate": null, "forum": "2f70OXlGQMd", "replyto": "2f70OXlGQMd", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/-/Official_Review", "content": {"title": "Beautifully written paper", "review": "This might be the most beautifully-written paper I have seen in a fairly long career.  With the removal of two lines in the Conclusion section, I would happily urge immediate publication, and would use it as an example in writing courses.\n\nSTRENGTHS:\n\nBeautifully written Introduction that clearly establishes the \u201creal-world\u201d (i.e. non-natural-language-processing) motivation for the work with appropriate citations to the clinical psychology literature. It then goes on to make a clear statement about the goals of the paper, and makes a reasoned argument for the innovation of the work (rather implicitly, but still, it\u2019s there) with respect to the natural language processing literature. So: clear statement about what the paper is going to do, well-argued significance claim, and well-supported innovation claim.\n\nThe construction of the data set is really nicely done, especially with the use of only the first 6 months of data from each year.  This presumably is meant to assume that when later looking at the Pandemic Depression dataset, there is no confound from seasonal effects on mental health (the pandemic having entered broad public consciousness in the US in the early months of 2020, and this being only April--I mention this because the pandemic dates back to at least November of 2019 and there was widespread awareness of this at the highest levels of the US government well before that entrance into broad public consciousness, which is certainly relevant to discussions of the materials, since it speaks directly to the appropriate months to include).  Consider making that seasonal effect explicit, if that is, indeed, the intent--it\u2019s a strong point of the methodology.\n\nThe discussion of the characteristics of the dataset in the second paragraph of Section 2.3 (\u201cIt is important to note here\u2026\u201d) gives excellent insight and background.  Additionally, I would point out that it is the paper\u2019s adroit use of discourse markers like \u201cIt is important to note here\u201d that makes this paper such an excellent example of scientific writing.\n\nThe presentation of potential alternative explanations for the findings in the Discussion section is one of the most beautiful parts of the paper.  Respectful consideration of alternative points of view increases the reader\u2019s confidence in the overall reasoning behind the paper immensely--very nicely done.\n\nWEAKNESSES\n\nThe paper gives very few details about the LSTM that is at the heart of the methodology, and very detail about preprocessing, as well.  Especially given that there does not seem to have been much of the latter and so it presumably wouldn\u2019t take up much time or space, consider adding those details to an appendix.\n\nThe two lines that I would strongly recommend removing: \u201cIn this paper we show the effectiveness of an LSTM text classifier using fastText word embeddings at\u2026\u201d The paper actually does not show that particularly well.  The only point of comparison FOR THE PERFORMANCE OF THE LSTM/EMBEDDINGS COMBINATION ITSELF is to previously published results. When making claims based solely on performance numbers, the level of detail available to the reader who wants to reimplement the work becomes absolutely crucial. As Kenneth Church has put it: \u201cThe better the numbers are, the more important it is to reject the paper. We can't afford papers that report results without insights.\u201d ...and there are no insights REGARDING THE LSTM/EMBEDDINGS COMBINATION that I was able to find in this paper.  Where would they come from? Manipulation experiments--swapping in and out sources of embeddings, swapping in and out other classifiers, etc.  Note that this is an issue of what can and cannot be said about the NLP--it does not take anything away from the beautifully discussed findings regarding depression.\n\nIn contrast to that 2-line conclusion regarding the LSTM/embeddings: the analysis of the results in terms of comparison with (a) reported data on depression rates, and (b) on the variability or lack thereof in the two control years--is really creative and insightful.  See all 3 paragraphs on Section 4.1, Model Efficacy, for that analysis.\n\nSo: to strengthen the paper, consider making it not about how well the LSTM/embeddings combination performs, but rather about the findings regarding depression.  We are talking here about removing two lines that make the paper\u2019s conclusions be fully supported by the methodology and its results.  \n\nAgain: overall, this paper is exemplary. Removal of the two lines identified above would make it even better.\n\n\n", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper3/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=JQCYcdHfXyJ", "paper_id": "JQCYcdHfXyJ", "reviews": [{"id": "WiMx6b54yy2", "original": null, "number": 3, "cdate": 1588604168441, "ddate": null, "tcdate": 1588604168441, "tmdate": 1588604168441, "tddate": null, "forum": "JQCYcdHfXyJ", "replyto": "JQCYcdHfXyJ", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/-/Official_Review", "content": {"title": "Valuable resource", "review": "The paper describes a novel dataset containing answers to a survey that asked participants to describe in short and long text their emotional states and rate their levels of  anger, anxiety, desire, disgust, fear, happiness, relaxation, and sadness. The dataset includes responses from 2500 UK residents collected during a critical period of the cover-19 pandemic.\n\nThe paper also investigated the predictive performance of lexicon-based and supervised classifiers. Preliminary analyses of the data showed significant correlations between the respondents emotional ratings and the scores inferred by LIWC for the same emotions. However, these correlations are much higher for longer texts, which is not surprising since LIWC was not created for microblog style content and longer text has more words that can match with the lexicon. Similar trends were observed with a supervised model trained to predict the emotional ratings given the text answers. Finally, topic analysis of the data showed that the main topics expressed in shorter text are different than in longer text. \n\nThe paper is well written, well scoped and well executed. The dataset is very interesting and it will be useful for the NLP community not only from the standpoint of understanding how people respond to global crises but also to better understand how the characteristics of social media might influence what kinds of information people decide to share. The cautionary tale about using Twitter to study the public's reactions to these kinds of events is worth a closer look. I am not sure how much we can extrapolate from this, given that in real life people can post more than one tweet about a subject, and they do so spontaneously which is different from being asked to post about something specific on a survey.  Some \"experimenter effect\u201d might be at play here. ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/AnonReviewer2"]}, {"id": "6ylmKgW1LcD", "original": null, "number": 2, "cdate": 1588216798343, "ddate": null, "tcdate": 1588216798343, "tmdate": 1588216798343, "tddate": null, "forum": "JQCYcdHfXyJ", "replyto": "JQCYcdHfXyJ", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/-/Official_Review", "content": {"title": "Good first steps toward understanding the UK public's emotional response toward covid19", "review": "The focus of this manuscript is to 1) describe a corpus of long and short lengthened emotional responses to the covid19 pandemic by the public, 2) identify meaningful associations between linguistic measures and emotional responses, and 3) develop prediction models for automatically classifying unseen texts according to their emotional response categories.\n\nQuality: The usage of LIWC lexicon to identify topical/linguistic information is a good start. I'm interested in how differently tools like empath (https://github.com/Ejhfast/empath-client) would perform in identifying pre-configured and new topics on this corpus and what additional insights could be drawn from it. \n\nThe correlation values appear low, but I'm wondering if that's due to out of vocabulary terms. Perhaps, a quick manual review of LIWC term coverage and a lexicon enrichment might help identify a stronger signal. \n\nSome emotions seem a little hard to tease out or have close relationships e.g., worry, anxiety, fear, etc. It would be interesting to understand commonalities and distinguishing characteristics in terms of linguistic measures of related/close categories. \n\nClarity: A few points should be clarified or explained: 1) did you collect any additional meta-data about the participants e.g., sex, gender, age, race, professions (essential vs. non-essential workers), etc. that could be useful to contextualize or identify particular worries among groups? 2) did these \"texts\" also include emoticons that could be used to convey emotional response and topical information? \n\nIt would also be interesting to sample more than 2 days. I wonder how the topics will shift as the pandemic unfolds. \n\nAlso, I would recommend revisiting the corpus title as its very UK-centric and covers a broad range of emotions. What about \"UK COVID19 Public Emotional Response dataset\"?\n\nOriginality: The coupling of the open survey with traditional linguistic and topic modeling approaches for examining the global threat has some originality. The predictive model serves as an initial baseline. It would be interesting to evaluate other traditional machine learning classifiers to establish reasonable baseline performance.  \n\nSignificance: The topic is certainly significant and a nice first attempt at obtaining self-reported emotional concerns of the public. This is also a great tool that if deployed more broadly could capture insights across regions, countries, and continents.\n\nThank you for making this invaluable resource publicly available to researchers!", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/AnonReviewer3"]}, {"id": "Y3V8flq1x6E", "original": null, "number": 1, "cdate": 1588053543736, "ddate": null, "tcdate": 1588053543736, "tmdate": 1588053543736, "tddate": null, "forum": "JQCYcdHfXyJ", "replyto": "JQCYcdHfXyJ", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/-/Official_Review", "content": {"title": "Useful dataset", "review": "Summary: The paper introduces a self-reported dataset of 2500 short and long (each) texts about emotions of people during the COVID-19 pandemic. The paper then analyses the dataset in terms of LIWC properties, output of a topic model (most probable topics) and a linear regression model to predict emotion based on TFIDF and POS-based features. The dataset will certainly be useful. The fact that it is self-reported and has both short and long texts are noteworthy.\n\nSuggestions:\n1) Short and long texts by the same participant do not necessarily have to be 'parallel'/'analogous', it seems. If this is indeed the case, I would suggest mentioning so.\n\n2) It would be good to know the reason behind picking worry as the key emotion. (In other words, the choice of calling this a 'worry dataset' and not an 'emotion dataset' is not clear). The question asked to the participants (when they draft their text) does not mention 'worry' explicitly. They are asked to rate how worried they feel. However, in addition, the participants are also asked to record other emotions.\n\n3a) Section 2.2: The description accompanying worry clubs it with 'anxiety'. However, table 1 shows that only 55% participants reported anxiety.\n\n3b) Please elaborate \"The participants\u2019 self-reported ability to express their feelings in the long text\". Was it a part of the form?\n\n4) It is not clear if the number of tokens is the same as vocabulary. It would be useful to know the vocabulary sizes of the datasets.\n\n5) The github repo also includes LIWC statistics of the texts. This could also potentially be useful.\n\n6) There is a low correlation between the 'concerns' (work, money, death?) and worry. In contrast, the top topics from the model include job and family. Is it surprising?\n\n7) It would be useful to add statistics on how frequently the participants reported using Twitter. This would be helpful to understand the quality of the short text.\n\n8) Observation: The classifier is not state-of-the-art. It would be useful to add citations to papers which use linear regression for emotion analysis.\n\n9) Was the linear regression model also trained using spaCy?\n\n10) Is the low MAE for worry related to the fact that worry was central to the annotation? Could there have been a bias in the annotations? The stdev for worry is also the lowest (as shown in Table 1).\n\nThe dataset would certainly be useful for future work. The analysis of the dataset (LIWC, topic models) is very interesting. The paper is easy to follow as well.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper1/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=HxIZzQZy_0F", "paper_id": "HxIZzQZy_0F", "reviews": [{"id": "Dy9PZAGjNjL", "original": null, "number": 3, "cdate": 1593452440892, "ddate": null, "tcdate": 1593452440892, "tmdate": 1593452440892, "tddate": null, "forum": "HxIZzQZy_0F", "replyto": "HxIZzQZy_0F", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/-/Official_Review", "content": {"title": "Engineering white-paper, but regrettably lacking in science", "review": "Summary:\nthe article describes the process and end result of creating a chatbot aimed at providing vetted COVID-related information to the public.\n\nGeneral impression:\nJennifer clearly represents a considerable effort, undertaken by a talented group under great time pressure, using vast amounts of information that is highly uncertain and in flux. \n\nNow for the submission: to put it perhaps soberingly, it is 60% helicopter-view engineering white paper, 20% sales pitch, 10% incidental observations, 8% future work, and 2% science. It is the virtual absence of scientific substance that is my main concern. \nAs one illustration: the manuscript has 24 citations, 11 of those look peer-reviewed, 5 of these are provided in the future work (\u2018ongoing challenges\u2019) section, therefore not supporting the past activities but rather motivating future ones. Several of the other ones are referred to outside of their scope (e.g. the Vargas reference). Related research on chatbox design, the spine of this work, is all but absent. (2 citations, from 30 and 15 years ago). \n\nNote that the submission has no \u2018Results\u2019 section. No systematically collected observations or other evaluation materials are introduced. At the very least, end-user usage statistics would have been informative to assess the impact of this work.\nThe engineering decisions that are reported make sense, but are largely not substantiated with supporting literature or first-hand evaluation. \n\nWhile it is claimed, it is not clearly demonstrated that this project addresses misinformation (or disinformation). It is an access point (and repeater of) trustworthy information but not one that specifically points out misinformation, or hunts it down. It is not fully clear how accountability is ensured for the automated provision of information to the general public \u2013 can users easily vet the sources of such information, and is there a path of recourse when a user spots incorrect answers? Who is responsible for the answer in such a case, especially so if it led to harm?  Are there mechanisms to prevent deliberate infiltration of the expert-crowd or other efforts to sabotage Jennifer (think of Tay AI)? \n\nMore detailed points:\nThe Abstract refers to COQB, but the main article never does.\n\nSection 2.4: \"Answers to questions should be verified against reliable sources in the language of question.\"\n--> That is a debatable statement: why would an English language source suddenly be necessarily inadequate when a person asks a question in French!?\n\nDiscussion: \"Jennifer has successfully demonstrated that, with the right combination of technology and human experts, information from reputable sources can be more quickly and effectively organized and shared at scale.\"\n--> This is a statement that is not supported by anything reported in the submission.\n\n\"Given the evolving tasks and the large number of volunteers with diverse background, putting the right process around tasks, workflow, and sequencing (Norheim-Hagtun and Meier, 2010) is key to ensuring efficient use of the volunteers\u2019 time to the advantage of the project.\"\n--> Unfortunately, full documentation of tasks, workflow, and sequencing is not provided in this manuscript, and use of volunteer time is not assessed.\n\nConclusions: \n\"Jennifer leverages cutting-edge chatbot technology, as well as a diverse network of volunteers from around the globe, to combat misinformation related to the pandemic.\" \n--> Only one of these three claims is supported by the presented material.\n\nAt best, this submission could be included as a discussion article, certainly not a research article. Accepting it as a full peer-reviewed research contribution would lend it more credibility than it deserves.\n\nMinor points, stylistic points:\n\"to best prevention and management practices.\" -->?? \"to prevention and management best-practices.\"\n\nSection 2.3: \" following guidelines and recommendations in (National Academies of Sciences, Engineering, and Medicine, 2017)\". The citation appears to point to a research agenda document, rather than a set of guidelines and recommendations.\n\nThe sentence \"Much of the recent research focusing on automating the task of fact checking (e.g., Adair et al. (2017); Pathak and Srihari (2019)).\" is incomplete.\n\nSeveral citations are incomplete re. sources, most notably the Jurkowitz (Mark, not Marl) citation. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/AnonReviewer1"]}, {"id": "0sxaWPz7IIe", "original": null, "number": 2, "cdate": 1593445355922, "ddate": null, "tcdate": 1593445355922, "tmdate": 1593782240902, "tddate": null, "forum": "HxIZzQZy_0F", "replyto": "HxIZzQZy_0F", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/-/Official_Review", "content": {"title": "Impressive system, lacking crucial details", "review": "The authors describe a chatbot and a dataset of frequently asked questions regarding the SARS-CoV-2 disease. They enumerate the challenges in building an effective health chatbot. They introduce a dataset of SARS-CoV2 and COVID19 questions.\n\nI would like to congratulate the authors on having an actual deployed system. I have many concerns about the paper and the datasets themselves that hopefully the authors can address.\n\nPros:\n1. The authors collect what might be a high quality dataset harvested from many QA sources\n2. They provide compelling examples of good bot behavior.\n3. They provide a reasonable roadmap forward.\n4. They are displaying great care in deployment of their system, particularly beyond their initial input domain.\n5. I am a huge fan of the ongoing curation of the answers in their dataset.\n\nConcerns:\n1. The authors should provide a brief overview of the capabilities from Juji: Does the question/QA grouping come from Juji itself, or do the authors have some other approach? (From a brief skim of the Juji paper it seems that the authors must have taken some alternative approach)\n2. There is no measure of question/QA grouping. Presumably this should be a very high precision grouping since incorrectly including a question could mean it has a wrong answer.\n3. Similarly, there is no measure of inter-rater agreement on the evaluation of the answers in the crowd sourced context. A measure such as Krippendorf's alpha (or many others) would be appropriate here and essential to knowing how well the system performs overall. A measure like this becomes doubly important when the authors are attempting to fight the spread of misinformation.\n4. How were the automatically generated question generated? If you used Juji templates, what are some examples? Given the constraints of available structured data (e.g. CDC data), what types of questions did you choose to answer, and which ones did you not? \n5. For the questions gathered from multiple sources, how are conflicts resolved? Presumably two sources do not always have consistent answers.\n6. How many people evaluate each question/answer pair?\n7. How is the translation performed? I can't tell if it's automatic with manual curation or entirely manual. If there was an automatic component, what system did this?\n8. I am concerned about the use of \"engagement\" as a metric of success. This becomes even more concerning to me when more time spent interacting with a system is seen as a measure of its success - while I agree that when answering questions one might need further clarification or to know about related questions and answers - encouraging people to spend more time interacting with a system could lead to a perverse incentive where it keeps users \"engaged\" without answering their questions. \n\nThe authors have built an impressive system, but I am reluctant to recommend it for acceptance without further details in data generation and evaluation. If these details were added (even for the system/questions/answers at a particular point in time), I would gladly recommend this paper for acceptance.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/AnonReviewer2"]}, {"id": "nVg2Zk7d4au", "original": null, "number": 1, "cdate": 1593145948055, "ddate": null, "tcdate": 1593145948055, "tmdate": 1593145948055, "tddate": null, "forum": "HxIZzQZy_0F", "replyto": "HxIZzQZy_0F", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/-/Official_Review", "content": {"title": "N/A", "review": "The paper provides a good description of the COVID-19 Q&A chatbot and the process of creating the crowd-sourced Q/A pairs that the bot uses for question answering. The authors also outline the opportunities and challenges of implementing COVID-19 chatbots in the real world.\nWhile the study authors list examples of lessons learned as well as open challenges of using chatbots in a pandemic setting in which information changes quickly, it would be very helpful to better understand the use of a Jennifer-like chatbot in a situation in which the evidence-base is more stable. It would also be very helpful to understand the authors' perspectives on how chatbot technologies and their use could be effectively evaluated, and how such an evaluation could be better integrated into the chatbot development and validation of the provided responses. In addition, it might be helpful to provide examples of other chatbot technologies that have been used successfully during and prior to the pandemic, as this could put better into perspective the issues and imitations that are being raised in the manuscript. \nAnother important aspect regarding the use of chatbot technologies is their acceptance both by public health authorities as well as the intended users. In using novel technologies, governments and public health organizations typically tend to take a more conservative approach, and accept them only following rigorous testing and evaluation. Equally, there may be also hesitancy from certain population groups with formed/strong opinions to engage with chatbots, particularly when provided answers originate from just one or several sources (i.e. when the whole body of evidence is not provided). It remains unclear who is (are) the intended target audience(s) of the chatbot and, ultimately, its objective. It would be very helpful to have that information stated and discussed up front. Lastly, it is important to recognize the significant limitations of the use of chatbot technologies for \"fact-checking\" in the absence of a robust knowledge-base. What has been presented in the paper may be more applicable to situation in which there is a need to help users identify and navigate through the relevant content, particularly when information is not well structured or ambiguous. It would also be great if the authors could reflect in the sustainability of initiatives that have a very high reliance on volunteers \nI would recommend that the manuscript be accepted, as it provides a good example on the potential usefulness of chatbot technologies in supporting the general public to efficiently find credible information on the web.  ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper21/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=SPxaJuM4Hbz", "paper_id": "SPxaJuM4Hbz", "reviews": [{"id": "-SfWfzSmKc", "original": null, "number": 3, "cdate": 1593934215640, "ddate": null, "tcdate": 1593934215640, "tmdate": 1593934215640, "tddate": null, "forum": "SPxaJuM4Hbz", "replyto": "SPxaJuM4Hbz", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/-/Official_Review", "content": {"title": "Study of automatic classification of LitCovid categories.", "review": "This article presents a comparison of methods for the classification of articles from the LitCovid collection. From all the evaluated methods, one based on BioBert performs better compared to other evaluated methods. The contribution of the paper is a comprehensive study of a broad range of methods to the multi-class classification of LitCovid. The classifiers are evaluated on a small set of papers from the CORD-19 collection. The article is clearly written and plenty of details. The authors provide the data and code, which would support reusability and reproducibility.\n\nThe performance on CORD-19 is significantly lower compared to the reported numbers for LitCovid. This might be due to several reasons, including the limited size of the CORD-19 articles used or the way manual annotation done by the authors might differ from the one performed in LitCovid.\n\nThe LitCovid collection already provides the classification, thus the classifier might have limited used unless a specific use case is specified in which this work would be used.\n\nThe title might be willing to include the specific collection on which the methods have been tested on, since the collections and the labels are provided by the LitCovid data set.\n\nThe article has been recently uploaded and currently has almost 28k PubMed articles. It might be relevant to mention when the documents were obtained. The authors mention 8k, thus probably it was obtained sometime in April.\n\nIn table 1, 2861 \u2014> 2,861", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/AnonReviewer4"]}, {"id": "PRJM_hpjoC", "original": null, "number": 2, "cdate": 1593796328800, "ddate": null, "tcdate": 1593796328800, "tmdate": 1593796456219, "tddate": null, "forum": "SPxaJuM4Hbz", "replyto": "SPxaJuM4Hbz", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/-/Official_Review", "content": {"title": "Overall a good exploration of previous document classification algorithms applied to Covid-19.", "review": "The paper presents an exploration of the main document multi-classification algorithms, training and developing on the LitCovid dataset and testing on a small manually annotated portion of the much larger CORD-19 dataset. The LitCovid dataset includes labels for each document to 8 categories with about 1/3 of documents including multi-labels. The significance lies in the usage of these multi-classification algorithms for researchers, clinicians, epidemiologists, and policy makers to find the most relevant articles in a timely manner given the urgency of the pandemic. \n\nThe paper is clear and well-written. The application of document classification algorithms to Covid-19 is novel, but the algorithms themselves are not.\n\n\nPros:\n- An in-depth exploration of many different algorithms along with tuning for best performance.\n- Contains both intrinsic and extrinsic evaluations.\n- The discussion on data efficiency is quite interesting and can have a large impact on how much data is needed to annotate for future creation of gold standard datasets.\n- An error analysis that suggest future work and updates.\n- Important to be applying all research we have so far on these new datasets to help with Covid-19.\n\n\n\nCons:\n- The manual annotation of the subset of CORD-19 seems to not be reliable as 34% of errors were annotation related.\n- Guidelines and annotation process not provided for the CORD-19 set.\n- The CORD-19 set is small and the performance does drop, suggesting that the models are not generalizable.\n- No discussion of providing these models to LitCovid to help with the annotation labeling, even if it is a starting point.\n- The accuracy is quite low for most algorithms and there is no discussion about this.\n- Very little discussion on the very different distributions of the categories between LitCovid and CORD-19. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/AnonReviewer2"]}, {"id": "C7OHi0i4FKI", "original": null, "number": 1, "cdate": 1593624499405, "ddate": null, "tcdate": 1593624499405, "tmdate": 1593624499405, "tddate": null, "forum": "SPxaJuM4Hbz", "replyto": "SPxaJuM4Hbz", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/-/Official_Review", "content": {"title": "Review of Document Classification for COVID-19 Literature", "review": "This paper provides an empirical evaluation of several standard models' performances on a covid-19 related document classification task. Specifically, Covid-19 research papers are classified into one or more of eight subcategories based on their topic. Datasets for this task are constructed from LitCovid, and the Covid-19 Open Research Dataset. These datasets are shared online. Finetuned pre-trained language models are found to outperform more traditional models, such as SVM, CNN, or LSTM. In particular, BioBERT and Longformer are found to be most effective.\n\nThe paper introduces a multilabel document classification dataset which categorizes Covid19 related articles into one or more of eight subcategories. This dataset is distinct in that it represents a large body of work in the medical domain, united by a common subject. The data is drawn largely from LitCovid, with a supplemental test set drawn from the COVID-19 Open Research Dataset (CORD-19). The paper notes that models trained on the LitCovid data generalize poorly to the CORD-19 data, and theorizes that this is due to the models failing to ignore the overarching COVID-19 topic. It is unclear if this is the case, however, as, while CORD-19 includes papers related to other coronaviruses, COVID-19 is the overarching topic of both datasets.\n\nThis paper provides a thorough analysis of many different models' performance with thorough documentation. However, the efficacy of fine-tuned pretrained language models on document classification is well established in a large body of research. While this particular classification task is somewhat novel, demonstrating that finetuned pretrained language models are most effective upon it is a relatively limited contribution.\n\nPros\n - introduces a multilabel document classification task related to COVID-19\n - provides a dataset to support this classification task\n - provides a clear and thorough empirical evaluation of many different models' performances on this task\n\nCons\n - the empirical performance evaluation largely confirms trends shown by previous research\n - models trained on the provided dataset are shown to generalize poorly. The reasons for this are underexplored.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper18/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=JENSKEEzsoU", "paper_id": "JENSKEEzsoU", "reviews": [{"id": "CfSFTgnG87J", "original": null, "number": 3, "cdate": 1593356401802, "ddate": null, "tcdate": 1593356401802, "tmdate": 1593356401802, "tddate": null, "forum": "JENSKEEzsoU", "replyto": "JENSKEEzsoU", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/-/Official_Review", "content": {"title": "Potentially a good resource", "review": "This work presents a question-answering dataset created on a subset of CORD-19. Obviously, having a large QA dataset is valuable and if done well, can be a useful research both in the bioNLP field. The dataset is created by finding \"answers\" to potential questions that the text under examination would answer, surely, this effort has taken many hours to create. For what has been done, much less time and effort is put into writing about it. The manuscript is vert fragmented and hard to follow:\n- Abstract: Not clear what exactly is done and what contributions are\n- Introduction: You could reduce explanation on CORD-19 (removing the name of organisations for example) and refer to it in a citation. Instead it was expected to see what the NLP problem here was and what are the contributions of this work. None of that is there.\n- Related work is hardly a literature review. What is the common practice in the NLP community in creating a QA dataset. This is an old area. Surely there would be reputable (not arxiv) papers there to check and compare? Why tools are there and why are they relevant given they are two IR tools mentioned? \n- Section 3 needs a full rewrite. All the important details are missing. What were the annotation instructions and why? Ho w many annotators did you have? Was there any quality control? Any inter-annotator agreements for example?\n- Not sure if the  paragraph before 3.1 makes any sense. BioBERT and SciBERT and so on are more representations. What is the relevance here?\n- In Section 3, it says annotators are told they are developing a \"method\". How is this a method? \n- Method section is quite weak but maybe enough for a dataset work. \n- Please check your references, even old ones are arxiv. Maybe they are published somewhere? or maybe you can find a peer-reviewed citation for some of those.\n\nOverall, even with the urgency of publishing COVID-19 related work, the paper should have acceptable quality which I believe this one need revision to get there. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/AnonReviewer4"]}, {"id": "OnmvkG9ThO", "original": null, "number": 2, "cdate": 1592783159673, "ddate": null, "tcdate": 1592783159673, "tmdate": 1593380269317, "tddate": null, "forum": "JENSKEEzsoU", "replyto": "JENSKEEzsoU", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/-/Official_Review", "content": {"title": "QA dataset on CORD-19", "review": "Summary of Work: This work provides a new resource, a QA dataset built on top of CORD-19 annotated for span prediction task in form of SQuaD dataset. The dataset contains 2K question from 147 articles (I am not clear on this point, the authors say they extracted 445 documents). They also built a model on top of this dataset by finetuning roberta base and find improvement over original roberta base.\n\nWhile the dataset may be useful, we don't really know what criteria the annotators used to annotate the questions (How do they select what to annotate as answer? , what is considered important? - Do note that the authors also provide online videos of instructions that I have note reviewed which may contain the answer to this.)\n\nAlso the authors mention the questions can be reviewed/corrected by other annotators but again I don't know if it was done for every question and by how many other annotators. The annotators are said to be volunteers (I assume that to mean they were not paid) but I am not sure how they were recruited and how their qualification were evaluated (the paper says the authors require them to have a masters in biomedical sciences, although not sure how that is checked).\n\nIn general, the paper provides us some info about the new dataset, but the details are left out. As such, I am not confident in its utility for useful (and trustable) research .\n\nThe modelling framework is straightforward although their may be obvious improvements that can be made by training on biomed corpora. The top-n-accuracy metric needs more explanation (does the overlap mean overlap in text or position -- the first one is useless since we overlap on stopword easily, the second one might be more useful, but more analysis is needed).\n\nThis work needs a spell check (caronavirus -> coronavirus, fee -> see, and more).\n\nI would note that a lot of my criticism maybe resolved by providing more details. But without them, I cannot truly provide a good review of the dataset itself. Therefore, currently I am giving a marginally below threshold score (and not a clear rejection since the dataset *may* be useful)\n\nUPDATE: The authors answered questions presented above. The concern still remains about the quality of annotations, as well as the utility of model released. On the basis of this, I have increased my score.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/AnonReviewer2"]}, {"id": "sCoDR2-fOYk", "original": null, "number": 1, "cdate": 1592586818079, "ddate": null, "tcdate": 1592586818079, "tmdate": 1592587342105, "tddate": null, "forum": "JENSKEEzsoU", "replyto": "JENSKEEzsoU", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/-/Official_Review", "content": {"title": "Development of a QA dataset for COVID-19; a work in progress that requires revision", "review": "Authors have developed a QA dataset based on scientific articles about coronaviruses released as part of the COVID-19 Open Research Dataset (CORD-19). A small set of 450 articles were selected based on keyword matching, random sampling, and expert search, and around 2K Q-A pairs were developed against these articles, where question were generated by annotators and answers were sentences in the articles. Annotators were required to have a degree in the biomedical sciences. Also, the annotated dataset and a fine-tuned BERT-based model have been released. \n\nAuthors investigate an important problem, and the paper is well organized and well written. In addition, such a dataset could be a valuable resource as it enables computer scientists and clinicians to address their information need about COVID-19 based on reliable sources (scientific literature).\n\nHowever, there are few shortcomings that prevents me from recommending the paper for acceptance at this time:  \n\n1. Data Quality: Each QA pair has been annotated by only one annotator. I suggest having the data annotated by at least two annotators followed by a third one (or a discussion between the first two annotators) to adjudicate the disagreements. It's important to consider that a good model should learn the actual task as apposed to optimally mimicking the behavior of a single annotator. In addition, I wonder if annotators labeled \"all\" sentences of articles that answer the questions. This is important for correct evaluation (models should not be penalized for correct predictions that are not labeled). In addition, I found many questions in the dataset that:\n\na): are not necessarily relevant COVID-19:\n- \"What is the main cause of HIV-1 infection in children?\"\n- \"What plays the crucial role in the Mother to Child Transmission of HIV-1 and what increases the risk\"\n- \"What is the molecular structure of bovine coronavirus?\"\n- \"What causes the outbreak of SARS and MERS?\"\n\n\nb) are general with potentially multiple correct answers:\n- \"Who plays a role in regulating the immune response to a vital infection?\"\n- \"Which species are more prevalent but less severe?\"\n- \"What is a significant cause of Influenze like illness among healthy adolescents and adults presenting for medical evaluation?\"\n\n\nc) combined several answers together:\n- Q: \"Which species are more prevalent but less severe?\"\n  A: \"HCoV-HKU1, HCoV-OC43, HCoV-NL63, and HCoV-229E\"\n\n\nIn addition, \"no answer\" questions are probably the most interesting and prevalent questions about COVID-19. Such questions have not been developed in the context of this work.\n\n\n2. Modeling: Articles were splitted into multiple chunks of text and only two chucks (a positive chunk containing the answer of a given question and a randomly sampled chunk as negative example) were used to test the model. This design choice can oversimplify the task. In addition, given that the \"no answer\" output of the model was disabled, I'm not sure how the model works on the negative chunks. What should the model predict in cases of negative chunks?\n\n\n3. Evaluation: Top-n-accuracy measure is defined as follows: \"it compares the gold label against n model predictions and looks for any overlap between prediction and answer positions.\" It is not clear how accuracy is derived from overlaps. But, if \"any\" overlap between prediction and answer positions is treated as a hit, then Top-n-accuracy is not a good/reliable metric because a small overlap (e.g. a stopword) is just enough to treat a wrong prediction as a correct answer, and an untrustworthy algorithm as a trustworthy one. This is specially problematic for questions with long answers.\n\nI recommend authors to consider and address the above comments and re-submit their papers.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper17/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=W3Dzaik1ipL", "paper_id": "W3Dzaik1ipL", "reviews": [{"id": "ts_MHIZGEQy", "original": null, "number": 3, "cdate": 1594008174715, "ddate": null, "tcdate": 1594008174715, "tmdate": 1594138217099, "tddate": null, "forum": "W3Dzaik1ipL", "replyto": "W3Dzaik1ipL", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/-/Official_Review", "content": {"title": "A Good Positioning or Pilot Study using Graph Community Detection and Bio-BERT Embedding for Topic Clustering and Query Matching with multiple potential applications", "review": "The paper is well-written with clarity and identification of gaps, limitation and future studies.  \n\nStrength: This is a good pilot study employing graph-based community detection and semantic similarity matching at sentence level using pre-trained bio-BERT embedding model for topic clustering and query matching.  It also describes experiments using the algorithms for information retrieval, document summarization, and question and answer bot.  \n\nWeakness: 1. Due to lack of groud-truth data sets, neither of the methods are evaluated quantitatively. 2. The topic clustering using only the paper title can be limiting as an article may have multiple topics.  3. The information retrieval system returning the relevant article based either on the paper title or sentence similarity is more of relevant document retrieval rather than information retrieval given the query.  This weakness is also reflected in the Q&A bot because returning an article or even a passage to a question is not the same as returning precise answer to the question as expected or desired by the user from Q&A bots. 4. Although the authors identified the limitation of pre-trained Bio-BERT model doesn't include COVID-19, the paper did not describe how it overcome this limitation.\n\nHowever, the authors are trained in the field and familiar with the relevant literature.  Given the time, this study has good research and application potential.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/AnonReviewer3"]}, {"id": "T8Nb254pXvV", "original": null, "number": 2, "cdate": 1593782867350, "ddate": null, "tcdate": 1593782867350, "tmdate": 1593782867350, "tddate": null, "forum": "W3Dzaik1ipL", "replyto": "W3Dzaik1ipL", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/-/Official_Review", "content": {"title": "An IR & IE engine for CORD-19 dataset works without the need for any labelled data", "review": "This paper presented a search engine that can perform both information retrieval and extraction for the COVID-19 Open Research Dataset. \n\nThe information retrieval component first converts the article collection into its graph representation. The graph is constructed by leveraging both Citation Network and semantic similarity between documents derived from sentence vectors produced by BioSentVec. A Community Detection algorithm Ego-splitting is then applied to the graph for identifying clusters of documents. When answering a given query, the system constructs a candidate set by gathering articles from the clusters of which document\u2019s titles are most similar to the query in terms of BioBert embeddings. The system then compares the query vector with the BioBert vectors of entire articles in the candidate set and returns the most similar articles as final results.\n\nThe information extraction component has two different setups, Question Answering, and Summarisation. The former is done by using BioBERT for reading comprehension and the latter is done by K-means clustering on the sentence embeddings and extracting the centroids.\n\nStrength\n\n1. The paper presented a system that uses pre-trained and un-supervised models only. This is particularly meaningful as the time and resource for annotating data for COVID-19 related literature are very limited at the moment while the need for such systems is urgent.\n\n2. The Kaggle shared task is used to aid the qualitative analysis to test the system performance when facing real-world information needs when there are limited resources for quantitative analysis. \n\nWeaknesses\n\n1. Although it has been mentioned in the introduction that the direct use of BioBERT might not be optimal, BioBERT is not fine-tuned by using the CORD-19 dataset. \n\n2. No visualization to aid qualitative analysis. The system proposed for IR heavily depends on a graph-based clustering algorithm. However, there is no figure visualizing the derived map. The paper mentioned that the granularity of the map is controlled by a hyper-parameter, which is crucial to the entire system. But the choice of this parameter is not discussed and well-justified. Hence it might be interesting to visualize the map in different granularity and pick the one with the best cluster coherence. \n\n3. Other than the use of BioBERT, it is not clear how the system is optimized for the CORD-19 dataset. It would be better if the system can leverage features that are specific to this context. \n\n\nDetails\n\nSection 2\nA flow chart of the entire pipeline would help in depicting the system at a high-level.\n\nSection 2.1\nHow is the threshold for semantic edges selected?\n\nSection 2.2\nThere are many concepts that the reader might not be familiar with here, such as \u2018\u2019ego-net\u2019\u2019 and \u2018\u2019ego-splitting\u2019\u2019, since the paper does not have a section dedicated for introducing related work, it would be clearer if more detail of these methods is provided.\n\nSection 2.3 - 2.4\nHere the system aims to reduce the set of candidates by filtering documents at cluster-level first. However, when doing cluster matching, the system still needs to compare the similarity between the BioBERT embeddings of the query and the title of each document. This should be fine for CORD-19. But for better scalability, it would be good to reduce the time complexity from the number of documents to the number of clusters.\n\nSection 2.6\nIt is not clear whether this system uses a general BERT or BioBERT.\n\nSection 3.1\nIt would be better to introduce the dataset earlier since it is supposed to be what the design of methodology based on.\n\nSection 3.2\nHow are the 38k papers sampled from the CORD-19 dataset?\n\nSection 3 (general)\nIs the summarization system also evaluated?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/AnonReviewer4"]}, {"id": "D7egLAlf_JN", "original": null, "number": 1, "cdate": 1593752670709, "ddate": null, "tcdate": 1593752670709, "tmdate": 1593752670709, "tddate": null, "forum": "W3Dzaik1ipL", "replyto": "W3Dzaik1ipL", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/-/Official_Review", "content": {"title": "An interesting search engine for CORD-19 but not properly evaluated.", "review": "The article describes a search engine dedicated to the CORD-19 corpus, a corpus focused on Covid-19 and released during the pandemic. The search engine relies on a similarity graph to find relevant documents for a given query. The nodes of the graph are the corpus articles and the edges are marking the existence of common citations between the articles or a high textual similarity between them. The ego-splitting algorithm was used to cluster the graph. Bio-BERT is heavily used to return, for a given a query, the most appropriate clusters, select the more relevant articles of the clusters selected, and the best matching sentences. Unfortunately, by lack of time and ground truth, the search engine was not quantitatively evaluated, only qualitatively evaluated.\nStrength \n\n    The article tackles an important problem and will provide a well-needed tool to help research. Can the authors give an estimation of the total time needed to implement and deploy the search engine? Is the search engine ready and available to be used by the community? \n    The article is well written and overall easy to follow. Some typos. \n    I found the idea to base the search engine on a similarity graph interesting and the intensive use of Bio-BERT should ensure the quality of the answers of the search engine. \n\nWeakness \n\n    The article has been submitted too quickly and should be revised before publication. The main limitation of the study, already acknowledged by the authors, is the lack of evaluation. I agree with the authors than without ground truth a quantitative evaluation is difficult to perform but a better qualitative evaluation is possible and should have been done before submission. In section 3.6 the authors described a possible way to estimate the precision of the search engine. Without resorting to Mechanical Turk, a simple double-blinded annotation should be sufficient to compute the statistic needed. To estimate the recall, a small set of articles could have been randomly selected and a manual evaluation of the clusters they have been assigned to, as well as the clusters they should have been assigned to, performed.  \n    There is no related work section and the article failed to compare the method proposed with the state-of-the-art methods in IR. I would also expect the quantitative evaluation to be performed on the results of a baseline system. \n    The Q&A (and chatbot?) functionalities of the system are very briefly presented and could probably be discussed in another paper, focusing this paper on the search engine. \n\nDetails \nIntroduction \n=> the first occurrence of BioSentVec in bracket is probably a reference missing, please double check \n=> contribution 3 is difficult to read \n=> contribution 4, what are the intents? \n2.1 \n=> Was the unification of the references easy done? How the unification was performed, was the performance evaluated? \n=> typo \u2018cities\u2019 \n=> if I understand correctly an edge is drawn between article A and B if A cites C and B cites C, a formal definition could  clarify the reading \n=> The authors mentioned that for the simplicity of the discussion they consider the 2 types of links indistiguinshable but are they different in the computation? If yes, it has to be explained \n=> typo: \u201cif they have multiple citations in? common\u201d \n2.2 \n=> the ego-splitting algorithm should be explained in more detail. Without reading the reference, the idea of the algorithm is hard to understand in the current version \n2.3 \n=> What are the cluster labels, they are defined yet \n=> \u201cis to purpose labels for each query in lieu of the supervised multi-label classification which is not possible due to the lack of the ground truth labels\u201d, the sentence is unclear to me \n2.6 \n=> a figure showing the full pipeline could be useful \n3.1 \n=> the description of the data should be in the method section, not in the results. The authors should also refrain to use bold fonts \n3.2 \n=> how 0.3 was chosen? \n=> typo: \u201cthere a lot of clusters\u201d \n3.4 \n=> As it is currently phrased in the document, I am not sure if the authors are just using the data available on Kaggle or if they actually try to solve the shared-tasks, please precise  \n3.5 \n=> please, provide the numbers for the quantitative evaluation: how many clusters, how many articles were manually checked? Was the verification done double-blinded? \n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper15/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=ub9_2iAo3D", "paper_id": "ub9_2iAo3D", "reviews": [{"id": "m0fN1h31Q3", "original": null, "number": 3, "cdate": 1594069497050, "ddate": null, "tcdate": 1594069497050, "tmdate": 1594374194591, "tddate": null, "forum": "ub9_2iAo3D", "replyto": "ub9_2iAo3D", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/-/Official_Review", "content": {"title": "Interesting correlation, but not actionable and not clear", "review": "This paper analyzes the correlation between Covid19 cases (as reported by JHU) and relevant tweets, on a per-country based granularity.\nThe results are remarkable, showing a very strong correlation (Table 2) for a model trained on Italian data. Moreover, using modern multi-lingual embeddings, the trained regression carries over to other languages; although the correlation there is very variable (and sometimes negative).\nThe results are intriguing and show once more how expressions on social media reflect physical reality. \n\nI have however two major concerns:\n\n1/ Why is this useful?\nNot in the sense of what could public health officials do with such models (although I have no clue what they could do). It seems to me (and please correct me if I am wrong) that you are using the tweets of day D to predict number of cases of day D. If that is the case, then the causality is the other way round (cases => tweets). It would be much more interesting to try to predict number of cases at day D+1, or even better at day D+n.\n \n2/ Reproducibility \nThere are lots of things that are not clear. Those are not fundamental issues, but I cannot recommend acceptance in the current state, as I could not understand exactly what the authors did, much less would I be able to reproduce it\nFiltering: \n  - why do you remove tweets with hyperlinks?\n - \"we remove [...] tweets discussing countries other than Italy\". What does this mean?\n - \"We further filter Italy\u2019s tweets for a balanced representation of tweet embeddings.\" What does this mean?\nModel:  what exactly is a model? Is it the embedding + the total frequency of the selected words? Could you enumerate all the \"models\" (feature set) you used and - maybe in the appendix - the values for all of them?\nEvaluation: Why do you not report mean error? The correlation itself is not very actionable, the predicted value would be\n\nAlso, there is a confusion between language and country, which is conflated. The given argument is that the chosen languages have a majority country, but for rigourousity I would recommend replacing country everywhere by language as it is misleading.\n\nFig 1 seems to be done with the number of tweets before the filtering of Sect 2.5. Why?\n\nFinally, I am not sure if I understand how the transfer is done. Is it correct to say that you use the same regression and provide as feature the Japanese/Indonesian/etc tweets after putting them through the multi-lingual embedding?\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/AnonReviewer5"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/AnonReviewer5"]}, {"id": "9urbye2Kyb", "original": null, "number": 2, "cdate": 1592500953991, "ddate": null, "tcdate": 1592500953991, "tmdate": 1592500953991, "tddate": null, "forum": "ub9_2iAo3D", "replyto": "ub9_2iAo3D", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/-/Official_Review", "content": {"title": "Good idea but some methodological concerns", "review": "The following paper hypothesizes that tweets can be used to model COVID-19 outbreaks in across countries. The paper does this by using cross-lingual sentence embeddings from mBERT and LASER to predict case-counts.\n\nAlthough this is a good idea and Figure 1 is particularly compelling, I find that the paper is at best a work in progress and at worst intentionally misleading. I'd recommend substantially more work before it is ready for publication. \n\nMy biggest concern is that the way the tweets are filtered and the time-chunks are specified, I have no reason to believe that this model is using tweets to actually predict an outbreak, as the authors imply (NB the authors are careful to say they are \"aligning\", not \"predicting\", although I think this intentionality is rather muddy). It seems to me that they are simply capturing the response to an outbreak already occurring -- I'm unclear what the value of this is to social scientists and policymakers.\n\nThe authors explicitly filter for words such as \"lockdown\", \"quarantine\", \"social distancing\", \"epidemic\", and \"outbreak\", to perform their alignment, which to me seem to describe tweet-responses to policy rather than tweet-responses to sickness. I think the authors' hypothesis would be better served by choosing words, topics or other indicators that are more personal and health-related -- words like \"fever\", \"cough\" or \"lack of smell\" -- to avoid such confounding.\n\nFurther, the authors utilized fixed time-periods to explore their regression, which is a little confusing to me. I think the authors should use date-ranges in each country relative to the kth case in that country. Since their date-ranges are so wide, I worry that the date-ranges are simply capturing the full policy response of a government that has already predicted an outbreak.\n\nWhy is spearman's correlation the only metric used? If the authors are conducting a regression experiment, there are other more compelling and interpretable metrics. Why aren't significance-values included for the correlation?\n\nWhy do the authors say that they observe \"right-skewed Gaussians\"? This is clearly more of a point process (i.e. a Hawkes process.)\n\nAdditionally, I would urge a more serious consideration of other confounders as well. I'm not sure what the best ones to use would be, but I think some policy analysis is necessary -- when did each country actually institute a lockdown? Do lockdowns effect overall non-COVID tweet-volume as well? I'm sure there are confounders in the literature.\n\nIf this is not possible, then I urge a reframing of the paper. The authors need to be clearer about what they are actually purporting to do, and not hide behind words like \"align\".", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/AnonReviewer2"]}, {"id": "dFKdhXneqjF", "original": null, "number": 1, "cdate": 1591902567685, "ddate": null, "tcdate": 1591902567685, "tmdate": 1591902567685, "tddate": null, "forum": "ub9_2iAo3D", "replyto": "ub9_2iAo3D", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/-/Official_Review", "content": {"title": "Review of: Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment", "review": "# [REVIEW] Cross-lingual Transfer Learning for COVID-19 Outbreak Alignment\n\n10th June 2020\n\n## SUMMARY\nThis short paper describes work on cross-lingual transfer learning to track COVID-19 cases across Italy, Thailand, Japan, Turkey, and Indonesia (i.e. languages that are largely spoken in a single country).  Using case statistics derived from Johns Hopkins COVID dashboard, the researchers aim to determine (a) if the number of COVID-related tweets is associated with case numbers (good correlations were achieved for this), and (b) can this training be applied to other countries that may be at a slightly different point in their COVID trajectory i.e. cross-lingual transfer learning (a range of correlations with JHU data were achieved ranging from -.316 to 0.859, indicating that the approach has some utility \u2014 but see caveats below).  \n\nIt is difficulty for me to assess the quality of this paper relative to other submissions, but I suspect that this use of cross-lingual transfer learning is sufficiently interesting to justify a short paper.\n\n## MAJOR COMMENTS\n1.  There is a major methodological issue not related to the NLP and not something you can be reasonably expected to do anything about \u2014 but I think it\u2019s important to point it out as a limitation:  The international ground truth data for COVID is  not very reliable regarding underlying prevalence/incidence of COVID-19.  Even in the US, there have been stark differences in approaches to testing, and the criteria for testing. International comparisons are even more difficult. This undermines the evaluation somewhat.\n\n## MINOR COMMENTS [NITPICKING]\n1.  [p1c1] \u201cWith globalization, it is intuitive that countries have followed earlier affected regions in patterns of outbreaks and measures to contain to them (Cuffe and Jeavans, 2020).\u201d Consider rephrasing this to emphasise that it is the increased travel associated with globalization that is important, rather than globalisation per se.\n2.  [p3c1] \u201cBert as service\u201d probably requires a few words of  explanation (at least for this reviewer - I had to google it)\n3.  [p3c2] \u201cWhen measuring against new daily cases, the correlations are not as significant in time II\u201d  suggest avoiding using the word significance here, unless you are referring to statistical significance.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper11/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=EC1vWkJXpjy", "paper_id": "EC1vWkJXpjy", "reviews": [{"id": "OCfxZaxJpcP", "original": null, "number": 3, "cdate": 1589391099436, "ddate": null, "tcdate": 1589391099436, "tmdate": 1589391099436, "tddate": null, "forum": "EC1vWkJXpjy", "replyto": "EC1vWkJXpjy", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/-/Official_Review", "content": {"title": "Novel task with under-developed motivation", "review": "This paper presents a BERT-based model for solving the novel task of grounding sentences to 3D locations in a representation of a human male body. The authors induce training labels by automatically extracting a list of organs and their synonymous wordforms using the SciSpacy UmlsEntityLinker and extracting sentences containing at least one mention of an organ on their curated list. The ground-truth voxel coordinates are assigned using organ locations from a 3D atlas, and several BERT models are fine-tuned using a distance-based regression loss. The paper presents a novel task, is clearly written, and thoroughly explains their experimental choices and settings.\n\nIssues:\n\n1. One of the key premises of the paper is that physical proximity in the human body reflects functional and semantic relatedness to a significant degree. This statement needs more justification, especially since it is such an important part of the motivation for this work. Looking at a model of a human torso, it seems that the centroid of the left lung may be closer to the centroid of the stomach than to the centroid of the trachea. Similarly, the centroid of the stomach seems closer to that of the spleen and pancreas than of the large intestine.\n\n2. It's not clear what is gained by performing this as a regression task to directly predict 3D coordinates instead of as a classification task that can then be transformed to 3D coordinates using the atlas (the ClassCenter model). The motivation seems to be that in cases when the classification model gets the wrong organ, the predicted 3D location is significantly worse than in the regression model (i.e. NVD-O for ClassCenter is higher). However, the classification model identifies the correct organ with much significantly higher frequency (i.e. IOR is higher). The overall effect is that even in the masked setting, the average per-sentence voxel distance is much lower for ClassCenter (i.e. taking the linear combination of NVD and NVD-O w.r.t. IOR).\n\n3. The use case needs further justification. In what situations is specifying a position in a 3D atlas preferable to submitting a textual (or UMLS-keyword) query? Since the training data only uses the centroids of organs, is there a meaningful difference between querying for the centroid of the stomach vs. somewhere else within the organ? Are the relative positions of sentences embedded within the same organ semantically meaningful, or mostly a product of noise in the regression?\n\n4. Representing abstracts as a point cloud composed of individual sentences seems like it would cause issues for the information retrieval task presented in section 7.2. What happens to the majority class of sentences that don't contain a mention of an organ, either implicitly or explicitly? Does the frequency of sentences containing an organ mention accurately represent the relevance of the document?", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/AnonReviewer1"]}, {"id": "uD53XL9oEw-", "original": null, "number": 2, "cdate": 1588516975441, "ddate": null, "tcdate": 1588516975441, "tmdate": 1588516975441, "tddate": null, "forum": "EC1vWkJXpjy", "replyto": "EC1vWkJXpjy", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/-/Official_Review", "content": {"title": "interesting exploration with unclear justification", "review": "This paper describes methods for learning a mapping between sentence vectors (as produced by the [CLS] token in BERT) and 3D points in the human body. The idea is that sentences that are about some anatomical site can be mapped to that position in the body for visualization. It is never completely clear from the paper why this needs to be learned, since the training pre-processing already is finding anatomical site mentions and essentially normalizing them to a set of body parts with known coordinates. The only thing I can figure is that they are using their pipeline as a way to generate labeled training data, and they intend for this to be applied to sentences without explicit anatomical site mentions. This is maybe supported by the fact that their training does include 50% masking of anatomical sites. In that case, there is a missing element here, which is that the vast majority of sentences in a document are not \"about\" any organ at all, so mapping them into organ space is meaningless. So for this algorithm to be applicable, one would first need to pre-process sentences somehow for whether they should go onto the organ mapping stage at all. And in any case, their example application presumably is just mapping the sentences that did have anatomical site terms. Overall, I think the logic of the approach needs to be spelled out more clearly. As it is, it feels like an interesting trick that one can learn this mapping but I just don't see why it's necessary.\n\nOther issues:\n- This mapping will surely generate \"point clouds\" around organs (i.e. sentences mentioning lung will be spatially distributed near the lungs rather than all mapping directly to the centroid of the lung). This may give an expert in anatomy some sense that these minor differences are anatomically meaningful where I believe it would be largely noise, and if some finer-grained meaning were there it would be impossible to distinguish from noise.\n- Results tables are never referred to in the text\n- There should be some discussion of what you \"want\" if there are multiple organ mentions. I certainly don't want some \"average\" position, but also don't want it to just show up in 1 position, it should probably show up in all 3 positions. But that is not a function anymore so not really something you can ask a neural network to do.\n- When masking anatomical sites in the training data, do you ever use the same sentence in both the masked and unmasked form? I think it would be preferable with this dataset to randomly choose one form before training, rather than randomly choosing to mask each time an instance is loaded (which could result in different masking behavior for the same instance across epochs) because otherwise it could be memorized.\n- I don't know if self supervised is the right term here. It's more like a clever way of generating supervised instances.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/AnonReviewer3"]}, {"id": "TqlgXJaErj8", "original": null, "number": 1, "cdate": 1587523417257, "ddate": null, "tcdate": 1587523417257, "tmdate": 1587523417257, "tddate": null, "forum": "EC1vWkJXpjy", "replyto": "EC1vWkJXpjy", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/-/Official_Review", "content": {"title": "Interesting anatomical exploration of COVID articles using BERT-based grounding", "review": "The paper proposes a self-supervised approach to ground sentences in COVID-19 articles to a 3D human atlas. This is the first study to use self-supervision to map sentences in medical articles to anatomical locations in the 3D atlas space. Unlike the prior works that utilized the atlas space, they formulated the grounding as a regression problem, thereby allowing a better idea about the semantic closeness of the sentences to the target body locations. The study has also proposed the potential use of this grounding approach for data visualization and document retrieval use cases.\n\nStrengths:\n-- The study employs a fully self-supervised technique for grounding sentences to a 3D human atlas. This is neat and has a lot of potential applications beyond COVID-19.\n-- This work takes into account the prevalence of multiple organs in the same sentence while calculating the loss while training.\n\nMajor issues:\n1. As discussed as one of the limitations that user study needs to be done to validate the query tools, as it is difficult to verify the actual performance of the document retrieval tool from the current version. Moreover, since the distance between the centroids of the point clouds is used to retrieve the articles relevant to a query, it is difficult to interpret whether this approach is useful as this does not take into account which of the sentences in the abstract are more close to the query. Some sentences in the article might just be providing background information and the corresponding organs might not be of interest to the user. To address this, it may be considered to have a way to identify the sentences of interest.\n\n2. A brief discussion of interpreting the results mainly to indicate any potential relation between the impact of using the masked technique and the evaluation metrics used can be included.\n\n3. Although the proposed method definitely obviates the expensive annotation part, it might be good to further compare the evaluations with a supervised model to validate that self-supervision performs better than a fully supervised approach. At the least, it would be good to compare the performance of these models with supervised models used on other datasets in the previous works for grounding medical text to 3D space.\n\nMinor issues:\n1. As already pointed out in the discussion that the models have only been trained on single sentences, it needs to be investigated whether a similar loss contribution strategy would work well when multiple sentences are included in the training process as organs appearing in different sentences might be very different from each other.\n2. An evaluation of the methods to illustrate their performance on sentences having rare or infrequent organs may be reported.\n3. How is the 8000 sentences mark determined for tackling the imbalance of different organs?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper5/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=PlUA_mgGaPq", "paper_id": "PlUA_mgGaPq", "reviews": [{"id": "r405CzUub_7", "original": null, "number": 3, "cdate": 1587548155603, "ddate": null, "tcdate": 1587548155603, "tmdate": 1587548155603, "tddate": null, "forum": "PlUA_mgGaPq", "replyto": "PlUA_mgGaPq", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/-/Official_Review", "content": {"title": "Useful resources collected and introduced", "review": "This work is an introduction to a suite of resources and their corresponding ideas revolving around the COVID data provided by the Allen institute. Authors in particular provide Neural Covidex which allows exploration of information retrieval and NLP techniques over the COVID dataset.\n\nThe positives of this manuscript is as it also says gathering all the information and resources one would need to start exploring this dataset and further the techniques without having to spend weeks to put them all together. It is significant effort to get this far and of course authors are relying on their previous work over many years. There are some good pointers for some of the recent work in biomedical IR that is useful to know. I personally learnt from the content and enjoyed reading it.\n\nThis work however is written in haste (as it was needed due to the time limit of the current situation) and it is lacking the formal language of a scientific paper and of course evaluation. Obviously evaluation on this particular dataset is not straightforward given for example TREC is only starting on that effort. However though some initial analysis of the dataset could strengthen it. I was half expecting to see the discussion on evaluation metrics be a bit more mature and be given a separate section at least. This work as it stands, while very useful for the IR/NLP community it needs some reworking of the content to get to the state of publication in an ACL workshop. \n\n\n\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/AnonReviewer2"]}, {"id": "v_Lr_Cw1sDL", "original": null, "number": 2, "cdate": 1587408439332, "ddate": null, "tcdate": 1587408439332, "tmdate": 1587408439332, "tddate": null, "forum": "PlUA_mgGaPq", "replyto": "PlUA_mgGaPq", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/-/Official_Review", "content": {"title": "Laudable effort, but currently more preprint material", "review": "This paper describes the rapid deployment of an IR system for the CORD-19 dataset. The system borrows state-of-the-art pieces, such as T5 and BioBERT, with training on MS MARCO. A search interface is shown that includes potential answer highlighting. Absent hard evaluation data, the authors provide more of a narrative of the system development, from initial conceptualization, early builds, deployment, and social media advertisement.\n\nFirst and foremost, the authors are to be congratulated for this work. The effort is most laudable.\n\nThe style and tenor of the paper should be described as somewhere between a Medium post and a work-in-progress preprint. While normally this would be out of place, it is less out of place in a workshop such as this one. The casual language is fine and almost cute, while the frankness is quite welcome, but the other preprint-like or web post-like aspects of the paper are more problematic.\n\nLet's start with the lack of evaluation, which the authors acknowledge that \"It is, of course, expected that papers today have an evaluation section that attempts to empirically quantify the effectiveness of their proposed techniques\". Of course, this empirical validation is what makes it science, as opposed to engineering/marketing. I certainly understand that the resource commitment to a TREC-style evaluation is beyond one group's ability under a pandemic situation. But the authors present the solution within their own paper: from footnote 14 it appears that the TREC-style evaluation is underway, and that should have preliminary results available well before this workshop's deadline. So why not simply issue this as a preprint to flagplant their admittedly laudable effort, then wait until some empirical results are available and submit *that* paper to the workshop?  If the authors plan to submit a work with results as a separate publication, this should be made more clear and a more compelling argument needs to be made for the scientific usefulness of the \"behind the scenes\" story of this search engine.\n\nThe authors make the claim that instead of the importance of search result ranking (despite Section 3 being about how great the system is at ranking on other tasks), that instead what is really important are the interface improvements that increase the usability of the system. However, every real-world IR evaluation has come to exactly this conclusion: experts always request various bells and whistles. First, note that users can't see the relevant articles that were missed, so they have little choice but to comment on the interface. But more importantly, good ranking != good usability, this is no novel claim. But usability evaluation is a well-honed science, and the authors do not perform any kind of usability evaluation either. These are less resource-intensive as well, typically requiring just an IRB protocol and some experts willing to provide feedback.\n\nMy main stylistic issue is that in many places this paper comes across as a brag-fest for the accomplishments of the group. These accomplishments are beyond doubt, of course, which is all the more reason why the authors can avoid tangents to cite unnecessary prior work (e.g., most of the BERT stuff in the first paragraph of Section 3.3, as this is not even used in the system).  The implications in Section 5 that the authors' group's \"culture\" and use of good software practices, unlike other poor-coding researchers, is also unnecessary (why is a \"faculty advisor\" reference even there?). One can extol the virtues of good culture and software engineering without coming across as bragging, so I would recommend a re-write of those parts of this paper to take a more scientific tone.\n\nMinor:\n- In Section 3.1 it is unclear what the \"1\" in \"n+1\" comes from. Do the authors also include a document that is just the title/abstract without the paragraphs?\n- \"who are engage in\" -> \"who are engaged in\"\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/AnonReviewer3"]}, {"id": "0OSrp-gWXIG", "original": null, "number": 1, "cdate": 1587312585741, "ddate": null, "tcdate": 1587312585741, "tmdate": 1587312585741, "tddate": null, "forum": "PlUA_mgGaPq", "replyto": "PlUA_mgGaPq", "invitation": "aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/-/Official_Review", "content": {"title": "Evaluation of a rapidly deployed search system for the CORD-19 data set", "review": "The authors have quickly stood up a conventional and neural search system based on the CORD-19 dataset, which is a commendable task given the global crisis caused by the Covid-19 pandemic. However, this paper is just a description of their system and design decisions, with some additional discussion of why a conventional TREC system-oriented retrieval evaluation would be limited. I agree with the authors on that point.\n\nHowever, it would be helpful to have some sort of evaluation of their system to gauge whether their approach offers any novelty beyond the multiple other systems that been stood up and linked to from the Allen Institute site where the data is housed.\n\nWhile I agree that a system-oriented evaluation approach would be limited, it would also be helpful to, say, compare the baseline and neural approaches. The first round of the TREC-COVID challenge evaluation is being conducted as I write this, and the first set of results will be available by late April or early May. I believe a better approach would be to include these results and then discuss their limitations.\n\nIf the authors do not believe the system-oriented results are important, they can explain why. They could provide some usage statistics for their system and describe other real-world use. They can also propose better evaluation studies, including those that involve users as they allude to in their paper.\n\nOverall this is good work, but it could be much better, and we will hopefully learn more as the system is used, the test collection grows, and more complex tasks beyond ad hoc retrieval are evaluated with it.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2020/Workshop/NLP-COVID/Paper2/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=p4SrFydwO5", "paper_id": "p4SrFydwO5", "reviews": [{"id": "r7yrE0Liysr", "original": null, "number": 3, "cdate": 1638240968734, "mdate": null, "ddate": null, "tcdate": 1638240968734, "tmdate": 1638240968734, "tddate": null, "forum": "p4SrFydwO5", "replyto": "p4SrFydwO5", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper32/-/Official_Review", "content": {"title": "A novel method of empirical attacks and defenses using semantic transformations", "review": "This paper proposed novel defense and attack methods using image transformations. The random transformation defense is designed by averaging the scores of results under random transformations. This paper proposed to use Bayesian optimization to select the most informative transformation parameters. The authors also re-implemented and evaluate BaRT attacks and improve their performance.\n\nThe experimental results and solid and significant so I recommend a clear acceptance.\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper32/Reviewer_LPPi"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper32/Reviewer_LPPi"]}, {"id": "dU0_9HXBmFI", "original": null, "number": 2, "cdate": 1638175660986, "mdate": null, "ddate": null, "tcdate": 1638175660986, "tmdate": 1638175660986, "tddate": null, "forum": "p4SrFydwO5", "replyto": "p4SrFydwO5", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper32/-/Official_Review", "content": {"title": "A more reliable evaluation of robustness for random transformation defenses", "review": "The authors show that backward-pass differentiable approximation struggles to approximate some transformations accurately, and non-differentiable transformation can\u2019t guarantee robustness. Furthermore, the authors propose a novel attack method to evaluate random transformation defenses. This work provides a more reliable evaluation of robustness for random transformation defenses.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper32/Reviewer_vUox"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper32/Reviewer_vUox"]}]}, {"paper_url": "https://openreview.net/forum?id=UiF3RTES7pU", "paper_id": "UiF3RTES7pU", "reviews": [{"id": "dFKw3L-4xK", "original": null, "number": 1, "cdate": 1638260902061, "mdate": null, "ddate": null, "tcdate": 1638260902061, "tmdate": 1638260902061, "tddate": null, "forum": "UiF3RTES7pU", "replyto": "UiF3RTES7pU", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper18/-/Official_Review", "content": {"title": "Review of Paper 18", "review": "This paper proposes a metric of robust error with rejection, with the motivation that: 'For small perturbations within $\\epsilon_{0}$, both an incorrect prediction and rejection are considered to be an error. For perturbations larger than $\\epsilon$, rejection is not considered to be an error'. Based on this new metric, a corresponding adversarial training objective is designed in Equation (8). Empirical evaluations are done on MNIST and CIFAR-10, under both seen and unseen adaptive attacks.\n\nThe key to make this paper be widely accepted is to make the community buy in the new definition of *robust error with rejection*, in which the rejection is justified or not based on the magnitude of perturbations. This assumption is somewhat strong, since universal $\\epsilon_{0}$ and $\\epsilon$ may be suboptimal, e.g., an easy example with large perturbation should still be correctly classified and not be rejected, while similarly a hard example could be assigned a smaller $\\epsilon_{0}$. The authors may polish their definition into instance-dependent version, which could be more flexible and reasonable.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper18/Reviewer_rAKF"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper18/Reviewer_rAKF"]}]}, {"paper_url": "https://openreview.net/forum?id=1o5Bzo7BO3v", "paper_id": "1o5Bzo7BO3v", "reviews": [{"id": "YUVQDvYYhH1", "original": null, "number": 2, "cdate": 1638188189239, "mdate": null, "ddate": null, "tcdate": 1638188189239, "tmdate": 1638188189239, "tddate": null, "forum": "1o5Bzo7BO3v", "replyto": "1o5Bzo7BO3v", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper16/-/Official_Review", "content": {"title": "Review for adversarial attacks with attention", "review": "This paper introduces a white box adversarial attack method using attention to refine the PGD attack. A GNN is trained on adversarial examples generated by PGD to narrow down the search space of PGD. The GNN is used in the attack algorithm to learn from possible 'bad' start points. Experiments show that the proposed method increase the attack efficiency and success rate compared to the baseline method. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper16/Reviewer_6hzb"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper16/Reviewer_6hzb"]}, {"id": "_PrRUNkRt7U", "original": null, "number": 1, "cdate": 1638006577581, "mdate": null, "ddate": null, "tcdate": 1638006577581, "tmdate": 1638006577581, "tddate": null, "forum": "1o5Bzo7BO3v", "replyto": "1o5Bzo7BO3v", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper16/-/Official_Review", "content": {"title": "A good idea to introduce GNN into adversarial attacks. The efficiency of regular adversarial attackers is improved.", "review": "Pros:\n1. The writing is good.\n2. The explanation of using GNN is clear.\n3. The experimental results are convincing.\n4. Using GNN as an attention mechanism to find the pitfalls of a classifier is a good idea. Maybe it can be used in more important scenarios.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper16/Reviewer_aczm"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper16/Reviewer_aczm"]}]}, {"paper_url": "https://openreview.net/forum?id=u_lOumlm7mu", "paper_id": "u_lOumlm7mu", "reviews": [{"id": "vsWI4_sF-UD", "original": null, "number": 2, "cdate": 1638168751302, "mdate": null, "ddate": null, "tcdate": 1638168751302, "tmdate": 1638168751302, "tddate": null, "forum": "u_lOumlm7mu", "replyto": "u_lOumlm7mu", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper30/-/Official_Review", "content": {"title": "Convergence Analysis of No-Regret Learning Algorithms in Min-Max Stackelberg Games", "review": "This paper provides a convergence proof of no-regret learning algorithms in min-max Stackelberg games. Under certain assumptions, the authors prove that the no-regret learning algorithms will converge to a equilibrium after $T$ iterations in pessimistic and optimistic settings (with Lagrangian regret). The author then apply above theorems to OMD and derive $O(\\frac{1}{\\epsilon^2})$ convergence rate for those algorithms. Finally, the authors study the dynamic Stackelberg games and give theoretical proof for independent strategy sets.\nOne interesting question is: can these analyses be applied to two-player zero-sum games modeled by Markov Decision Process, which might be a more practical and challenging question to be considered.\n\nAlso some drawbacks must be addressed in terms of writing. Some inline functions can be adjusted for better reading, and grammar mistakes should be corrected before submission.\n\nthe average of the players\u2019 strategies converge to a Stackelberg equilibrium. -> converges to\n\nin average iterates. -> in average iterations.\n\nWe provide a review of related work in Appendix BThis paper is organized as follows. -> Appendix B. This", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper30/Reviewer_nG3n"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper30/Reviewer_nG3n"]}, {"id": "hcWCy4lcZz", "original": null, "number": 1, "cdate": 1637745151062, "mdate": null, "ddate": null, "tcdate": 1637745151062, "tmdate": 1637745151062, "tddate": null, "forum": "u_lOumlm7mu", "replyto": "u_lOumlm7mu", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper30/-/Official_Review", "content": {"title": "A novel work for Min-Max Stackelberg Games", "review": "This work considers min-max Stackelberg games. For two special settings of this problem, this paper proposes no-regret algorithms with convergence guarantee. Moreover, this work provides the theoretical analysis as well as expereimetal results of the algorithms' robustness.\n\nHowever, the connection between this work and adversarial mechine learning is relatively weak. Moreover, it's better to adjust the format of some equations, like the equation in the bottom of page 2 and in the top of page 3, the Lipschitz-continuous condition in the final of sec 2,  \u201cvanilla\u201d regret in page 4, the objective in Example 4.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper30/Reviewer_21Dc"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper30/Reviewer_21Dc"]}]}, {"paper_url": "https://openreview.net/forum?id=Dp5B1YhYlwY", "paper_id": "Dp5B1YhYlwY", "reviews": [{"id": "XvoG6OtRhMd", "original": null, "number": 2, "cdate": 1638290471504, "mdate": null, "ddate": null, "tcdate": 1638290471504, "tmdate": 1638290471504, "tddate": null, "forum": "Dp5B1YhYlwY", "replyto": "Dp5B1YhYlwY", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper29/-/Official_Review", "content": {"title": "Adversarial attacks for cyber-physical system.", "review": "This paper proposes a novel adversarial attack method for cyber-physical systems (CSPs). An encoder-decoder model is first trained to learn and interpret the features of sensing data. The encoder is further used to train a discriminator. Finally, the encoder and discriminator constitute a surrogate model to generate adversarial examples. Two CSP case studies are considered to demonstrate the effectiveness of the proposed method.\n\nWeakness:\n\nIt\u2019s better to introduce the CPS in related work.\n\nMore advanced transfer-based attack methods should be considered since FGSM and PGD are not strong transfer-based attacks, such as momentum-based attack methods [1].\n\n[1] Dong, Y., Liao, F., Pang, T., Su, H., Zhu, J., Hu, X., & Li, J. (2018). Boosting adversarial attacks with momentum. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 9185-9193).\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper29/Reviewer_4go9"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper29/Reviewer_4go9"]}, {"id": "gM-1qXMGdgs", "original": null, "number": 1, "cdate": 1638003765130, "mdate": null, "ddate": null, "tcdate": 1638003765130, "tmdate": 1638006661397, "tddate": null, "forum": "Dp5B1YhYlwY", "replyto": "Dp5B1YhYlwY", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper29/-/Official_Review", "content": {"title": "A good paper to realize adversarial attacks in CPS scenario. It has been shown effective in two defense cases, compared with baseline models.", "review": "Pros:\n1. This paper utilizes Cycle-GAN to disentagle domain and attribute features. This may be something new in CPSs.\n2. The paper is easy to follow.\n3. The experiment results are sufficient with two cases involving safety-sensitive applications.\nCons\n1. The paper is in lack of novelty. It is more like a application of latent space attack in CPS scenario.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper29/Reviewer_gS8q"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper29/Reviewer_gS8q"]}]}, {"paper_url": "https://openreview.net/forum?id=HbasA9ysA3", "paper_id": "HbasA9ysA3", "reviews": [{"id": "2B0g68X3SDo", "original": null, "number": 2, "cdate": 1638172192746, "mdate": null, "ddate": null, "tcdate": 1638172192746, "tmdate": 1638172192746, "tddate": null, "forum": "HbasA9ysA3", "replyto": "HbasA9ysA3", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper28/-/Official_Review", "content": {"title": "A Two-Stage Problem Formulation for Deriving Robust Classification Tree", "review": "This paper proposes a novel framework to formalize generating robust classification tree as a two-stage optimization problem. The authors address the generation problem as optimizing the decision variables after calculating the worst perturbation sets.\n\nDespite the performance improvement of proposed model, the method seems to be inefficient when scaling to large datasets, because it can be very expensive to find worst perturbation sets within such large datasets. Also, the baseline addressed in this paper is merely non-robust one, it would be more comprehensive to include other robust tree generation methods for comparison.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper28/Reviewer_iYNi"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper28/Reviewer_iYNi"]}, {"id": "eubgkITL5yZ", "original": null, "number": 1, "cdate": 1637823536462, "mdate": null, "ddate": null, "tcdate": 1637823536462, "tmdate": 1637823536462, "tddate": null, "forum": "HbasA9ysA3", "replyto": "HbasA9ysA3", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper28/-/Official_Review", "content": {"title": "Interesting Approach but needs better evaluation", "review": "**Summary**:\n\nThe paper introduces a method to build optimal decision trees that are robust to adversarial perturbations. The authors present a cost and budget framework which can be used to obtain an optimal solution using a modified form of Benders decomposition. They conduct evaluation on several public datasets and demonstrate the robustness of their model against shifts in distribution. \n\n**PROS**\n\n1. Decision trees are widely used in the industry because they are interpretable models; this work will be useful in defending against adversarial attacks in critical operations like risk, fraud and security.\n2. The authors have provided a strong mathematical foundation to their approach. In particular, I am impressed with the proofs they have presented, which are thorough and detailed.\n3. The authors have performed significant testing and benchmarking to evaluate their approach. \n\n**CONS**\n1. Although the testing is non-trivial, the authors have not described which datasets they have used for testing their approach. The UCI repository has a number of datasets, with a wide variety of features (categorical, continuous, non-normalized, standardized, etc). Since the results will depend on the nature of the features, it is important to know what datasets were used. \n2. The authors have considered 7200 seconds as a time limit for constructing the optimal tree. The paper should have an evaluation that describes how the performance is affected as more time is permitted for training. This is because in many industry settings, model training is conducted asynchronously and offline, and hence more time may be provided.\n3. As is common with research on adversarial attacks and robustness, the paper should ideally provide an example of perturbed data points (preferably on a dataset with a small number of explainable features) that are misclassified by a standard (non-robust) decision tree but correctly classified using your approach. \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper28/Reviewer_d2sp"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper28/Reviewer_d2sp"]}]}, {"paper_url": "https://openreview.net/forum?id=LGlhzn1ZJl", "paper_id": "LGlhzn1ZJl", "reviews": [{"id": "nT44BKsckl-", "original": null, "number": 2, "cdate": 1638171182680, "mdate": null, "ddate": null, "tcdate": 1638171182680, "tmdate": 1638171182680, "tddate": null, "forum": "LGlhzn1ZJl", "replyto": "LGlhzn1ZJl", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper26/-/Official_Review", "content": {"title": "An adversarial detector based on multiple model representations", "review": "This paper proposes two approaches using multiple model representations to detect adversarial examples. The authors conducted ablation studies to verify the contribution of the number of underlying models. The major weakness is that comparisons with other adversarial detectors are lacking.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper26/Reviewer_tpsd"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper26/Reviewer_tpsd"]}, {"id": "2K1cKVWqnXn", "original": null, "number": 1, "cdate": 1638013750668, "mdate": null, "ddate": null, "tcdate": 1638013750668, "tmdate": 1638013750668, "tddate": null, "forum": "LGlhzn1ZJl", "replyto": "LGlhzn1ZJl", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper26/-/Official_Review", "content": {"title": "Interesting idea of ensembling models to detect adversarial instances", "review": "This paper proposed to detect adversarial instances by ensembling the deep representations of multiple models in two ways ---- model-wise or unit-wise. The experiments is conducted on CIFAR-10 with the attack methods of FGSM, BIM and CW. The results show that with the incremental number of ensemble models or units, the detection accuracy will increase.\n\nStrengths:\n* The paper is well-written and the figures clearly convey the main ideas.\n* The idea of incorporating the representations from multiple models to detect adversarial instances is straightforward yet effective.\n\nWeaknesses:\n* Comparison with existing adversarial example detection methods should be given.\n* Experiments on other datasets can be further conducted.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper26/Reviewer_UUsc"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper26/Reviewer_UUsc"]}]}, {"paper_url": "https://openreview.net/forum?id=defs2E_Mrf0", "paper_id": "defs2E_Mrf0", "reviews": [{"id": "30uktDpUFJl", "original": null, "number": 2, "cdate": 1638282146298, "mdate": null, "ddate": null, "tcdate": 1638282146298, "tmdate": 1638282146298, "tddate": null, "forum": "defs2E_Mrf0", "replyto": "defs2E_Mrf0", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper24/-/Official_Review", "content": {"title": "Review for a metamorphic adversarial detection", "review": "This paper propose a metomorphic adversarial detection method for face recognition system. The idea is clear and writing is good. I think it is a interesting topic. There is some advice. 1)Some pictures in this paper seem similar to the previous paper. I strongly suggest a replacement. 2)Face recognition systems involve face alignment before the verification. It is not clear wheather transformations like rotation remain effective.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper24/Reviewer_uzxp"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper24/Reviewer_uzxp"]}, {"id": "O-kLxjWSlQM", "original": null, "number": 1, "cdate": 1638180655314, "mdate": null, "ddate": null, "tcdate": 1638180655314, "tmdate": 1638180655314, "tddate": null, "forum": "defs2E_Mrf0", "replyto": "defs2E_Mrf0", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper24/-/Official_Review", "content": {"title": "Metamorphic Adversarial Detection Pipeline", "review": "This paper proposes to use statistical techniques to learn optimal thresholds of separation between clean and adversarial examples, and achieves excellent detection accuracies.\n\nExperimental performance can be demonstrated that the method can effectively detect adversarial examples and achieve a good performance. However, the weakness is also listed as follows:\n\n1.\tMore datasets should be introduced for comprehensive comparisons, such as MS-Celeb-1M[1].\n\n2.\tWill different face detectors affect the final performance?\n\n[1] MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper24/Reviewer_Kysc"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper24/Reviewer_Kysc"]}]}, {"paper_url": "https://openreview.net/forum?id=Ex1yemaQgU", "paper_id": "Ex1yemaQgU", "reviews": [{"id": "G-Y1mMFrTg_", "original": null, "number": 2, "cdate": 1638422472029, "mdate": 1638422472029, "ddate": null, "tcdate": 1638422472029, "tmdate": 1638422472029, "tddate": null, "forum": "Ex1yemaQgU", "replyto": "Ex1yemaQgU", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper23/-/Official_Review", "content": {"title": "Good Approach and Extensive Evaluation", "review": "**Summary**:\n\nIn this work, the authors have described a novel approach towards detecting adversarial perturbations in images. The approach uses conditional VAEs trained on clean (non-perturbed) images, and leverages that adversarial perturbed examples actually come from a different distribution than the predicted class and hence will have a higher reconstruction error. The authors evaluate their approach over several known black-box and white-box methods. \n\n**PROS**:\n\n1. The authors address the distinction between random noise and adversarial perturbation, which is important since not all random noise will be adversarial. \n2. The authors extensively evaluate their approach over known attacks, which shows that the CVAE based method can be of practical significance. \n3. The approach leverages correctly the fundamental characteristics of autoencoders -- that since adversarial examples will cause only imperceptible distribution shifts in the feature space, the reconstruction error is high. In other words, the tradeoff between classification label and adversarial perturbation is leveraged. \n\n**CONS**\n1. In the introduction, the authors explain drawbacks of statistical, network-based and distribution methods such as domain-dependency and non-transferability. It would be also good to address whether the CVAE approach overcomes any of these issues, and if so, how. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper23/Reviewer_1NMu"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper23/Reviewer_1NMu"]}, {"id": "45SUuUX-7oG", "original": null, "number": 1, "cdate": 1638258155314, "mdate": null, "ddate": null, "tcdate": 1638258155314, "tmdate": 1638258155314, "tddate": null, "forum": "Ex1yemaQgU", "replyto": "Ex1yemaQgU", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper23/-/Official_Review", "content": {"title": "Review of Paper 23", "review": "This paper propose to use CVAE to detect adversarial examples, while avoid be sensitive on random noisy samples. The experiments are done on MNIST and CIFAR-10, under different attacks and threat models.\n\nThe idea of exploiting the information of predicted labels is reasonable, and the authors also evaluate the method under white-box attacks (i.e., adaptive attacks). However, recent work [1] find that many detection-based defenses may over-claim their performance, so it would be more convinced if the authors can convert their reported results into classification-based defenses and do a sanity check along with [1].\n\n[1] Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper23/Reviewer_L2gD"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper23/Reviewer_L2gD"]}]}, {"paper_url": "https://openreview.net/forum?id=HvRAM-dpmEv", "paper_id": "HvRAM-dpmEv", "reviews": [{"id": "NMqQkxNiKdK", "original": null, "number": 1, "cdate": 1638242040185, "mdate": null, "ddate": null, "tcdate": 1638242040185, "tmdate": 1638242040185, "tddate": null, "forum": "HvRAM-dpmEv", "replyto": "HvRAM-dpmEv", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper22/-/Official_Review", "content": {"title": "A novel method for diferentiating a bilevel programming solver", "review": "This paper proposed a novel method for calculating gradients of a bilevel programming solver. This problem has a wide range of applications like adversarial training, GAN, and combinatorial optimization problems. \n\nPros\nThe method is novel and interesting and it can easily be embedded into a neural network as a layer. The author also implements it in several examples like linear and non-linear inequality constraints.\n\nCons\nI think the author could provide more examples or applications about adversarial learning. For example, adversarial training (AT) is also a bilevel optimization problem. Can your method be used in AT?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper22/Reviewer_hDgc"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper22/Reviewer_hDgc"]}]}, {"paper_url": "https://openreview.net/forum?id=6gEDBV8g-Q", "paper_id": "6gEDBV8g-Q", "reviews": [{"id": "eCJ1U6N5U", "original": null, "number": 2, "cdate": 1638015218061, "mdate": null, "ddate": null, "tcdate": 1638015218061, "tmdate": 1638015421319, "tddate": null, "forum": "6gEDBV8g-Q", "replyto": "6gEDBV8g-Q", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper21/-/Official_Review", "content": {"title": "An effective voxel-drop-based certified defense method on PointNet.", "review": "Pros:\n\n1, The math is good, and the equations are clear.\n\n2, The intuition is direct.\n\n3, The paper is easy to follow.\n\nCons:\n\n1, The number of comparison methods are not enough.\n\n2, It will be better if a pipeline figure is added into the paper, which shows how the defense works.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper21/Reviewer_29so"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper21/Reviewer_29so"]}, {"id": "_4vE2cRWW-E", "original": null, "number": 1, "cdate": 1637996035588, "mdate": null, "ddate": null, "tcdate": 1637996035588, "tmdate": 1637996035588, "tddate": null, "forum": "6gEDBV8g-Q", "replyto": "6gEDBV8g-Q", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper21/-/Official_Review", "content": {"title": "Review of the submission", "review": "This paper proposes a provable defense based on randomized smoothing for certifying robustness against clustering attacks on 3D point clouds.\n\nStrengths:\n- The motivation of using the random sampling strategy is clear.\n- The theoretical results are provided.\n- Some experiments can demonstrate the effectiveness of the method.\n\nI also have some concerns about this work:\n- Is it the first work to study provable defenses of 3D classifiers? If not, please discuss with previous work.\n- Can you show the certified robustness in experiments?\n\nOverall, I think this work is interesting and makes a contribution to the field. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper21/Reviewer_VaXN"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper21/Reviewer_VaXN"]}]}, {"paper_url": "https://openreview.net/forum?id=og7CXiEXqpZ", "paper_id": "og7CXiEXqpZ", "reviews": [{"id": "QkWkaSO5tLP", "original": null, "number": 2, "cdate": 1638188157146, "mdate": null, "ddate": null, "tcdate": 1638188157146, "tmdate": 1638188157146, "tddate": null, "forum": "og7CXiEXqpZ", "replyto": "og7CXiEXqpZ", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper20/-/Official_Review", "content": {"title": "An ensemble training method for robustness", "review": "This paper proposes an ensemble training method to enhance the robustness. The ensemble training is implemented by training a super-net called random gated network (RGN). An interesting block called random gated blocks (RGB) is proposed to diversify the vulnerability of different paths through the RGN. Extensive experiments demonstrate the effectiveness of RGN. \n\nWeakness:\nThere are too many typos in this paper. Please correct them. For example, \u201cPan et. al. treat the distribution\u201d in Page 3 (should be Pang et. al.); Algorithm 1 (incorrect line numbers, redundant right bracket, meaningless \u201c=0\u201d in last line)\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper20/Reviewer_6qUn"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper20/Reviewer_6qUn"]}, {"id": "qpMDZmffDL", "original": null, "number": 1, "cdate": 1638012648986, "mdate": null, "ddate": null, "tcdate": 1638012648986, "tmdate": 1638189452813, "tddate": null, "forum": "og7CXiEXqpZ", "replyto": "og7CXiEXqpZ", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper20/-/Official_Review", "content": {"title": "An simple yet efficient ensemble training method.", "review": "Pros:\n1, The proposed ensemble training method is simple yet efficient. Compared with conventional methods, this method is easier to scale up and faster.\n2, The paper is easy to follow.\n3, Most of the experiments are convincing.\n\nCons:\n1, Though one advantage of the proposed method is easy-to-scale-up. However, it is also admitted that the scaling-up in the method brings no benefit, which is disappointing.\n2, Since one contribution is minimal computational overhead, the paper should offer the comparison on training speed with other methods.\n3, The proposed method cannot support the ensemble of models in different architectures.\n4, The algorithm 1 is not formal.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper20/Reviewer_Fxua"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper20/Reviewer_Fxua"]}]}, {"paper_url": "https://openreview.net/forum?id=EfhpoMWSqUN", "paper_id": "EfhpoMWSqUN", "reviews": [{"id": "KPriC9-sIVw", "original": null, "number": 1, "cdate": 1637997216393, "mdate": null, "ddate": null, "tcdate": 1637997216393, "tmdate": 1637997216393, "tddate": null, "forum": "EfhpoMWSqUN", "replyto": "EfhpoMWSqUN", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper19/-/Official_Review", "content": {"title": "Review for the paper \"Broad Adversarial Training with Data Augmentation in the Output Space\"", "review": "This paper proposes an interesting approach for adversarial training, that the data augmentation is applied to the output space.\n\nAdvantages:\n- Figure 1 is clear to show the motivation of this paper, while is also reasonable.\n- The proposed technique is simple and general for various adversarial training paradigms, including supervised learning, self-supervised learning.\n- The results are clear to show the effectiveness.\n\nI have some suggestions to further improve this paper:\n- The section number is missing in the paper, e.g., in the first paragraph in Method, \"Multiple approaches for adversarial training are outlined in Section .\"\n- The authors are encouraged to conduct experiments using AutoAttack.\n\nOverall, this is a good paper with sufficient contribution to the field. Thus I recommend acceptance.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper19/Reviewer_CcYk"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper19/Reviewer_CcYk"]}]}, {"paper_url": "https://openreview.net/forum?id=EQjwT2-Vaba", "paper_id": "EQjwT2-Vaba", "reviews": [{"id": "ABp94hGZ1Wt", "original": null, "number": 2, "cdate": 1638243491332, "mdate": null, "ddate": null, "tcdate": 1638243491332, "tmdate": 1638243491332, "tddate": null, "forum": "EQjwT2-Vaba", "replyto": "EQjwT2-Vaba", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper17/-/Official_Review", "content": {"title": "Novel method for network verification", "review": "The author proposed a polytope traversing algorithm for network verification within a certain region. For Relu networks, the function is piecewise linear and decision regions are partitioned by many polytopes. By traversing these polytopes using a specific algorithm, we can verify a sample within a given region. I also have some concerns. What's the complexity of the method? Is it possible to scale it to larger datasets like ImageNet? I think the scalability is the major drawback of these deterministic verification approaches compared with probabilistic approaches like Randomized Smoothing. If this method can be further extended to larger-scale datasets, I think it will be a breakthrough.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper17/Reviewer_m27H"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper17/Reviewer_m27H"]}, {"id": "hAwxc71viXb", "original": null, "number": 1, "cdate": 1637738396697, "mdate": null, "ddate": null, "tcdate": 1637738396697, "tmdate": 1637738396697, "tddate": null, "forum": "EQjwT2-Vaba", "replyto": "EQjwT2-Vaba", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper17/-/Official_Review", "content": {"title": "A novel work for proposing polytope traversing algorithm", "review": "This paper points out that ReLU NNs will divide the input domain into many local polytopes. Based on this observation, this work develop a polytope traversing algorithm via BFS and apply in many aspects like local adversarial attacks. The idea is novel and exactly makes sense. \n\nHowever, I have some concerns about how this work can be applied to larger and more real tasks like image classification. First, the dimension of images is large, which may significantly increase the computational complexity of this algorithm. Second, since the sizes of different local polytopes may vary a lot, directly search polytopes via BFS may not find the optimal solution in some application like generating adversarial noises. Maybe the authors can attempt to test their methods in some image dataset like MNIST.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper17/Reviewer_9CmL"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper17/Reviewer_9CmL"]}]}, {"paper_url": "https://openreview.net/forum?id=rq2hMS4OaUX", "paper_id": "rq2hMS4OaUX", "reviews": [{"id": "8abeMCTA5ko", "original": null, "number": 2, "cdate": 1638250211396, "mdate": null, "ddate": null, "tcdate": 1638250211396, "tmdate": 1638250211396, "tddate": null, "forum": "rq2hMS4OaUX", "replyto": "rq2hMS4OaUX", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper11/-/Official_Review", "content": {"title": "Review of Paper11", "review": "**Summary Of The Paper:**\n\nThis work studies the problem of the perceptual quality of adversarial images. The authors propose two separate attack agnostic methods to increase the perceptual quality. Experiments are conducted to demonstrate the efficacy of the proposed methods.\n\n**Main Review:**\n\nStrength:\n* Interesting topic.\n* Somehow intuitive.\n\nWeakness:\n* The paper lacks some theoretical analysis, for example, how to define the perceptual quality. The authors claim that the proposed methods can generate adversarial examples with the best perceptual quality. However, little quantitative evaluation is performed to assess the quality of the images. This type of anecdotal evidence is entirely unacceptable in academic work.\n* The practical significance of the proposed methods is not clear, and it may be unnecessary in adversarial attacks.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper11/Reviewer_uSVu"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper11/Reviewer_uSVu"]}, {"id": "Ppu1QD8o6L2", "original": null, "number": 1, "cdate": 1638006230132, "mdate": null, "ddate": null, "tcdate": 1638006230132, "tmdate": 1638110068758, "tddate": null, "forum": "rq2hMS4OaUX", "replyto": "rq2hMS4OaUX", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper11/-/Official_Review", "content": {"title": "Simple and generic methods", "review": "This paper mainly proposed two attack-agnostic methods with normalized variance weighting and perceptual distance minimization to enhance the perceptual quality of adversarial examples. The proposed algorithms are simple and can be combined with other methods in practice. Experiments are carried out in CIFAR-10 and NIPS2017 Adversarial Learning Challenge datasets, showing the combination of two methods indeed decrease the perceptual distance.\n\nStrengths:\n* The paper is well-organized.\n* The proposed methods are simple but attack-agnostic, which increase the perceptual quality while preserve the fooling rate.\n\nWeaknesses:\n* The contributions are not adequate. The decrease of perceptual distance by minimizing the distance is obvious and inevitable, but why and how it can be helpful is not clear enough.  It seems that it doesn't work well for images with dominantly high or low variance zones, then the work seems not useful since the poor perceptual quality of adversarial examples often occurs in these cases. \n* More analysis on whether the proposed methods may bring worse efficiency or transferability should be given. Also, the experimental of results comparing the normalized variance weighting and the variance-based box-constraints should be given instead of a casual remark.\n* Some statements are confusing. Why the statement that ''our normalized variance weighting method is not suitable to measure for traditional Lp norms''  holds? More explanations should be given.\n* There are some typos. For instance, in the algorithm2, I think the condition $class_{y_{opt}}\\ne class_{x}$ is a mistake.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper11/Reviewer_nVja"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper11/Reviewer_nVja"]}]}, {"paper_url": "https://openreview.net/forum?id=UHBsuFPrJ11", "paper_id": "UHBsuFPrJ11", "reviews": [{"id": "dGy7h4A_KJ", "original": null, "number": 2, "cdate": 1638261463802, "mdate": null, "ddate": null, "tcdate": 1638261463802, "tmdate": 1638261540573, "tddate": null, "forum": "UHBsuFPrJ11", "replyto": "UHBsuFPrJ11", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper10/-/Official_Review", "content": {"title": "An instresting work.", "review": "This paper studies robustness indicators of deep models with the goal of better estimating robustness on \"unknown\" datasets.  The authors argue that fixed test sets (e.g., ImageNet-C) are only able to capture a small portion of possible data variations and are limited and prone to generate new overfitted solutions.  Towards this end, the authors proposed a novel method to estimate the robustness behaviour of trained models by analyzing the learned feature-space structure. \n\nWhat I really like about this work is taking an empirical approach to understanding the robustness of the models' inner feature space and providing experimental observations.  Overall this paper is generally well written and focuses on an important direction of understanding the models' robustness on unknown datasets.\n\n## Strength\n1). The overall presentation of the paper is clear and easy to follow.\n\n2). In addition to the empirical experiments, the paper also provides some theoretical analysis.\n\n3). Interesting intuition around the concept of robustness.\n\n## Weakness\n1). Motivation for using clustering methods as a robustness indicator is not well explained.\n\n2). More datasets should be incorporated.  ImageNet-P perturbations are not included in the paper.  Another important recent benchmark not mentioned in the paper is ImageNet-A ). If the authors want to make their claims more reliable, I would encourage them to consider these datasets (in addition to ImageNet and ImageNet-C).\n\n3). Some experimental results are not explained. For example, in Figure 7,  when epsilon increases,  the correlation becomes weaker.  This seems to be a conflict against the main contribution of this method.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper10/Reviewer_YBeh"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper10/Reviewer_YBeh"]}, {"id": "eW5Aulv3u9C", "original": null, "number": 1, "cdate": 1637911565314, "mdate": null, "ddate": null, "tcdate": 1637911565314, "tmdate": 1637911565314, "tddate": null, "forum": "UHBsuFPrJ11", "replyto": "UHBsuFPrJ11", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper10/-/Official_Review", "content": {"title": "A new perspective for assessing robustness from the clustering performance of the model's latent space.", "review": "**Pros:**\nGenerally this paper proposes a new indicator for the model's robustness based on the clustering performance of the model's latent space. Also, vast experiments demonstrate the correlation between the indicator and the model's robustness under corrupted inputs, and proposed indicator clearly overperforms the naive baseline, i.e. the class overlap in the latent space.\n\n**Cons:**\nHowever, some doubts still need to be addressed:\n- It seems that the clustering performance highly depends on latent space samples, so one question is: will the robustness indicator still work when the latent space samples are derived from a different dataset other than the training dataset?\n- Considering the adversarial robustness, acquiring adversarial examples of a known model using methods like FGSM or PGD is neither complex nor time-consuming. Therefore, I don't quite understand why we need to explore the latent space features from the samples with clustering, it seems to require more time and computation resources.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper10/Reviewer_vMwH"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper10/Reviewer_vMwH"]}]}, {"paper_url": "https://openreview.net/forum?id=WMIoz7O_DPz", "paper_id": "WMIoz7O_DPz", "reviews": [{"id": "lF9Sx_FnogA", "original": null, "number": 2, "cdate": 1638241353690, "mdate": null, "ddate": null, "tcdate": 1638241353690, "tmdate": 1638420861885, "tddate": null, "forum": "WMIoz7O_DPz", "replyto": "WMIoz7O_DPz", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper9/-/Official_Review", "content": {"title": "Lacks Novelty", "review": "**Summary**: \n\nThe paper talks about how adversarial perturbations can affect the performance of OOD detectors. They present a unified framework to study both adversarial attacks on in-distribution as well as OOD inputs (ie attacks which aim to increase both FP and FN). An algorithm called ALOE is presented that trains the model with perturbed inputs and improves robustness towards such attacks. \n\n\n**PROS**\n\n1. OOD detection is an important problem due to adversarial attacks and data drift in the real world, hence the problem is pertinent. \n2. Evaluation is detailed and compares against well-known methods. \n\n\n**CONS**\n\n1. To me, the paper lacks innovation and novelty. Reduced to the basic version, the proposed approach is simply adversarial training with some minor tweaks. Exposing the model to perturbed inputs to improve robustness has been done previously, see [1] and [2] for examples. The only difference is the domain; while previous experiments were on classifiers, these are on OOD detectors (which are also fundamentally, classifiers). \n2. The authors claim that one of the contributions is that they 'show that state-of-the-art OOD detectors can fail to distinguish between in-distribution examples and OOD examples under small adversarial perturbations'; however, this is not surprising, see [3].\n3. Finally, the attacks presented are _white box_ which seems improbable. OOD detectors are generally not exposed as an endpoint, and most users do not even perceive that there is an OOD detector at work here. Therefore, I believe that white box attacks against OOD detectors are not of practical signifiance.\n\n\n**References**\n\n[1] Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. \"Explaining and harnessing adversarial examples.\" arXiv preprint arXiv:1412.6572 (2014).\n\n[2] Wang, Y., Ma, X., Bailey, J., Yi, J., Zhou, B., & Gu, Q. (2019, June). On the Convergence and Robustness of Adversarial Training. In ICML (Vol. 1, p. 2).\n\n[3] Sehwag, V., Bhagoji, A. N., Song, L., Sitawarin, C., Cullina, D., Chiang, M., & Mittal, P. (2019, November). Analyzing the robustness of open-world machine learning. In Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security (pp. 105-116).", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper9/Reviewer_ZnPo"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper9/Reviewer_ZnPo"]}, {"id": "s5oncARB0mo", "original": null, "number": 1, "cdate": 1638009663948, "mdate": null, "ddate": null, "tcdate": 1638009663948, "tmdate": 1638009663948, "tddate": null, "forum": "WMIoz7O_DPz", "replyto": "WMIoz7O_DPz", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper9/-/Official_Review", "content": {"title": "Review", "review": "**Summary of the paper:**\n\nThis paper extensively studies the problem of robust OOD detection on common OOD detection approaches and shows that existing OOD detection algorithms can be easily attacked to produce mistaken OOD prediction by adding small perturbations to the in-distribution and OOD inputs. To address the challenge, the authors propose an effective method to improve the robust OOD detection performance. Moreover, the authors show that the proposed method can improve the robust OOD detection performance by up to 58.4% compared to the previous state-of-the-art method on several benchmark datasets.\n\n**Detailed comments:**\n\na.) This paper studies the problem of _Robust Out-of-Distribution Detection_ and shows that state-of-the-art OOD detectors can be easily fooled by adding small perturbations to the in-distribution and OOD inputs. The related analysis and conclusion are interesting and valuable if there is no similar analysis in the past.\n\nb.) The proposed method performs robust training by exposing the model to both adversarially crafted inlier and outlier examples, which is simple yet effective and works well for a wide range of datasets.\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper9/Reviewer_NGPC"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper9/Reviewer_NGPC"]}]}, {"paper_url": "https://openreview.net/forum?id=gVe36H8OrHW", "paper_id": "gVe36H8OrHW", "reviews": [{"id": "AFm_qcmGbuW", "original": null, "number": 2, "cdate": 1638285790712, "mdate": null, "ddate": null, "tcdate": 1638285790712, "tmdate": 1638285790712, "tddate": null, "forum": "gVe36H8OrHW", "replyto": "gVe36H8OrHW", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper5/-/Official_Review", "content": {"title": "Alternating Loss Functions for UAP", "review": "This paper proposes a new method based on the idea to optimize the norm of adversarial examples. The alternating loss function involves 2 branches: optimize norm or optimize the attack loss. This setting works extremely well in generating unviersal adversarial perturbation. The proposed method outperform the baseline method supported by the experiments on Imagenet. \n\nTo improve the paper, I think the structure could be optimized by claiming the contributions in the introduction. In all, it is a good paper with clear idea and massive experiments.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper5/Reviewer_ZC8i"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper5/Reviewer_ZC8i"]}, {"id": "Dy6ESs8GVWI", "original": null, "number": 1, "cdate": 1638159323176, "mdate": null, "ddate": null, "tcdate": 1638159323176, "tmdate": 1638331396724, "tddate": null, "forum": "gVe36H8OrHW", "replyto": "gVe36H8OrHW", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper5/-/Official_Review", "content": {"title": "Methods using alternating loss functions to generate UAP", "review": "This paper proposed to train UAP with alternating loss functions, including three types of schedule. Further, a circle mask is adopted to reduce the $\\ell_2$ and $\\ell_\\infty$ norm of the perturbations with the same fooling rate. The experiments are conducted on a subset of ImageNet and the results show the proposed methods, especially P-AL, get closer to the desired fooling rate.\n\nStrengths:\n* The combination of alternating loss function scheme and the training of UAP is interesting.\n* The analysis of perturbations distribution supports the empirical claim that perturbations accumulate around the edges.\n\nWeaknesses:\n* The writing has some mistakes. For instance, the fooling rate in algorithms is not defined well, even contradicts itself in algorithm 2. Also, grammar mistakes are common.\n* The motivation of this alternating scheme is not clear.\n* The formulation of UAP training might be mathematically wrong, especially Equation 2. $P\\approx \\delta$ should be a constraint, not a term of $\\min$. Also, I doubt the claim that '' this problem can be turned into a min-max problem as well by setting $\\delta$ to 1''.\n* Some statements are confusing. The bold numbers in the tables seem not to be the greatest or the smallest. Also, for the metric of fooling rate, I don't see why it's proper to say that the closer to the desired fooling rate the better the method is. \n* More analysis of the filter mask (e.g., shape, diameter) can be provided. \n\n ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper5/Reviewer_DeJ9"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper5/Reviewer_DeJ9"]}]}, {"paper_url": "https://openreview.net/forum?id=wGkmGrDsco8", "paper_id": "wGkmGrDsco8", "reviews": [{"id": "JSkDiBIOC9d", "original": null, "number": 2, "cdate": 1638252466688, "mdate": null, "ddate": null, "tcdate": 1638252466688, "tmdate": 1638252466688, "tddate": null, "forum": "wGkmGrDsco8", "replyto": "wGkmGrDsco8", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper4/-/Official_Review", "content": {"title": "Review of Paper4", "review": "**Summary of the paper:**\n\nThe authors propose a novel diversity-promoting learning approach for the deep ensembles to overcome the shared vulnerabilities in its members. Experiments on  MNIST, Fashion-MNIST, and CIFAR-10 are conducted to demonstrate the efficacy of the proposed methods.\n\n**Main Review:**\n\nStrength:\n* The proposed method is simple and achieves the goal of improving the adversarial robustness of deep ensembles. \n* Several ablation studies are presented to illustrate the proposed method.\nWeakness:\n* The saliency diversification learning objective may damage the interpretability of the DNNs.\n* Why not take the large-scale data set (ImageNet) into consideration to evaluate the effectiveness of the proposed method.\n* In Table. 1, the experiments on CIFAR-10 may show that the efficacy of the proposed method is limited. \n* You can make an ablation study on CIFAR-10 compared with adversarial training (with small perturbation like $\\epsilon=2/255$). Maybe adversarial training performs better on vanilla accuracy and robust accuracy.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper4/Reviewer_vqvD"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper4/Reviewer_vqvD"]}, {"id": "WUnnzQ5WwId", "original": null, "number": 1, "cdate": 1638180781076, "mdate": null, "ddate": null, "tcdate": 1638180781076, "tmdate": 1638180781076, "tddate": null, "forum": "wGkmGrDsco8", "replyto": "wGkmGrDsco8", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper4/-/Official_Review", "content": {"title": "Saliency Diversified Deep Ensemble for Robustness to Adversaries", "review": "This paper proposes a diversity-promoting learning approach for the deep ensembles, which promotes saliency map diversity (SMD) on ensemble members to prevent the attacker from targeting all ensemble members by introducing an additional term. Thus it can improve ensemble robustness to adversaries. However, some concerns are also listed as follows:\n\nAdversarial training is a currently popular and effective method. What is the effect of this method on CIFAR-10 under adversarial training? And what are the corresponding time-consuming results? Besides, AutoAttack[1] can be involved in this paper for white-box evaluation.\n\n[1] Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks.\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper4/Reviewer_UNi9"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper4/Reviewer_UNi9"]}]}, {"paper_url": "https://openreview.net/forum?id=035VtDXUjLN", "paper_id": "035VtDXUjLN", "reviews": [{"id": "haDzqIch_4r", "original": null, "number": 2, "cdate": 1638262553131, "mdate": null, "ddate": null, "tcdate": 1638262553131, "tmdate": 1638262553131, "tddate": null, "forum": "035VtDXUjLN", "replyto": "035VtDXUjLN", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper2/-/Official_Review", "content": {"title": "A new normalization method.", "review": "The paper introduces a new normalization method named pixel-wise tensor normalization which improves both accuracy and robustness of the model. However, the results shows somewhat improvement, but not significant. Also, I think the paper is not providing enough theoretical backups for the claimed algorithm, and it prevents me from being completely convinced. Also, the paper does not seem to be a complete draft - there are many points that seem to be incomplete. The paper still needs further polishment and is not ready for publication at the moment. ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper2/Reviewer_KVLA"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper2/Reviewer_KVLA"]}, {"id": "hG8xShthFTJ", "original": null, "number": 1, "cdate": 1638000676757, "mdate": null, "ddate": null, "tcdate": 1638000676757, "tmdate": 1638000676757, "tddate": null, "forum": "035VtDXUjLN", "replyto": "035VtDXUjLN", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper2/-/Official_Review", "content": {"title": "Review of paper \"Tensor Normalization and Full Distribution Training\"", "review": "This paper proposes two techniques including tensor normalization and full distribution training to improve model robustness. These two techniques are easy to understand, and bring improved robustness compared with the baseline. Here are some suggestions for the authors.\n\n- Can the proposed methods be integrated with adversarial training? And how about the results?\n- Do the proposed methods have other advantages beyond adversarial robustness, such as natural robustness evaluated by CIFAR-C.\n\nHope the authors can further improve this paper.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper2/Reviewer_b7Y4"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper2/Reviewer_b7Y4"]}]}, {"paper_url": "https://openreview.net/forum?id=gP4WxGjNd3k", "paper_id": "gP4WxGjNd3k", "reviews": [{"id": "E8IoMVBauNh", "original": null, "number": 1, "cdate": 1638180546219, "mdate": null, "ddate": null, "tcdate": 1638180546219, "tmdate": 1638180546219, "tddate": null, "forum": "gP4WxGjNd3k", "replyto": "gP4WxGjNd3k", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper33/-/Official_Review", "content": {"title": "Meta Adversarial Perturbations", "review": "This paper proposes a meta adversarial perturbation (MAP) and obtains a better initialization that causes natural images to be misclassified with high probability, which is only updated through a one-step gradient ascent update.\n\nExperimental performance can be demonstrated that the method can better mislead adversarial example classifiers and achieve better performance. \n\nThe weakness is also listed as follows:\n\n1.\tThe authors are encouraged to evaluate the performance on more datasets, such as ImageNet.\n\n2.\tMore baselines should be introduced for comparison, such as DIM[1] and TIM[2].\n\n\n[1] Xie et al. Improving transferability of adversarial examples with input diversity\n\n[2] Dong et al. Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper33/Reviewer_sXuN"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper33/Reviewer_sXuN"]}]}, {"paper_url": "https://openreview.net/forum?id=Y3fjmc2vkKA", "paper_id": "Y3fjmc2vkKA", "reviews": [{"id": "0Mxinj5KVO", "original": null, "number": 1, "cdate": 1638016971866, "mdate": null, "ddate": null, "tcdate": 1638016971866, "tmdate": 1638016971866, "tddate": null, "forum": "Y3fjmc2vkKA", "replyto": "Y3fjmc2vkKA", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper27/-/Official_Review", "content": {"title": "A good research to discriminate adversarial perturbations between ResNet and transformer.", "review": "Pros:\n1. The paper is easy to follow.\n2. Utilization of patch vestiges in vision transformer is a new perspective to develop defense models\nCons:\n1. The experiments are too simple. More comparisons should be added to comprehensively exhibit the advantages of this method.\n2. To demonstrate the generality of the patch vestiges in adversarial perturbations, more adversarial attack methods should be considered.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper27/Reviewer_oWJ5"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper27/Reviewer_oWJ5"]}]}, {"paper_url": "https://openreview.net/forum?id=o_O7TOBC7jl", "paper_id": "o_O7TOBC7jl", "reviews": [{"id": "rzoynhY-zEs", "original": null, "number": 1, "cdate": 1637734372289, "mdate": null, "ddate": null, "tcdate": 1637734372289, "tmdate": 1637734372289, "tddate": null, "forum": "o_O7TOBC7jl", "replyto": "o_O7TOBC7jl", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper25/-/Official_Review", "content": {"title": "A good work for improving the robustness against unauthorized replication attacks", "review": "This work proposes Constrained Randomization of Policy (CRoP) as a deep reinforcement learning defence method against unauthorized replication attacks. Though the theoretical part needs to be organized better, the extensive experiments show the effectiveness of CRoP.\n\nSome suggestions:\n\n1. It's better and more clear to first define the attack objective as well as the defence objective. \n\n2. Some symbols can be more concise, e.g. in eq(1), $\\!\\exists \\hat{a}\\in\\hat{A}$ may be replaced with $\\hat{A} = \\emptyset$.\n\n3. It's better to define the meaning of the symbol before it's first used, e.g. $m_n$.\n\n4. Some theoretical results need more careful discussion, e.g. eq(9) provides an upper bound, what's the connection with defence? \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper25/Reviewer_p6YY"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper25/Reviewer_p6YY"]}]}, {"paper_url": "https://openreview.net/forum?id=1RALS1IpSh8", "paper_id": "1RALS1IpSh8", "reviews": [{"id": "gRgT9_xMeQg", "original": null, "number": 1, "cdate": 1638166786163, "mdate": null, "ddate": null, "tcdate": 1638166786163, "tmdate": 1638166786163, "tddate": null, "forum": "1RALS1IpSh8", "replyto": "1RALS1IpSh8", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper15/-/Official_Review", "content": {"title": "Review", "review": "This paper proposes a heterogeneous architecture searching method based on NAS. The proposed method encourages heterogeneous networks, such that networks further improve diversity for ensemble, and thus, boost the adversarial robustness of DDF. The empirical studies are insightful.\n\nMain concerns:\n\n1. There are works in the Bayesian deep learning community that try to diversify the deep ensemble in principle, see [1, 2]. Can the proposed approach be closely connected with them to improve the novelty?\n\n2. The current empirical studies are not so thorough. It is better to show this approach can achieve a SOTA performance.\n\n[1] Function Space Particle Optimization for Bayesian Neural Networks. Wang et al., ICLR 2019.\n[2] D'Angelo, Francesco, and Vincent Fortuin. \"Repulsive Deep Ensembles are Bayesian.\" NeurIPS 2021", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper15/Reviewer_bypE"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper15/Reviewer_bypE"]}]}, {"paper_url": "https://openreview.net/forum?id=Z8lffFu2rTT", "paper_id": "Z8lffFu2rTT", "reviews": [{"id": "jY2OPcufsmI", "original": null, "number": 1, "cdate": 1638326520438, "mdate": null, "ddate": null, "tcdate": 1638326520438, "tmdate": 1638326520438, "tddate": null, "forum": "Z8lffFu2rTT", "replyto": "Z8lffFu2rTT", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper14/-/Official_Review", "content": {"title": "Review of Paper 14", "review": "This paper proposes an SVD-based metric to measure the adversarial transferability between models, based on which the authors further develop an ensemble-based defense, which outperforms previous baselines.\n\nThere are some suggestions for extending this paper to a full version:\n1. Include AutoAttack in evaluation, which is the most commonly used benchmark attack right now.\n2. Polish the format of equations, e.g., Equation (4) where the subscript is not correctly compiled.\n3. Figure 1 is informative but is a little bit dazzled to parse.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper14/Reviewer_yGxj"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper14/Reviewer_yGxj"]}]}, {"paper_url": "https://openreview.net/forum?id=aLB3FaqoMBs", "paper_id": "aLB3FaqoMBs", "reviews": [{"id": "nYZOIxL8jo0", "original": null, "number": 1, "cdate": 1637998103616, "mdate": null, "ddate": null, "tcdate": 1637998103616, "tmdate": 1637998103616, "tddate": null, "forum": "aLB3FaqoMBs", "replyto": "aLB3FaqoMBs", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper13/-/Official_Review", "content": {"title": "Review of paper \"Is AutoAttack/AutoBench a suitable Benchmark for Adversarial Robustness?\"", "review": "This paper discusses several limitations of AutoAttack and RobustBench for robustness evaluation. It points out two limitations: 1) The adversarial examples generated by AutoAttack can be easily detected. 2) AutoAttack does not generalize well to datasets with higher resolutions. This paper provides excessive experiments to validate these two findings.\n\nOverall, it is interesting to see such discussions on AutoAttack, which is the most popular benchmark to evaluate adversarial robustness. The findings are insightful and could be useful for future research. The authors are encouraged to further complete their paper to a long version. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper13/Reviewer_kxJ3"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper13/Reviewer_kxJ3"]}]}, {"paper_url": "https://openreview.net/forum?id=n3PMOhS42s6", "paper_id": "n3PMOhS42s6", "reviews": [{"id": "IxULmkTnSvo", "original": null, "number": 1, "cdate": 1638180376939, "mdate": null, "ddate": null, "tcdate": 1638180376939, "tmdate": 1638180376939, "tddate": null, "forum": "n3PMOhS42s6", "replyto": "n3PMOhS42s6", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper12/-/Official_Review", "content": {"title": "An Adversarial Benchmark for Fake News Detection Models", "review": "This paper proposes an adversarial benchmark for fake news detection, which is designed to evaluate models\u2019 ability to reason about real-world facts. And some findings can strengthen the need for fake news classification models.\n\nHowever, the author is also expected to make more analysis and experiments for a benchmark. A clearer discussion and definition should be also considered.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper12/Reviewer_3VAy"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper12/Reviewer_3VAy"]}]}, {"paper_url": "https://openreview.net/forum?id=vKc1mLxBebP", "paper_id": "vKc1mLxBebP", "reviews": [{"id": "-1rzdbDaHW", "original": null, "number": 1, "cdate": 1638327174567, "mdate": null, "ddate": null, "tcdate": 1638327174567, "tmdate": 1638327174567, "tddate": null, "forum": "vKc1mLxBebP", "replyto": "vKc1mLxBebP", "invitation": "AAAI.org/2022/Workshop/AdvML/Paper6/-/Official_Review", "content": {"title": "Review of Paper 6", "review": "This paper highlights an interesting observation that robust models have learned to downsample more accurately and suffer significantly less from aliasing than baseline models. SOTA models are considered using RobustBench, while visualization results seem promising.\n\nAlthough showing a robust model suffers less from aliasing is cool, it would be much more intriguing to show vice versa, i.e., a model that suffers less from aliasing is more robust. This cause-effect relationship is not always reversible, for example, a robust model has semantic input gradients, but a model with semantic input gradients (e.g., a generative one learned by score matching) may not be robust. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/AdvML/Paper6/Reviewer_HPbf"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/AdvML", "AAAI.org/2022/Workshop/AdvML/Paper6/Reviewer_HPbf"]}]}, {"paper_url": "https://openreview.net/forum?id=FuojrywNwIM", "paper_id": "FuojrywNwIM", "reviews": [{"id": "koozXjpqrIR", "original": null, "number": 2, "cdate": 1638325653985, "mdate": null, "ddate": null, "tcdate": 1638325653985, "tmdate": 1638325653985, "tddate": null, "forum": "FuojrywNwIM", "replyto": "FuojrywNwIM", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper25/-/Official_Review", "content": {"title": "Timely research with exciting results, more details of computational gain would make the work stronger", "review": "The paper proposes an operator learning approach to learn a mapping between initial and final states of the droplet coalescence process to enable rapid and accurate part-scale build simulation. Authors compare this approach to previous work and show the impressive acceleration and reduction of the required data for learning. This is very timely research that can have considerable implications for quality control in additive manufacturing. \n\nThe paper contains preliminary results for deposition settings and reports the computational gain. However, I would like to see a more detailed analysis beyond the demonstration of the two cases. For example, the authors state that only 729 pairs were used for training with the proposed approach. How were these 729 pairs selected is unclear.\n  ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper25/Reviewer_xMZ7"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper25/Reviewer_xMZ7"]}, {"id": "P9O6kMmu5ZN", "original": null, "number": 1, "cdate": 1638300268391, "mdate": null, "ddate": null, "tcdate": 1638300268391, "tmdate": 1638300268391, "tddate": null, "forum": "FuojrywNwIM", "replyto": "FuojrywNwIM", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper25/-/Official_Review", "content": {"title": "The paper presents a new Fourier Neural Operator (FNO) approach to accelerate manufacturing simulations", "review": "The paper presents a new Fourier Neural Operator (FNO) approach to accelerate metal jet droplet deposition manufacturing simulations. The proposed approach is an order of magnitude faster than the existing state-of-the-art reduced-order simulation approach. The preliminary results show that the FNO approach works better for large spacing between droplets but might need further training for smaller droplet spacings. Overall the results look promising.\n\nI have some minor comments. A more detailed timing and accuracy results would make the advantages of the FNO approach more clear. The quality of the figures could be improved to use vector graphics. Finally, as a possible extension of the work, it might be interesting to understand the effect of the FNO architecture on the results.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper25/Reviewer_uvTA"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper25/Reviewer_uvTA"]}]}, {"paper_url": "https://openreview.net/forum?id=CFB_X4D_gQb", "paper_id": "CFB_X4D_gQb", "reviews": [{"id": "HmXI8kuQpuW", "original": null, "number": 2, "cdate": 1638380033091, "mdate": null, "ddate": null, "tcdate": 1638380033091, "tmdate": 1638380033091, "tddate": null, "forum": "CFB_X4D_gQb", "replyto": "CFB_X4D_gQb", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper24/-/Official_Review", "content": {"title": "Marginally novel paper with interesting applications", "review": "The paper extends Continuous Time Echo State Networks (CTESN) for surrogating systems with nonlinear reponses. The method presented in the paper changes the CTESN formulation by adding a forcing term (in terms of bounded basis functions) allowing CTESN type networks to capture inherent discontinuities or external effects. This allows CTESN type models to now be used to surrogate models with nonlinear responses. In addition the authors propose such models to be composable, thus allowing for modelling complex systems with multiple components. They show an application of the same with an 9-Bit inverter.\n\nPros:\n1. The paper shows some interesting applications of the modified CTESN surrogates. \n2. NR-CTESN performs well for the presented application.\n\nCons:\n1. NR-CTESN seems to be an obvious modification of CTESN. The authors do not clearly point out why such a modification is non-trivial. \n2. In my understanding,  CTESN can also solve the same problem, albeit with careful design, which NR-CTESN helps in avoiding. Could the authors elaborate the difference in terms of the provided inverter example? From observation, it appears that the inverter model also requires careful design. \n3. Figure 2 is missing the predicted response.\n4. Additionally, the paper does not present any quanititative evidence of the NR-CTESNs for the DAC application, which probably is more interesting.\n5. Finally, the paper could be better motivated by presenting if and how the CTESN model fails for the given examples while NR-CTESN succeeds.\n\nIn summary, the paper does not present a clear motivation of why NR-CTESN is better than CTESN, and has some glaring errors. I recommend a borderline reject, unless the authors fix such errors in the final draft.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper24/Reviewer_dvgV"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper24/Reviewer_dvgV"]}, {"id": "hRymVQowtFV", "original": null, "number": 1, "cdate": 1638207821958, "mdate": null, "ddate": null, "tcdate": 1638207821958, "tmdate": 1638207821958, "tddate": null, "forum": "CFB_X4D_gQb", "replyto": "CFB_X4D_gQb", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper24/-/Official_Review", "content": {"title": "Paper with a strong motivation, but results section could be strengthened, and existing one figure in the result presented is incomplete.", "review": "This paper proposes a new type of surrogate model non-linear called Continous Time Echo State Network (NR-CTESN) that is built upon a previously proposed Continous Time Echo State Network (CTESN) model. The CTESN model is interesting because it has previously been shown to be able to capture systems with multi-scale dynamics. The NR-CTESN model improves upon the CTESN model by adding the ability to incorporate external forcing functions to the generic formulation of CTESN. Experiments were shown on two case studies for an inverter and a digital-to-analog converter, which shows that the proposed surrogate models can accurately emulate these systems and accelerate the simulations significantly. The introduction and formulation of this paper were written well with a motivation that is of great significance to real applications. However, the results section can be improved upon to make the results more convincing. \n\nSpecifically, in Figure 2, the prediction line is not seen, and the red and blue line referenced in the caption is also not seen in the figure. \n\nAdditional results for the inverter would have made the results section stronger. \n\nAlso, i(t) is not defined in the second page left column when describing Equations 1 and 2\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper24/Reviewer_xBsv"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper24/Reviewer_xBsv"]}]}, {"paper_url": "https://openreview.net/forum?id=gLEgKWySYId", "paper_id": "gLEgKWySYId", "reviews": [{"id": "6YjZ0cJW8UF", "original": null, "number": 2, "cdate": 1638374441448, "mdate": null, "ddate": null, "tcdate": 1638374441448, "tmdate": 1638374441448, "tddate": null, "forum": "gLEgKWySYId", "replyto": "gLEgKWySYId", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper23/-/Official_Review", "content": {"title": "Analysis of PINNs under misspecified priors", "review": "The paper presents an analysis of PINNs under misspecified priors. The authors prove that PINNs converge even under these situations. The authors then demonstrate a practical application of the proposed idea on a time-series problem of lathe chatter.\n\nThe paper is well written, and the given theorems prove that the PINNs converge even with misspecified priors. I had a minor comment regarding the assumption of ellipticity for the given ODEs. I was not sure where this was used to prove the convergence. Would PINNs also converge for misspecified priors, even for other kinds of ODEs?\n\nOverall, this is a great workshop paper.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper23/Reviewer_qsnc"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper23/Reviewer_qsnc"]}, {"id": "fUEIEzvvyU", "original": null, "number": 1, "cdate": 1638229222384, "mdate": null, "ddate": null, "tcdate": 1638229222384, "tmdate": 1638229222384, "tddate": null, "forum": "gLEgKWySYId", "replyto": "gLEgKWySYId", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper23/-/Official_Review", "content": {"title": "Well written paper; minor clarification required", "review": "This paper has two major contributions: (1) Providing the theoretical convergence proofs of PINNs under misspecification, and (2) using PINNs, tackling the problem of predictive maintenance of Lathe machines, specifically under imbalances data distribution. Both the contributions are novel and relevant to this workshop. The paper is well written and the results are good and the theoretical proof is sound. Here are a few questions for some minor clarification.\n\n1. While Theorem 1 is sound and is justified based on the assumptions, I am not sure as a machining expert if I want the Loss to be zero. In other words, as a practitioner of deep learning in manufacturing, I would be interested in seeing a term bounded by \\epsilon (the iid noise of the empirical data) in Equation 5. That could help me in controlling the noise in the data collected. \n\n2. In the results section are the authors letting the *a,b,c,d* of the ODE be fixed during training PINNs or they are set to be *trainable*? If all the expert is doing is to minimize MSE by playing around with *a,b,c,d*, it might be better to make a,b,c, and d be *trainable* and thus the authors may get better performance.\n\n3. The term pure data model, PINN is confusing in figure 1. PINN (traditionally are known as *data-free* methods) cannot be called a pure data model. \n\n4. This idea of imbalance data distribution is similar to that pursued in this paper: https://ojs.aaai.org/index.php/AAAI/article/view/16992 (although called as extrapolation capability than imbalanced dataset). The authors may benefit from the probable comparison with the method they propose here.\n\noverall, the paper looks good. The above-mentioned clarifications would be good.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper23/Reviewer_tviE"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper23/Reviewer_tviE"]}]}, {"paper_url": "https://openreview.net/forum?id=BJSHAXe-XZz", "paper_id": "BJSHAXe-XZz", "reviews": [{"id": "2O18WdJJ9s-", "original": null, "number": 2, "cdate": 1638302025873, "mdate": null, "ddate": null, "tcdate": 1638302025873, "tmdate": 1638302025873, "tddate": null, "forum": "BJSHAXe-XZz", "replyto": "BJSHAXe-XZz", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper22/-/Official_Review", "content": {"title": "Review of Multigrid Distributed Deep CNNs for Structural Topology Optimization", "review": "This paper has combined ideas from multi-grid approach, transfer learning of CNN weights across spatial resolutions, and data-parallel distributed training to build a CNN framework for performing topology optimization at higher resolution compared to previous works. The authors have demonstrated a 4.77x speed up with their approach at a high resolution of 128x128x128. \n\nPros: Well written paper, clever usage of Pyramid U-net, transfer learning within multi-grid approach\n\nCons: It is not clear what is the sensitivity of the prescribed multi-grid stride level discretization to the minimal allowable feature sizes on the optimized structure. Also it is not mentioned how boundary conditions are incorporated as inputs into the training, which eventually raises the question of how scalable this approach would be to different topology optimization problem with a wide spectrum of requirements (Volume fraction, boundary conditions, loading, multi-material etc.). It would be helpful to lay out the major technical, data and implementation challenges for transitioning this tool into a structural designer's workflow. ", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper22/Reviewer_w87H"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper22/Reviewer_w87H"]}, {"id": "5lEVMUh6ka", "original": null, "number": 1, "cdate": 1638235417370, "mdate": null, "ddate": null, "tcdate": 1638235417370, "tmdate": 1638235417370, "tddate": null, "forum": "BJSHAXe-XZz", "replyto": "BJSHAXe-XZz", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper22/-/Official_Review", "content": {"title": "Review for Multigrid Distributed Deep CNNs for Structural Topology Optimization", "review": "The paper mainly proposed a convolutional neural network (CNN) that can cope with high-resolution 3D geometry. Transfer learning is used to training CNN from low resolution to high resolution.  Due to the high computational cost on training CNNs on high-resolution 3D geometries, authors craftly utilize multigrid approach to reduce the training time for the deep learning framework. Although the multigrid approach originated from resolving patrial differential equations, the paper creatively explored extendable applications on training CNNs and data parallel technique to alleviate the workload of machines.\n\nThis multigrid distributed CNNs accelerate the training process by 4.77x, which achieved comparable loss value with single resolution method. The multigrid predicted geometries are accurate when comparing to the solid isotropic material with Penalization method (SIMP). For the clarity it would be useful if authors demonstrate the multigrid approach with some schematic diagram of the algorithm. Exploring more generic extendable relationship between various type of data would be promising future goals.", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper22/Reviewer_Pt3g"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper22/Reviewer_Pt3g"]}]}, {"paper_url": "https://openreview.net/forum?id=rm4rxTrrTjd", "paper_id": "rm4rxTrrTjd", "reviews": [{"id": "gTZoaev25Rv", "original": null, "number": 2, "cdate": 1638323909485, "mdate": null, "ddate": null, "tcdate": 1638323909485, "tmdate": 1638402381037, "tddate": null, "forum": "rm4rxTrrTjd", "replyto": "rm4rxTrrTjd", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper21/-/Official_Review", "content": {"title": "The paper presents a Generative Adversarial Network-based design methodology which allows uncertainty quantification (UQ) of geometric variability. The main idea is to learn a low-D representation of possibly high-D nominal design spaces, and quantify the uncertainty through the learning of a conditional posterior distribution of the fabricated designs given any nominal design. The framework has been demonstrated on two design examples \u2013 airfoil design and optical metasurace absorber design. ", "review": "\u2022\tThe idea of using GANs to simultaneously learn the reduced design space and the conditional distribution quantifying the manufacturing uncertainty is novel.\n\n\u2022\tCould you elaborate on the distinction between the variabilities present in the parent and the child latent space?\n\n\u2022\tIn some sense, the fabricated design space for a given nominal design involves heuristics in how the fabricated space is created (which is expected to be so \u2013 each problem is different). But it would be helpful to understand the effect of noise in creating the fabricated design space. For example, what happens when the standard deviation of the Gaussian noise is increased from 0.02 in the airfoil design fabricated space? What effect does it have in the optimization cycle in terms of evaluations/data requirement? If it is beyond the scope of this paper for a demonstration, it would be helpful to have some comments regarding this. \n\n\u2022\tAny comments on how the initial samples were selected for the Bayesian optimization (BO) phase? As we know that BO results can be strongly influenced by the initial design. Also, what was the criterion for stopping the BO loop ?\n\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper21/Reviewer_tLTY"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper21/Reviewer_tLTY"]}, {"id": "aeXKLHP0ajE", "original": null, "number": 1, "cdate": 1638211584203, "mdate": null, "ddate": null, "tcdate": 1638211584203, "tmdate": 1638211584203, "tddate": null, "forum": "rm4rxTrrTjd", "replyto": "rm4rxTrrTjd", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper21/-/Official_Review", "content": {"title": "A novel approach to Robust Design leveraging conditional generative models", "review": "This paper addresses the use of generative models for design under uncertainty, such as in the case where manufacturing variability may affect a design's performance or feasibility. The key idea of the paper is that rather than modeling design under uncertainty as a sequence of bounds or independent random variables, you can use a generative model to model the high dimensional covariance among the design parameters, and thus more accurately estimate the likely uncertainty. The other key idea in the paper, which I found quite compelling and novel, is to model this uncertainty as a conditional distribution over a given nominal design\u2014that is, that one can directly learn how manufacturing (or other) variability is likely to arise given a target (i.e., nominal) design. This is a natural way of model uncertainty, since it goes directly from the \"as designed\" part to the \"as made\" part, and the properties of the generator can be usefully interrogated.\n\nThe paper itself uses a standard InfoGAN setup with a proposed weight sharing scheme for the \"nominal\" and \"fabricated\" shapes, and then uses the trained generators for Bayesian Optimization in both the standard and robust setting. It tests the model on airfoil and metasurface design examples, showing that, perhaps as expected, the robust designs possess higher performance than standard designs when subjected to manufacturing certainty. In addition, the paper provides a dataset of comparisons designs (nominal, fabricated) that can spur further developments along these lines for the community. The paper is well executed in the target scope for the workshop and has clear relevance to the workshop outcomes and goals; thus I think this is a good fit for this venue. One minor concern that the authors can consider as they move this work forward after the workshop is that, as written, the figures only compare the results in the standard and robust conditions for the *proposed GAN model* and not with respect to another compelling alternative (perhaps simpler) model or existing approaches to robust design. For this to be of wider archival use, you would need those comparisons, though for workshop discussion I think the scope and relevance of the workshop paper is fine as is.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper21/Reviewer_PYQp"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper21/Reviewer_PYQp"]}]}, {"paper_url": "https://openreview.net/forum?id=mpx0DARLU7", "paper_id": "mpx0DARLU7", "reviews": [{"id": "i-rjK0RtSVW", "original": null, "number": 2, "cdate": 1638235314034, "mdate": null, "ddate": null, "tcdate": 1638235314034, "tmdate": 1638235314034, "tddate": null, "forum": "mpx0DARLU7", "replyto": "mpx0DARLU7", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper20/-/Official_Review", "content": {"title": "Spatiotemporal field prediction using a hybrid ML framework", "review": "This paper proposes a general purpose ML framework for prediction of spatiotemporal fields. The paper is well-motivated and well-written. However, connecting the work with the central theme of the workshop (AI for design) more strongly would be more useful. The framework has two parts, the first part is an autoencoder that is trained with multi-fidelity data, the second part is a GP that maps the global input parametric condition to the embedding space of the autoencoder. Hence, during testing a parametric input can be converted to a code (using the trained GP) and then to the spatiotemporal field (using the trained decoder). Although some discussion is provided in the results section, it is not entirely clear from the framework description how the GP focuses on predicting modal coefficients that correspond to HF data. The overall framework in figure 1 can also be improved to distinguish between the training and testing stages. Ablation studies in the results section show a lot of promise in terms of leveraging multi-fidelity data as opposed to only expensive HF data. \n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper20/Reviewer_LZ9M"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper20/Reviewer_LZ9M"]}, {"id": "zrv95A5sPr", "original": null, "number": 1, "cdate": 1638216768419, "mdate": null, "ddate": null, "tcdate": 1638216768419, "tmdate": 1638216768419, "tddate": null, "forum": "mpx0DARLU7", "replyto": "mpx0DARLU7", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper20/-/Official_Review", "content": {"title": "Well-written paper. Interesting study of multi-fidelity spatio-temporal field prediction using deep learning model with promising preliminary results. Recommend it to be accepted.", "review": "This paper aims to overcome the bottleneck of data scarcity in predicting the Spatio-temporal field of non-linear dynamic systems when using data-driven models. By combining a series of designed low- and high-fidelity datasets, the proposed deep learning model (MF-CAE) generated promising results compared to single-fidelity CAE. The single-fidelity and multi-fidelity Gaussian Processes (in Stage 2) were also compared to demonstrate the efficacy of the multi-fidelity framework. The framework is clearly described with sound preliminary results.\n\nPros: Well-written paper. Clear framework and methodology. Promising results demonstrate the efficacy of the framework in solving the data scarcity when high-fidelity data is expensive to obtain.\n\nCons: Not clear how costly it is to obtain high-fidelity data. When using multi-fidelity data, I'm curious about what the best combinations will be. That means there could be a study to show how the different resolution hierarchies (how low and how high the fidelity should be?) impact final prediction results.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper20/Reviewer_c7av"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper20/Reviewer_c7av"]}]}, {"paper_url": "https://openreview.net/forum?id=r7-mkF0QOCr", "paper_id": "r7-mkF0QOCr", "reviews": [{"id": "ePNRQN6mVqY", "original": null, "number": 2, "cdate": 1638235637540, "mdate": null, "ddate": null, "tcdate": 1638235637540, "tmdate": 1638235637540, "tddate": null, "forum": "r7-mkF0QOCr", "replyto": "r7-mkF0QOCr", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper19/-/Official_Review", "content": {"title": "Review for Fast Unsupervised Generative Design for Structural Topology Optimization", "review": "The paper mainly proposed a novel Generative Adversarial Network (GAN) framework\u2014Wasserstein GAN with Optimized Latent Representations (WGAN-OLR), which can generate similar structure with target structure that generated from the solid isotropic material with Penalization method (SIMP). This is timely work with novel GAN framework drastically reduces the computational cost of traditional topology optimization. By using deep learning algorithms, authors facilitate the process of coping with data that constrained by underlying physical conditions. Moreover, WGAN-OLR is interesting contribution as it utilized novel encoder and decoder structures that provide more robust latent representations. The WGAN-OLR consistently outperforms the baseline WGAN and generating densities that are comparable to SIMP optimized densities. What could be quantitative metrics to evaluate the robustness of the model (as opposed to visual comparison)? The paper would benefit from the analysis of the computational cost?", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper19/Reviewer_XBGk"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper19/Reviewer_XBGk"]}, {"id": "3IsBC1VltBM", "original": null, "number": 1, "cdate": 1638213174230, "mdate": null, "ddate": null, "tcdate": 1638213174230, "tmdate": 1638213174230, "tddate": null, "forum": "r7-mkF0QOCr", "replyto": "r7-mkF0QOCr", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper19/-/Official_Review", "content": {"title": "A WGAN architecture for structural TO", "review": "This paper proposes a new type of architecture for Generative Design, applied in this case to structural topology optimization. The paper introduces readers to back in TO then proposes a dual encoder-decoder WGAN and the training details therein. It demonstrates the method on a SIMP optimized dataset similar to other types of ML-structural TO papers. It provides some visual comparisons of the density fields generated by the proposed architecture along with a simpler WGAN for comparison.\n\nThis paper fits the topic of the workshop well and provides some interesting ideas that could lead to useful discussion. I had some reservations about this paper that the authors might address in future efforts:\n* The paper refers to itself as a \"completely unsupervised\" method, but I don't think this is entirely technically accurate, given the supervised losses on the SIMP-Optimized densities as well as the input strain energies (which do encode useful information typically also found in more traditional supervised formulations of this generative design task). This doesn't decrease the merit of the paper overall, but I do think this will confuse readers.\n* The paper frequently uses adjectives to describe parts of the method or results but does not quantify this in any meaningful way. For example, in the title \"Fast\" or in the body \"exceptional results\" or \"substantially outperforms\" and many other places, without providing meaningful quantitative measures or a sense of what these adjectives constitute.\n* The paper notes in the discussion that the differences between the WGAN and WGAN-OLR may result from \"...the learning capacity of the generator itself...\" and I will also note that the number of free parameters in the WGAN-OLR network appears to significantly exceed that of the WGAN architecture in Fig. 3. In this way, it is unclear if the changes you see in Fig. 2 are the result of the architectural differences or mearing the significantly increased number of networks and network capacity.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper19/Reviewer_9udN"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper19/Reviewer_9udN"]}]}, {"paper_url": "https://openreview.net/forum?id=ug3MANo4x8z", "paper_id": "ug3MANo4x8z", "reviews": [{"id": "yVGh8tZAT-", "original": null, "number": 2, "cdate": 1638456955129, "mdate": null, "ddate": null, "tcdate": 1638456955129, "tmdate": 1638456955129, "tddate": null, "forum": "ug3MANo4x8z", "replyto": "ug3MANo4x8z", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper18/-/Official_Review", "content": {"title": "Well written paper for GP based system ID for optical fiber communication networks", "review": "This paper presents a GP approach to create a data-driven emulatorof a detailed physics optical fiber communication network simulator. The GP approach naturally accounts for parameter uncertainty and serves as a robust surrogate model that can be used for parameter estimation based on observations. This is well-motivated problem. \nSome suggestions/clarifications:-\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n- Clarification on how expensive the SSFM approach is to create the dataset\n-\u00a0Impact of synthetic noise on parameter estimation, specifically comment on the trade-off between dataset size and the maximum underlying noise that the estimator can handle.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper18/Reviewer_xWV2"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper18/Reviewer_xWV2"]}, {"id": "c2otxYDe0Y", "original": null, "number": 1, "cdate": 1638305539402, "mdate": null, "ddate": null, "tcdate": 1638305539402, "tmdate": 1638305539402, "tddate": null, "forum": "ug3MANo4x8z", "replyto": "ug3MANo4x8z", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper18/-/Official_Review", "content": {"title": "Review of Gaussian Process-Driven History Matching for Physical Layer Parameter Estimation in Optical Fiber Communication Networks", "review": "This paper has demonstrated a GP-driven history matching (HM) approach for parameter estimation/calibration at the physical layer of a optical fiber comm network. The authors have laid out the motivation of this problem well and they have shown that this approach can yield a high accuracy in estimation with a low data requirement. \nPros: a suitable application of GP-based HM in parameter estimation; algorithms are clearly described in detail for reproduction by a practitioner. \nCons: Generally GP-based approach fails to scale with dimension. It is not clear from the paper how this approach would perform regarding accuracy and data requirement when the parameter space is high dimensional. ", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper18/Reviewer_9hAQ"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper18/Reviewer_9hAQ"]}]}, {"paper_url": "https://openreview.net/forum?id=vO4ciAVPlcr", "paper_id": "vO4ciAVPlcr", "reviews": [{"id": "icu4o8G56p", "original": null, "number": 2, "cdate": 1638369164609, "mdate": null, "ddate": null, "tcdate": 1638369164609, "tmdate": 1638369164609, "tddate": null, "forum": "vO4ciAVPlcr", "replyto": "vO4ciAVPlcr", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper17/-/Official_Review", "content": {"title": "Nice paper combining manifold learning and Bayesian optimization", "review": "The paper introduces a new algorithm that combines elements of Bayesian optimization, nonlinear manifold learning, and autoencoder training to accelerate optimization in high-dimensional design spaces. The algorithm is validated on two toy datasets, and several properties of convergence (both in terms of training time as well as number of samples) are reported \n\nThe paper is nicely written and the direction seems compelling. Some (minor) points of feedback:\n- Consider validating on more challenging/realistic scenarios.\n- Label both axes in figs 3,4,5,6.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper17/Reviewer_Zot6"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper17/Reviewer_Zot6"]}, {"id": "GVXxcp7A0Mq", "original": null, "number": 1, "cdate": 1638326256104, "mdate": null, "ddate": null, "tcdate": 1638326256104, "tmdate": 1638326256104, "tddate": null, "forum": "vO4ciAVPlcr", "replyto": "vO4ciAVPlcr", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper17/-/Official_Review", "content": {"title": "Interesting work that could benefit from better presentation. ", "review": "The paper introduces the epsilon-frontier algorithm coupled with an autoencoder to accelerate the optimization in high-dimensional spaces. This interesting approach chooses only a subset of data (close to the current optimum). It is timely work with high potential. \n\nThe paper proposes the generic approach but only shows the results for the toy example. Moreover, most plots are challenging to decipher; some are not referenced in the paper (figure 5) and axis labels (reader needs to read the document to find the meaning of axis carefully). How generic is this observation from Figure 5? Was epsilon selected once? I wonder if some adaptive strategy could help to make this method less dependent on epsilon. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper17/Reviewer_nfk4"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper17/Reviewer_nfk4"]}]}, {"paper_url": "https://openreview.net/forum?id=5ThX8_KgZwQ", "paper_id": "5ThX8_KgZwQ", "reviews": [{"id": "pkzdJiYWa4", "original": null, "number": 2, "cdate": 1638194786228, "mdate": null, "ddate": null, "tcdate": 1638194786228, "tmdate": 1638194786228, "tddate": null, "forum": "5ThX8_KgZwQ", "replyto": "5ThX8_KgZwQ", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper16/-/Official_Review", "content": {"title": "Generalizability of InvNet across material system and device thickness", "review": "This paper applies the InvNet framework developed by some of the authors in a previous paper to another material system and a different device thickness, showing the framework generalizes. Since the model incorporates a physics based surrogate, I expected the authors would investigate generalizability without retraining the InvNet and surrogate model on different material and/or thickness, however the description seems to suggest both are retrained - if this is not the case, please highlight that. If retraining was indeed done, then is the paper claiming generalizability of the architecture only? If so, this should be clarified. Also, was the retraining done in a 'fine-tuning' manner or starting from scratch? The obtained density profiles are good matches to the target - could this match be improved further with additional iterations or was a local minimum obtained - please comment. It is interesting that no mode collapse was observed at least for some of the target densities. It would be interesting to see the diversity of J profiles generated by different initializations in Fig 9.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper16/Reviewer_EaMB"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper16/Reviewer_EaMB"]}, {"id": "nsh8CN30mI4", "original": null, "number": 1, "cdate": 1637779361895, "mdate": null, "ddate": null, "tcdate": 1637779361895, "tmdate": 1637779361895, "tddate": null, "forum": "5ThX8_KgZwQ", "replyto": "5ThX8_KgZwQ", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper16/-/Official_Review", "content": {"title": "Well-written paper. Interesting inverse design model with sound preliminary results of 2D microstructure designs. Recommend it to be accepted.", "review": "Inverse design is an interesting topic. It short-circuits the costly iteration of gradient-based design optimization by directly mapping performance metrics to design variables. This paper maps the target short circuit current density J to the 2D microstructure designs represented as images. A generative model, InvNets, is used to learn the mapping by constraining J as the invariance of the generative model. The paper is well written with sound and promising preliminary results. \n\nPros: Well-written paper. Clear framework and methodology. Promising results showing the impact to the domain of organic solar cell design.\n\nCons: Not clear how the surrogate simulator is used in the InvNets training given the surrogate model's weights are not updated during the training. It looks like the output of the surrogate model is again fed into the generator.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper16/Reviewer_niei"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper16/Reviewer_niei"]}]}, {"paper_url": "https://openreview.net/forum?id=1RRU6ud9YC", "paper_id": "1RRU6ud9YC", "reviews": [{"id": "gN7JqKnS31", "original": null, "number": 2, "cdate": 1638382152051, "mdate": null, "ddate": null, "tcdate": 1638382152051, "tmdate": 1638382152051, "tddate": null, "forum": "1RRU6ud9YC", "replyto": "1RRU6ud9YC", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper15/-/Official_Review", "content": {"title": "Interesting work", "review": "The paper proposes a new Grassmanian manifold based shape representation for airfoils. The authors suggest that such a representation may be more conducive to AI/ML algorithms. They also show the advantages of Grassmanian representations over CST, the current state of art representations for airfoils.\n\nPros:\n1. The proposed representation is intuitive and well motivated for airfoil shape representation.\n2. Fig.3b shows that the compressed representation shows that Grassmanian representations are similar to a mixture of Gaussians whereas the prevailing CST representations are more discrete spaces. This shows some advantages of the representations for gradient based optimization. \n3. The paper is well written and presents useful comparisons to illustrate the advantage of the proposed model.\n\nCons:\n1. The paper could do with a clear application of an AI/ML task to evidence the claims.\n\nIn summary, the paper appears to be a good addition to the workshop and will be of interest to the community.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper15/Reviewer_MERY"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper15/Reviewer_MERY"]}, {"id": "3IsF8yk1cX_", "original": null, "number": 1, "cdate": 1637903853465, "mdate": null, "ddate": null, "tcdate": 1637903853465, "tmdate": 1637903853465, "tddate": null, "forum": "1RRU6ud9YC", "replyto": "1RRU6ud9YC", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper15/-/Official_Review", "content": {"title": "Review for the novel Grassmannian Shape Representations of Aerodynamic Applications", "review": "Summary: this paper presents a novel airfoil shape design method based on data-driven techniques. Specifically, the authors proposed a novel representation of shapes which decouples affine-style deformations from a rich set of data-driven deformations over a submanifold of the Grassmannian. By comparing the principal geodesic deformations and consistent blade deformations with the traditional affine deformations, data-driven techniques show the critical efforts on representations and parameterizations of airfoil design problems in aerospace domain. This proposed method is very interesting to apply data-driven techniques for complex airfoil shape design. This work can provide some useful insights to the aerospace area on the airfoil shape design. The work is easy to follow and well written. While I have a couple concerns in mind. First, though data-driven techniques may provide better solutions, how practical is it when these are applied to real design problems? Since affine transformations are simple and easy to be implemented in practice. The author should discuss the difference in the paper. Second, how complex is the Grassmannian shape representations in theory? Though the author have shown clearly the derivation in the work, it would be better to see some complexity analysis in the paper. ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper15/Reviewer_rmjv"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper15/Reviewer_rmjv"]}]}, {"paper_url": "https://openreview.net/forum?id=OXRPY_aPhd-", "paper_id": "OXRPY_aPhd-", "reviews": [{"id": "MXsoQ4hg9is", "original": null, "number": 2, "cdate": 1638293416054, "mdate": null, "ddate": null, "tcdate": 1638293416054, "tmdate": 1638372560757, "tddate": null, "forum": "OXRPY_aPhd-", "replyto": "OXRPY_aPhd-", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper14/-/Official_Review", "content": {"title": "The paper presents a framework for AI-driven exploration of the design space to aid in inverse design", "review": "The paper presents preliminary results for an AI-driven design space exploration for thermal systems. The authors present a design space exploration tool that uses AI tools to generate new designs. Preliminary results show that the generated designs are as good as human synthesized designs, if not better. \n\nI have a few comments for improving the paper. \nThe authors talk about manufacturability in the paper but do not provide any concrete details. Some discussion of the same would make the paper complete.\n\nI was not sure how the new designs were being generated. A description of the generation process would be helpful.\n\nFinally, a minor comment is that the quality of the figures could be improved by using a vector figure format (such as eps, pdf, etc.). Currently, some of the figure labels are not that legible.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper14/Reviewer_trQC"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper14/Reviewer_trQC"]}, {"id": "ytaFwXgvUCC", "original": null, "number": 1, "cdate": 1637735744093, "mdate": null, "ddate": null, "tcdate": 1637735744093, "tmdate": 1637735744093, "tddate": null, "forum": "OXRPY_aPhd-", "replyto": "OXRPY_aPhd-", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper14/-/Official_Review", "content": {"title": "Interesting and promising topic. A framework has been proposed, and preliminary data has been provided. Recommend the paper to be accepted. ", "review": "Machine Learning (ML)-driven design-space exploration tool is an interesting and promising topic. This paper has been focused on the design exploration of thermo-fluid applications (e.g., heat sinks). The paper clearly proposed the ML-driven design-space exploration framework and provided the preliminary thermo-fluid designs. It aims to use an ML-based model to generate innovative designs that fill the current performance gaps in conventional design methods.\n\nPros: The paper is well written with a clear framework and objective. The targeted thermo-fluid applications will be impactful if successful. Preliminary designs have been provided, which are promising for Pareto frontier learning using an ML-based model.\n\nCons: The ML model is still under development. Limited details are provided about the ML model in the present paper.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper14/Reviewer_h5pk"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper14/Reviewer_h5pk"]}]}, {"paper_url": "https://openreview.net/forum?id=U-5NOEMx4n_", "paper_id": "U-5NOEMx4n_", "reviews": [{"id": "1Ngh_r_FQBI", "original": null, "number": 2, "cdate": 1638381995839, "mdate": null, "ddate": null, "tcdate": 1638381995839, "tmdate": 1638402350508, "tddate": null, "forum": "U-5NOEMx4n_", "replyto": "U-5NOEMx4n_", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper13/-/Official_Review", "content": {"title": "The authors have proposed a differentiable design technique for dynamic programming, called soft-DP. This has been demonstrated for target matching problems, and the framework has been validated for three applications - game design, histogram approximation and materials design.", "review": "The work rates high on originality, quality and significance. A strong point of this work is identifying the advantage of soft-DP over data-heavy approaches. If possible within the scope of this paper, some clarity is desired on the following points:\n\n1) In Fig. 2, MLP and CNN have been reported to have overfitted the noisy targets. Could you elaborate on the MLP/CNN architectures? Can the overfitting be improved with hyperparameter tuning of the surrogates?\n2) Any thought on adapting this methodology for situations when the DP updates are expensive? For example the microstructure design problem involves 2^12 DP updates, which can grow exponentially when the problem becomes more complex with more than two phases. How do we tractably adapt these for situations when the underlying DP updates are expensive to compute?\n\n\nSome minor typographical errors to be corrected:\n1) Page 2. Before equation 4: To get a differentiable loss, we first V with $V_\\sigma$. - Please check for correctness\n2) Page 2.  \"The key lies in observing that even when we cannott\" - spelling of can not\n3) Page 2. Gradients of solutions. \"In several problem\" - should be \"problems\"\n4) Page 2. \"which maps an signal\" - should be a signal", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper13/Reviewer_CmNy"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper13/Reviewer_CmNy"]}, {"id": "5VDNg-Rygtt", "original": null, "number": 1, "cdate": 1638238901108, "mdate": null, "ddate": null, "tcdate": 1638238901108, "tmdate": 1638238901108, "tddate": null, "forum": "U-5NOEMx4n_", "replyto": "U-5NOEMx4n_", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper13/-/Official_Review", "content": {"title": "Good work; minor suggestions", "review": "In this paper, the authors propose a *soft-DP* framework which is a differentiable (i.e., can be used in gradient-based learning systems such as deep learning) dynamic programming framework. This framework has several advantages as pointed out by the authors including tasks such as histogram-approximation, and material microstructure reconstruction. The idea is novel and relevant to this workshop with large applicability in design and manufacturing problems.  The results are comparable with some of the state-of-the-art methods (DSA) and also traditional methods with just an MLP or a CNN. \n\nThe following are my minor comments:\n1. There is some typo near Equation 4 making it unclear. Further, it is not clear how inaccuracy of $V_{\\Omega}$ will prevent $V(x)$ from converging to $c$. Isn't this the regular chain rule and regular MSE loss used all along in all training protocols? The authors could be a bit more specific on what is not allowing the  $V_{\\Omega}$ to converge to $c$. \n2. The authors introduce the term debiased soft-DP but do not show the proper comparison between soft-DP and debiased soft-DP for a given problem. \n3. A general note is while the authors claim that soft-DP (or for that matter any differentiable programming approach) is much economical than training a surrogate, there is no proof to claim this. Specifically, since in each forward pass of the debiased soft-DP, actual $V$ is calculated to reduce the bias. It seems that training a surrogate may give better results.\n4. While this paper is good for this workshop, more quantitative comparisons and ablations studies may be needed for improving this work.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper13/Reviewer_cmVr"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper13/Reviewer_cmVr"]}]}, {"paper_url": "https://openreview.net/forum?id=e6k_JgCT1P", "paper_id": "e6k_JgCT1P", "reviews": [{"id": "t58BbOyEW4J", "original": null, "number": 2, "cdate": 1638402300424, "mdate": null, "ddate": null, "tcdate": 1638402300424, "tmdate": 1638402300424, "tddate": null, "forum": "e6k_JgCT1P", "replyto": "e6k_JgCT1P", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper12/-/Official_Review", "content": {"title": "The authors have presented a GAN-based cloning strategy that helps in reducing the probability estimation variance for rare events. An optimization problem is solved to control the disturbance induced by cloning on the density function. ", "review": "The advantages of GAN-based cloning strategies over random cloning have been clearly demonstrated, which is a strong point of novelty and significance of this work.\n\nSome comments/questions regarding the approach:\n1) Could you elaborate on how the hyperparameter of the swarm optimization are chosen that ensures the proximity of the clones to the parent realizations?\n2) The authors have noted the large data requirement for the generative model. In case the generative model is not well trained under data limitations, what effect does that have on the optimization step? Is there a way to update the generative model sequentially during the optimization for an iterative improvement?\n\nOverall, the work is of high quality and has great potential for growth and significance in the field.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper12/Reviewer_jW57"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper12/Reviewer_jW57"]}, {"id": "kABRbZhvSFC", "original": null, "number": 1, "cdate": 1638210292623, "mdate": null, "ddate": null, "tcdate": 1638210292623, "tmdate": 1638210292623, "tddate": null, "forum": "e6k_JgCT1P", "replyto": "e6k_JgCT1P", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper12/-/Official_Review", "content": {"title": "A GAN based improved on rare event estimation methods.", "review": "This paper primarily concerns methods for reducing the variance in importance splitting-based probability estimators in the context of rare events. The paper argues that the standard strategy in Genealogical importance splitting\u2014random splitting\u2014can fail in cases where the probability distribution has the type of degeneracies seen in rare event distributions. To get around this, the paper proposes generating perturbations instead via a GAN. Specifically, the method builds upon Genealogical adaptive multilevel splitting (GAMS) which samples small perturbations from a normal distribution ($\\eta$). This paper instead substitutes $\\eta$ with conditional GAN-generated samples. \n\nOverall, this paper fits the scope of the workshop and presents some interesting ideas that could benefit discussion at the workshop. The background and motivation were well explained and the experiments were sound and easily reproducible using known examples. My only concerns, though these are minor for a workshop paper and are just suggestions for if the authors take this work further forward are: (1) It would have been nice to see this applied to a more design or manufacturing-oriented example, rather than the KSE example given, and (2) the paper only compared the KSE and KSE+GANISP method\u2014are there other competing approaches that this method would be benchmarked well against?\nOne minor technical notes of possible future interest to the authors: The optimization is Equation 7 uses PSO to match samples in the latent space coordinates. You could consider in future work either (a) backpropagating directly through the generator to minimize Eqn. 7 or (b) investigating bi-directional maps between $z$ and $\\xi_{parent}$ such as normalizing flows or autoencoder type models.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper12/Reviewer_tN7B"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper12/Reviewer_tN7B"]}]}, {"paper_url": "https://openreview.net/forum?id=u_ghY9PnAyZ", "paper_id": "u_ghY9PnAyZ", "reviews": [{"id": "ukq8qA_uVKb", "original": null, "number": 2, "cdate": 1638488744397, "mdate": null, "ddate": null, "tcdate": 1638488744397, "tmdate": 1638488744397, "tddate": null, "forum": "u_ghY9PnAyZ", "replyto": "u_ghY9PnAyZ", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper10/-/Official_Review", "content": {"title": "Deep Symbolic Optimization for PC Design", "review": "This paper proposes a RL-based optimization framework of the components of a power converter topology. Interestingly, they represent the PC topology as a program tree, and use a RNN to populate the tokens in the tree while maximizing a reward function. The paper is nicely written and is easy to follow.\n\nBelow I list suggestions/comments to further improve the paper:\n(1) Many details, such as the RNN model, RL training protocol, number of tokens, accuracy of the surrogate model, are currently missing, which can be added to the Appendix. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper10/Reviewer_nJZc"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper10/Reviewer_nJZc"]}, {"id": "aDG57OjSmLp", "original": null, "number": 1, "cdate": 1638034796320, "mdate": null, "ddate": null, "tcdate": 1638034796320, "tmdate": 1638034796320, "tddate": null, "forum": "u_ghY9PnAyZ", "replyto": "u_ghY9PnAyZ", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper10/-/Official_Review", "content": {"title": "Review for deep symbolic optimization for electric component", "review": "Summary: This paper applied deep symbolic optimization method to size the electric component in fixed topology power converters. Specifically, the authors presented a new framework for the sizing of components for fixed topology PCs based on given design requirements by leveraging a RL training signal, which has shown the superiority over the traditional methods based on domain knowledge that could be time-consuming in the design. The application in this work seems to be interesting and novel in the design of PCs. The empirical results look promising for different fixed topologies. While the paper is well written and easy to follow, I think the paper can be improved by taking into account the following aspects. First, the authors should give a little more detail on the RL framework though I can understand it might be due to the limit of the space. In the current draft, it is a bit difficult to understand the DSO based on the RL training signal. Second, it would be better to see some concrete results on the comparison of learning time, though Table 2 has shown the improvement in terms of efficiency. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper10/Reviewer_Y2bm"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper10/Reviewer_Y2bm"]}]}, {"paper_url": "https://openreview.net/forum?id=L_OfmAEqgNy", "paper_id": "L_OfmAEqgNy", "reviews": [{"id": "YlCtahuPo8R", "original": null, "number": 2, "cdate": 1638383055109, "mdate": null, "ddate": null, "tcdate": 1638383055109, "tmdate": 1638383055109, "tddate": null, "forum": "L_OfmAEqgNy", "replyto": "L_OfmAEqgNy", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper9/-/Official_Review", "content": {"title": "Nice Meta-paper the describes the landscape of AI for Design. Will be even better if it can flesh out opportunities and open problems", "review": "This is a good survey paper based on performers of the DIFFERENTIATE initiative of ARPA-E.\nThe paper creates a taxonomy of AI approaches used in simulation-based design. This taxonomy consists of three classes - domain-expert optimizers, high-fidelity, and low-cost evaluators, and generative/inverse models. \nThis fits well to the workshop goals and will be a useful paper for the attendees.\nSome suggestions:\n1) The taxonomy is incomplete. There are other AI approaches in Design that may be worth noting to flesh out the taxonomy (perhaps these are not utilized by the D' performers and hence not included?)\n2) It will be useful to lay out some of the open questions/opportunities in the field of Ai-enabled design (generalizability guarentees, sample complexity) and also make the case for open-source datasets.\n\n ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper9/Reviewer_Em9U"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper9/Reviewer_Em9U"]}, {"id": "o78mmezD3yD", "original": null, "number": 1, "cdate": 1638249250083, "mdate": null, "ddate": null, "tcdate": 1638249250083, "tmdate": 1638249250083, "tddate": null, "forum": "L_OfmAEqgNy", "replyto": "L_OfmAEqgNy", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper9/-/Official_Review", "content": {"title": "I give accept to this paper. Provides a good survey on design problems leveraging ML methodologies.", "review": "This paper provides a survey on design problems in terms of expert optimizers, low-cost high-fidelity evaluators, and inverse design tools. The author states that while the RL approach is still par with the traditional methodology, the authors' view in leveraging the surrogate models (GP and DNN) and generative models seems to have the potential to lower the cost of design problems. \n\nI believe this is a solid survey paper on the current status of a design problem and fits well to the workshop.\n", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper9/Reviewer_9Zt6"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper9/Reviewer_9Zt6"]}]}, {"paper_url": "https://openreview.net/forum?id=IlBRnwuFLvw", "paper_id": "IlBRnwuFLvw", "reviews": [{"id": "2mY-Dqva1v8", "original": null, "number": 2, "cdate": 1638384192006, "mdate": null, "ddate": null, "tcdate": 1638384192006, "tmdate": 1638384192006, "tddate": null, "forum": "IlBRnwuFLvw", "replyto": "IlBRnwuFLvw", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper8/-/Official_Review", "content": {"title": "Good paper", "review": "The authors present an attention based architecture to predict Remaining Useful Life (RUL) for engineering systems. The proposed model consists of three paths -- a time-oriented attention network, a feature-oriented attention network, and a bidirectional long short-term memory (LSTM) network.\n\nPros:\n1. The proposed model performs better than other approaches used for RUL prediction on the dataset analysed.\n2. The architecture is well motivated for the problem. The authors also show ablation studies to motivate the choice of the various subcomponents.\n\nCons:\n1. The approach is tested only on a single dataset (C-MAPPs turbofan engine RUL prediction). This, however,  seems to be the standard for other methods solving this task. \n2. The approach is almost a straightforward application of existing attention networks. Therefore, there is limited novelty in the work.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper8/Reviewer_9hJ5"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper8/Reviewer_9hJ5"]}, {"id": "hBYz8rDz8Yq", "original": null, "number": 1, "cdate": 1638219526130, "mdate": null, "ddate": null, "tcdate": 1638219526130, "tmdate": 1638219526130, "tddate": null, "forum": "IlBRnwuFLvw", "replyto": "IlBRnwuFLvw", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper8/-/Official_Review", "content": {"title": "Spatiotemporal attention mechanism for RUL estimation", "review": "The paper proposes a deep learning architecture involving spatial (along the feature dimension) and temporal attention blocks to predict remaining useful life (RUL) for engineering systems. The paper validates the proposed framework with a well-known use case in the PHM community, C-MAPSS engine health monitoring data set. Empirical results show marginal performance improvement over state-of-the-art RUL estimation methods. The relevance of the paper in this workshop is a bit low. However, spatiotemporal attention based (interpretable) models are generally useful for engineering system modeling. While the paper reviews literature relevant to the general concept of attention mechanism, there have been many works recently in the area of spatiotemporal attention for multivariate time series analysis (e.g., Gangopadhyay, Tryambak, et al. \"Spatiotemporal attention for multivariate time series prediction and interpretation.\" ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021.) which are not discussed adequately. A brief discussion comparing and contrasting the proposed framework with other existing spatiotemporal attention architectures will be useful. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper8/Reviewer_2z9F"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper8/Reviewer_2z9F"]}]}, {"paper_url": "https://openreview.net/forum?id=yG0EWFkvyjB", "paper_id": "yG0EWFkvyjB", "reviews": [{"id": "xoXCMRMkxfi", "original": null, "number": 2, "cdate": 1638376519436, "mdate": null, "ddate": null, "tcdate": 1638376519436, "tmdate": 1638376519436, "tddate": null, "forum": "yG0EWFkvyjB", "replyto": "yG0EWFkvyjB", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper7/-/Official_Review", "content": {"title": "Very interesting approach for adapting autoencoders to anomaly detection", "review": "The paper proposes the quantile autoencoder (QAE) as an architecture for deep anomaly detection. The main idea is to use a \"pinball loss\" that also measures the quality of quantiles of the output distribution (as opposed to standard autoencoders that only predicts the expected value). Results are shown on anomaly detection using various benchmark datasets.\n\nThe paper is very well written and the contributions are timely.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper7/Reviewer_yxod"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper7/Reviewer_yxod"]}, {"id": "zNrc37ZtwdJ", "original": null, "number": 1, "cdate": 1638234254745, "mdate": null, "ddate": null, "tcdate": 1638234254745, "tmdate": 1638234254745, "tddate": null, "forum": "yG0EWFkvyjB", "replyto": "yG0EWFkvyjB", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper7/-/Official_Review", "content": {"title": "Good work; need more comparisons", "review": "In this paper, the authors propose an autoencoder-based anomaly detection framework specific to aleatoric uncertainty terms using a quantile autoencoder. Apart from the reconstruction error being a metric for anomaly detection, the authors also use the channel-wise consistency to further get two quantiles of the reconstruction distribution for measuring the distribution. The idea is interesting and the results are shown to be significantly better than the benchmark considered (i.e. the vanilla autoencoders). \n\nThe only concern in my opinion on this paper is that the comparison is mainly performed with AE (which is sufficient for a workshop but maybe not for eventual publication). I suggest the authors look for comparing the method with other baselines including (but not limited to):\n\n1. https://arxiv.org/pdf/2103.12051.pdf\n2. https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf\n3. https://openreview.net/forum?id=rctFXFsFvbI\n\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper7/Reviewer_7P6j"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper7/Reviewer_7P6j"]}]}, {"paper_url": "https://openreview.net/forum?id=vQmS8ueWIFm", "paper_id": "vQmS8ueWIFm", "reviews": [{"id": "pHspW83BWRN", "original": null, "number": 2, "cdate": 1638373536305, "mdate": null, "ddate": null, "tcdate": 1638373536305, "tmdate": 1638373536305, "tddate": null, "forum": "vQmS8ueWIFm", "replyto": "vQmS8ueWIFm", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper6/-/Official_Review", "content": {"title": "Nice new method for developing deep surrogate PDE solvers in a data-efficient manner ", "review": "The paper proposes a natural approach for improving sample (data) efficiency in deep surrogate PDE solvers. The high level idea is to use two spatial scales (first train a \"low-fidelity\" model and use its outputs as side information for a final, high fidelity model); this in combination with an active learning strategy leads to data reductions of upto 10x.\n\nThe paper is nicely written and the topic is timely.\n\nPoints of feedback: a) consider validating on more challenging complex systems. b) why only 2 scales? is there room for an extension to a hierarchy of coarse-to-fine mappings (analogous to multiresolution analysis).\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper6/Reviewer_jTZ1"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper6/Reviewer_jTZ1"]}, {"id": "xLInT-3-aTf", "original": null, "number": 1, "cdate": 1638156605985, "mdate": null, "ddate": null, "tcdate": 1638156605985, "tmdate": 1638156752746, "tddate": null, "forum": "vQmS8ueWIFm", "replyto": "vQmS8ueWIFm", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper6/-/Official_Review", "content": {"title": "Coarse-to-fine physics informed mapping, promising results", "review": "This paper presents a method (PEDS) to construct physics informed surrogate model using a coarse to fine framework where a NN is used to map the fine input to a 'generated' coarse input which is then combined with a coarse version of the fine input and fed to a coarse physics based solver. The NN + combination weights is trained end-to-end with the coarse solver. The method, though similar to neural and coarse-to-fine space mapping methods (except for combination of generated coarse and coarse version of input, which can have different dimensionalities), is shown to perform significantly better, especially when coupled with active learning. \n\nThe results would be strengthened if the comparison to SM was with a dimension 1100, the same dimension that is learnt by the NN since PEDS with generator only gets pretty close to PEDS as per Table 1 (perhaps within error bars?), so the improvement could just be larger embedding dimension. Also, section numbers are missing in reference to appendix.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper6/Reviewer_sSYZ"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper6/Reviewer_sSYZ"]}]}, {"paper_url": "https://openreview.net/forum?id=bKfkgrx0mRI", "paper_id": "bKfkgrx0mRI", "reviews": [{"id": "nT1JFGFcOq_", "original": null, "number": 2, "cdate": 1638224535379, "mdate": null, "ddate": null, "tcdate": 1638224535379, "tmdate": 1638224535379, "tddate": null, "forum": "bKfkgrx0mRI", "replyto": "bKfkgrx0mRI", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper5/-/Official_Review", "content": {"title": "ML framework for DC-DC converter design", "review": "This paper proposes a two stage ML framework for designing selecting topology classes and optimizing circuit parameters of DC-DC power converters for a given design specification. The first stage involves designing a Decision Tree for selecting a topology class for the converter, while the second stage involves a RL agent for further design exploration. As done in most RL-based design framework, a surrogate model is built for fast function evaluation in the RL framework. While there is no novelty in the ML aspect, but the empirical results show that this framework may be useful for the application domain. The paper lacks in providing some critical details such as the aspect of reward engineering for the RL agent as well as the literature review is quite minimal and does not highlight many relevant work in the areas of RL-based design and use of ML-based surrogates for design optimization. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper5/Reviewer_oMhS"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper5/Reviewer_oMhS"]}, {"id": "zHx6XQwcus", "original": null, "number": 1, "cdate": 1638158857185, "mdate": null, "ddate": null, "tcdate": 1638158857185, "tmdate": 1638158857185, "tddate": null, "forum": "bKfkgrx0mRI", "replyto": "bKfkgrx0mRI", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper5/-/Official_Review", "content": {"title": "Optimizing DC-DC converter topology using ML, lacks related work", "review": "This paper presents a framework to optimize the design of DC-DC converters using machine learning methods. A decision tree is first used to identify the topology class of a given set of design features that is trained on a set of expert chosen topologies, then a reinforcement learning algorithm is used to optimize the design of the circuit for that topology class. To speed up the RL part, a neural network is trained as a surrogate for the reward function that is trained using power efficiency estimates from a physics based simulation/calculation. The method is shown to outperform brute force search for topology and circuit parameters.\n\nThe application and framework is sound, however there is no discussion of related work and comparison to any baselines. Also, it would be helpful to justify why RL is needed rather than an optimization approach such as Bayesian optimization (i.e. what causes the environment to be dynamic), also the neural network is not really physics informed - its simply trained on data from physical simulations.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper5/Reviewer_rRz5"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper5/Reviewer_rRz5"]}]}, {"paper_url": "https://openreview.net/forum?id=00I1UhSk55i", "paper_id": "00I1UhSk55i", "reviews": [{"id": "ApVJeKgGn_j", "original": null, "number": 2, "cdate": 1638457020397, "mdate": null, "ddate": null, "tcdate": 1638457020397, "tmdate": 1638465547230, "tddate": null, "forum": "00I1UhSk55i", "replyto": "00I1UhSk55i", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper4/-/Official_Review", "content": {"title": "Well written paper on RL for TO", "review": "This paper presents a RL approach for solving TO problems in 2D. A sensible framing of the state space, action space is presented. By formulating the transition probability in terms of convolutional operators, the authors are able to smartly utilize a lower resolution FE solver to learn the transition probability. This along with progressive refinement results in a very competitive approach.\n\nA couple of clarifications\n\n- Can the authors show a result with different locations of the 2 bounded elements? While the authors claim that the bounded elements are randomly assigned, every result shown only has bounded elements on the two edges of the domain. In particular, I am interested in seeing what happens when the bounded elements are (a) diagonally placed, and (b) when they are placed close to each other\n\n- How is the resolution jump handled? Please clarify", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper4/Reviewer_x11B"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper4/Reviewer_x11B"]}, {"id": "BCdUjbtq71", "original": null, "number": 1, "cdate": 1638207294487, "mdate": null, "ddate": null, "tcdate": 1638207294487, "tmdate": 1638207294487, "tddate": null, "forum": "00I1UhSk55i", "replyto": "00I1UhSk55i", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper4/-/Official_Review", "content": {"title": "Well-written paper with potential for extended results.  Minor clarifications will improve paper", "review": "This paper presents a reinforcement learning framework for solving the topology optimization problem. The authors demonstrate that by engineering the state space, action space, reward function, and the use of progressive refinement, their method can produce results that are competitive with conventional gradient-based methods while avoiding expensive FEA computations in the forward pass of the environment. They also show that their agent is able to generalize during test time to unseen loading conditions. The problem of topology optimization has been studied extensively in literature but the authors claim that this is the first work on using RL for topology optimization without any prior assumption on the design domain.  Overall, the paper is well-written, easy to follow along and the results are possibly significant if this method can be shown to be scalable to larger domains and also in 3D in the future. A few minor points that are confusing to be are:\n\nWhat is the purpose of the coefficient value of 5 in the reward function if both the volume fraction and strain energy are multiplied?\n\nIt is not very clear how the observation and action space resolution changes are handled going from training to testing? For example, going from 6x6 to 12x12 will increase the action space dimension, and subsequently the output dimension of the policy from 36 to 144. Wouldn't that require changing the dimension of the final layer of the network?\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper4/Reviewer_uGAj"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper4/Reviewer_uGAj"]}]}, {"paper_url": "https://openreview.net/forum?id=x-Tw-P777R", "paper_id": "x-Tw-P777R", "reviews": [{"id": "blmDQ8xs1oE", "original": null, "number": 2, "cdate": 1638487377174, "mdate": null, "ddate": null, "tcdate": 1638487377174, "tmdate": 1638487377174, "tddate": null, "forum": "x-Tw-P777R", "replyto": "x-Tw-P777R", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper3/-/Official_Review", "content": {"title": "Solid paper", "review": "The paper proposes a method for anomaly segmentation - a problem widely observed in manufacturing. For that purpose, they leverage hard augmentation, self-supervised learning for generation, and a discriminator for anomaly detection. Anoseg provides promising results when compared to existing methods. \n\nOverall, the paper is clearly written. However, the full end-to-end flow of the pipeline is hard to follow from the figures and the main text. I personally found the abstract provides a clear overview of the entire flow. I would suggest authors to include/reiterate the training/testing flow in the main text, as well as to expand figure captions,  to make the paper easier to follow.\n\nAuthors should include recent relevant works on novelty detection/generation/anomaly segmentation using deep generative models,  for example (1) \"RaPP: Novelty Detection with Reconstruction along Projection Pathway\", ICLR 2020; (2) \"Toward A Neuro-inspired Creative Decoder\", IJCAI 2020; (3)\"DFR: Deep Feature Reconstruction for Unsupervised Anomaly Segmentation\", arXiv:2012.07122.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper3/Reviewer_EeVd"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper3/Reviewer_EeVd"]}, {"id": "h8UIVFyRqDc", "original": null, "number": 1, "cdate": 1638207498707, "mdate": null, "ddate": null, "tcdate": 1638207498707, "tmdate": 1638207498707, "tddate": null, "forum": "x-Tw-P777R", "replyto": "x-Tw-P777R", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper3/-/Official_Review", "content": {"title": "Conceptually clear paper with convincing results. Additional details will make paper easier to follow", "review": "This paper discusses a method for anomaly segmentation using ideas from multiple fields, including hard augmentation to generate artificial data with anomalies, adversarial training for improved generalization, and coordinate channel concatenation to learn positional features. The authors compared their results to several state-of-the-art methods on a benchmark dataset and demonstrated that their methods outperformed other baselines and were significantly more robust to various thresholding values. The overall concept is clearly presented at a high level and the results shown are also convincing and would be significant, since the challenge of obtaining sparse anomalous data, can be circumvented. A couple of things which can be improved upon are:\n\nThe section on coordinate concatenation is not very clear and Figure 4 is not very informative as well. Additional descriptions on this section (maybe in the appendix) will make the paper easier to follow\n\nIt is also not clear to me what the discriminator during the training phase and the anomaly detector during the testing phase takes as input. During the testing phase, how is the fake data generated? Is it using the generator? Overall, a more descriptive section detailing the flow of data during training and testing will be helpful.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper3/Reviewer_cNDN"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper3/Reviewer_cNDN"]}]}, {"paper_url": "https://openreview.net/forum?id=SbCndr5Yu6T", "paper_id": "SbCndr5Yu6T", "reviews": [{"id": "DwZLBPqmr6Y", "original": null, "number": 2, "cdate": 1638493948382, "mdate": null, "ddate": null, "tcdate": 1638493948382, "tmdate": 1638493948382, "tddate": null, "forum": "SbCndr5Yu6T", "replyto": "SbCndr5Yu6T", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper2/-/Official_Review", "content": {"title": "Differential property prediction", "review": "Authors use XGBoost and MLP to predict property differences for different material pairs. While the paper is for most part well written, I am not convinced of the motivation, novelty, and experimental setting. The current problem can be handled using a learning to rank model, for which one can use simple (such as logistic regression) to complex (DNN) model) - an area that has been widely studied. Second, it is not clear how many samples were used for training/testing and what is input dimension. The number of training/test samples are 15/5 as reported. Then the paper states \"Material properties were measured for samples obtained from (on average) 10 locations along the length of an ex- truded tube.\" Does that mean that for each experiment there were 10 samples generated? Even then,  it is not clear how authors ensure that the XGBoost or a 3 layer MLP does not overfit and how do they handle curse of dimensionality. ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper2/Reviewer_ARNA"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper2/Reviewer_ARNA"]}, {"id": "qF4BQxd5dZm", "original": null, "number": 1, "cdate": 1638338931604, "mdate": null, "ddate": null, "tcdate": 1638338931604, "tmdate": 1638338979961, "tddate": null, "forum": "SbCndr5Yu6T", "replyto": "SbCndr5Yu6T", "invitation": "AAAI.org/2022/Workshop/ADAM/Paper2/-/Official_Review", "content": {"title": "Not fully convinced of the motivation of the approach, but well-written paper. ", "review": "This paper provides the differential property classification framework (DPC), which converts the regression into a classification problem. The author proposes labeling three different classes based on the difference of two input processing parameters and verifying their method on AA7075 tube properties. \n\nThe main concern of this paper is their justification of converting into a DPC model rather than a naive regression problem. The authors claim that \"classification problems often require fewer data to achieve an acceptable level of accuracy than regression problems do\"; however, this statement has no guarantee by just considering the dataset following basic linear models. Furthermore, the author will need to provide more systematic approach to support their argument since this is the primary motivation for leveraging the DPC model. \n\nFurthermore, in the section \"the DPC Framework and Model,\" the authors give an example \"if two samples have a max load of 1739.4kg and 1739.9kg respectively, we might not consider them different from the standpoint of this material property\" to support to use DPC. However, if the choice of $t$ needs to be large enough as a hyperparameter, I do not see the apparent motivation of converting the regression problem to a classification problem again. \n\nStill, I see the paper's topic fits into the workshop, and I give the rating marginally above the acceptance threshold.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["AAAI.org/2022/Workshop/ADAM/Paper2/Reviewer_MKyT"], "readers": ["everyone"], "nonreaders": [], "writers": ["AAAI.org/2022/Workshop/ADAM", "AAAI.org/2022/Workshop/ADAM/Paper2/Reviewer_MKyT"]}]}, {"paper_url": "https://openreview.net/forum?id=rRzl6UQxEb5", "paper_id": "rRzl6UQxEb5", "reviews": [{"id": "B89x5zOf0Gc", "original": null, "number": 2, "cdate": 1648400401863, "mdate": 1648400401863, "ddate": null, "tcdate": 1648400401863, "tmdate": 1648400401863, "tddate": null, "forum": "rRzl6UQxEb5", "replyto": "rRzl6UQxEb5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/-/Official_Review", "content": {"title": "Review for Team DMG at CMCL 2022 Shared Task", "review": "# Summary\nFor their contribution, the authors used a pre-trained XLM-R language model and trained an adapter, inserted into the frozen pre-trained LM in order to predict eye-tracking reading measures (first fixation duration & total reading time). They test several methods for both subtask 1 (1 adapter for all languages, language-specific adapters) and subtask 2 (zero-shot, e.g. using the adapters from subtask 1, translation of training set, translation of test set).\n\n#\u00a0Pros\n* Novel and efficient approach \n* Good results (placed 2nd)\n* The paper is nicely written and easy to follow\n* Besides the task itself, the authors also address and comment on interesting conceptual issues (e.g. what types of patterns does a single vs. language-specific adapters capture)\n* Translating the train/test sets is a simple (in a good way) yet effective approach for subtask 2\n\n# Cons\n* Since there seemed to be some space left, the methodology section could have been a bit more detailed or it could have been used for a formal definition of the problem setting & adapters.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/Reviewer_xo68"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/Reviewer_xo68"]}, {"id": "rOdxON0njf9", "original": null, "number": 1, "cdate": 1648246320368, "mdate": 1648246320368, "ddate": null, "tcdate": 1648246320368, "tmdate": 1648246320368, "tddate": null, "forum": "rRzl6UQxEb5", "replyto": "rRzl6UQxEb5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/-/Official_Review", "content": {"title": "Team DMG at CMCL 2022 Shared Task", "review": "# Summary\nIn this work, the authors propose the application of adapters to predict first fixation duration (FFD) and total fixation duration (TFD) averaged across tokens.\nThe authors utilize frozen pre-trained language models in combination with bottleneck adapters to predict the properties mentioned before.\nThey investigate several approaches: e. g. fine-tuning, mono- and multilingual PLMs, training or test set translations.\nThe final approach placed second in the Shared Task.\n\n\n# Pros\n- A novel approach using frozen PLMs with adapters to predict token reading measures.\n- Discuss various approaches with possible theoretical explanations.\n- Reproducibility via publicly available code.\n- Second place on the leaderboard.\n\n\n# Cons\n- None.\n\n\n## Minor comments and missing references\nSome minor suggestions/comments: \n\n- Research by Sood et al. [1] suggests that  RNNs/CNNs resemble more human attention than transformer-based architectures.\n\n- During the hyperparameter search, the epochs were always the maximum in the grid. My question is whether training further might have even further improved the performance?\n\n\n### References\n[1] Sood, Ekta and Tannert, Simon and Frassinelli, Diego and Bulling, Andreas. Interpreting Attention Models with Human Visual Attention in Machine Reading Comprehension. 2020. Proc. ACL SIGNLL Conference on Computational Natural Language Learning (CoNLL). doi:10.18653/v1/P17.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/Reviewer_6qvh"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper6/Reviewer_6qvh"]}]}, {"paper_url": "https://openreview.net/forum?id=HF-ez2Bi7-9", "paper_id": "HF-ez2Bi7-9", "reviews": [{"id": "B6Gl4IHekXc", "original": null, "number": 3, "cdate": 1648457036496, "mdate": 1648457036496, "ddate": null, "tcdate": 1648457036496, "tmdate": 1648457036496, "tddate": null, "forum": "HF-ez2Bi7-9", "replyto": "HF-ez2Bi7-9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/-/Official_Review", "content": {"title": "Meta-review", "review": "The paper presents the system description of Team \u00daFAL for the CMCL 2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior. The authors present a range of model comparisons for eye-tracking prediction. As pointed out by the reviewers, the paper has potential but requires some improvements. The descriptions should be more precise, especially regarding the motivation of the chosen model architectures and the discussion/analysis of the results.\n\nWe urge the authors to take the feedback from the reviewers into account and to improve their paper for the camera-ready deadline.", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Program_Chairs"]}, {"id": "HgZguqDwNf5", "original": null, "number": 2, "cdate": 1647765391623, "mdate": 1647765391623, "ddate": null, "tcdate": 1647765391623, "tmdate": 1647765391623, "tddate": null, "forum": "HF-ez2Bi7-9", "replyto": "HF-ez2Bi7-9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/-/Official_Review", "content": {"title": "High potential, but further work is needed", "review": "The paper describes the system proposed for the CMCL2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior, and the different architectures implemented and compared by the Team \u00daFAL.\n\n**Pros**:\ninteresting approach, the different results of the various systems implemented and compared have a high potential in explaining both possible psycholinguistic insights and the computational models' natures.\n\n**Cons**:\nthe paper is generally not precise enough. In particular: 1) no reason for the different architectures is provided, 2) the results are only reported, but not analyzed deep enough (i.e., the study lacks attempt in finding psycholinguistic-related explanations for the different performances)\n\n**General suggestions**:\n1) Give a justification for each different system (i.e., sys1, sys2, CWR, classifier, whole, first, mean, sum), that is, why you tried and compared these approaches.\n2) collect the tables in an Appendix to have more space for results discussion\n\n\nMinor\n\nIntroduction:\n - \u201chave also shown state-of-the-art performance on cross-lingual understanding tasks\u201d, insert at least one reference to a shared task or a study on cross-lingual understanding.\n- reference to Huggingface\n\nExperiments:\n- \u201cAll systems under the System-1/2 label were further trained as a BERT (bert) based system or a XLM (xlm)\u201d: labelS\n\nResults:\n- 4.1: \u201cHowever, it should be noted than 12 out of the first 20 best performing models\u201d: noted THAT\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/Reviewer_Ck4k"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/Reviewer_Ck4k"]}, {"id": "HazggDbk0b5", "original": null, "number": 1, "cdate": 1647337816174, "mdate": 1647337816174, "ddate": null, "tcdate": 1647337816174, "tmdate": 1647337816174, "tddate": null, "forum": "HF-ez2Bi7-9", "replyto": "HF-ez2Bi7-9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/-/Official_Review", "content": {"title": "Potentially informative contribution, but missing discussion of results", "review": "\nThis paper presents the system description for a contribution to the CMCL 2022 Shared Task on Multilingual and Crosslingual Prediction of Human Reading Behavior. The authors propose to tackle to task using pretrained language models and performed a systematic study of the effects of model (mBERT vs. XLM), context information, input representation, lexical features, and fine-tuning.\n\n# Pros\n\n- The authors carried out a systematic study of a range of different model configurations for the task\n- Different contributions to final performance are analyzed using an exhaustive grid-search\n\n# Cons\n\n- Figure 3, 4, 5: The x-axis label and ticks are not very informative. What are the different models? All possible model configurations? If yes, which configuration is which index? This information is crucial in order to allow the reader are more fine-grained interpretation of the results.\n\n- The results should analyzed for statistical significance. This is especially important for cases with only marginal differences, as for example the comparison between BERT and XLM (Section 4.2): Here, the difference in MAE is probably not significant.\n\n- The results are not discussed in relation to previous approaches for the task (especially regarding work on the challenge from 2021). In order to highlight the significance of the work, the authors should point out which results agree with previous findings, and which are novel.\n \n- The performance of the best model is only marginally better than the mean baseline as reported in the challenge (MAE 5.72 vs. 5.73) and substantially worse than the mean baseline taking into account the target language (MAE 4.27). The authors do not discuss the performance of their models with respect to this baseline. It would be interesting to analyze why even the best of all 48 different models perform that poorly. Is it because of the high variance of feature values between the languages? Would these models perform better if they were trained and evaluated only on one language?\n\n## Minor\n\n### Abstract\n- effects: affects\n- lesser: smaller\n\n### Introduction:\n- Missing reference for \u201cHuggingface\u201d\n\n### Results:\n- Table 2 &3: Wouldn\u2019t it be more infromative to report scores for the best performing model, instead of average over all tested models?\n- The results presented in Figure 1 and 2 could be presented in Tables, as they show only 4 and 2 data points. This would save space and make the results more readable.\n\n- Tables 6, 7, 8, and 10 are not at all mentioned in the text. If the results are not relevant, they can probably be removed?\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/Reviewer_Yo9z"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper5/Reviewer_Yo9z"]}]}, {"paper_url": "https://openreview.net/forum?id=rSHxo6ljXW9", "paper_id": "rSHxo6ljXW9", "reviews": [{"id": "BqLezEpnSf9", "original": null, "number": 2, "cdate": 1647852841598, "mdate": 1647852841598, "ddate": null, "tcdate": 1647852841598, "tmdate": 1647852841598, "tddate": null, "forum": "rSHxo6ljXW9", "replyto": "rSHxo6ljXW9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/-/Official_Review", "content": {"title": "The official shared task paper for CMCL 2022", "review": "The present presents the full description of the 2022 CMCL Shared Task which covers multilingual and crosslingual prediction of human reading behavior using diverse eye-tracking datasets. The paper illustrates the performance of each registered team with respect to their proposed (novel) solutions for both tasks evaluated via MSE. This paper merits a default acceptance as it summarizes the entire activity and contributions done for the Shared Task.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/Reviewer_LKSF"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/Reviewer_LKSF"]}, {"id": "rgWxW4ezVGq", "original": null, "number": 1, "cdate": 1647743016545, "mdate": 1647743016545, "ddate": null, "tcdate": 1647743016545, "tmdate": 1647743016545, "tddate": null, "forum": "rSHxo6ljXW9", "replyto": "rSHxo6ljXW9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/-/Official_Review", "content": {"title": "Good description of the multilingual eye-tracking feature prediction shared task at the CMCL workshop.", "review": "### Summary\nThis paper presents the second shared task on eye-tracking data prediction of the CMCL workshop. In this year's shared task, the participating teams submit systems to predict 4 eye-tracking features, including: the mean and the standard deviation of the first fixation duration (FFDavg and FFDstd), and the mean and standard deviation of the total reading time (TRTavg and TRTstd). The shared task contains two challenges. Subtask 1 requires the participants to predict the features in 6 provided langauges (zh, hi, ru, en, nl, de), and subtask 2 involves a new language (dk). This paper describes the dataset, preprocessing steps, the scoring metric, and the baseline methods. This paper also lists the results of the systems.\n\n### Reasons to accept\n- CMCL shared task is an important initiative. The datasets collected and the methods examined in CMCL shared task have a lot of potential future impacts.    \n- The version of this year introduces additional dataset, and considers how models trained on given languages can generalize to a held-out language.\n- This paper describes the shared task, the data, and the participating systems clearly.\n\n### Reasons to reject\nI do not find reasons to reject this paper.\n\n### Comments\n- Abstract at second last line: \"transformer\" -> \"Transformer\"  \n- Capture of figure 1: \"Example sentence\" -> \"An example sentence\"\n- The line above Secetion 7: \"zer-o-shot learning\" -> \"zero-shot learning\"  \n- The last bibliography entry at page 6 appears in blue font, while other entries appear in normal font. (Probably this is a problem with my display?)  \n- Lample & Conneau (2019) bib entry appears duplicated.  \n- Merkx and Frank (2021) bib entry appears duplicated.  ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/Reviewer_5fgw"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper4/Reviewer_5fgw"]}]}, {"paper_url": "https://openreview.net/forum?id=rVheScUGfZq", "paper_id": "rVheScUGfZq", "reviews": [{"id": "SWgrd37iz9", "original": null, "number": 2, "cdate": 1648209004608, "mdate": 1648209004608, "ddate": null, "tcdate": 1648209004608, "tmdate": 1648209004608, "tddate": null, "forum": "rVheScUGfZq", "replyto": "rVheScUGfZq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/-/Official_Review", "content": {"title": "A good paper that could use some more explanations", "review": "The paper describes a regression-based approach for the tasks of CMCL-2022. One of the systems described, achieves the lowest MAE score in the competition. The authors use regression features of a target word and the features of the preceding words along with surprisal of the word for their systems.  A total of 46 features were used as regression features. \nThe feature description could use some elaboration. For instance, it is not clear what normalized word index is. Also, how surprisal was calculated is not described. \nIt would have been interesting to have a cross-validation section to check if there was overfitting in the model.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/Reviewer_fcRw"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/Reviewer_fcRw"]}, {"id": "HGzgE2KYyzc", "original": null, "number": 1, "cdate": 1647446444008, "mdate": 1647446444008, "ddate": null, "tcdate": 1647446444008, "tmdate": 1647446444008, "tddate": null, "forum": "rVheScUGfZq", "replyto": "rVheScUGfZq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/-/Official_Review", "content": {"title": "HkAmsters at CMCL 2022 Shared Task: Predicting Eye-Tracking Data from a Gradient Boosting Framework with Linguistic Features", "review": "The paper describes the authors' regression approach to the first subtask of the CMCL 2022 Shared Task which scored best across all submissions. There are some parts of the analysis that are not clear to me and need, in my opinion, clarification before publication. Particularly how the model has been selected/evaluated. What part of the dataset have you used for that? This is crucial when comparing results from other participants in the shared task.\n\nFurther comments/questions:\n* binary features for capitalized words were used for all languages, have you evaluated the effect on languages like German where many more words are capitalized than in other languages?\n* what is meant with \"normalized word index\"?\n* how many \"previous words\" are included in the features?\n\nAnother comment concerns the number of features, 46 features seems a lot. The model might benefit from some cross-validation for feature selection to prevent overfitting. Have you looked at that?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/Reviewer_KK5N"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper3/Reviewer_KK5N"]}]}, {"paper_url": "https://openreview.net/forum?id=B0lg2tPwOxc", "paper_id": "B0lg2tPwOxc", "reviews": [{"id": "HaveFEq3BGq", "original": null, "number": 2, "cdate": 1647852081409, "mdate": null, "ddate": null, "tcdate": 1647852081409, "tmdate": 1647852154217, "tddate": null, "forum": "B0lg2tPwOxc", "replyto": "B0lg2tPwOxc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/-/Official_Review", "content": {"title": "Very well described details of the working system ", "review": "## Summary\n\nThis paper describes the system of NU-HLT for the CMCL 2022 shared task. The system, inspired by previous works in speech recognition, uses a novel preprocessing step involving the transformation of words to a global vector space using IPA. Next fourteen features were then extracted from the transcriptions. The features included features like length and frequency of words and language-model based features in the form of different n-gram based statistics. Psychologically-motivated features in the form of imageability and concreteness were also extracted. Finally, information theoretic features in the form of surprisal was extracted for the systems. Using WEKA, four ML algorithms ( Linear regression, MLP, Random Forest and k-NN) were used to train the systems for predicting FFDAvg and TRTAvg features. Additionally, top 50% of the predictors are identified using their correlation with FFDAvg and TRTAvg.\n\n## Reasons to accept \n\n* The system description is very clear, concise and informative. All the details about the features, experiments and hyperparameters are mentioned.\n* The idea of transforming the raw words into IPA is novel.\n\n\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/Reviewer_idfb"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/Reviewer_idfb"]}, {"id": "SO-gWxQ3Qfc", "original": null, "number": 1, "cdate": 1647719144867, "mdate": null, "ddate": null, "tcdate": 1647719144867, "tmdate": 1647743040161, "tddate": null, "forum": "B0lg2tPwOxc", "replyto": "B0lg2tPwOxc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/-/Official_Review", "content": {"title": "Good descriptions of a working system", "review": "### Summary\nThis paper describes the NU-HLT system in CMCL 2022 shared task. This system is inspired by both classical and recent previous works in speech recognition systems. First, the raw terms are transformed into a global shared space using IPA. Then, some features, including the frequency, length, N-gram, and information-theoretic features are extracted. Specifically, there are two psycholinguistically-motivated features: imageability and concreteness. Four ML algorithms from WEKA (LinReg, MLP, RF, kNN) are used to train to predict the FFDAvg and TRTAvg scores. Additionally, top predictor features with their correlation coefficients are identified.\n\n### Reasons to accept\n- The description of the system is clear. The hyperparameters including learning rate and the number of iterations are reported, allowing easy reproduction of the results.\n- The idea of transforming into IPA turns out to be novel and effective for predicting the FFDAvg and TRTAvg tasks.\n\n### Reasons to reject\nI see no serious issues with this paper.\n\n### Comments\n- The reporting of some results could be improved. E.g., in Table 1, there are many mentions of `k`, `m`. What do they mean?  \n- Table 2: highest correlation coefficients. Do you mean \"highest absolute correlation coefficients\"? Some numbers are negative there.  \n- Probably an additional feature selection procedure can be useful for further improving the predicting performance.\n- Reference: Some entries have urls, but the remaining do not. Recommend adding (or removing) urls to all entries to keep the style consistent.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/Reviewer_MaeN"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper2/Reviewer_MaeN"]}]}, {"paper_url": "https://openreview.net/forum?id=HZxe1KUug5", "paper_id": "HZxe1KUug5", "reviews": [{"id": "rIqgko-jtM5", "original": null, "number": 2, "cdate": 1648107926518, "mdate": 1648107926518, "ddate": null, "tcdate": 1648107926518, "tmdate": 1648107926518, "tddate": null, "forum": "HZxe1KUug5", "replyto": "HZxe1KUug5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/-/Official_Review", "content": {"title": "Combining transformer representations with handcrafted features for the prediction of multi- and cross-lingual eye-tracking reading data", "review": "This paper presents an approach that utilizes contextualized representations from transformer-based multilingual pretrained models along with 3 length-related handcrafted features for the prediction of multi- and cross-lingual human reading behavior. The results show that the models outperform the mean baselines and attain the 4th and the 1st places in the CMCL 2022 Subtask 1 and Subtask 2, respectively.\n\n**Pros**\n\nThe author explores a nice selection of models, involving mBERT, XLM and XLM-RoBERTa.\n\nThe author also implements various baselines (median baseline and regression models taking only the handcrafted features).\n\nExtensive results are reported regarding the prediction of each eye-tracking feature per model and feature ablation is conducted on the handcrafted features, which provides insightful information.\n\n\n**Cons**\n\nI think the model setups should be detailed further. For instance, why did the author use single-length output in baselines and 4-length output in the transformed-based models and would that have an effect on the final results? Why did the author choose to calculate a median baseline and what is the rationale behind the set of selected regression models?\n\nIt would be better if you could point to related work using transformers and handcrafted features for similar tasks earlier. For instance, Oh (2021) is mentioned, but only in Section 4.\n\n**Questions**\n\nWhat happens to rel_len if there is no preceding word?\n\nDid the author notice interesting outcomes depending on the input language?\n\n\n**Writing**\n\nWhat is meant by 'brain triggers'? Maybe using a different term here would be better.\n\nIn several lines, there seems to be an extra space before the comma (i.e. 'In this paper ,').\n\nend to end -> end-to-end\n\nseperate -> separate\n\nbreifly -> briefly\n\nIn the XLM paragraph, 'for different languages'\n\nIn the XLM-RoBERTa paragraph, add a space before 'It'\n\n'The entire model architecture is explained in Figure 1.' instead of 'in 1'.\n\n3.1 Features: Maybe first mention the features that you used and then, indicate the ones you discarded. It would also be nice if the author can clarify the connection to the dual pathways mentioning compound words.\n\nIn 4.1 'one of the possible reasons could be'\n\nIn the references, for the CMCL 2022 paper, also write '2022.' after the authors' names\n\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/Reviewer_3TrC"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/Reviewer_3TrC"]}, {"id": "H-eLKZJUG9", "original": null, "number": 1, "cdate": 1647862141724, "mdate": 1647862141724, "ddate": null, "tcdate": 1647862141724, "tmdate": 1647862141724, "tddate": null, "forum": "HZxe1KUug5", "replyto": "HZxe1KUug5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/-/Official_Review", "content": {"title": "A new SOTA paper for crosslingual eye-tracking prediction", "review": "The paper describes a method for predicting human reading behavior across multiple datasets that can be used for both multilingual and crosslingual setting. The proposed method extracts neural-based embeddings from large language models such as mBERT, XLM, and XLM-RoBERTa and combines them with traditional predictors such as token and sentence-based lengths. This hybrid method is shown to successfully work for the crosslingual prediction setting after obtaining 1st place against other proposed methods. This merits a clear accept for the paper.\n\nMinor questions for improvement of discussion:\n1. Figure 1 looks oddly large when the paper is read. I suggest resizing the figure to add more space for supporting discussions and analysis.\n2. Although using Transformer-based embeddings produced high results, readers working on the same topic, especially non-CS people, might appreciate insights from the author/s on possible weaknesses of embeddings from large language models compared to theoretically-grounded predictors such as surprisal. \n3. Aside from the size or parameter count, what other properties of XLM-RoBERTa do you think made it useful for crosslingual prediction? Based on the results, what property or nature of mBERT made it perform better than XLM for multilingual prediction?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/Reviewer_9pP4"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task", "aclweb.org/ACL/2022/Workshop/CMCL_Shared_Task/Paper1/Reviewer_9pP4"]}]}, {"paper_url": "https://openreview.net/forum?id=Bduz_QYg8Z5", "paper_id": "Bduz_QYg8Z5", "reviews": [{"id": "Sce3OMKhf5", "original": null, "number": 3, "cdate": 1648296564312, "mdate": 1648296564312, "ddate": null, "tcdate": 1648296564312, "tmdate": 1648296564312, "tddate": null, "forum": "Bduz_QYg8Z5", "replyto": "Bduz_QYg8Z5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper23/-/Official_Review", "content": {"title": "It performs well on the binary tasks, but has it really learned the distinction?", "review": "This paper tries to uncover whether transformers are able to distinguish temporal verbal aspect, in both fine-tuned and non-fine-tuned settings on two binary classification tasks related to telicity and duration?\n\nStrength:\nThe authors look at this problem from multiple perspectives. They created a dataset for French in addition to the available test set for English and create a qualitative dataset to zoom into particular cases.\n\nThe experimental set up allows us to see the contribution of several factors individually. For example,  by showing results for unseen vs seen verbs, the contribution of verb-specific knowledge becomes clear. The fine-tuned vs non-fine-tuned set up allows us to see in how far transformers are able to do the task with the general knowledge they contain etc.\n\nWeaknesses:\nEven though the experimental design is set up in such a way that we learn quite a bit on how well transformers fare on the task, given several pieces of information, I don\u2019t feel the paper gives an answer to whether transformers actually learn aspectual information. I think this is due to the fact that many tendencies in the results are not explained. For example you mention \u2018Examining the probability distribution of the two labels, all models were very confident in classifying sentences, regardless of their accuracy. This to me is a bad sign. The models should be less confident in cases when they are making the incorrect choice if they have actually learned someting. Also, the results on French are worse. The explanation given is not sufficient to me.\n\nI am still afraid that the model just picked up some superficial signals that allow it to do the task wel, without having actually learned the distinction.  Perhaps a simple baseline based on surface cues that the systems could outperform could take away these concerns. Or perhaps the task could be rephrased. Instead of a simple binary decision task, the model could be probed for its understanding of the telicity and durational aspects.\n\nThe authors make no specific reference to cognitive theory. It would be nice if they did given the workshop\u2019s focus.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_s1jw"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_s1jw"]}, {"id": "rCfetfrZuzc", "original": null, "number": 2, "cdate": 1648002321401, "mdate": 1648002321401, "ddate": null, "tcdate": 1648002321401, "tmdate": 1648002321401, "tddate": null, "forum": "Bduz_QYg8Z5", "replyto": "Bduz_QYg8Z5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper23/-/Official_Review", "content": {"title": "A look at aspect in transformers: it's probably there but it's not clear how", "review": "This paper explores the question of whether sentential embeddings derived from pre-trained language models support the classification of aspect. The paper reports experiments on categorizing two types of aspectual information in English and French using a variety of pre-trained transformer architectures, together with some baseline models. The results point to a positive conclusion, though it is interesting to note that the results in cases where the verb is not explicitly labeled do not represent all that much of an improvement over previous models (Friedrich and Gateva report an F1 of about 76%, which is just a hair lower than most of the no verb cases reported in Figure 10). I appreciated the paper's contribution, though I think it would benefit from a few modifications.\n\n1. I was very interested to read the discussion of the qualitative patterns in the results. However, I found it difficult to extract any general lessons about how the transformers were doing the tasks. The specific deficits that were uncovered in the qualitative analysis could be further probed, by breaking down the quantative results  along a variety of dimensions. For example, it would be revealing to break the results down by aspectual category (e.g., are telic or atelic sentences classified better?), by structure (e.g., are past tense or present tense sentences better classified wrt telicity? what about sentences with definite or indefinite objects?), and by corpus (given that each one was skewed toward one or the other of the categories).  Doing this might allow us to begin to more systematically understand how these complex models are going about the task and why the qualtitative patterns you observed are as they are. I'd like to know for instance how argument definiteness compares as a cue as compared to adverbial type as compared to verb tense as compared to the lexical semantics of the verb.  \n\n2. The description of the experiment was not as complete as I would have liked. How was classification done? Specifically, during finetuning, which embedding was used to do classification? Was it the [CLS] token or the verb embedding, and if the latter, what happened in cases where the verb was divided into multiple tokens? Were the embeddings averaged?\n\n3. The discussion of aspect in the paper isn't entirely clear on the distinction between aspect that is lexically determined and that which is the result of structural context (e.g., the properties of the object, adverbial modifiers, or inflectional morphology). The paper doesn't make explicit which of these is being targeted in the classification task discussed in the paper. I would have thought it was the latter, given some of the test cases (in Table 3 we see that \"eat\" can be either telic or atelic depending on its object). However, some of the comments in the paper lead me to think otherwise: \"it has been annotated for telicity and duration based on the verb's aspect\" (line 182), \"aspect is generally attributed to the verb\" (line 215). It would be helpful to clarify this, and to be clear about what diagnostics are being assumed to characterize each of the aspectual categories under discussion. Providing some more detailed characterization of the categories would be particularly helpful in the case of \"duration\", as it wasn't clear to me what the distinction was -- is it between states and activities (possibly habitual)? Is there a third category of non-durative predicates? \n\n4. I am skeptical that the translation-generated French dataset is sufficiently reliable as to produce interpretable results. Moreover the qualitative assessment didn't reveal any particularly clear generalizations that we can compare with those from English (where the results of the qualitative evaluation were similarly mixed). Moreover, the fact that the results of the pre-trained models was no better than the CNNs makes me worry that they are suffering from a mismatch between the pre-training data and the odd sentences in the aspectual fine-tuning data. Though I am in general quite pleased to see work that compares results across multiple languages, it might not be a bad idea to leave these French results aside until better data sets can be obtained.  \n\nSpecific comments:\n\nline 167: The procedure for creating the silver annotations in Friedrich and Gateva's dataset strikes me as possibly poblematic. Do we know how reliable it is in producing labels that English speakers agree with? Has this been checked in previous work?\n\nline 226: I don't understand the use of token_type_ids. Is this to specify which embeddings are used for classification? Or does this information get fed into the model so that it facilitate classication? The latter clearly seems like cheating, since we might have expected that the language model would learn about the importance of the verb for aspectual classifcation without any explicit annotation of the verb. And even the former doesn't seem ideal -- shouldn't we be able to classify the entire predicate (or even he entire sentence) as, say, telic or atelic, as compared to the word itself.\n\nTable 1: the differing skew with respect to the duration categories in the datasets is quite striking. As the paper notes, the model could sensibly try to solve this task by determining which corpus it comes from. Do you have a sense that this has happened to any degree? Does it perform worse on durative examples from Friedrich than it does on those from Captions (and vice versa for statives)? Also, why don't the number of labels for telicity equal the number of labels for duration?  Are some sentences only marked for one or the other?\n  \nLine 339: What contectual embedding did you use if more than one token is associated with the verb (in the case of subword tokenization)?\n\nFootnote 4: What is the measure of translation accuracy? Entire sentence correctness? Is there a correlation between problematic translations and problematic classification of aspect?\n\nLine 397: Do you have any ideas on why the BERT models yielded more categorical classifcations for aspect (but not duration) as compared to the others?\n\nline 471: Any idea about what made this case difficult? \n\nline 485: Any thoughts on why?\n\nline 494 et seq: Again any thoughts on why?\n\nline 517 (Figure 3): The differences across layers are pretty small. Should we take this to suggest that this classification task can be done using fairly superficial features, such as verb form. Also, it wasn't clear to me whether this probing study was done using the fine-tuned model or not. If not, what do you make of the fact that the results are nearly as good as those obtained from fine-tuning?\n\nline 542: An alternative interpretaion (which doesn't necessarily implicate the use of context) is that the input embedding of the unseen verb is relevantly similar to verbs on which the classifier was trained.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_5HRU"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_5HRU"]}, {"id": "HreglUjhBGq", "original": null, "number": 1, "cdate": 1647852359619, "mdate": 1647852359619, "ddate": null, "tcdate": 1647852359619, "tmdate": 1647852359619, "tddate": null, "forum": "Bduz_QYg8Z5", "replyto": "Bduz_QYg8Z5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper23/-/Official_Review", "content": {"title": "A great addition to the workshop", "review": "This is a very well crafted study, with a good combination of qualitative and quantitative results and a thorough analysis. The conclusions - albeit relatively \"obvious in hindsight\" - are a good addition to the \"BERTology\" program and point to some interesting directions for future research. I would have liked to have seen the next step in the analysis, namely, whether verb aspect classification performance is critical to downstream success (i.e. would a Transformer model be able to recover from a misclassification make a correct e.g. event ordering prediction), but this is also a good follow-up topic. Overall, I think this paper is great addition to the workshop.\n\n## Questions to authors\nIn footnote 4, what does an annotation accuracy of 73.5% refer to? The accuracy of the projected annotations from English? Or the accuracy of the annotator? If it's the former, what was the IAA rate for the whole sample?\n\nWas the finding that BERT had the highest performance for both telicity and duration surprising? Given the (excellently succinct) attribute presentation in \u00a73.3, why weren't the other models able to take advantage of their improvements over BERT?\n\nDo the findings in \u00a74.3 indicate that these models are mostly taking advantage of morphological information? Is that something that could be (or has been) checked with the qualitative datasets?\n\nCould another type of qualitative analysis be constructed with novel (nonse) verbs (Mary daxed carrots all day) and novel contexts (Mary sliced blinkets in foo minutes)?\n\nFor the decreased performance of models in French with the verb position information, is parsing accuracy the main culprit (if understand lines 557-8 correctly)? A manual annotation of a small sample of sentences could provide a sanity check for this. \n\nI'm not sure I undersrand the final point in the Discussion section. If the model architectures are different wouldn't it make sense to represent the semantics of language differently?", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_776c"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper23/Reviewer_776c"]}]}, {"paper_url": "https://openreview.net/forum?id=B_ux_XFeIWq", "paper_id": "B_ux_XFeIWq", "reviews": [{"id": "BFLgzk5bCG9", "original": null, "number": 3, "cdate": 1648396762233, "mdate": 1648396762233, "ddate": null, "tcdate": 1648396762233, "tmdate": 1648396762233, "tddate": null, "forum": "B_ux_XFeIWq", "replyto": "B_ux_XFeIWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper22/-/Official_Review", "content": {"title": "Attention in humans and neural systems ", "review": "This paper investigates the relationship between human attention (in the form of eye movements) and the attention used by pre-trained transformers. The authors perform a nice comparison between the way humans and multiple models process text. All in all, I find this paper well written and definitely of some interest to the CMCL community. For this reason, I would be happy to see it published.\n\nSaid so, I would still like to read more about the following aspects. The authors could easily shrink the related work section a little bit and gain the half-a-column necessary for clarification.\n\n* You claim that the first/early layers show the highest correlation overall. It is important to support this claim with some analysis and a bit more discussion on why we are seeing this pattern and what we can conclude.\n\n* Directionality is always tricky when dealing with human processing. Why not addressing it? There are plenty of uni-directional models that you could include in the analysis as a comparison point. \n\n* Given the audience, it would be nice to read more about the reason why it is important to draw a line between attention in humans vs. models. You could specify if such correlation can tell us more about processing in general. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_zT3s"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_zT3s"]}, {"id": "SpfxlH9dYfc", "original": null, "number": 2, "cdate": 1648097848236, "mdate": 1648097848236, "ddate": null, "tcdate": 1648097848236, "tmdate": 1648097848236, "tddate": null, "forum": "B_ux_XFeIWq", "replyto": "B_ux_XFeIWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper22/-/Official_Review", "content": {"title": "Review of eye-gaze and self-attention", "review": "\nThe paper discusses an approach to modeling eye-gaze using BERT and similar models. In particular it shows that dwell time in human eye-tracking data correlated with attention patterns in early layers of these models. Additionally, this correlation was found to be weak on data where participants had to respond to questions after reading sentences.\n\nI thought it was very well written paper. Tha authors do a wonderful job in stating the assumptions, in describing the hypothesis, situating their work in the previous literature as well as in discussing the results.\n\nMy key concern is with regard to the interpretation of the correlation and indeed, with the hypothesis of relating attention in transformers with human overt attention (operationalized via gaze duration/dwell time). This is because of the underlying nature of the model like BERT -- the authors state \"Its bidirectional structure means that each word token is placed in the context of the entire sequence instead of just the tokens appearing before it.\" Now, it seems to me that while such a mechanism could be used to model grammatical knowledge but it's difficult for me to understand how it could model an online process such as overt attention. This is because when English native speakers read a word in a sentence they have very limited access to the context on the right of a word that they are fixating. It is true that the authors are modeling gaze duration (rather than a measure like first fixation duration) which implies that the measure captures reading time due to regressions as well (i.e., looking at the word again after accessing right context), but we know that regressions are rare during reading. So, regressions being rare while typical reading implies that reading doesn't involve use of right context. Can this be said of the models being use to model overt attention? Indeed, given the nature of how BERT works one would expect the correlations to be in fact stronger in cases where reading involves active search for information (i.e., when reading to answer questions). This is because one could expect more rereading in such a setting.\n\nSo, my main concern is that the 'overt attention' - 'transformer attention' link that has been established in this paper is rather tenuous and in my understanding theoretically weak. I would request the authors to at least acknowledge this limitation of the work in the final draft, if the paper were to get accepted. The authors state that \"... this paper will present experimental evidence of a link showing the relationship between the two.\" I suggest that the author qualify the nature of this link; as it is currently stated, the use of the word 'link'  implies process parallelism which as discussed above is very misleading.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_YKVU"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_YKVU"]}, {"id": "SV3eLdbBLz5", "original": null, "number": 1, "cdate": 1647886702081, "mdate": null, "ddate": null, "tcdate": 1647886702081, "tmdate": 1647912600167, "tddate": null, "forum": "B_ux_XFeIWq", "replyto": "B_ux_XFeIWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper22/-/Official_Review", "content": {"title": "Human vs machine attention during reading", "review": " ## Overall\n \nThis paper analyzes the degree of correspondence between human eye fixation patterns during text reading and the attention distributions of pretrained transformer language models. Results show an overall high degree of correlation between model-generated attention weights and human gaze distributions across transformer architectures and layers, suggesting that transformers may converge via pretraining on a relatively human-like assessment of the importance of words in texts. Although I have some concerns about framing and methods, I think this paper should be of interest to computational psycholinguistics.\n\n\n## Major\n\n- Framing and motivation leave something to be desired. First, attention in the deep learning toolkit and attention as a cognitive process happen to be referred to with the same word in English, but that doesn't entail that the relationship between them is inherently scientifically interesting. The authors' assumed stance on the relationship between these two constructs is confusingly presented: the first sentence of the paper implies that both attentions are considered to be the same thing, whereas the first sentence of the 2nd par implies that they are \"appear to be completely different\". In reality, \"attention\" in DNNs is a cognitively inspired architectural innovation that improves task performance but whose role in the model's reasoning process is not well understood (e.g. Jain & Wallace 19, Serrano & Smith 19), let alone its relationship to human cognition. The paper would benefit from a clearer framing of the constructs under investigation. Second, why does the relationship between model and human attention matter? What do we learn about models or humans from a particular level of correlation between attention weights and eye gaze? To be clear, I'm *not* saying that these questions don't matter, only that it's on the authors to explain what's at stake. The paper dives right into the details without clearly setting up the questions that the authors want to answer.\n\n- Human gaze distributions were averaged prior to analyses. Because reading patterns are known to be highly variable across individuals, I think this is a serious weakness. In particular, it may lead to an exaggerated impression of human-model similarity by eliminating a major source of variation in the eye movement record. More realistic estimates could be derived from e.g. regression models of detailed (unaveraged) fixation distributions given model attention proportions, ideally in a mixed effects design. In addition, interpretation is made difficult by the absence of baselines. How good is 0.6 Spearman correlation, and what drives the correlations? Without controls, it's hard to say whether this is really about the model's learned attention vs less interesting phenomena that attention may merely reflect in some way, like the length or frequency of words.\n\n- This paper surveys a lot of the models in the huggingface inventory but the absence of GPT (and variants) is a liability, especially since GPT is one of the only SOTA transformer LMs that respects incrementality (a constraint faced by human readers) and produces representations that are substantially more similar to the human brain response to language than many of the other models considered here (Schrimpf et al 21, cited here). GPT is available from the same software library as the others -- why was it omitted?\n\n- Several critical claims are made based on numerical differences without direct statistical comparison. For example, none of the following claims are directly supported quantitatively:\n    - Lower layers are better correlated with human gaze than higher layers\n    - There is no relationship between the size of the model and attention-gaze correlation (this one actually isn't quantified at all, e.g. via correlation between nparams and spearman corr)\n    - BERT is better overall than the other models\n    - Attention-gaze correlations are higher during free (vs task-directed) reading\n    - Lower layers model eye movement control whereas middle layers model specific language processing operations\n\n\n## Minor\n\n- Rai & Le Callet 2018 is a suboptimal single citation to provide for the overt-covert attention distinction. Posner 1980 would be better.\n- Fig 1 is hard to interpret. Sure, many maxima are in early layers, but there are plenty of exceptions, and many from the highest layers. What's the pattern? How different are the layers from each other? A distribution would be a lot more informative here.\n- Ettinger 20 is cited as a study about eye movements vs machines, but they didn't look at eye movements. This cite should either be removed, or the context should be rephrased.\n- This paper is heavily inspired by Sood et al 20 and cites it frequently, but the presentation of that earlier work is strange. In particular, it's never said clearly enough that this paper is asking a different question from Sood et al 20. Sood et al 20 asked whether *model performance* on a QA task was anticorrelated with the *similarity* between model attention distributions and human gaze distributions. They showed that models that do well on the QA task have more similar attention distributions to humans, which is not the same as this paper's question about the *overall similarity* of human and model attention, independent of task. This is why Sood et al's associations are negative, which is an otherwise confusing outcome as presented here. It's also not clear why the authors feel beholden to account for \"departures\" of their findings from Sood et al's results at the start of S3.3. I'm glad this resulted in some interesting error analysis about the importance of normalizing over sentences vs paragraphs (though see next point), but I don't understand the reason for the question in the first place -- Sood et al and this paper are analyzing different things in response to different questions, so why would the results be expected to be the same?\n- The finding that model-human correlations are higher when normalizing over sentences vs paragraphs is presented as a puzzle and the authors speculate that model-human alignment may degrade with longer texts. However, the texts and model attention distributions are the same in both analyses (only the domain of normalization changes), so this explanation doesn't make sense to me. Plus isn't matching at the level of paragraphs strictly harder than matching at the level of sentences, since at the paragraph level, the model needs to reproduce the gaze distribution of each component sentence (i.e. the sentence-level task) *and* the overall proportion of gaze across sentences? So I think the degradation when normalizing over paragraphs just falls out from sentences being substrings of paragraphs. Which domain of normalization is more appropriate depends on the scientific question, which isn't fully spelled out here (see major point 1).\n- The paper puts all description of datasets in the appendix, but some high level description should be provided in the main text, especially since they go on to analyze differences between datasets/tasks in S3.3.\n- There are known potential problems with averaging bounded variables like normalized attention distributions: because the bound isn't taken into account in the average, values in the center of the range can have an excessive influence, and the degree of concentration toward the extremes can be poorly estimated. In the domain of Pearson correlation, this is often handled with Fisher transformation. Have the authors considered and tried to address possible influences of edge effects on their results?\n- To compute model attention distributions, averages were first taken across attention heads and token-level attention distributions, and then the weights on subword tokens were averaged to bring the tokenization into alignment with reading experiments. But it seems like a more principled method would first *sum* the attention weights allocated to each subword before any other averaging, since this sum represents the total proportion of attention allocated to the entire word.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_oK4s"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper22/Reviewer_oK4s"]}]}, {"paper_url": "https://openreview.net/forum?id=rTzgPQtx8-9", "paper_id": "rTzgPQtx8-9", "reviews": [{"id": "BK8gPiYm3M9", "original": null, "number": 3, "cdate": 1648273822750, "mdate": 1648273822750, "ddate": null, "tcdate": 1648273822750, "tmdate": 1648273822750, "tddate": null, "forum": "rTzgPQtx8-9", "replyto": "rTzgPQtx8-9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper20/-/Official_Review", "content": {"title": "Promising idea, but I had a hard time figuring out exactly what was done", "review": "This paper describes a model of scalar implicatures that is based on entropy and surprisal, evaluated against human judgements.\n\nIt seems like a promising idea, but I had a hard time figuring out exactly what was done.  I suppose the system interprets a weak word to be faint praise if there is a strong word with a high probability in the same context according to T5.  If so, then I suppose the entropy mentioned in the paper is just a high probability of the strong word compared to the weak word?  In any case, I think the presentation would benefit from a simple equation for the estimator and a clear example.\n\nIn particular, in the discussion, I did not follow the paragraph describing the example containing the phrase 'if guaranteed has low surprisal when the weak item is possible, then entropy might be low but the surprisal of certain could be high'.  Why does the surprisal depend on the weak item (aren't they alternatives?), and what is the entropy of?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_iSz7"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_iSz7"]}, {"id": "BdbeAkZH5M5", "original": null, "number": 2, "cdate": 1648148710216, "mdate": 1648148710216, "ddate": null, "tcdate": 1648148710216, "tmdate": 1648148710216, "tddate": null, "forum": "rTzgPQtx8-9", "replyto": "rTzgPQtx8-9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper20/-/Official_Review", "content": {"title": "Nicely written paper on modeling crucial aspects of scalar implicatures", "review": "The work reported in these pages tested the hypothesis that scalar implicatures (SI) rates depend on the listener's confidence in the underlying scale, where the availability was estimaed by using T5. The authors reported a significant correlation between SI rates and scale uncertainty.\n\nThis paper is well written and sufficently easy-to-read. The methodology is sound and the reported results may follow-up studies.\n\nA few issues:\n- the proposed methodology cannot be applied to all kinds of scalar implicatures. For instance, it is difficult to see how this approach can be used to model SIs implying a negation such as the fact that a sentence like \"The Sonic Youth played some songs of their fist album\" implies that \"The Sonic Youth  didn't play all the songs of their fist album\". I think that the authors should clearly explain the limitations of their methodology\n- by looking at figures 1.b and c it seems that there are a few leverage points that affect the linear relationship between SI rates and entropy or entropy over clusters. How does the correlation score change if we remove these outliers? I'm afraid that it may change significantly, at least in the case of SI ~ Entropy over completions.\n- it would be intesteresting to measure the correlation between Entropy over completions and Entropy over clusters.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_Z16g"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_Z16g"]}, {"id": "rNexdUwbPfq", "original": null, "number": 1, "cdate": 1647937360359, "mdate": 1647937360359, "ddate": null, "tcdate": 1647937360359, "tmdate": 1647937360359, "tddate": null, "forum": "rTzgPQtx8-9", "replyto": "rTzgPQtx8-9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper20/-/Official_Review", "content": {"title": "Interesting study using language models to explain scalar diversity", "review": "The paper addresses the linguistic hypothesis that scalar implicatures rates depend on the availability of a strong alternative. They operationalize availability as confidence in the underlying scale and estimate this using neural language modes. The results suggest that such uncertainty over alternatives can explain scalar diversity. \n\nThe paper is well-written, with clear explanations of the phenomenon of interest and of the methods used. The methodology introduced is creative and could inspire analogous applications of language models for linguistics.\n\nOther than the correlation values reported, it would be good to have some analysis like a regression, jointly with other potential predictors, in order to clarify the causal role of these uncertainty estimates over the scalar implicature rates.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_hMpT"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper20/Reviewer_hMpT"]}]}, {"paper_url": "https://openreview.net/forum?id=rzfGP7FeLZc", "paper_id": "rzfGP7FeLZc", "reviews": [{"id": "SOWlyhs1nGc", "original": null, "number": 3, "cdate": 1648257958735, "mdate": null, "ddate": null, "tcdate": 1648257958735, "tmdate": 1648258271916, "tddate": null, "forum": "rzfGP7FeLZc", "replyto": "rzfGP7FeLZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper19/-/Official_Review", "content": {"title": "Review of Modeling the Relationship between Input Distributions and Learning Trajectories with the Tolerance Principle", "review": "## Overall\n\nThis paper shows via computational simulations that the Tolerance Principle (TP; Yang 05), a theory of rule learning in child language acquisition, can explain previously attested uniformity across child learners of English in (a) which morphological patterns are acquired as productive rules and (b) the timecourse of rule acquisition. The TP defines a deterministic threshold over the proportion of exceptions that can be \"tolerated\" by a productive rule. Under the assumptions of the TP, the authors show empirically that rules may move in and out of productivity during learning due to variation in the relative number of exceptions learned, that the shape of these learning trajectories is influenced by the token frequencies of exceptions, and that simulations using data-driven token frequencies roughly replicate the timecourse of rule learning attested in studies of child language learning.\n\nThe writing and interpretation are generally clear, the motivation and methods are sound, and the results support the conclusions. I think this work is appropriate for CMCL, although the breadth of interest may be limited by how embedded it is within a particular theory (Yang 05).\n\n\n## Major\n\n- The TP framework assumed by this work takes for granted that children tasked with morphological rule learning can already (1) unambiguously segment words in running speech, (2) correctly identify the types of these segmented words as well as any lexical features that could be used to define domains of rules (e.g. syntactic category), and (3) conduct a global search over their entire vocabulary and hypothesized rule set each time a new word is learned, since this is required in order to determine (a) which words fall under the domain of application of each rule and (b) how many of these are exceptional, in order to decide whether to retain the rule according to the tolerance principle. No attempt is made here to show that the TP is more successful than some alternative theory at explaining a set of facts, so the results may be of limited interest to readers who reject one or more of these assumptions.\n- About 1/3 of the introduction is dedicated to discussing classical U-shaped trajectories (overregularization) from the acquisition literature, but this work isn't about overregularization. Neither the TP itself nor the computational simulations conducted here concern whether/when a learned rule will be incorrectly applied to an exception. The only question at issue here is when rules are learned in the first place (which certainly could be a necessary condition for overregularization, but not the whole story). Likewise, the abstract concludes that the study shows the TP underlies cross-linguistic differences in learning trajectories, but this again seems like a red herring. This study only uses data from English past tense verb morphology and says nothing directly about cross-linguistic variation. Sure, the result implies that languages with different token frequencies will have different trajectories, but whether this model replicates any known cross-linguistic differences is never evaluated. Thus, the framing of the abstract+intro seems to set up different questions than the ones the authors ultimately address.\n\n## Minor\n\n- The mathematical notation in S3.1 confusingly overloads variable names. In reality, there are 4 quantities involved: (a) the true in-domain vocabulary size, (b) the true number of exceptions, (c) the infant's vocabulary size at a particular point in learning (the sample size parameter of the hypergeometric distribution), and (d) the number of exceptions learned by the infant at a particular point in processing (the support of the hypergeometric distribution). But the authors use $N$ to refer to both (a) and (c) and $e$ to refer to both (b) and (d), so I had to puzzle over that section for a while in order to figure out how the hypergeometric distributions were being parameterized and thus what the plots were representing. Clearer notation would be helpful.\n- The plot axes (e and N-e) are a bit of a head trip because they both depend on e. Why not plot e vs N? Barring that, I was able to get my head around the plots by mentally relabeling the y axis as \"Num irregular\" and the x axis as \"Num regular\". Revising the axis labels along these lines would clarify things a lot.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_rnzi"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_rnzi"]}, {"id": "BAgg4QUXsGq", "original": null, "number": 2, "cdate": 1648207387764, "mdate": null, "ddate": null, "tcdate": 1648207387764, "tmdate": 1648210105412, "tddate": null, "forum": "rzfGP7FeLZc", "replyto": "rzfGP7FeLZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper19/-/Official_Review", "content": {"title": "Interesting ideas but scientific contribution is not clear ", "review": "The paper proposes to explain uniformity in children's language learning despite possible differences in individual learning trajectories. The authors investigate these ideas using the Tolerance Principle (TP) (Yang, 2016).\n\nI think the idea is interesting and the use of TP is a good way to approach this question. I do however have several comments/concerns that the authors need to address before they consider a publication.\n\n-First, I am sure if CMLC is a suitable venue since the paper does not use computational linguistic methods\n\n-While TP is a very simple concept, its description in the paper is extremely convoluted and unintuitive. Besides, the authors made use of highly ambiguous word choice and phrasing that impedes understanding for people who are not familiar with TP. To illustrate, the caption in Figure 1 says \"If e lies below \u03b8, then the learner should acquire *it* and memorize the exceptions\" here the reader would think that *it* refers to \"e\" whereas it should refer to the \"productive rule\" (which is not mentioned at all in the caption). The authors also talk about the \"sing-sang\" pattern, which is highly confusing. The pattern they mean is not sing-sang but \"-ing -> -ang\". Sing-sang is an example, but the author never makes this clear. I highly recommend the author to rewrite several parts of the paper to make it understandable. As is, the writing is unnecessarily cryptic and does not allow readers to understand what the authors are doing.\n\n-The authors do several simulations that are in my opinion totally unnecessary: the formula is extremely simple, and does not require more clarification through simulations. In fact, these simulations are counter-productive because they are harder to understand than the formula itself!\n\n-In my opinion, the only aspect of this work that is slightly novel is the fact of presenting words with different frequency distribution and showing that this leads to different learning trajectories. However, here again, I am afraid the result is obvious and doesn't require simulations. It is discussed in more intuitive terms in Yang 2016 and subsequent work and the concept of \"transient\" periods in learning trajectories is talked about lengthily. \n\nSure, if you do some weird sampling of words (by selecting the lowest frequency, lowest and highest, etc;.) you end up with different transient modes, but these are not insightful about real development since the sampling performed by the author is extreme/artificial and does not correspond to variability in the order of acquisition in children. It would have been more interesting if the authors took real longitudinal vocab acquisition (for example using http://wordbank.stanford.edu/) and showed there to be real variability in transient periods of productive vs. unproductive rule depending on variability in order of word learning of real children.\n\nThe part about CHILDES is completely disconnected from everything else. The authors use only one learning trajectory of how vocabulary grows, so we don't see any variability in the learning trajectory. In fact, this part is just duplicating the work in Yang 2016 who used exactly the same phenomena (i.e.,  the -ed rule vs. ing-ang) and the same CHILDES data.\n\nTo conclude, while I am sympathetic to the underlying ideas, the work does not make a solid case for it or present anything that we don't already know. In my opinion, the simulations only muddy the water (sorry!) instead of adding insights. Instead of simulations, I really encourage the author to use real data of variability in children learning trajectories and study the extent to which it follows the predictions of TP. \n ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_D2pM"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_D2pM"]}, {"id": "SN2e36RP9G9", "original": null, "number": 1, "cdate": 1648160451828, "mdate": 1648160451828, "ddate": null, "tcdate": 1648160451828, "tmdate": 1648160451828, "tddate": null, "forum": "rzfGP7FeLZc", "replyto": "rzfGP7FeLZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper19/-/Official_Review", "content": {"title": "Quantitatively assessing impact of child language input distributions on developmental learning trajectories", "review": "This paper models the relationship of child language input distributions on learning trajectories. This work is based on a cognitively motivated type-based learning model known as the Tolerance Principle that estimates a threshold of minimum exceptions to a linguistic pattern that are allowed for the language learner to productively use (and presumably influence decision-making and learning) a generalization in the grammar (in contrast to just memorizing individual items). The TP model has previously been used to account for inter-learner uniformity or how children acquire the same grammatical rules despite different learning input/environments (e.g., lexical variation).  \n\nThe authors show that the TP model accurately predicts how the type distribution of irregulars governs the overall learning outcome in line with previous work showing it can account for inter-learning uniformity. However, the novelty of this paper is in using the TP model to quantitatively assess how input distributions may drive variation in developmental learning trajectories. Specifically, how the token distribution (relative token frequencies or the order of acquisition of regular and irregular items) can lead to different learning trajectories. \nThe authors show this capability through an example using three different distributions of irregulars and their dramatic impact on the learning trajectory. They then show an application to real-world data mainly showing how this model can be used to quantify (visualize) the learning trajectories of the productive English past tense (the default past -ed) and the unproductive sing-sang sub-pattern drawing on CHILDES database.  \n\nThis has potential application towards quantitatively assessing how variation in input distributions accounts for observed cross-linguistical developmental learning trajectories. It would be great if the authors could give a specific example of this if the space allows for it as it would give the paper more breadth. I would also be interested in understanding how (if) this modeling approach could be extended to the developmental learning of larger linguistic structures (e.g., constructions or other)? \n\nThe theoretical description of the TP model and application to understanding how input distributions can impact developmental trajectories is very well explained. However, I think a little more effort should be spent in explaining how the different graphs/visualizations were created. Additionally, sometimes graphs are not referenced explicitly in the text such as in 3.1 in the last paragraph the authors reference a figure indirectly by simply stating \u201cThe second illustration demonstrates this\u201d. I think a bit of clean up in these areas and making sure the graph/visualizations are clearly explained despite space constraints will greatly benefit this paper overall. \n\nSmall edits: In 3.1 there is a typo, mainly \u201cIf irregulars are distributed uniformly [throughout] the distribution of types\u2026\u201d should replace \u201cIf irregulars are distributed uniformly [through out] the distribution of types\u2026\u201d.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_Skum"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper19/Reviewer_Skum"]}]}, {"paper_url": "https://openreview.net/forum?id=HOu4PQtgUWq", "paper_id": "HOu4PQtgUWq", "reviews": [{"id": "H-Egf7POkm5", "original": null, "number": 3, "cdate": 1648490265549, "mdate": null, "ddate": null, "tcdate": 1648490265549, "tmdate": 1648532571078, "tddate": null, "forum": "HOu4PQtgUWq", "replyto": "HOu4PQtgUWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper18/-/Official_Review", "content": {"title": "Looking for word co-occurrence probabilities in pre-trained word embeddings", "review": "This paper recycles the log-bilinear model (LBL), in a clever way to estimate bilexical co-occurrence probabilities using word embeddings. The motivation behind this work is that estimating word pair probabilities is often difficult due to the sparse nature of this data. Yet, having accurate word pair probabilities is relevant when conducting psycholinguistic experiments that evaluate usage-based cognitive language models (also likely in neurolinguistics it could be used as a useful baseline when trying to understand/evaluate the performance of word embeddings in decoding neural language activity in the brain). The authors propose to re-use the log-bilinear model from Mnih and Hinton 2007, arguably the simplest of neural language models, to estimate word-pair probabilities, specifically, by using as input to the LBL pre-trained static word embeddings (fastText word-vectors).\n\nThe performance of the LBL model is examined across four different languages (Arabic, English, Spanish, and Korean) while controlling for the size of the training data. They specifically look at predicting the distribution of attributive adjectives given nouns and nominal direct objects given verbs. The results are convincing with the log-bilinear model outperforming several baselines (i.e., lower negative log\nlikelihood). Particularly revealing is that it also consistently did better than a softmax distribution on target words as a function of the context word embedding (or when only using a word embedding for the context not the target word) confirming the utility of using word embeddings. I imagine that due to the light-weight nature of this model it would be of particular interest to language\nresearchers in cognitive science. The authors are also planning on making the code (trained model) available after publication. The only issue I have is that the paper doesn\u2019t really address the sparse nature problem they originally used to partially motivate this work. To this extent, it would be good to note if the authors observed any significant performance advantages when changing the size of the\ntraining data set (compared to the baselines)? It would be good to give users a rough guideline on these metrics so that this model can be properly used (also performance using other common word embeddings other than fastText).\n\nTypo: Page 4, Section 4.3 Results, \u201cThese is perhaps not surprising\u2026\u201d should be \u201cThis is perhaps not surprising\u201d.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_8X5b"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_8X5b"]}, {"id": "S9ewkG2uM9", "original": null, "number": 2, "cdate": 1648046558970, "mdate": 1648046558970, "ddate": null, "tcdate": 1648046558970, "tmdate": 1648046558970, "tddate": null, "forum": "HOu4PQtgUWq", "replyto": "HOu4PQtgUWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper18/-/Official_Review", "content": {"title": "A potentially useful tool for psycholinguists", "review": "This paper describes an estimation technique for word co-occurrence probabilities, unifying two relatively old pieces of technology: static word embeddings and a log-bilinear model from Mnih and Hinton 2008. The authors show that word pair probabilities remain useful in some psycholinguistic analyses and argue that large pretrained LMs which are now the state of the art in word prediction may not be able to read off the probabilities of interest without extensive computational effort (e.g. evaluating every word in the target set, in a particular context). Their model outperforms some basic LM smoothing techniques and is relatively lightweight and easy to estimate.\n\nBoth the mathematical framework and the presentation of related work are admirably clear given the limited space available. Results are very good across multiple languages (variants of this technique outperform very reasonable baselines, such as learning a softmax distribution over the target word, by large margins on many languages).\n\nGiven the space constraints, I would not expect to see a lot of task-specific analyses here. It would be nice to have an idea of how performance varies in training set size, and why performance is so low when the target vocabulary is unrestricted. These are likely to be important questions for psycholinguists considering how to use this technique.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_tnxr"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_tnxr"]}, {"id": "rTMe-jAuPG5", "original": null, "number": 1, "cdate": 1647967896897, "mdate": 1647967896897, "ddate": null, "tcdate": 1647967896897, "tmdate": 1647967896897, "tddate": null, "forum": "HOu4PQtgUWq", "replyto": "HOu4PQtgUWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper18/-/Official_Review", "content": {"title": "An old model made new with word embeddings", "review": "This paper proposes a way to estimate word co-occurrence probabilities by leveraging word embeddings. The method uses a log-linear bilinear model that had been proposed by Mnih and Hinton some time ago, but marries it with pre-trained word embeddings that are derived from a much larger corpus, and which are not specialized to specific types of word co-occurrence. The results are fairly impressive: the trained model yields lower negative log likelihood in all cases, as compared to a number of other baselines. Overall, I found the approach sensible, if not groundbreaking, and the evaluation reasonably compelling.  I have a couple of points I'd like to raise:\n\n1. There is considerable variation in performance across the languages (In the adj-noun case, Korean is uniformly the best performing, and . Arabic and Spanish the worst, though there is some variation across models. Things are different in the verb-object case.) Does this stem from the differently-sized test sets (I am assuming that the training data were identically sized across languages), or from differences in the fasttext embeddings (perhaps stemming from differences in training data again), or from differences in the languages, or something else? It would be helpful for the paper to say something about this. For one thing, it would be useful to give sizes of the datasets, as well as measures of the number of distinct context and target words. \n\n2. The paper starts by talking about the cognitive utility of having estimates of co-occurrence probability, and the difficulty of doing that in the context of limited (parsed) data. It would be helpful to know the degree to which the proposed method is doing better in contexts of limited data.  In particular, it would be interesting to know how performance of the different models varies as the training data changes in size. For models that can do better with less data, we'd expect to see convergence with smaller datasets.  It would also be useful to know just how well the different models can do in the limit, if we give them limitless data (or nearly as much as we have). Part of the lower performance might be due to difficulty in parameter estimation, and part might be due to the structure of the model, so it'd be useful to know the degree to which the proposed method is really solving the sparse data problem.  \n\n3. Given that this is for CMCL, I'd like to have seen some discussion about the cognitive plausibility of the approach. it is commonly thought that word embeddings represent lexical semantics, but clearly similar meaning will not be sufficient to capture co-occurence probability (as in cases of differences in register, or word collocations). Instead, the important property of word embeddings that is being exploited here is that they are derived exactly from attempts to predict co-occurrence. From that perspective, should we expect that any specific way of deriving word embeddings would perform better than another?  \n\nSpecific comments:\n\nline 61: why can't we use a language model to get predicted adjectives by renormalizing the predicted distribution to limit the support to the same 20k adjectives you look at here? How do the distributions we get in this way from existing large language models (e.g., GPT-3 or BERT) compare to what we get here?\n\nline 204: why these hyper parameters?\n\nline 282: what does it mean that nouns are more open class? That there are more of them? If so, say that. They are both clearly open class.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_JehU"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper18/Reviewer_JehU"]}]}, {"paper_url": "https://openreview.net/forum?id=BuO4I7FgUbq", "paper_id": "BuO4I7FgUbq", "reviews": [{"id": "HAxe04UznGc", "original": null, "number": 3, "cdate": 1648268854249, "mdate": 1648268854249, "ddate": null, "tcdate": 1648268854249, "tmdate": 1648268854249, "tddate": null, "forum": "BuO4I7FgUbq", "replyto": "BuO4I7FgUbq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper12/-/Official_Review", "content": {"title": "Interesting work on improving Codenames clue generation but conclusions are unclear", "review": "This paper reports an attempt to improve models/agents playing the game Codenames. The authors use co-occurrence-based relatedness measures to select clues. They modify the scoring functions used in prior work and compare performance of all pairwise combinations of their relatedness measures and scoring functions at generating clues which lead to correct guesses by English and Hungarian speakers.\n\nMAJOR\n\nThis is an interesting study though the implications for cognition or linguistics could be made more salient given the scope/audience of CMCL. The innovations in terms of scoring functions seem useful. However, I'm not quite sure what the main take-away of this study is. Performance across all the combinations was very different for English vs. Hungarian. The authors suggest that the Hungarian data are more valid, but it's unclear which differences are reliable/interesting.\n\nI also found it odd that the choice of lambda isn't justified anywhere. It seems like it would be helpful to know more about how it impacts the agents' behavior, how the value of 0.5 was chosen in previous work, and whether that is still the optimal value given the new relatedness metrics and scoring functions.\n\n\nMINOR\n\nThe abstract of the paper is not very clear. I think it assumes that the reader already knows how codenames works. I actually did and still found it very opaque. \n\nThe paper fails to cite relevant work by Kumar, Garg, and Hawkins (2021). It would be useful to reference this work and clarify any major differences between their approach and the one presented here.\n\nAshok Kumar, A., Garg, K., & Hawkins, R. (2021). Contextual Flexibility Guides Communication in a Cooperative Language Game. Proceedings of the Annual Meeting of the Cognitive Science Society, 43. Retrieved from https://escholarship.org/uc/item/92m138t3\n\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_28kX"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_28kX"]}, {"id": "BF-xYQQYizc", "original": null, "number": 2, "cdate": 1648231200617, "mdate": null, "ddate": null, "tcdate": 1648231200617, "tmdate": 1648231226627, "tddate": null, "forum": "BuO4I7FgUbq", "replyto": "BuO4I7FgUbq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper12/-/Official_Review", "content": {"title": "Solid work but some questions about conclusions and prior literature", "review": "This paper contributes to a small but growing literature investigating the codenames board game as a way to evaluate models of human semantic memory. The authors separate sources of semantic relatedness and decision rules and evaluate both of these in their ability to guide human players in an online game. \n\nThe direct evaluation of algorithm outputs is a major strength of the paper, as is the systematic evaluation of the space of different relatedness/scoring pairs. There is surprisingly little variation in performance among relatedness/scoring pairs, however, and there  is not much systematicity (e.g., sometimes a particular scoring rule performs better with one relatedness measure and worse with another). Further,  no statistical analysis is presented. These observations make me worried that \u2013 despite the large amount of data \u2013\u00a0the conclusions in favor of specific settings are tentative. \n\nA notable new line of work by Kumar and colleagues has investigated both other sources of relatedness and judgments and other metrics, though both the details of the games and the evaluations are different enough to be difficult to compare:\n- Kumar et al. (2021a) - https://escholarship.org/uc/item/92m138t3\n- Kumar et al. (2021b) - https://onlinelibrary.wiley.com/doi/full/10.1111/cogs.13053\n\nAlso, there was no reference to an older, foundational paper, Xu & Kemp (2010) - https://proceedings.neurips.cc/paper/2010/file/766d856ef1a6b02f93d894415e6bfa0e-Paper.pdf\n\nIn sum, this seems like solid work but my enthusiasm was dampened by my limited confidence in the meaningfulness of results comparisons and by the omission of prior work. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_GDsD"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_GDsD"]}, {"id": "SrHe4J2DjGq", "original": null, "number": 1, "cdate": 1648225244280, "mdate": 1648225244280, "ddate": null, "tcdate": 1648225244280, "tmdate": 1648225244280, "tddate": null, "forum": "BuO4I7FgUbq", "replyto": "BuO4I7FgUbq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper12/-/Official_Review", "content": {"title": "nice work", "review": "This paper builds on and improves previous work on modeling the Codename game. The authors introduce both new semantic association measures and new scoring functions that optimize the choice of clue words. The authors also compare the model predictions to human players online in both English and Hungarian.\n\nThe paper is well written,  the methods are clearly justified, and the results are compared with previous work and show increased performance.\n\nI am not an expert in this sub-filed of study but I enjoyed reading the paper and found it interesting. I do not have any major concerns and thus, I recommend acceptance.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_zsee"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper12/Reviewer_zsee"]}]}, {"paper_url": "https://openreview.net/forum?id=B6PlLQtl8Zq", "paper_id": "B6PlLQtl8Zq", "reviews": [{"id": "BudxT5AzRM5", "original": null, "number": 3, "cdate": 1648402069050, "mdate": 1648402069050, "ddate": null, "tcdate": 1648402069050, "tmdate": 1648402069050, "tddate": null, "forum": "B6PlLQtl8Zq", "replyto": "B6PlLQtl8Zq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper8/-/Official_Review", "content": {"title": "Investigating multimodal referring items using transformers", "review": "In this paper, the authors use CLIP (a multimodal vision + language neural model) to quantify the descriptiveness and discriminative of human dialogues when describing visual inputs.\n\nThe work is interesting, and overall well presented. The only part I would like spelled out better is the ability to really get cognitive insights into the possible strategies adopted by humans. So far, the link is really not there and unfortunately, undermines the conclusions we can draw from this study.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_6fTE"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_6fTE"]}, {"id": "S-EgB8Grjzq", "original": null, "number": 2, "cdate": 1648214604977, "mdate": 1648214604977, "ddate": null, "tcdate": 1648214604977, "tmdate": 1648214604977, "tddate": null, "forum": "B6PlLQtl8Zq", "replyto": "B6PlLQtl8Zq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper8/-/Official_Review", "content": {"title": "An interesting study on multimodal referring utterances", "review": "This paper presents experiments on quantifying the descriptiveness and discriminativeness of referring utterances in dialogues, by using a pre-trained multimodal modal. The study is well-presented and has shown interesting results. I only have one minor question about the COCO dataset. It says that the COCO set used in this study was a part of the PB-GOLD, but while PB-GOLD's utterances were related (section 2), later it says COCO dataset's captions were independently produced (page 3). Maybe some clarification would help us understand the nature of PB-GOLD dataset.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_yWif"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_yWif"]}, {"id": "rKbeqBXNUGq", "original": null, "number": 1, "cdate": 1647883073555, "mdate": 1647883073555, "ddate": null, "tcdate": 1647883073555, "tmdate": 1647883073555, "tddate": null, "forum": "B6PlLQtl8Zq", "replyto": "B6PlLQtl8Zq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper8/-/Official_Review", "content": {"title": "Nice work. Applies state-of-the-art tools in a simple and effective manner in order to measure human language usage in a conversation.", "review": "The paper uses the CLIP language-vision model in order to measure the descriptiveness (how well an utterance describes an image in isolation) and discriminativeness (to what extent an utterance is effective in picking out a single image among similar images) of human language as it develops in a conversation.  The focus is on utterances that refer to visual entities. The paper presents interesting conclusions, reasonable explanations and it paves the way for future research with CLIP and similar tools.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_YG2K"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper8/Reviewer_YG2K"]}]}, {"paper_url": "https://openreview.net/forum?id=BduGIXtlLZc", "paper_id": "BduGIXtlLZc", "reviews": [{"id": "HbxytlD9M9", "original": null, "number": 3, "cdate": 1648156791454, "mdate": 1648156791454, "ddate": null, "tcdate": 1648156791454, "tmdate": 1648156791454, "tddate": null, "forum": "BduGIXtlLZc", "replyto": "BduGIXtlLZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper7/-/Official_Review", "content": {"title": "Well written paper with unimpressive results", "review": "The authors describe a classification experiment in which they mixed linguistic and visual features to predict the semantic relation holding between the components of a noun noun compound. \n\nBy itself the paper is well written and the topic very interesting. \n\nHowever, I find the reported results a bit unimpressive due to a series of reasons:\n- first of all, the differences in the reported F-measures are mostly almost negiglible. The authors should at least comment on that\n- the negative correlation between concreteness score and classification success is really puzzling, almost worrying. From an intuitive point of view, it suggest that the visual information (as encoded in this experiment) is not really that useful\n- it is not clear why the authors didn't test the performance of the visual features in isolation\n- a crucial piece of information that is missing from the paper is an analysis of the relation-wise perfomance of the best-performing classifier", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_Zq1M"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_Zq1M"]}, {"id": "ShVlqDNH9G5", "original": null, "number": 2, "cdate": 1648149601835, "mdate": 1648149601835, "ddate": null, "tcdate": 1648149601835, "tmdate": 1648149601835, "tddate": null, "forum": "BduGIXtlLZc", "replyto": "BduGIXtlLZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper7/-/Official_Review", "content": {"title": "A useful contribution in need of some clarity/reframing", "review": "This is a well-written paper; the authors clearly lay out the objective, the previous work on the topic, and their contribution. However, the reported performance increases are very modest, and some methodological choices are unclear. Overall, I think this paper is appropriate for CMCL if the authors adjust the framing and provide some clarifications.\n\n1.\tThe main claim is that concatenating word2vec and visual (ResNet) activations will improve interpretation (classification) of compound nouns by providing additional semantic information. However, the actual increases are very small (an average of 1% or less). It would be helpful if the authors acknowledged that the increases are actually quite modest. Moreover, Table 5 in the appendix shows that comparable performance gains can be observed even in cases where the nouns do not have a visual representation (so their final representation is word2vec + zeros). Thus, the utility of visual representations remains debatable.\n2.\tImageNet representations are obtained by averaging representations of several images. Has that been shown to be a useful approach for representing visual concepts? I would imagine that even if providing visual information is beneficial, averaging several distinct image vectors might make the visual representation less useful than it could have been if, say, the most prototypical image was chosen (this might depend on the specific object type too, e.g. less concrete objects are likely more visually diverse).\n3.\tI don\u2019t quite get the way the Full Additive Model was implemented. Were the x, y, and z vectors pretrained word2vec vectors? More generally, you state toward the beginning that the goal is to learn a way to represent compounds compositionally, yet if the compound is frequent enough to have its own ground truth representation (z), doesn\u2019t it violate the compositionality premise? \n4.\tIs there a reason why visual reps alone aren\u2019t used for classification? Seems like a useful baseline.\n5.\tThe authors address the question of whether word concreteness affects their results by (a) examining how many imagenet images each word is associated with, (b) performing additional tests of whether image availability and concreteness affects classification accuracy. However, a key question here seems to be addressed only indirectly: do compounds with concrete words benefit more from adding visual representations? This could be done by dividing the compounds into 2 groups, concrete and abstract, and examining whether the benefits of adding visual reps vary between these two groups. Alternatively, the tests in Table 6 can be complemented by an explicit comparison of relative concreteness effects in L and VL modalities. The question of whether adding image vectors benefits only highly concrete words arose for me as soon as I read the title/abstract, so I think it\u2019d be important to address it a bit more.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_rwmZ"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_rwmZ"]}, {"id": "HYLgPTXQKz9", "original": null, "number": 1, "cdate": 1648075711056, "mdate": 1648075711056, "ddate": null, "tcdate": 1648075711056, "tmdate": 1648075711056, "tddate": null, "forum": "BduGIXtlLZc", "replyto": "BduGIXtlLZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper7/-/Official_Review", "content": {"title": "Seems to work, but the prose oversells the results", "review": "This paper investigates whether and to what extent augmenting linguistic representations with visual representations can improve a system's classification of noun-noun compounds (NNCs). NNCs come from the Tratz (2011) data set. They try a few different ways of combining the linguistic and visual representations.\n\nI appreciated that they specified several data splits up front: course vs fine-grained labels, and train/dev/test splits controlling for both the modifier and head members of the NNCs. This allows, in theory, for a lot of interesting comparison and analysis.\n\nOne major challenge which the authors faced was how to match up images from ImageNet with the Tratz NNCs. They present an algorithm to do this which seems reasonable, but is still quite approximate. This bring this up again in the conclusion. My worry is that their results might be greatly affected by their matching heuristic rather than the problem at hand, and while this is a great topic for a follow-up, I wish they had addressed it in this paper. I believe it is more critical than they made it out to be.\n\nThey present F1 scores for a family of 3 baseline models which take majority classes of the entire compound, head, or modifier in the training data. Providing a sensible baseline is something that is often skipped these days, so I appreciated this. \n\nThey test a concatenate and an additive model for combining ResNet visual representations with word2vec linguistic representations. \n\nThey find similar but not identical results for the additive and concatenative model. The latter performed slightly better on average, and in both cases they generally outperform word2vec alone. I was a bit surprised when I got to the results though, because +ResNet really is only a little bit better than word2vec alone. It seemed kind of incongruous with the big claims made in the prose of the paper. It's sort of trivial to assume that including additional informative data (as through ResNet) should help performance if it's combined correctly, and that is what we see from the results. So my question is, are these results dramatic enough to be interesting? And why aren't they better? Was it because of the matching heuristic? I don't know\n\nAlso not sure what part of this paper is meant to be cognitive modeling. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_JpgF"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper7/Reviewer_JpgF"]}]}, {"paper_url": "https://openreview.net/forum?id=rTMeHmKeI-5", "paper_id": "rTMeHmKeI-5", "reviews": [{"id": "SKIeR28BJ75", "original": null, "number": 3, "cdate": 1648477877952, "mdate": 1648477877952, "ddate": null, "tcdate": 1648477877952, "tmdate": 1648477877952, "tddate": null, "forum": "rTMeHmKeI-5", "replyto": "rTMeHmKeI-5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper4/-/Official_Review", "content": {"title": "An interesting new model of language representation but not entirely convincing ", "review": "This paper presents a new model for word embeddings that is based on the Unitary-Evolution Recurrent Neural Network architecture. The main advantage of the proposed embeddings is that they don't rely on non-linear cell operations making the resulting representations more interpretable and natively compositional. \n\nWhile the promise of a more interpretable language representation model is very interesting, I'm not entirely convinced the new embeddings provide more intuitive explanations of what is being represented. The analysis still relies on linear algebra operations and interpretation of arbitrary distance values. The examples of syntactic and semantic closeness are equally transparent in the geometric interpretation of traditional word vectors and the effect size is easily mapped on the attention weight of regular attention-based DNN. In addition, we didn't see a concrete example of the advantage of URNs being able to handle compositionality natively. Ideally, there would be a \"head-to-head\" comparison (either qualitative or quantitative) between the proposed unitary embeddings and the more established techniques.\n\nRegarding the model's performance on a language task, despite the claims of the authors, there is no comparison with state-of-the-art methods for agreement task. For example, Goldberg (2019) achieves very similar results (up to 4 attractors) to the ones reported for TURN.\n\nThere are mentions of the current model's higher computational cost, but there are no figures to demonstrate whether this type of modeling can be practically used instead of the current generation of Transformer-based architectures.\n\nFinally, despite claims to this effect, there is no evidence of the proposed model's neurological validity. The reference to models of human learning and representation in the Introduction (lines 87-89) is vague and lacks supporting citations.\n\nOverall, while the use of URNs as embeddings is an interesting concept to explore, I'm not entirely sure this paper has created a convincing account. \n\n\n## Comments to authors\nI didn't find the mathematical (modeling) sections of the paper very easy to follow. I would highly recommend the use of a running example throughout sections 2 and 3.\n\nTo prove the claim that \"[unitary embeddings] can focus on specific dimensions of meaning and structure, and they can be driven by specific NLP tasks\" it would be very interesting to show the same words being characterised differently due to the task (e.g. showing that the distances in Table 2 flip to group together semantically similar concepts rather than syntacticly similar ones).", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_AkA5"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_AkA5"]}, {"id": "SZEgKOXVcfq", "original": null, "number": 2, "cdate": 1648145264588, "mdate": 1648145264588, "ddate": null, "tcdate": 1648145264588, "tmdate": 1648145264588, "tddate": null, "forum": "rTMeHmKeI-5", "replyto": "rTMeHmKeI-5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper4/-/Official_Review", "content": {"title": "Robust mathematical implementation of a new RNN which provide a totally explainable deep learning model for natural language learning and representation", "review": "This paper introduces a new Recurrent Neural Network that includes Unitary Matrices at each step. The cell uses a linear transformation of the space instead of applying non-linear activations.\nThe authors evaluate how the RNN captures long-distance dependencies on two tasks: number agreement and Dick-language modeling (a symbolic synthetic language). The tasks are well-described and coherent with their research questions; results demonstrate how this mathematical implementation can help understand the linguistic representations created by deep neural architectures.\n\nThe paper offers a solid mathematical explanation and motivation for the implementation. The authors make everything as precise as possible, even if mathematical sections are a bit demanding for non-mathematicians. The only point that maybe could be more transparent regards the \"average effect.\" In section 4.1, the exposition is condensed into very few lines. I suggest providing more details about this measure, making it more painless for a larger audience.\n\nThe only limitation of the presented work is perhaps that one must train the network for every specific task in a supervised way.\n\nThe overall judgment is favorable. I would be glad to see this model tested on semantic compositional tasks in NLP.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_PSXn"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_PSXn"]}, {"id": "SUXlElS4Uf5", "original": null, "number": 1, "cdate": 1647883499778, "mdate": 1647883499778, "ddate": null, "tcdate": 1647883499778, "tmdate": 1647883499778, "tddate": null, "forum": "rTMeHmKeI-5", "replyto": "rTMeHmKeI-5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper4/-/Official_Review", "content": {"title": "An interesting paper which proposes a new neural embedding network which emphasizes compositionality and sentence embedding. The network is linear and hence arguably paves the way to interpretable comparisons with humans.", "review": "This paper proposes a new neural model for word embeddings, which uses unitary matrices as the primary device for encoding lexical information. This model does not employ non-linear activation functions, and can hence be used with linear algebra tools. The model emphasizes compositionality. The model is interesting but I am not sure the work is directly related to the theme of the workshop (which is the main reason that I did not give the work a higher score). ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_7SS9"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper4/Reviewer_7SS9"]}]}, {"paper_url": "https://openreview.net/forum?id=BGMfS7tgIWq", "paper_id": "BGMfS7tgIWq", "reviews": [{"id": "rHxx0-PQ0zc", "original": null, "number": 3, "cdate": 1648404229919, "mdate": 1648404229919, "ddate": null, "tcdate": 1648404229919, "tmdate": 1648404229919, "tddate": null, "forum": "BGMfS7tgIWq", "replyto": "BGMfS7tgIWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper3/-/Official_Review", "content": {"title": "Combining vision and language to model semantic similarity and relatedness", "review": "In this paper, the authors investigate the use of multimodal (text+image) embeddings to predict semantic similarity and relatedness between word pairs.\nAll in all, the paper is well written and discusses a topic that is central to the CMCL community. However, there are still parts that are unclear and this makes the overall contribution weaker.\n\n* It is not clear to me how you can say that: VGEs explain additional variance after including text-based representations? This really needs more explanations. \n\n* Similarly, it is not clear how you can quantify the non-overlapping information captured by the different models. \n\n* Figure 1 needs more attention. Firstly, it has to be explained in more detail. Moreover, the two scales should be the same: this is extremely misleading. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_4sDq"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_4sDq"]}, {"id": "r4heOuEdof9", "original": null, "number": 2, "cdate": 1648227440345, "mdate": 1648227440345, "ddate": null, "tcdate": 1648227440345, "tmdate": 1648227440345, "tddate": null, "forum": "BGMfS7tgIWq", "replyto": "BGMfS7tgIWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper3/-/Official_Review", "content": {"title": "Careful experiments that disentangle visual information in text and actual image data", "review": "This is a well-written paper that carefully experiments with VGEs and compares the additional variance that can be explained using VGEs compared to text-based models.\u00a0\n\n\nStrong points:\n\nThe paper makes a contribution to previous work by disentangling the visual information that may be contained in the text part of a dataset such as MSCOCO and the actual image data.\u00a0\n\n\nIt shows results on a large number of datasets and tasks and meaningful subparts thereof. There is definitely substance.\n\n\nWeak points:\n\nThe paper investigates a worthwhile but considerably researched topic on two  well-known tasks. The method for creating VGEs is taken from previous work with some adaptations. In terms of novelty, the paper does not excel.\n\n\nEven after careful re-reading, I am not completely convinced that the results between the VGE model and the textual models are comparable. The method used to create the VGE is so different (more contextualised than the text-based models) that one wonders whether the contributions of the VGE model are not due to the model instead of the visual features.\u00a0\n\n\nI would also like to see Figure 1 better explained, in particular the grey bars. These represent \u2018the partial R2 of the VGEs after controlling for the variance explained by that text-based model\u2019. Do you mean here the given text-based model, so word2vec for example? From the way these scores are represented, one on top of the other, you would get the idea that these scores can be added to arrive at a combined performance. I doubt that this is true though. Perhaps the partial R2 scores could be explained in more detail.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_wj8M"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_wj8M"]}, {"id": "rpPl9_IV8Gq", "original": null, "number": 1, "cdate": 1647883889601, "mdate": 1647883889601, "ddate": null, "tcdate": 1647883889601, "tmdate": 1647883889601, "tddate": null, "forum": "BGMfS7tgIWq", "replyto": "BGMfS7tgIWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper3/-/Official_Review", "content": {"title": "The paper presents visually grounded word embeddings and show that they predict both human reaction times and human judgements of word similarity. This is an interesting work that very well fits the theme of the workshop.", "review": "The paper presents visually grounded word embeddings and shows that they predict both human reaction times and human judgements of word similarity. I like the fact that the paper compares both to a reaction time experiment  and to word similarity judgement data. The fact that the proposed model performs well no both, is a nice indication of its cognitive plausibility.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_P9g8"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper3/Reviewer_P9g8"]}]}, {"paper_url": "https://openreview.net/forum?id=ruuMvmFeIb5", "paper_id": "ruuMvmFeIb5", "reviews": [{"id": "H2Gx_Gy7Azq", "original": null, "number": 3, "cdate": 1648402192038, "mdate": 1648402192038, "ddate": null, "tcdate": 1648402192038, "tmdate": 1648402192038, "tddate": null, "forum": "ruuMvmFeIb5", "replyto": "ruuMvmFeIb5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper17/-/Official_Review", "content": {"title": "A Bayesian model of phase coherence in frequency-tagged EEG data", "review": "This paper discusses disadvantages of a frequentist ITPC analysis (such as loss of statistical power, no full characterization of the structure of the data) of frequency-tagged EEG data, and introduces a Bayesian model as a novel alternative. \nThe model includes:\n* a wrapped Cauchy distribution as a model of the data (a set of angles drawn from a unimodal probability distribution on the circle)\n* a prior for the mean phase for each participant-electrode-condition triplet as a uniform on a circle\n* a condition-dependent prior for the scale parameter of the distribution, resulting in different mean resultants\n \nThe authors show that the posterior distributions yielded by this model give a richer and more complete picture of the data than the original frequentist ITPC analysis.\n \n**General**\n\nThe paper is clearly written and of theoretical interest to the community. The characterization of the data derived via the analysis allows for interesting new conclusions that were not detectable using the ITPC method, which are relevant to the original research question. As someone without a background in EEG time-series analysis, the proposed Bayesian model nevertheless strikes me as straightforward and well-motivated. To make the novel contribution of the paper even stronger I suggest a discussion of how this approach compares to a mixed-effects model, which can also model the random effects in the data that ITPC as a summary statistic glosses over.\n \n**Specific questions/Comments**\n* One thing that wasn\u2019t clear to me from the write-up is how the simplifying assumption of choosing independent location parameters per participant-electrode-condition triplet instead of per participant-electrode pair affects the model results (lines 144ff).\n* I would have liked to see the unabbreviated names for all 6 conditions somewhere in the paper, especially since the ML condition for which the model provides a novel result in relation to RR is not listed as an experimental condition in the Burroughs et al. (2021) paper; The same is true for the RV condition, but this name is more transparent given the other conditions. I assume ML and RV correspond to the two extra conditions described as fillers in the Methods section of Burroughs et al. (2021), and analyzed in Figure 2 of their Supplementary Materials, where RV = RRRV and ML = ADVP, but it would be good to make this correspondence clear. Furthermore, if this alignment is correct it may be good to discuss a potential effect of these two streams having 12 four-word phrases instead of 24 two-word phrases as the other conditions on the critical ML-RR modeling results.\n \nOverall, I think this paper provides an interesting contribution and I am looking forward to seeing the full description of the different Bayesian models and their robustness advertised at the end of the paper.", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_khn9"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_khn9"]}, {"id": "SV3lXBvmKz9", "original": null, "number": 2, "cdate": 1648076602532, "mdate": 1648076602532, "ddate": null, "tcdate": 1648076602532, "tmdate": 1648076602532, "tddate": null, "forum": "ruuMvmFeIb5", "replyto": "ruuMvmFeIb5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper17/-/Official_Review", "content": {"title": "A Bayesian analysis of a neurolinguistic EEG study", "review": "This submission describes a Bayesian analysis of frequency-tagged EEG experiments, a type of experimental paradigm used in neurolinguistics research. The analysis is meant to serve as an alternative to a traditional frequentist analysis from prior works, which averages over electrodes and items instead of explicitly accounting for associated variance.\n\nMain contributions of the work:\n1.\tA discussion of a Bayesian EEG analysis as an alternative to frequentist methods\n2.\tAn attempt to explicitly model item and participant effects\n3.\tA nuanced discussion of Bayesian priors required to model inter-trial phase coherence (ITPC) effects\n\nQuestions and clarifications:\n1.\tThe authors pitch the need to model item and participant effects as the main incentive for switching to Bayesian analysis. However, there is a frequentist approach that achieves the same effect \u2014 mixed effects modeling. Mixed effects models have been gaining popularity for EEG analyses, including analyses of ITPC (see e.g. Koerner & Zhang, 2017). Of course, this doesn\u2019t mean that the Bayesian analysis has no value, but I would recommend the authors to adjust their motivating arguments (and possibly mention mixed effects models as a frequentist alternative)\n2.\tDifferential effects across electrodes/participants. The authors correctly state that averaging the data across electrodes and participants \u201cwashes out\u201d effects of interest that vary across them. However, their analysis doesn\u2019t quite seem to address this issue: the effect of condition is modeled to be the same across all electrodes and participants if I understand it correctly. Thus, while modeling the variance in participant-, electrode-, and condition-specific averages is certainly a step forward, differential effects across participants and electrodes remain unaccounted for in this model.\n3.\tHow much data are required for the proposed analysis? It might be helpful to have a brief discussion of guidelines for determining whether the number of, e.g., item repetitions across participants is sufficient to fit the model. \n4.\tIn eqs. 7 and 8, does alpha without a subscript correspond to the baseline value shared across participants, electrodes and conditions? The current wording is a bit ambiguous on that point.\n5.\tThe justification for using the log-logistic link function to model gamma is unclear to me (an outsider to this subfield). We don\u2019t need to know the specifics but a one-line explanation or a reference would help.\n\n\nMinor:\n-\tTo better advertise the analysis for scientists used to frequentist methods, it might be useful to include Bayesian factor as a more direct alternative to frequentist hypothesis testing\n-\tIn Figure 3, you might want to highlight the key conditions of interest\n\nOverall, this is an interesting contribution to the field of EEG data analysis, with clear applications in the domain of neurolinguistics.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_vD5a"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_vD5a"]}, {"id": "HbNxNl3OJfc", "original": null, "number": 1, "cdate": 1647442923613, "mdate": 1647442923613, "ddate": null, "tcdate": 1647442923613, "tmdate": 1647442923613, "tddate": null, "forum": "ruuMvmFeIb5", "replyto": "ruuMvmFeIb5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper17/-/Official_Review", "content": {"title": "a nice methodological note regarding a previous analysis", "review": "This would make a nice poster at CMCL. It simply lays out a Bayesian version of Frequentist analysis that was used in a published paper last year. Although there is no cognitive modeling per se, the method itself will be interesting to a variety of CMCL attendee. There is probably *not* enough here for an article in a journal like _Bayesian Analysis_ so it's appropriate that we offer a venue in which to share this work.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_Pgx7"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper17/Reviewer_Pgx7"]}]}, {"paper_url": "https://openreview.net/forum?id=H__evmFlUZ9", "paper_id": "H__evmFlUZ9", "reviews": [{"id": "r42lKWqKsM5", "original": null, "number": 3, "cdate": 1648232961289, "mdate": 1648232961289, "ddate": null, "tcdate": 1648232961289, "tmdate": 1648232961289, "tddate": null, "forum": "H__evmFlUZ9", "replyto": "H__evmFlUZ9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper16/-/Official_Review", "content": {"title": "Learning non-local alternations via tier creation", "review": "The authors propose a model for learning non-local phonological alternations via the creation of feature tiers. The work sits at the intersection of tier-based analyses of phonotactic computational complexity (Heinz et al) and artifical grammar learning (AGL) experiments on learning of local and nonlocal phonological processes. The submission is as an extended abstract.\n\nThe authors provide pseudocode for the functioning of the model, walk the reader through an example of its functioning on some data, and discuss its relevance to human performance on previous AGL experiments. They also compare the model's performance against those of competing HMM and FSM based models.\n\nThe authors make a number of claims that require non-trivial support e.g. (i) that learning non-local is harder than local, which may be true in AGL scenarios but this says little or nothing about natural language acquisition scenarios, or (ii) claims from model learning results that human learners construct tiers.\n\nThere is a fair amount of unclarity in the formalism and notation: it feels like much of this could have been eliminated from this submission but would benefit a subsequent lengthier submission where there is more room for definitions and examples.\n\nSome specific notes:\n- opening discussion of English plural morph refers to it as a phonological segment (omitting discussion of the [-Id] realization)\n- the composition of V should be clarified in line 94 (i.e. input-output pairs of what; this is unclear from context)\n- if segments are treated as bundles of features (line 117) then it's not clear why segments continue to be referred to\n- it's not clear how the final tier is written back to the final output form; the tier projection operation as described seems to be lossy (the \"final sequence\" in lines 135-137 appears to only be the final tier representation)\n- the input V (set of input-output pairs) to Algorithm 1 appears to not be used/referenced anywhere in the algorithm\n- the notion of \"accuracy\" referenced on line 148 and in Algorithm 1 is not clear; accuracy at what?\n- the work is reminiscent of the search/copy approach (Samuels, Nevins, Reiss/Mailhot) to phonological operations (including the observation that strict locality is merely a special case of non-locality), only with unnecessary notational baggage and it's not clear what it's benefit is\n\nNotwithstanding all of the above, the paper is a promising start to work that could eventually make contact with the tier-based formal work from the Stony Brook group providing some linking hypotheses across Marrian levels of phonology. It would benefit from being presented and critiqued and I'd like to see it accepted and presented.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_ztMY"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_ztMY"]}, {"id": "r6wga0xrizc", "original": null, "number": 2, "cdate": 1648214228875, "mdate": 1648214228875, "ddate": null, "tcdate": 1648214228875, "tmdate": 1648214228875, "tddate": null, "forum": "H__evmFlUZ9", "replyto": "H__evmFlUZ9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper16/-/Official_Review", "content": {"title": "Interesting but the model could benefit from more phonological knowledge?", "review": "This paper reports a model that learns distant phonological alternations. The results of the model are overall comparable to human learners' performance. I think the paper is quite interesting, but to be honest I'm not sure what would be the application of this model. In natural language, non-local alternations are often conditioned by the phonological context (e.g., assimilation, which is the case in the real-language examples cited in this paper). The current model doesn't seem to have phonological knowledge. I'm curious to know what would be the next step of this project. Is the goal to simulate human learners?", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_pZXL"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_pZXL"]}, {"id": "HYbgbbq38z9", "original": null, "number": 1, "cdate": 1647917560607, "mdate": 1647917560607, "ddate": null, "tcdate": 1647917560607, "tmdate": 1647917560607, "tddate": null, "forum": "H__evmFlUZ9", "replyto": "H__evmFlUZ9", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper16/-/Official_Review", "content": {"title": "Learning Non-Local Phonological Alternations via Automatic Creation of Tiers", "review": "The article presents a computational model for dealing with phonological alternations. It presents a cognitive argument for why this is interesting, but could also use a computational argument for why this is interesting, i.e., how might this model be used? Overall it is very well written and easy to understand. The only problems I had with the article were about formatting:\n\n1. Place Figures and Tables below the paragraphs that you first mention them in. For instance, Figure 1 is on the first page but not mentioned until the second, while Table 2 is before the paragraph starting on line 271.\n2. As far as I know (although if I'm wrong please ignore this), the symbol, \"\u00a7\", is not required of you to use. I was quite confused about what it was supposed to mean and you don't use it consistently. For a while I thought you were trying to use a symbol for the word 'Figure'. After clicking on it I grasped that you're using it to mark the presence of a footnote, but then later you also use it to denote a section in the main text. \nIn terms of footnotes, seeing as the citations are spelled out, i.e., not superscripted, there's no reason to use a confusing symbol that takes up space. I recommend you use superscripts for footnotes and delete the \"\u00a7\" (as you did on line 267). That's my first opinion. My second opinion is that you can do without footnotes entirely. You don't say anything that can't be added to the main text or left out. For instance, footnote 1 is there just to tell you that in 3.1.1 there is more info... You don't need a footnote for that. I would even say that footnote 2 is something that should be in the main text as its an important detail. \nIn terms of using the \"\u00a7\" symbol to denote sections in the main text... I suppose the question would be \"why?\" Does it facilitate reading? On line 153, does it make reading easier to tell the reader they can find out more in the section that immediately follows? My first opinion is that you get rid of these as I don't understand what purpose they serve. My second opinion is that if you really want to keep them then you need to follow writing logic and put them in parentheticals because they do not belong within the syntax of the sentences you are placing them in. You did this correctly on line 211.\n\nBelow are some minor writing mistakes\n1. line 028: 'phonological environments'\n2. line 072: 'a phonological tier is a representation', or 'phonological tiers are representations'\n3. line 102: 'process'\n4. line 112, 'a local rule, \ud835\udc5fadj, applied'\n5. line 228: 'the one that scored higher'\n6. line 239: 'over the non-harmonizing choice'\n7. line 246 and 247: 'and consequently could not generalize from the training data to test instances even when humans did'\n8. line 258: 'All vowels that participate'\n9. line 273 and 274: 'consisting of 200 training words and 800 novel words'\n10. line 275: 'D2L learned'", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_tYg5"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper16/Reviewer_tYg5"]}]}, {"paper_url": "https://openreview.net/forum?id=r4exumYxLWq", "paper_id": "r4exumYxLWq", "reviews": [{"id": "SExgWGEWqMq", "original": null, "number": 3, "cdate": 1648133128663, "mdate": 1648133128663, "ddate": null, "tcdate": 1648133128663, "tmdate": 1648133128663, "tddate": null, "forum": "r4exumYxLWq", "replyto": "r4exumYxLWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper25/-/Official_Review", "content": {"title": "Interesting work", "review": "This work uses a transformer model to investigate learning the past tense from child-directed speech. The study focuses on whether the model variants can exploit information from morphology, auxiliaries, or temporal adverbs.\n\nI found the study very interesting and relevant, and a very good fit for this venue.\n\nThere are a number of points that could be improved. The nonce test is definitely relevant, but it is based on a very small number of items. I also found the paper could do a better job at situating the results.  It is unclear to me what we learn from comparing the 3 tokenizers. I also missed some reflection on what the results entail for language acquisition.The authors almost apologetically mention that the model is not cognitively plausible, but I think that is not necessarily a downside: these are conclusions from a data-driven model, which are relevant to gather insight on which linguistic information can be exploited. Some discussion on this would make the paper stronger.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_R9j9"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_R9j9"]}, {"id": "BAM-OWRsdf9", "original": null, "number": 2, "cdate": 1648045568462, "mdate": 1648045568462, "ddate": null, "tcdate": 1648045568462, "tmdate": 1648045568462, "tddate": null, "forum": "r4exumYxLWq", "replyto": "r4exumYxLWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper25/-/Official_Review", "content": {"title": "English tense information is mostly carried by auxiliaries in child-directed speech", "review": "This paper describes a simulation study in learning to predict tense from CDS sentences from the Adam corpus. The model uses auxiliaries and the past suffix -ed to detect tense, but does not learn morphologically irregular past tenses nor the periphrastic future \"going to\". These effects are linked to trends in input frequency as well as analyses from the human learning literature.\n\nI found the paper very interesting in its focus on language acquisition of an important semantic distinction and in linking explicitly to work on human learning. I also appreciated the use of nonce verbs and various probing techniques in analyzing the reuslts.\n\nI did have some problems in following the argumentation.\n\n1: Line 63 says \"the other hypothesis is that temporal adverbs could facilitate\" the learning of tense. But I don't see where this hypothesis comes from. The cited research on the following lines suggests that children don't pay much attention to temporal adverbs. So whose hypothesis is this and why is it worth studying?\n\n2: I am a bit confused about the model setup. My understanding is that the model is a 2-layer transformer without any pretraining (section 4.1) and that only the tokenizers are adopted from pretrained LMs (section 4.2). Table 2 shows the training data sizes of three models, Roberta, BabyBerta and 2y/o BabyBerta and also their number of parameters (which should be irrelevant if no pretraining is used). I think these pretrained models are used only to create the tokenizers, not the model itself. However, I am not perfectly clear on this point, especially because later tables 3 and 5 report performance by \"Model\" ranging across Roberta, BabyBerta and 2y/o. \n\n3: Following from this, if no pretraining is used, I am not sure why this decision was made. Pretraining followed by fine-tuning is known to learn more robust semantic representations than just learning to classify and would potentially do a better job of extracting the lexical semantics of irregular verbs based on their distribution. Why train a new transformer from scratch instead of using BabyBerta itself as a model and adding a classifier layer on top of it?\n\n4: Although the three tokenizers are compared throughout, there is no clear conclusion about the differences between them; I am not sure in the end why this comparison is important.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_71ka"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_71ka"]}, {"id": "HLXxJbntdG9", "original": null, "number": 1, "cdate": 1648036854869, "mdate": 1648036854869, "ddate": null, "tcdate": 1648036854869, "tmdate": 1648036854869, "tddate": null, "forum": "r4exumYxLWq", "replyto": "r4exumYxLWq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper25/-/Official_Review", "content": {"title": "Some good ideas, but not sure about the point", "review": "This paper asks whether linguistic input alone (i.e., without situational context) is sufficient for acquiring English tense. They hypothesize that it is, and test with three related transformer models, RoBERTa, which uses BPE to capture sub-word information, BabyBERTa, which is trained on English CHILDES, and a 2yo-BabyBERTa trained on a fraction of CHILDES. They conclude that there results support the hypothesis.\n\nI like that the authors trained on CHILDES and used BabyBERTa. The recognize that RoBERTa, which trained on orders of magnitude more data than a learner would receive by age 2-3 may overachieve for that reason. 2yo-BabyBERTa seems unecessary to me. BabyBERTa was trained on 5M words, but that's just a large fraction of what an individual learner would hear. It seems unnecessary to restrict it further.\n\nI'm worried about the posibility of test-on-train here. Isn't 5M words pretty much all of English CHILDES? Can the authors be sure that BabyBERTa (or even RoBERTa? I don't know) weren't trained on the subset of CHILDES that they're testing on?\n\nThe authors report results on a held out (but see above) test set and a set of sentences with nonce verbs. They find very good (.90-.92 accuracy) on the held out set, and middling performance (0.48-0.59) on the nonce set.\n\nI don't believe the author's conclusion is motivated for two reasons:\n\nFirst, they argue based on the results on the held-out test set, that since the transformers learn to distinguish tenses well, that this shows that language input alone is sufficient. However, they could've come to the opposite conclusion based on the nonce study. A contrarian could easily conclude language alone is insufficient.\n\nSecond, and I think more profoundly, is that there's no particular reason to believe that transformers are good models of human learning. The authors rightly acknowledge this: \"Although the transformer models do not represent children\u2019s acquisition mechanisms, we hope this study could provide some insight in understanding the acquisition process of tense.\"\n\nSo we can't conclude anything about acquisition from this study, other than, perhaps, that training on a big chunk of CHILDES works almost as well as training on 30B tokens of miscellaneous text for this purpose.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_UzZu"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper25/Reviewer_UzZu"]}]}, {"paper_url": "https://openreview.net/forum?id=H_u4_mYxL-c", "paper_id": "H_u4_mYxL-c", "reviews": [{"id": "BCelhH5NAMc", "original": null, "number": 3, "cdate": 1648409156313, "mdate": null, "ddate": null, "tcdate": 1648409156313, "tmdate": 1648409301049, "tddate": null, "forum": "H_u4_mYxL-c", "replyto": "H_u4_mYxL-c", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper24/-/Official_Review", "content": {"title": "Difficult to confirm the conclusions since key details of the model setup and evaluation are missing", "review": "This paper proposes a cue-based retrieval model for a really interesting pronoun resolution phenomenon in German: The distinction in reference preferences between personal vs. demonstrative pronouns, depending on different aspects contributing to a referent\u2019s saliency. Contributing factors to a referent\u2019s saliency that are considered include subjecthood, agenthood and order of mention, which are fleshed out in terms of (weighted) cue prominence in the new models proposed. The authors show that a model with these additional weighted prominence cues is able to account for key empirical patterns in human data found by Schumacher et al. (2006), as defined in Effects 1-3 in the paper.\n\n**General**\n\nThe paper is well-written and provides a great overview of the phenomenon of interest and motivation for the modeling work that is its main contribution. The models seem (mostly) straightforward; however, key information about the model and evaluation methodology and are omitted, which leave the conclusions the authors want to draw unwarranted (for now).\n\n**Specific questions/Comments**\n\n* A key component missing in the paper is a well-defined model evaluation metric. For example, looking at Table 2, we see that Models 2 & 3a severely overestimate condition a., underestimate b., and are about in the right ballpark for conditions c. & d. Yet, Model 3a is claimed to capture the relevant variance in the human data. What are the variances for the conditions in the human data? What is the variance in the model results? Do they align? The way it reads now is a qualitative comparison of proportions where an Effect is captured if the target referent is chosen more than 50% of the times, disregarding differences in preferences between conditions in the human data, which seems unsatisfactory.\n* Relatedly, is there a particular reason why there is no effect described that relates to the AA-NC condition? The baseline model seems to be closest, quantitatively & qualitatively speaking, to the human data here, whereas both other models underestimate the proportion. So *is* the baseline model capturing some crucial variance in the data that the other models are not?\n\n* Again relatedly, is a unanimous preference for the second referent expected for the baseline model given that the retrieval cues are always consistent with both referents (provided I understand this correctly)? Shouldn\u2019t the model perform at chance? Clarifying the model description and training regime would be helpful for this I believe.\n* \u201cIn the modified model we weighted the retrieval cue of thematic role 1.5 times higher than other cues used to retrieve the antecedent\u201d. Is it true that the thematic role cue is weighted 1.5 times higher than the baseline model cues as well, or only higher than other prominence-inducing cues (grammatical role/ order of mention)? The former seems counter-intuitive as grammatical features should provide a stronger bias for pronoun resolution than thematic roles. If my interpretation is correct, it would be good to add empirical evidence for this effect, as I don\u2019t think this is concluded by Schumacher et al. (2016), which is their reference.\n\n**Thoughts regarding future extensions to the modeling work (do not need to be included in the paper!)**\n\n* As it stands the paper assumes a complementary distribution between personal pronouns *er/sie/es* and demonstrative pronouns *der/die/das*. I wonder how other demonstrative pronouns like *dieser, jener, derjenige* will figure into this constellation?\n* Furthermore, given the way in which the models for PPros and DPros are set up, I wonder how this approach will extend to contexts in which there are more than two referents in the context? (cf. Patterson & Schumacher 2021)\n\n**Minor**\n\n* For reader orientation, it would be good to spell out the critical effects in terms of predictions that clearly relate to the human data in Table 2. I.e., Effect 1: P(first referent|AA-CA, PPro) > P(second referent|AA-CA, PPro)\n\nOverall, this paper takes a cool approach to modeling an interesting phenomenon, but given the lack of detail in the model description and evaluation, the conclusions it draws do not seem sufficiently supported.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_ahUb"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_ahUb"]}, {"id": "Sgl6tAzAMq", "original": null, "number": 2, "cdate": 1648402053071, "mdate": 1648402053071, "ddate": null, "tcdate": 1648402053071, "tmdate": 1648402053071, "tddate": null, "forum": "H_u4_mYxL-c", "replyto": "H_u4_mYxL-c", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper24/-/Official_Review", "content": {"title": "Some critical details missing in the current submission", "review": "\nThe paper describes an approach to model personal and demonstrating pronoun resolution using the ACT-R cue-based theory. The authors compare the baseline model with 3 models that differ in terms of use of prominence features (thematic role, grammatical role, order of mention) as retrieval cues and weights assigned to these cues. The results show that the models with weighted cues perform best in capturing pronoun resolution patterns found in the human data. The model for the personal pronoun resolution captures all the 3 effects, while the model for the demonstrative pronoun resolution captures 2 out of 3 effects. The weighted cues model outperforms the baseline and prominence (but no weights) models.\n\nI found the paper to be well motivated as well as well written. However one key issue with the paper is that the claims are unsubstantiated, i.e., not enough details are provided regarding the methodology and evaluation. For example, we don't know if the difference in percentages found in the human data significantly different? Similarly, the authors claim that the models 2 and 3a/3b are able to capture various effects, e.g., \"The model captured Effect-1 and Effect-2 for the PPro: ...\" what is the basis of saying this? Is it based on the fact that the differences in the percentages found in the human data and the models are qualitatively similar or was there some objective way of testing this similarity? On similar lines, the authors state that \"Model predictions are generated by running 10000 simulations for each model\" and \"The antecedent preferences of the model are determined by calculating proportions of referents retrieved across all simulations\". This evaluation criterion is not backed by a rationale, for example, to make the prediction of the model more comparable with the experiment, shouldn't the model be evaluated on the same number of items that the humans were exposed to? and then to take correct proportion of PPro/DPro from them? \n\nIn sum, this is a good work, but I am unable to evaluate it with confidence given the lack of information regarding some critical issues related to methodology and evaluation.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_SofH"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_SofH"]}, {"id": "BY8xoGa23f9", "original": null, "number": 1, "cdate": 1648311570843, "mdate": 1648311570843, "ddate": null, "tcdate": 1648311570843, "tmdate": 1648311570843, "tddate": null, "forum": "H_u4_mYxL-c", "replyto": "H_u4_mYxL-c", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper24/-/Official_Review", "content": {"title": "It is difficult to find clear evidences from this short paper supporting the initial claim. ", "review": "This paper addresses the question of pronoun reference focusing on personal and demonstrative pronouns in German. It proposes different models and study more specifically the question of prominence, showing the interest in adding this constraint in predictive model. The paper addresses an interesting question and proposes different models for studying the problem. However, it suffers from lack of details  in the description of the models, the  evaluation of the results and the discussion. It is difficult to find clear evidences from this short paper supporting the initial claim. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_oGD6"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper24/Reviewer_oGD6"]}]}, {"paper_url": "https://openreview.net/forum?id=ruOUP7FxLbc", "paper_id": "ruOUP7FxLbc", "reviews": [{"id": "SzMg8YXrjzq", "original": null, "number": 3, "cdate": 1648214909932, "mdate": 1648214909932, "ddate": null, "tcdate": 1648214909932, "tmdate": 1648214909932, "tddate": null, "forum": "ruOUP7FxLbc", "replyto": "ruOUP7FxLbc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper21/-/Official_Review", "content": {"title": "Good paper but I wish there were more explanations about the goal", "review": "This paper explores the effectiveness of a small RNN when learning a phenomenon of vowel harmony. I guess it's assumed that if a smaller neural network could do the job as well as a larger model, the smaller model is a better choice than the larger one. But still, I wish the authors had explained in more concrete terms what are the benefits of a small RNN. Also, the current phenomenon under investigation is vowel harmony. Would the model results be very different if it is working on a different phenomenon of complex pattern recognition? Is the design of the current model informed by morphophonological conditions of vowel harmony in any way?", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_8gan"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_8gan"]}, {"id": "r9IxZwMqabq", "original": null, "number": 2, "cdate": 1647317592993, "mdate": 1647317592993, "ddate": null, "tcdate": 1647317592993, "tmdate": 1647317592993, "tddate": null, "forum": "ruOUP7FxLbc", "replyto": "ruOUP7FxLbc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper21/-/Official_Review", "content": {"title": "Nice paper on an understudied phenomenon, but lots of morphophonological assumptions are implicitly built into the model", "review": "Seems like a nice and well-motivated study, and I appreciate the authors' effort to look into modeling a linguistic phenomenon that is relatively understudied despite being typologically common.\n\nI am a bit unsure what to make of the claims about the model doing well based on a small RNN, because no matter how small you make the model, there is still a lot of morphophonological knowledge implicitly built in to the very assumptions of the model (e.g. Marantz, 2013 [doi: 10.1080/01690965.2013.779385]).", "rating": "6: Marginally above acceptance threshold", "confidence": "1: The reviewer's evaluation is an educated guess"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_XYm7"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_XYm7"]}, {"id": "HlxubaytWc", "original": null, "number": 1, "cdate": 1647013120333, "mdate": 1647013120333, "ddate": null, "tcdate": 1647013120333, "tmdate": 1647013120333, "tddate": null, "forum": "ruOUP7FxLbc", "replyto": "ruOUP7FxLbc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper21/-/Official_Review", "content": {"title": "Promising first exploratory step", "review": "The authors explore whether small-scale neural networks learn vowel harmony. I am not familiar with the precise literature on modeling phonology using deep learning (so I cannot evaluate the novelty), but the task is straightforward and the phenomenon/task is simple.\n\nI believe this is a nice first exploratory step. For this effort to contribute to the literature, more work needs to be done.\n\n-The authors use a relatively large RNN model originally designed to account for past-tense morphology and scale it down to learn vowel harmony. I don't think we can draw a conclusion from this work as we are comparing apples and oranges.\n\n-The authors show that a model can map some lemmas to their inflections, it's not clear to me what cognitive insight we get from these results? Is the idea to show that humans (babies) learn vowel harmony from distributional information? in which case, does the model reproduce some patterns in children's development?\n\n-There is no quantitative test of vowel harmony, no comparison to previous work?\n\n-The authors select two languages from SIG-MORPHON Shared Task without justifying why these two languages? is it because of their morphological complexity or their typological difference? How does the model behave in the other languages? It is a very simple task and more data is available (about 100 languages in the SIG-MORPHON Shared Task), and I don't see a reason why limit the study to two languages?\n\n-The authors should do a thorough/quantitative investigation of separation between front and back vowels (because that's the latent representation of interest) and not just a qualitative visualization. Also, strangely, the authors do not show results in Turkish to verify if the latent separation exists in Turkish as well.\n\n-No abstract?", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_A28a"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper21/Reviewer_A28a"]}]}, {"paper_url": "https://openreview.net/forum?id=BMMeDmKg8Zc", "paper_id": "BMMeDmKg8Zc", "reviews": [{"id": "rCelwiw1J7c", "original": null, "number": 3, "cdate": 1648453534883, "mdate": 1648453534883, "ddate": null, "tcdate": 1648453534883, "tmdate": 1648453534883, "tddate": null, "forum": "BMMeDmKg8Zc", "replyto": "BMMeDmKg8Zc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper15/-/Official_Review", "content": {"title": "Hard to identify the main messages the authors want to convey", "review": "There's something potentially of interest here but this version of the paper feels very disjointed. It is hard to identify the key thread of ideas that the authors intend to be the main take-home message, and it is hard to understand the logical links between various sections of the paper.\n\nPerhaps the key concrete point that I can identify is that classifiers tend to change from narrowly-applicable to more general over historical time, and the model presented in section 4 correctly recreates this effect. This is the most meaningful common thread I can find running through the paper. The empirical point about the historical change is buried in the middle of section 2 (lines 174-183) in amongst discussion of all sorts of other things, and the fact that the simulations recreate this pattern is mentioned (lines 468-473) as one of three findings in section 4.2. (Even this would be clearer if the authors explicitly mentioned that more features means more specific. And at line 460, it should be stated explicitly that the graphs show the average number of features *per classifier*.) In between, there's very little to help the reader connect the dots: for example, the intro to section 4 says nothing about what kind of patterns the authors are hoping to recreate (only that they will \"investigate the dynamics of classifier systems over time\").\n\nThe logic of the relationship between section 3 and section 4 seems muddled. In section 3 itself, the corpus study is presented as evidence *against* the non-neutral, ambiguity-avoidance hypothesis, and this is presented as justification for adopting a model without functional pressures in section 4. But the abstract, for example, says that \"acquisition without reference to ambiguity avoidance is *sufficient* to drive broad trends\", which makes it sound like the paper will be treating the neutral hypothesis as the simpler/null hypothesis and showing that additional assumptions (i.e. non-neutrality) are unnecessary. So there's a confusing inconsistency in the way the authors talk about which hypothesis (neutral or non-neutral) is the one that makes \"additional assumptions\".\n\nThere's a lot of material in section 2 which seems to be irrelevant: differences between classifiers and noun classes, age at which children exhibit competent use, semantic vs. arbitrary. All of this leaves the reader thinking that maybe some of these empirical facts will be things that the authors end up offering an explanation for, but as far as I can tell most of it plays no role. This includes the fact that the timecourse of a single child's acquisition demonstrates a move towards over-use of general classifiers; I don't understand how the simulations have any connection to that. (I'm still confused after lines 532-536.)\n\nIn section 3, I think I understand the important take-home message of the corpus study itself, but the presentation is somewhat confusing at times.\n\t- The logic at lines 244-248 seems slightly wrong. The preceding paragraph already established a candidate cause of greater homophony in Mandarin than Cantonese. Given this, if it's *also* true that homophony avoidance drives change, then we'd expect more classifier disambiguation in Mandarin than in Cantonese. The phrasing in the paper seems to suggest that the homophony avoidance hypothesis plays a part in predicting the increased ambiguity in Mandarin.\n\t- As far as I can tell, the terms \"homophony\" and \"ambiguity\" are used more or less interchangeably. This isn't necessarily incorrect, but the logic could be clearer if the authors stuck to just one term.\n\t- Similarly, the phrase \"homophony avoidance\" is somewhat confusing. As defined by the authors (line 266), the degree of homophony is just determined by the particular collection of form-transcription pairs that occur in the corpus. (It might also help to note that the transcription effectively determines the pronunciation.) So there's no way for classifier usage to \"avoid\" homophony. So something like \"homophony mitigation\" or \"homophony circumvention\" would be better than \"homophony avoidance\". (Perhaps the authors intended to distinguish between *homophony* and *ambiguity avoidance*, which would make sense, but the usage doesn't seem to be consistently in line with that.)\n\t- It might help to mention that matching on types means matching on *character* types, not *transcription* types.\n\t- In Table 1, why is the number of types for Mandarin_type not exactly 1182?\n\nIt's (mostly) unclear what the authors really want the reader to take away from the presentation of the results in section 4. They mention three findings (lines 456), but only one is clear the me: the one about moving towards generality, in the paragraph beginning at line 464. The second finding is something about the fact that the simulations tend to reach steady states (476-488), but I can't find any mention of what empirical point this is intended to align with. The last paragraph (489-501) seems to be framed as the third finding, but again this just seems to be a report of how certain simulations turned out, rather than an identifiable trend that meaningful aligns with an empirical target. A few lines later this is all just summarized as \"provides insight into the long-term dynamics of classifier systems\" (507), but the authors don't even seem to be trying to express what that insight is.\n\nThe opposition between \"input\" and \"functional factors\" (line 219) seems like a category error to me. Certainly there is always a tension between the input and generalization in any form of learning; but then the question of what role functional factors play is a question about the nature of the generalization that occurs, not the balance between input and generalization. I had a similar reaction around lines 506: would a proponent of functional pressures say that their account is not \"acquisition-driven\"? The idea that acquisition drives change (which is virtually a truism) seems orthogonal to the question about functional pressures.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_eXxh"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_eXxh"]}, {"id": "HqUli4lv0G5", "original": null, "number": 2, "cdate": 1648418867356, "mdate": 1648418867356, "ddate": null, "tcdate": 1648418867356, "tmdate": 1648418867356, "tddate": null, "forum": "BMMeDmKg8Zc", "replyto": "BMMeDmKg8Zc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper15/-/Official_Review", "content": {"title": "Analyzing and simulating the acquisition of noun classifiers over generations", "review": "This paper analyzes classifier systems that categorize nouns in Mandarin and Cantonese child-directed speech and in light of the findings of this analysis, proposes a population-based model of classifier acquisition and change over time. Models with various setups produce classifiers that are more generalized with fewer features as the simulation progresses, seeming to indicate a neutral learning scheme based on inputs rather than functional factors.\n\n**Pros**\n\nThe authors explore various setups of simulations and an interesting set of results are reported, providing insightful information regarding possible theories of the evolution of classifiers.\n\nThe authors motivate their population-based transmission simulation with findings from the analysis of actual human data and also relevant developmental literature, focusing on neutral learning from input.\n\nThe simulation results point to an inclination toward the production of generalized classifiers, seeming to confirm the authors\u2019 motivation behind the implementation of these models.\n\n**Cons**\n\nI was confused by the significance findings reported in footnote 2. Even though for the types, the difference is insignificant, for the tokens, Mandarin has more disambiguated homophones. Then, in Section 5, it is written that Mandarin classifiers disambiguate homophones significantly less often, which I thought was more in line with what was reported in Table 1. It would be nice if the authors clarify what numbers were exactly being contrasted in these tests to provide a stronger motivation for their choice of simulation model. \n\nThe simulation models seem to be rather independent of the child-directed speech data, apart from the idea of neutral learning. It would be informative to contrast these models with a model that follows functional objectives or models that include noun attributes and classifier features akin to the ones observed in real human data. \n\n**Writing**\n\n004 amiguity -> ambiguity\n\n031 Remove 'encode'\n\n032 concretely -> concreteness (?)\n\n063 'during the' repeated\n\n105 are -> our (?)\n\n119 is -> has\n\n130 concretely -> concreteness (?)\n\n286 'the' repeated\n\n604 variability\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_8g4d"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_8g4d"]}, {"id": "SxlmRGd3zc", "original": null, "number": 1, "cdate": 1648292554659, "mdate": 1648292554659, "ddate": null, "tcdate": 1648292554659, "tmdate": 1648292554659, "tddate": null, "forum": "BMMeDmKg8Zc", "replyto": "BMMeDmKg8Zc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper15/-/Official_Review", "content": {"title": "An interesting study on modeling the acquisition of classifier systems, though not so much on modeling language change.", "review": "This paper shows two sets of experiments in an attempt to explicitly model change in classifier systems as some outcome of child language acquisition. The topic is interesting, and the paper includes several interesting ideas, and has great suggestions about future work. However, there are some parts that are not clear to me. While it assumes that language acquisition may drive trends in classifier patterns over time, what the changes are have not been clearly defined. For example, in the introduction, the authors mentioned the replacement of the general classifier 'mei' with the currently more dominantly-used 'ge' over time; while this indeed is an interesting point of inquiry, the studies presented in the paper were not able to address this type of change. Alos, is adults' using more specific classifiers while dropping the general classifiers considered \"a change\"? If yes, this point should be elaborated. The authors mentioned that such selections may be related to discourses, or due to sociolinguistic factors, but the experiment results only show that children tend to acquire the (old or new) uses of classifiers presented by adults, and then stabilize the use of them, and therefore although I agree with the authors that the results support the trends of learning and neutral processes, they do not seem to be related to language change. \n\nBelow are some minor suggestions about the organization and the contents. \n1. Introduction: Need to reconsider what role the example of 'mei'-'ge' plays in the paper.\n2. Section 2 can directly highlight how similar classifier systems and inflectional agreement systems are in terms of modeling, and then elaborate how the classifier system can be modeled. Currently, the first half of the section suggests the otherwise (i.e., they are very different grammatical properties).\n3. The differences between classifiers and measure words do not seem to be relevant to the current study. Maybe using classifiers as a cover term would be enough.\n4. Mandarin 'ge' although is a general classifier, it functions as an individualizer (i.e., its function is to pick out one individual entity in particular); the description of it at the beginning of the paper is a bit misleading. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_t543"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper15/Reviewer_t543"]}]}, {"paper_url": "https://openreview.net/forum?id=B_OII7tlIZ5", "paper_id": "B_OII7tlIZ5", "reviews": [{"id": "rclDhfW2zq", "original": null, "number": 3, "cdate": 1648263854762, "mdate": 1648263854762, "ddate": null, "tcdate": 1648263854762, "tmdate": 1648263854762, "tddate": null, "forum": "B_OII7tlIZ5", "replyto": "B_OII7tlIZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper14/-/Official_Review", "content": {"title": "Neural language models predict hireability", "review": "This paper reports an investigation of how neural language models can be used to judge a candidate's \"hireability\" and other traits from transcripts of job interviews and writing samples (E1) and prosodic information (E2). They find that embeddings derived from linguistic information alone can outperform the feature-engineered baseline model from previous work which included features for prosody, eye movements, etc. Adding prosodic features results in some performance improvement, but not for the model which already had the highest correlation with human ratings on its own (word2vec).\n\nOVERALL\n\nThis is an interesting set of studies, however, I'm not sure that CMCL is the best venue for it. The primary take-away seems to be that neural language models could be used to aid in the process of evaluating candidates, but it's not at all clear what the cognitive/linguistic implications are. If the goal is primarily application, the authors should discuss the important limitations of using these kinds of algorithms to make decisions that impact people's lives, given the well-known biases that they tend to reflect. If the goal is to draw some conclusions about cognition, the link needs to be made much more clear in the framing. \n\n\nMINOR \n\nThe main conclusion suggests that NLMs can be useful for candidate trait evaluation but in fact the evidence presented here only shows that the 4 models highlighted in the main text provide any advantage. It's unclear how many of the model variants actually outperform the baseline. It appears that only a few best-performing ones are statistically compared to the baseline, so the conclusion becomes even more narrow. Again, this would be fine if the goals are about engineering a model that predicts well but unclear what to make of this in terms of cognitive interpretations.\n\nIt seems like the choice to only use prosody in addition to embeddings could be better motivated. I am not familiar with the original work (Naim et al., 2018) but it seems like the lack of performance improvement due to facial features in those models doesn't preclude that they could explain meaningful variance in the current models, when paired with a different set of predictors.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_WANP"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_WANP"]}, {"id": "HVeeTjFVsG5", "original": null, "number": 2, "cdate": 1648212388659, "mdate": 1648212388659, "ddate": null, "tcdate": 1648212388659, "tmdate": 1648212388659, "tddate": null, "forum": "B_OII7tlIZ5", "replyto": "B_OII7tlIZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper14/-/Official_Review", "content": {"title": "Predicting hireability from interview transcripts", "review": "The authors set out to demonstrate that behavioral/personality traits that are deemed relevant for job interview scoring can be predicted on the basis of neural representations of paragraphs of interview transcripts. They compare against a baseline model using hand-crafted features and show that neural representations (static e.g. word2vec and contextual i.e. BERT, also augmented with prosodic information) significantly outperform the baseline. It's somewhat surprising to see this submitted to CMCL, as there is no clear cognitive modeling component to the paper.\n\nIt is interesting and unexpected (to this reader) that simple word2vec representations were effectively the best performing representations. I suggest this has more to do with the human raters from whom target scores were obtained (about whom we get no information, e.g. were they trained human resources professionals?) than with the authors' suggestions that prosodic cues are only leveraged when insufficient linguistic cues are available.\n\nI have serious concerns with the ethical implications of this work, especially in light of the fact that ethical considerations are not discussed at all. Technology like this has a very real potential to be misused, but more concerningly often proves discriminatory even when used without nefarious intent. There is a growing literature on the disparate impacts of technology used to assess personal/behavioral traits across demographics. At the very least these concerns need to be addressed in depth in order for a paper like this to be accepted (even setting aside the question of fit for CMCL).", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_9nkW"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_9nkW"]}, {"id": "rWExVFu2wGq", "original": null, "number": 1, "cdate": 1647982715880, "mdate": 1647982715880, "ddate": null, "tcdate": 1647982715880, "tmdate": 1647982715880, "tddate": null, "forum": "B_OII7tlIZ5", "replyto": "B_OII7tlIZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper14/-/Official_Review", "content": {"title": "Text prediction of hireability", "review": "This paper describes text-based systems for predicting various qualities related to job interview performance. Systems using word2vec and BERT can outperform traditional feature-based classifiers using small feature sets like LIWC and some basic computer vision applied to interview video. Some scores (including whether the interview candidate smiled) are actually better predicted from text than video. Where differences between w2v and BERT exist, w2v is generally better; the gap can potentially be closed by using prosody.\n\nThe work's main strengths are the somewhat surprising fact that some non-textual scores can be predicted from text and the significant improvement over previous work.\n\nI see two main weaknesses: fit with CMCL and misgivings about the paper's impact.\n\nWith regard to fit, there is relatively little in this paper that seems cognitive or psychological. The most significant psychological point made is that \"when not enough linguistic cues are available at the lexical-semantic level, additional extra-linguistic materials are required to successfully process the information provided\", but the argument for this is that prosody improves the weaker BERT classifier more than the strong w2v classifier. Adding extra features generally improves weak classifiers more than strong ones. Moreover, the analysis in the paper does not single out instances where \"not enough linguistic cues are provided\", but rather ones where the classifier is not making good use of the cues it already has. (As an additional point, failure to find significance should not be considered as an indicator that the effect does not exist, particularly when the models have different variances--- lines 237-244.)\n\nWith regard to impact, automated systems for hiring are an ethical minefield (with Amazon's famously sexist hiring tool frequently cited as an example of what not to do). This paper does not consider potential ethical issues resulting from real-world deployment of this technology. Some things that would have to be considered are: the paper makes predictions about qualities such as smiling and speech rate from text which *must be* purely correlational. Such indicators cannot be reported to a decision-maker without explaining that they are imputed without reference to the actual phenomena they claim to be measuring. The paper does not evaluate bias on the basis of demographic characteristics in the classifier output. The current system outperforms the baseline on most of the individual personality factors but not on overall hireability, leading to questions about the validity of this judgment in the first place. While these questions are probably beyond the scope of this work, the paper should include a clear statement that this system cannot be deployed for any practical purpose and a citation to the ethics literature to explain why.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_TVRN"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper14/Reviewer_TVRN"]}]}, {"paper_url": "https://openreview.net/forum?id=HpPE8mKeIZc", "paper_id": "HpPE8mKeIZc", "reviews": [{"id": "HN2x1T9PvM9", "original": null, "number": 3, "cdate": 1647962807225, "mdate": 1647962807225, "ddate": null, "tcdate": 1647962807225, "tmdate": 1647962807225, "tddate": null, "forum": "HpPE8mKeIZc", "replyto": "HpPE8mKeIZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper10/-/Official_Review", "content": {"title": "The rediscovery of syntactic structure", "review": "This paper puts forward what I imagine is intended as a novel model of syntactic structure for natural language, which allows uniformities across languages to be straightforwardly characterized via a single underlying (declarative) structure. The paper then goes on to argue that this model could be used as the basis for an MT system. \n\nMuch as I am sympathetic to the importance of abstract structure in characterizing natural language syntax and in deriving underlying meaning, the current paper does not advance our state of understanding of this area. The proposed theory comes across as a rehashing of existing ideas that have popped up repeatedly in the history of grammatical description. The synapper structures for noun phrases look very much like dependency trees. The proposal for interrogatives in section 4.3 recalls Zelig Harris's idea that non-canonical sentence types need to be transformed into a \"normal form\".  The idea that structures can exhibit ambiguity goes back to Chomsky's earlier arguments (in \"Syntactic Structures\"). And the proposal that syntactic structure should allow recursive embedding has a similarly long history.  The one novel contribution concerns the cyclic character of word order patterns, and the division into clockwise and counter-clockwise languages. This is a novel idea, so far as I am aware (though one could imagine deriving this distinction from the approach to word order explored by R. Kayne in his \"Antisymmetry of Syntax\" book). This idea would be more compelling if it could be shown that the distinction between these two classes of languages correlated with some other property. Otherwise, it comes across as merely taxonomic. \n\nThe paper's discussion of MT is even weaker. After a detailed recounting of the performance of existing systems on the translation of a single Korean sentence into English, the paper puts forward what would be the translation of the same sentence derived from the current approach. The problem is, as far as I can tell, there is no implemented system. And in carrying out this translation, the paper permits arbitrary changes to be made in service of producing the translation (e.g. lines 596-600). Saying what the answer *would* be if such a system existed will not be convincing at all to readers with any appreciation of the complexity of building MT systems. While I don't think that NLP progress should be held hostage to performance on benchmark datasets, as incremental advances won't necessarily lead to fundamental progress, the bar for progress is higher than what is done here. \n\nFinally, the paper presents this structure-based approach to MT as though it is a novel contribution. However, the idea that translation should be done via a mapping between a cross-linguistically uniform underlying structure is a well-studied one, called either syntactic transfer or interlingua, depending on the abstraction of the analysis.  For more recent syntactic-transfer approaches, see the discussion in Williams, Sennrich, Post, and Koehn's book on Syntax-Based Statistical Machine Translation. And it would be worth paying attention to the many well-studied cases of structural divergence, where the mapping from the structure of one language to the structure of another is far from isomorphism, since they will pose problems for the approach proposed in this paper. (For an old, but still useful discussion, see B. Dorr's 1994 Computational Linguistics paper \"Machine Translation Divergences: A Formal Description and Proposed Solution\", but there's lots of work since then on this topic.)  I should also point out that much of the debate on per-NN syntax-based MT models concerned how to best represent the mapping between languages so as to best accommodate the divergences that exist.", "rating": "1: Trivial or wrong", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_DEGb"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_DEGb"]}, {"id": "BdZxXScrSM5", "original": null, "number": 2, "cdate": 1647823419409, "mdate": 1647823419409, "ddate": null, "tcdate": 1647823419409, "tmdate": 1647823419409, "tddate": null, "forum": "HpPE8mKeIZc", "replyto": "HpPE8mKeIZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper10/-/Official_Review", "content": {"title": "An unclear approach to \"Machine Translation\" via cyclic graphs", "review": "I like to believe I always try to write constructive reviews, but I have to say that reading this paper was a puzzling experience.\nAs it is written, the paper lacks any depth in its relation to the vast variety of literatures the authors seems to want to connect to. \nWhat is the paper about? Left to the introduction alone, one would first think it a critique of constituency-based approaches to syntactic structure. Then it seems to be about how purely syntactic approaches are unnecessary for the task of machine translation, then it becomes a critique of Probabilistic models (in general. Any model whose output is probabilistic is unfit for machine translation according to the authors).\n\nThe paper  introduces a representation of sentences in the forms of unlabelled, cyclic graphs: a curious chimera of constituency structure, dependency trees, and a hint to lexical-functional graphs --- that has none of the formal advantages of these existing approaches, while attempting to capture the same information. The authors claim this \"new\" representation is better for Machine Translation broadly defined, but there is no evidence of this from a quantitative nor qualitative perspective.\n\nContent issues aside, the paper is just not thematically fit for CMCL. To clarify, I do think that there are many different ways to do \u201ccomputational modeling\u201d, and that a purely formal approach can be plenty \u201ccomputational\u201d. However, there is no modeling in here in any possible interpretation of the term, nor there is a computational contribution beyond the trivial existence of graphs (in fact, this is stated explicitly in the abstract!), nor there is anything resembling a \u201ccognitive\u201d topic. \n\n\n## Specific Comments\n\nLack of focus aside, the paper makes an astounding number of unsupported claims (basically, one per paragraph), which are at best trivial and often plainly wrong. I address some of the broader ones in what follows to exemplify how the paper is completely disconnected from current work in linguistics and computational linguistics.\n\n- The first part of the introduction seems to take issue with how constituency based approaches deal with the mapping between syntactic variation and semantic interpretation. While of course there are plenty of approaches that argue for a tighter relation between syntax and semantics, it is a strong claim that similarly interpreted sentences cross-linguistically should map to the same syntactic structure. Additionally, this shows a misunderstanding of what standard constituency approaches do --- that is exactly to give identical syntactic structures to the same grammatical relations across languages, modulo what the authors seem to care about most, *head directionality*. Even putting these two points aside, the issue of semantic representations across languages is one the paper never goes back to. In fact, the papers end up adopting a representation (in the form of cyclic undirected graphs) that has NO explicit encoding of basic grammatical dependencies.\n\n- On the same page, the authors go ahead to claim *No one has yet been able to demonstrate how such a process can take place 6almost instantaneously in the human brain.*\n\n    *Such a process* here being the process of establishing grammatical relations between words. Now, putting aside the decades of psycholinguistic work on parsing across a variety of syntactic frameworks that the authors seem to think not relevant, this is once again a point the paper never goes back to. Again, the \u201cformalism \u201d adopted by the paper is then a form of cyclic graph  which the authors never bother to formally introduce. How are these graphs derived from sentences?\n\n- We then get to what seems to be the main focus on the contribution: an improved machine translation model. Apart from not defining the scope of the problem at all, there is no attempt to contextualize the contribution with respect to the existing literature in the subfield --- apart from a few random references to transformers models. In fact, given how focused the intro is on syntactic representations, it is puzzling how the paper completely ignores the vast literature on how syntactic information (be if from constituency or dependency trees or both) has been incorporate in MT approaches of different kind.\n\n- They also state that \u201cprobabilistic\u201d approaches are problematic because they do not lead to a 100% accuracy \u2014 which I take to mean a 1-t-1 correspondence between two sentences in two different languages \u2014 which is of course a puzzling statement by itself given that contextual translation is never 1-to-1 even when done by human annotators.\n\n- The rest of the paper becomes even harder to follow. The method section presents a \u201cdecomposition\u201d of sentences based on S, V, O elements, which basically reintroduces constituency/dependency structures, again sprinkled with a variety of unsubstantiated claims.\n\n    Crucially, their \u201cmodel\u201d is not, in fact, a model. There is no attempt to explain the properties of their representations, how the system is supposed to work theoretically, how it would handle things like modifiers alternation, and within language word order variation. The authors seem to believe this \"multidimensional\" approach to be somehow simpler that constituency/dependency trees, while of course formally it is far from being simple (and putting aside the fact that hierarchical representations are trivially multidimensional).\n\n- There is also a puzzling section about \u201cambiguity\u201d which is not about ambiguity at all. Their non-ambiguous examples aside, the authors quickly claim that lexical ambiguity can be dealt with within their \u201cframework\u201d (I use the term loosely) but do not even mention crucial cases of syntactic ambiguity?\n\n- Additionally, it was truly unclear to me how to interpret the \u201cComparison of MT Models\u201d section, as there is no comparison (unless we think extrapolating one paragraph from Google Translate counts as a comparison). Reading this section made it seem like the authors believe that translating a sentence can truly be reduced to the task of one to one translation of words (dismissed as an easy trick itself) and picking a point to start from in their graph.\n\n\n", "rating": "1: Trivial or wrong", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_MJq5"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_MJq5"]}, {"id": "rddl_MtnEGq", "original": null, "number": 1, "cdate": 1647786255815, "mdate": 1647786255815, "ddate": null, "tcdate": 1647786255815, "tmdate": 1647786255815, "tddate": null, "forum": "HpPE8mKeIZc", "replyto": "HpPE8mKeIZc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper10/-/Official_Review", "content": {"title": "A bizarre submission", "review": "The paper is too general, too vague and full of statements that are not supported by references, experiments or even a rigorous case study. Closer to central theme of the paper, the denouncement that applications of syntax trees have been very limited in scope, with the exception of UD ignores a rich tradition of computational linguistics and NLP research. Even if we limit our scope to the field of MT, there are a number of studies that explicitly use syntactic parsing as part of their modeling which is not mentioned (let alone compared to) in this paper.\n\nThere are numerous misconceptions in this work, the two most pressing ones being the idea that there is such a thing as \"100% accurate translation\" (ignoring the fact that translation is highly subjective and even human expert translations can produce more than one perfectly valid translation), and that matching syntactic structures across languages is sufficient (or even necessary) for a faithful translation.\n\nFinally (albeit less critical than it should be) there is the point that the paper is neither computational nor modeling (both of which are part of the workshop's name).", "rating": "1: Trivial or wrong", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_3nkC"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper10/Reviewer_3nkC"]}]}, {"paper_url": "https://openreview.net/forum?id=rpPGIQtxI-q", "paper_id": "rpPGIQtxI-q", "reviews": [{"id": "rK8xW55nhfc", "original": null, "number": 3, "cdate": 1648310921327, "mdate": 1648310921327, "ddate": null, "tcdate": 1648310921327, "tmdate": 1648310921327, "tddate": null, "forum": "rpPGIQtxI-q", "replyto": "rpPGIQtxI-q", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper9/-/Official_Review", "content": {"title": "Not enough discussion", "review": "This paper adresses the question of left-corner parsing and the cognitive motivation of reinforcement learning approaches to this problem. The paper first recalls the main aspects of the LC parsing technique and provides  examples. This first part is very pedagogical, but could be reduced and leave place for the core of the paper. The paper then describes the experiment by presenting first what authors call the environment setup. The idea consists in extracting from the PTB several trees and analyze the behavior of a parser. At each step, depending on the action selected by the parser, a penalty is associated with the state. The experiment itself consists in studying the behavior of 15 reinforcement learning algorithms, applied to a subset of trees chosen for their simplified structures (reduced depth, all starting with an NP-subject). A description of the main characteristics of each RL technique is given, and a  summary of the results with a short discussion is proposed. \n\nThe paper presents an interesting and important idea, proposing a method and some results in the perspective of arguing in favor of a cognitive ground for RL algorithms. However, it suffers from several drawback. First, the method for selecting the penalty is not well motivated, and looks arbitrary. The same for the proposed evaluation metrics, that are very basic. But the main problem of the paper is that it fails at providing any evidence in favor of a cognitive motivation. There is no precise analysis of the core of  RL mechanisms that should be arguments in favor of that. The paper only gives a set of results, with no precise discussion and no conclusion. At this stage, even though the idea is interesting, it seems to me not elaborated enough to be presented at CMCL. ", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_BjvH"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_BjvH"]}, {"id": "Bb4lFrPZ2G9", "original": null, "number": 2, "cdate": 1648265025065, "mdate": 1648265025065, "ddate": null, "tcdate": 1648265025065, "tmdate": 1648265025065, "tddate": null, "forum": "rpPGIQtxI-q", "replyto": "rpPGIQtxI-q", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper9/-/Official_Review", "content": {"title": "Unclear motivation", "review": "The paper describes a method for training a left-corner parser through reinforcement learning using word vectors from a variety of off-the-shelf language models.  Evaluations compare several of these models.\n\nMy main difficulty with the paper is that it does not motivate the need to use reinforcement learning in this way.  For example, is this a model of human grammar acquisition?  If so, there should be more discussion of theories of grammar acquisition that might be supported by the these results.\n\nSecondarily, the paper provides extensive explanations of things like self-paced reading and garden path effects that are probably quite familiar to CMCL audiences, and very little explanation of reinforcement learning or what an 'environment' is in this context, which are more unusual.  Also, it is a bit strange to have an example parse with no formal specification of the parsing rules, even if they are taken from another paper.\n\nFinally, there's no discussion of earlier uses of reinforcement learning in incremental parsing, e.g. Le and Fokkens 2017 in EACL.\n\nThere might be an idea here, but I think the presentation must be reworked fairly substantially to be acceptable.\n\nMore minor: the paper should include citations for claims like 'AC architectures have been argued to be cognitively realistic' on page 8, and other mentions of 'cognitively realistic'.\n", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_DZ3M"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_DZ3M"]}, {"id": "rclcTQZBG5", "original": null, "number": 1, "cdate": 1647805378125, "mdate": null, "ddate": null, "tcdate": 1647805378125, "tmdate": 1647805785826, "tddate": null, "forum": "rpPGIQtxI-q", "replyto": "rpPGIQtxI-q", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper9/-/Official_Review", "content": {"title": "This paper presents an approach to left-corner parsing of constituency structure (as CFGs) based on Reinforcement learning. The authors explore various RL environments, and evaluate them with respect to several baselines. However, the paper is lacking in motivation, and there is no clear placement of the authors' question/motivation/techniques with respect to the broader cognitive modeling literature. ", "review": "To the Editors: I feel compelled to state that I had already reviewed this paper for a previous conference several months ago, and none of the issues found there have been addressed. Because of this, I can't confidently believe the authors' would  take the reviews into account in a potential camera ready. The rest of my review is the same as my previous one, since nothing in the paper has been changed.\n\n## Big Picture Comments\n\nFrom one side, the paper is generally well-written and the technical results seem sound (it is not possible to replicate the results, since the authors do not share their code, but the technical set-up appears correct to me, independently of the specific numerical scores).\nThe contribution is **potentially** interesting, but in ways that are made hard to evaluate given the paper.\nUnfortunately, the main issue with this paper  its lack in clarity with respect to aims and overall conceptual contribution. In short: it is unclear what we are actually learning from the paper, and who the authors' think should be interested in their results (psycholinguists?computational linguists interested in symbolic models? neural network researchers? all of the above?). This is partially an artifact of significant presentation issues. I hope my comments below might help the authors' clarify the goals of the paper and its contribution to the broader literature.\n\n## Specific Comments\n\nOne issue in presentation is, in my opinion, the focus of the first half of the paper given the audience. The authors spend almost half of the paper motivating constituency parsing, and walking us through an example of the shift/predict/scan operations. This to me seems quite trivial, and if the purpose is to exemplify the rewards, that's anyway made clearer in the later section.\nHowever, what is missing is the motivation behind why applying a RL approach to this problem is valuable, and a walkthrough of RL fundamental intuitions, which seems to me way more needed given the scope of the paper than the scan/predict example.\n\nI know it seems I am being picky about form, but the reason is that this lack of motivations makes the rest of the paper relatively weak.\nIt seems like the whole contribution is to substitute the classical control structure of these kind of parsing algorithms with a RL agent. Which, fine, but what is the advantage?\nThe authors seem to be implying that the contribution is showing that the economy heuristic guiding the agents is learned from experience, but that just doesn't seem to be true in any relevant sense. The fact that shortest parsing paths are preferred is baked into the reward structure, both at the local choice level and in terms of total reward, which explicitly penalized longer paths. So ok, this is less explicit than an oracle considering number of actions explicitly, but I would not say it \"derives\" from experience.\n\nIn turn, this leads the experimental section to land quite flatly. The authors claim implementing these kind of algorithms is challenging for RL. But so what is the contribution meant to be? In the introduction it seemed that the authors were arguing for advantages coming from applying RL to this parsing \"problem\". But then towards the end it seems that the contribution is in highlighting the limits of RL?\nI am not saying these are not interesting results per se, they could be, but the authors never state why they should.\n\nIn short,  I think the conceptual foundation is missing from the paper, and thus the reader is left wondering. In this sense, the paper could benefit from a conclusion/summary section moving back from the particular results of the last section to the broader contribution. Clarifying what the authors think the aim of their approach is.\n\n\nSome minor notes:\n\n- The authors put a lot of emphasis on the parsers being \"cognitively plausible\", and I think they mean two things: (a) the eargerness of the left corner strategy (cue Resnik) and (b) the shortest path (parsing step counting) heuristic. Is that correct? I have no problems with either, in principle. But I don't think the prominence of either in the actual suggested contribution justifies having \"cognitively plausible\" in the title. The referenced literature seems to be lacking in this sense, missing a lot of work on connecting symbolic parsing algorithms to sentence processing behavior (boston2008parsing,chen2021quantifying,stanojevic2021modeling) Also note that there is a variety of ways (depending on what kind of cognitive, representational commitments one entails) in which these kind of minimal-steps ideas can be understood.\n\n- In the abstract and through, the authors mention evaluating the\"psycholinguistic implications\" of RL algorithms, but there is barely a mention of that towards the end (that is left uninterpretable given the content of the paper). It is also left unclear how actually plausible these algorithms are, since the tree depth and things like adjunction seem to matter in ways that clearly do not for the human parser (sturt2005processing). In fact, we are even left wondering what the \"cognitively plausible\" mentioned in the title refers to.\n\n## Some References\n\n@article{boston2008parsing,\ntitle={Parsing costs as predictors of reading difficulty: An evaluation using the Potsdam Sentence Corpus},\nauthor={Boston, Marisa Ferrara and Hale, John and Kliegl, Reinhold and Patil, Umesh and Vasishth, Shravan},\njournal={Journal of Eye Movement Research},\nvolume={2},\nnumber={1},\nyear={2008}\n}\n\n@article{chen2021quantifying,\ntitle={Quantifying Structural and Non-structural Expectations in Relative Clause Processing},\nauthor={Chen, Zhong and Hale, John T},\njournal={Cognitive Science},\nvolume={45},\nnumber={1},\npages={e12927},\nyear={2021},\npublisher={Wiley Online Library}\n}\n\n@inproceedings{kobele2013memory,\ntitle={Memory resource allocation in top-down minimalist parsing},\nauthor={Kobele, Gregory M and Gerth, Sabrina and Hale, John},\nbooktitle={Formal grammar},\npages={32--51},\nyear={2013},\norganization={Springer}\n}\n\n\n@inproceedings{stanojevic2021modeling,\ntitle={Modeling incremental language comprehension in the brain with Combinatory Categorial Grammar},\nauthor={Stanojevi{\\'c}, Milo{\\v{s}} and Bhattasali, Shohini and Dunagan, Donald and Campanelli, Luca and Steedman, Mark and Brennan, Jonathan and Hale, John},\nbooktitle={Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics},\npages={23--38},\nyear={2021}\n}\n\n@article{sturt2005processing,\ntitle={Processing coordinated structures: Incrementality and connectedness},\nauthor={Sturt, Patrick and Lombardo, Vincenzo},\njournal={Cognitive Science},\nvolume={29},\nnumber={2},\npages={291--305},\nyear={2005},\npublisher={Wiley Online Library}\n}", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_xqgf"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper9/Reviewer_xqgf"]}]}, {"paper_url": "https://openreview.net/forum?id=SO_e8XKgUbq", "paper_id": "SO_e8XKgUbq", "reviews": [{"id": "HWVxfQq4pGq", "original": null, "number": 3, "cdate": 1648343578226, "mdate": 1648343578226, "ddate": null, "tcdate": 1648343578226, "tmdate": 1648343578226, "tddate": null, "forum": "SO_e8XKgUbq", "replyto": "SO_e8XKgUbq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper6/-/Official_Review", "content": {"title": "Misses the point I'm afraid", "review": "This paper addresses the phenomenon of human comprehenders frequently misassign thematic roles to arguments in ways that seem to be driven by \"processing heuristics based on their expectations about events ... rather than relying on syntactic rules\". For example, participants frequently misinterpret 'The dog was bitten by the man' as having the man as the patient and the dog as the agent. The authors train a neural network model to construct a representation of a sentence which captures information about the assignment of thematic roles to arguments. They find that, in line with what has been observed in humans, the model's accuracy in assigning roles is lowest for passive, semantically-anomalous sentences like 'The dog was bitten by the man', and highest for active, non-anomalous sentences like 'The dog bit the man'.\n\nThis would be somewhat interesting if the only empirical facts at hand were the facts about misinterpretations that the authors review in the introduction. (There would be the usual questions about the interpretability of the neural model, but there would at least be something to talk about.) But the whole interest of the Ferreira-style findings is the fact that those interpretations are *mis*interpretations -- when we say that they are *mis*interpretations, we don't mean that they diverge from what the stodgy old syntax textbooks say, we mean that they diverge from what those same human comprehenders will tell you if you give them a couple of extra seconds to think about it. That's the other fact at hand which the authors seem to completely disregard (and that's why the stodgy old syntax textbooks say what they say). The whole interest, in other words, is what sort of mind would exhibit this divergence between interpretations at two different timescales. The model described in the paper does not exhibit any such divergence, it only captures one half of the picture.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_GMha"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_GMha"]}, {"id": "BcgyPM43fq", "original": null, "number": 2, "cdate": 1648276054578, "mdate": null, "ddate": null, "tcdate": 1648276054578, "tmdate": 1648276538125, "tddate": null, "forum": "SO_e8XKgUbq", "replyto": "SO_e8XKgUbq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper6/-/Official_Review", "content": {"title": "The paper could be a bit more carefully worded", "review": "This paper describes a neural role-filler model that correctly mixes up arguments in sentences manipulated to have inverted canonical subjects and objects.\n\nI think there's a contribution here, but the motivation should be worded a bit more carefully.  Evidence of human errors on these kinds of manipulated stimuli may suggest an auxiliary 'good enough' comprehension model which runs in parallel with a more precise parser that can reliably comprehend complex sentences with nested conditions, conjunctions, negations, etc.  This would not challenge the view that parsers are necessary, as claimed in the first paragraph.  Statements like 'Most theories ...' in the introduction need some citations, as does the sentence after that (presumably that refers to Ferreira and Kutas, et al).\n\nAlso, a clarity issue: on line 125 there a reference to 'Fasttext' which isn't explained.\n\nA minor point: swapped arguments is also a kind of speech error; I wonder if comprehension errors are simply assuming a speech error has happened?\n\nFinally, the acknowledgements section is usually omitted in anonymous submissions, as it has the potential to de-anonymize the submission.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_iUsJ"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_iUsJ"]}, {"id": "St-eQNfYyG5", "original": null, "number": 1, "cdate": 1647444522684, "mdate": 1647444522684, "ddate": null, "tcdate": 1647444522684, "tmdate": 1647444522684, "tddate": null, "forum": "SO_e8XKgUbq", "replyto": "SO_e8XKgUbq", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper6/-/Official_Review", "content": {"title": "the perennial appeal of syntax-free comprehension", "review": "This paper represents a revival of the view originally championed by Tom Bever in 1970 that some route of the human sentence processing mechanism is free from the influence of grammar.  While Bever's own proposal includes a 2nd route that is influenced by grammar, this submission only focuses on the first route. The paper exhibits a model that faithfully misperceives Patients as Agents when they are more plausible in that semantic role.\n\nIn the writing, I sense a suggestion that somehow modeling this phenomenon bolsters the view that syntax is unnecessary (e.g. \"pose a challenge to classic linguistic theories and models\" page 4). This is not true. This view, while perennially-appealing to syntax-haters around the world, is simply not supported by Ferriera's results, Kuperberg's or by this paper's modeling. Rather what I think this paper shows is that recurrent neural networks can faithfully implement what David Caplan (MIT Press 1992) has called the \"heuristic route\" -- I take this to be roughly the same as Bever's syntax-free Perceptual Strategies from the 1970s.\n\nIf this submission's rhetoric were recalibrated to say for example \"this is a model of what people with Broca's Aphasia can do\" it could make a valuable contribution by deriving predictions about new cases where plausibility might override structure. Another improvement would be to characterize the contribution of the gated units (i.e LSTM) as compared to Doug Rohde's thesis which used ungated, Elman style Simple Recurrent Nets.\n\nI am recommending reject because publication of this version would reflect badly on CMCL. As inclusive as we are at this workshop, scholarship is a non-negotiable requirement. However, if the author were to reframe the contribution i.e. to remove the spurious argument against classic linguistic theories and models, I think it would be appropriate to accept.", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_Noc4"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper6/Reviewer_Noc4"]}]}, {"paper_url": "https://openreview.net/forum?id=BffxIQYlLbc", "paper_id": "BffxIQYlLbc", "reviews": [{"id": "SglyyuKiG9", "original": null, "number": 3, "cdate": 1648232406879, "mdate": 1648232406879, "ddate": null, "tcdate": 1648232406879, "tmdate": 1648232406879, "tddate": null, "forum": "BffxIQYlLbc", "replyto": "BffxIQYlLbc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper5/-/Official_Review", "content": {"title": "Preliminary blend of two RSA extensions", "review": "The authors study \"habituality\" inferences using an example from a previously-collected dataset by Kravtchenko & Denberg, 2015). They attempt to derive these under the rational speech acts framework and find that a base RSA agent fails, but that a blend of habitual and noisy channel RSA variants can produce these inferences and can mirror the empirical observation that when the triggering statement is more prominent, the inference gets stronger. \n\nThis is an interesting but somewhat incremental extension to RSA theory, picking up on the Bergen and Goodman (2015) noisy channel RSA model. The theoretical contribution is to work out how these two model variants can be combined, and that seems quite appropriate for the current venue. Unfortunately, the empirical side is not yet well fleshed-out: the prior data are not described in any depth, and the evaluation is completely qualitative. Further, the model depends on establishing a confusion matrix for utterances that is (as noted as a limitation by the authors) currently simply invented. A minimum step here would be to conduct some kind of sensitivity analysis to show that it is not the specific details of this confusion matrix that produce the result. \n\nIn sum, this feels like a good start but some further evaluation is needed to cement the contribution of the work. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_HsPv"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_HsPv"]}, {"id": "rubgaf4_Dfq", "original": null, "number": 2, "cdate": 1647965205287, "mdate": 1647965205287, "ddate": null, "tcdate": 1647965205287, "tmdate": 1647965205287, "tddate": null, "forum": "BffxIQYlLbc", "replyto": "BffxIQYlLbc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper5/-/Official_Review", "content": {"title": "Interesting but too preliminary, with clear empirical limitations", "review": "This paper presents a formal model \u2014 within the RSA framework \u2014 of pragmatic inferences about the frequency of an activity that arise when utterances contain information that is in principle redundant (under default assumptions for an event type). The authors first present a version of the model (hRSA) that incorporates prior expectations given common ground knowledge, building on Degen et al (2015).  This model fails to account for the possible preference of speakers to use more costly utterances to convey unusual meanings and the fact that these more costly utterances strengthen the inference. To remedy this, the authors proposed a modified version of the model (noisy hRSA), which takes into account the memorability of a given utterance form, building on Bergen and Goodman (2015).\n\nI have read the paper with interest, but do not think that it is suitable for CMCL. The paper makes theoretical predictions, which is a strength. However, the work in its current state is largely incomplete: \n\n- the model revolves around one single example (the one given in the introduction) and no details about data are given (e.g., the data collected by Kravtchenko & Demberg (2015) is not described; nothing is said about how many types of events were targeted in the experiments by Kravtchenko (2021) regarding habituality priors);\n- most importantly, no empirical evidence is provided for assumption (c), i.e., the hypothesized speaker behaviour which the model captures has not been empirically validated and it\u2019s not clear why this should hold; \n- similarly, no evidence for the claim that \u201cspeakers are very reluctant to use exclamation marks or other markers even in this condition\u201d (lines 304-306);\n- the values in table 1 are made up (\u201cintuitively plausible\u201d with no empirical evidence and not substantiated by a well-defined theory);\n\nThe authors acknowledge these weaknesses at the end of the conclusions. Given these limitations, my assessment is that the paper does not currently contain enough substance and is not a good fit for this workshop in particular. \n\nOther comments: \n\n- The RSA framework is given for granted. The paper should include a brief description of its main components. Space is clearly not an issue. \n\n- The term \u201catypicality inferences\u201d used in the title is never used in the paper, where instead the phenomenon studied is referred to as \u201chabituality inferences\u201d.\n\n- What does hRSA stand for? (Is it \u201chabituality RSA?). This acronym is used in section 3.1 without spelling out what it stands for, and without a citation (in line 246, it appears that this is not a contribution of the present paper but rather a model introduced in previous work). \n\n- Lines 169 and 385: wrong citation format. \n\n- Consider shortening the abstract, using one single paragraph, which is the established scholarly practice in the field. ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_ACau"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_ACau"]}, {"id": "BrBgAx9ca-c", "original": null, "number": 1, "cdate": 1647319541761, "mdate": 1647319541761, "ddate": null, "tcdate": 1647319541761, "tmdate": 1647319541761, "tddate": null, "forum": "BffxIQYlLbc", "replyto": "BffxIQYlLbc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper5/-/Official_Review", "content": {"title": "Interesting study, could use some more attention to existing understanding of implicature and common ground", "review": "I'm not sure that the way the authors measured the habituality prior will really get accurate measurements. If we assume that paying the cashier logically follows from going shopping, then even asking the question of how often he pays the cashier may introduce the same sort of Q-implicatures that stating \"he paid the cashier\" does -- respondents might think \"why ask me that unless there is reason to suspect that he often doesn't\"? Thus, these ratings might not be giving a baseline habituality level; they might just be showing the same inferences that the main experiment is showing.\n\nIt seems to me that many potential implicatures may become available in the sorts of utterances used here. \"John went shopping -- oh yeah, and he paid the cashier\" might implicate that he doesn't usually pay, but it might implicate lots of other things as well, and it's not even clear to me that \"John usually doesn't pay\" is even the most likely implicature to arise (hence the rather small effect seen in the author's previous studies -- even in the more marked conditions, there is still a plurality of participants thinking that John usually pays). It's especially hard to know what implicature to recover here without any context (so it would be useful to see the full stories that were used in the study; if participants only see these utterances in a minimal context I suspect that their interpretations would be so all over the place there would be nothing interesting to model; the authors mention that these were put in story contexts but I don't see the full texts anywhere). It seems like it's easy for an interlocutor to notice that the utterance is weird (flouting the maxim of quantity, the Q-principle, or whatever we want to call it) and that the speaker intends to produce some implicature, but exactly what that implicature is is very underdetermined -- indeed this has been one of the core criticisms of Gricean pragmatics ever since it started. \n\nThe authors state near the beginning of the paper that there has been little research attention to pragmatic inferences that involve changing one's beliefs about the common ground, but this doesn't seem right. Quite a lot of theorizing in pragmatics and discourse analysis has assumed that communication is all about updating the common ground and mutual knowledge; e.g., contra stuff like Grice's theory of non-natural meaning, some approaches argue that the whole point of communication is to get an interlocutor to introduce something new into their understanding of the common ground. (e.g. Discourse Representation Theory.) Some pragmatic phenomena, particularly presupposition and conventional implicature, have been explained with recourse to how they put things into the common ground (e.g. work by Stalnaker, Potts; for a summary of work from the very dawn of pragmatics see e.g. chapter 4.4 of Levinson 1983).", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_px8X"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper5/Reviewer_px8X"]}]}, {"paper_url": "https://openreview.net/forum?id=SGfgrQYeUWc", "paper_id": "SGfgrQYeUWc", "reviews": [{"id": "SBgezgC2YG9", "original": null, "number": 3, "cdate": 1648115177561, "mdate": 1648115177561, "ddate": null, "tcdate": 1648115177561, "tmdate": 1648115177561, "tddate": null, "forum": "SGfgrQYeUWc", "replyto": "SGfgrQYeUWc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper2/-/Official_Review", "content": {"title": "Not relevant for the CMCL venue", "review": "The paper compares BERT predictions for texts written in two different registers, in Italian: newspapers and poetry.\n\nI do not see a fit for this paper in this venue, as there is no cognitive modelling involved, just a test of BERT's predictions for different registers. There is a section reviewing a small amount of computational psycholinguistic work in sentence processing, but the current study differs from the reviewed ones in that it does not compare against human behavior. Hence conclusions cannot be related to cognitive processing in any meaningful way.\n\nThe dataset is extremely small (18 sentences). The authors justify this choice based on the fact that they can do more extensive qualitative analysis on a small dataset. However, given this size, it is highly doubtful that the results are robust enough to draw any conclusions.\n\nOther comments:\n- acronym DL is not introduced in the abstract, and it seems like a too general way to refer to the models used in the paper, which are all instances of BERT, as far as I could tell.\n- explaining what is non-canonicity in the introduction would be helpful\n- self-citations should be avoided to preserve anonymity", "rating": "2: Strong rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_YeEh"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_YeEh"]}, {"id": "rawlYnyw_G9", "original": null, "number": 2, "cdate": 1648025521319, "mdate": 1648025521319, "ddate": null, "tcdate": 1648025521319, "tmdate": 1648025521319, "tddate": null, "forum": "SGfgrQYeUWc", "replyto": "SGfgrQYeUWc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper2/-/Official_Review", "content": {"title": "Linguistically relevant but computationally vague work", "review": "This paper explores the ability of Transformer Models to predict a word in Italian sentences. The authors investigate how predictions vary in canonical and non-canonical order of the same sentences from two different domains (poetry and newspapers). \n\nThe investigation is relevant, and the linguistic motivations are well defined. However, there are some substantial limits. \nOn a theoretical side, the authors claim their work is part of the line of research where human word predictivity is compared and tested by the performance of DNNs in next-word-prediction tasks. If this is was the aim, authors should test their results with behavioral data. In my opinion, this is more of a study on the linguistic abilities of Transformer Models.\n\nMoreover, the dataset selected is too small to make strong claims about the results. While it is true that this allows a detailed error analysis, the setup is questionable; among all, sentences are not balanced between the two domains.\n\nThe critical aspect, however, is the computational implementation. The description of the experimental setup is too vague. \nOn the one side, some decisions are not motivated (why do they choose the output of the first or projection layer and not other layers?), and the resources used are not clearly stated. For instance, the authors state they use BERT, but then they cite UmBERTo, which actually inherits from RoBERTa the base model architecture. On the other side, the way the evaluation is described is so obscure that it is hard to understand what was concretely done, yet making it hard to reproduce. For instance, it is unclear what they mean by 'We evaluate word co-occurrence frequencies by means of embeddings as the cosine value made available by BERT': the cosine is used as a measure to compute the similarity between two word-embeddings, but in the paper, I cannot find which are the two embeddings directly compared. The prediction technique should be given more details, specifically how the authors deal with cases when a word is split into subtokens by the tokenizer.\n\nI recommend that the authors rewrite the paper entirely by reformulating the research questions and detailing the experimental method precisely.\n\nLast but not least, the paper is not anonymized. Indeed, in two cases, the authors explicitly refer to their previous works (line 126: 'We already discussed 126 elsewhere (Delmonte, 2021)..',  and footnote 5 '5We comment and analyze in depth all sentences in a paper..'), which is against the double-blind reviewing policy.", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_DaR1"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_DaR1"]}, {"id": "SqLlPxqM_Gc", "original": null, "number": 1, "cdate": 1648007663442, "mdate": 1648007663442, "ddate": null, "tcdate": 1648007663442, "tmdate": 1648007663442, "tddate": null, "forum": "SGfgrQYeUWc", "replyto": "SGfgrQYeUWc", "invitation": "aclweb.org/ACL/2022/Workshop/CMCL/Paper2/-/Official_Review", "content": {"title": "Interesting work but lacking in many aspects", "review": "The current work investigates word prediction in Italian sentences. A BERT model is used to predict a masked word in sentences with differing complexity. The complexity of the sentences is operationalised via the genre of the text (new vs poetry); in particular via frequency of the word as well as word order/semantics. \n\nWhile this is an interesting and pertinent investigation, I am afraid the way the paper is written makes it extremely difficult to understand the experimental setup, the key hypothesis and the results. For example, at no point in the paper do the author clearly state how the masked word prediction task is operationalized. The authors state \"To this aim we ran BERT by masking each content word and some function word, ... \" -- what does masking some function word mean? Relatedly, it is unclear if while making a prediction, the model has access to the right context of the masked word. This is important because the model is being compared to how humans predict a word. Human word prediction is incremental in nature where only the left context is used to make upcoming prediction.\n\nIn addition, the work is not contextualised in the larger psycholinguistic prediction literature; the current citations in section 2 is cursory at best.\n\nMy suggestion would be that the authors should completely rewrite the paper by making the research questions, the experimental method and the results more accessible.\n\nFinally, the submission to the CMCL workshop has to be anonymous and self citations have to be avoided -- the authors write \"We already discussed elsewhere (Delmonte, 2021) that languages like Italian, which have a rich morphology, ...\"; such a statement is a clear violation of the guidelines.\n\n\n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_P5MN"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CMCL", "aclweb.org/ACL/2022/Workshop/CMCL/Paper2/Reviewer_P5MN"]}]}, {"paper_url": "https://openreview.net/forum?id=rhz7nqYfF-q", "paper_id": "rhz7nqYfF-q", "reviews": [{"id": "HN2gHFt6qGq", "original": null, "number": 5, "cdate": 1648183677147, "mdate": null, "ddate": null, "tcdate": 1648183677147, "tmdate": 1648183677147, "tddate": null, "forum": "rhz7nqYfF-q", "replyto": "rhz7nqYfF-q", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review", "content": {"title": "Interesting idea and reasonable experiment results", "review": "This paper proposed an interesting idea to learn the Tokenizer/Vocabulary for federated language models. The previous word-level tokenizer/vocabulary can be potentially generated by the following methods: (1) use a public dataset, which may have distribution shift compared to the targeting task; (2) directly collect from target task, which may cause privacy concern; (3) use private heavy hitter to directly collect from target task, which does not seem to provide desirable privacy utility tradeoff. This paper proposed to train a sub-word language model with differentially private federated learning from the targeting task, and then use the trained model to generate/sample words to build the word-level tokenizer. Experiments on stackoverflow, reddits with wiki data as extra public dataset show the effectiveness  of the proposed method. \n\nIn general, I think the idea is interesting. The paper is well written, technically solid, and the experiments seem to make sense. I think the draft can be further improved by clarifying the following\n(1) Why do we still want to sample a word-level tokenizer if we can train good models with sub-word tokenizer?\n(2) I cannot get the intuition why the proposed method can be better than private heavy hitters. Could the authors provide more intuition and highlight it in experiments?\n\nThe authors may also be interested in the following paper and blogpost that show how to get DP in FL in practice:\nPractical and Private (Deep) Learning without Sampling or Shuffling https://arxiv.org/abs/2103.00039\nFederated Learning with Formal Differential Privacy Guarantees https://ai.googleblog.com/2022/02/federated-learning-with-formal.html", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_qmwZ"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_qmwZ"]}, {"id": "rCexZR_kqMc", "original": null, "number": 4, "cdate": 1648126152907, "mdate": null, "ddate": null, "tcdate": 1648126152907, "tmdate": 1648126152907, "tddate": null, "forum": "rhz7nqYfF-q", "replyto": "rhz7nqYfF-q", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review", "content": {"title": "Review", "review": "This paper proposes a federated learning framework to train a tokenizer while it does not require additional privacy budget in differential privacy. Training the tokenizer is an important part of learning a language model (e.g., Transformer and BERT), but to my best knowledge, it is the first work to study how to train the tokenizer in federated learning setting. \nAlthough the first two contributions (i.e., 1) performance degradation from training with a different distribution and 2) sub-word tokenizer eliminates the out-of-vocabulary problem) are quite obvious, I appreciate this work and advocate accepting the article in this workshop to discuss further. Here are some of my concerns:\n1.\tI am confused about the system and privacy model, especially how public (Wiki) and private (Reddit or StackOverflow) dataset is distributed over the server/clients. The authors assume that stale tokenizer is trained with the public dataset with a certain privacy budget. However, if the public dataset is utilized to train the model, why should differential privacy be applied? In addition, who generates dataset by utilizing the stale (or old) tokenizer and who update the model embeddings? Clarification about these questions from the FL perspective can improve the paper.\n2.\tIn experiments, it would be better to highlight the paper\u2019s contribution if comparing the two settings in the same privacy budget: 1) proposed scheme (i.e., train old tokenizer with DP and train the new tokenizer without additional privacy budget) and 2) directly train the tokenizer based on private dataset in private FL with the same privacy budget. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_9nuF"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_9nuF"]}, {"id": "BublvHd3KG9", "original": null, "number": 3, "cdate": 1648113726610, "mdate": null, "ddate": null, "tcdate": 1648113726610, "tmdate": 1648113760569, "tddate": null, "forum": "rhz7nqYfF-q", "replyto": "rhz7nqYfF-q", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review", "content": {"title": "Review", "review": "This paper provides a novel method on training a tokenizer along with the language model privately in a federated learning setting. By utilizing the post-processing theorem of differential privacy, the authors claim that the proposed method satisfies DP without additional privacy cost on training the tokenizer. Empirical results show that the proposed method outperforms heavy-hitters algorithm both in terms of privacy and utility.\n\nIn general this paper is well written, with enough background knowledge explained for readers to understand. The motivation is also clear and the algorithm description makes sense. Here are some comments I have to improve the work:\n- The authors should clearly clarify what type of privacy the proposed method is protecting. It seems that client-level privacy is enforced and a trustworthy server is assumed. I feel it is important to explicitly state this so that it is clear where the clipping and noise is happening in the FL algorithm.\n- It seems from that the proposed method outperforms heavy hitters algorithm even omitting the extra privacy budget induced by the latter. Could the authors provide the exact \\epsilon and \\delta for the heavy hitters algorithm? Alternatively, could the authors show the utility performance difference given the same privacy budget, including the separate privacy budget, in order to see how much the proposed method outperforms the former.\n- There are two minor questions during training a sub-word tokenizer: 1. How does it encode the word when there are multiple sub word combinations? Does it simply search for the one that appears earliest in the dictionary? 2. When updating model embeddings with sub-words, it doesn't seem to be a bijection: different combinations of subwords could result in the same summation, causing words with different semantic meanings to be mapped to the same embedding. Could the authors explain whether this will cause problem to the proposed method?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_zXFH"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_zXFH"]}, {"id": "HV2leMxUtM5", "original": null, "number": 2, "cdate": 1648087048282, "mdate": null, "ddate": null, "tcdate": 1648087048282, "tmdate": 1648087048282, "tddate": null, "forum": "rhz7nqYfF-q", "replyto": "rhz7nqYfF-q", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review", "content": {"title": "Reasonable idea, good results, but more work needs to be done before this can be used in practice", "review": "Thanks for the submission! I enjoyed reading this paper. The goal of this paper is to improve the tokenizer using the samples matching the real distribution of the data without incurring an additional PFL budget. The basic idea is to start with a tokenized from a public dataset, which might not match real data, and then improve that tokenizer using samples obtained from the trained model. After that, replace the old tokenizer with the new one and repeat this process. Evaluations show good results on Reddit and StackOverflow datasets. \n\n1. To apply it to real-world use cases, it\u2019s a bit unclear when we should start sampling the trained model and using the new tokenizer. Experiments shown in Section 5.4 seem to suggest that there is no easy answer, and it might depend on the underlying dataset and algorithm. Given that, any suggestions on how ML practitioners can adopt this? I assume they cannot try multiple options and pick the best one because that would require an additional budget?\n2. The experiments seem to be conducted with a fixed budget. I am curious to learn how the proposed algorithm compares with baselines if we got the chance to increase the budget to hit a target perplexity?\n3. The evaluation results look good. I am curious if the improvements can also be proven in theory as well. And is it possible to quantify the improvements before training? \n4. Are there any limitations of the proposed algorithm?\n5. IIUC, before replacing the old tokenizer with the new one, we will need to pause the current process, and use samples from the model to train the new tokenizer. In practice, how long does it take to bring the new tokenizer to a reasonable state, and will this delay be an issue? \n6. Is it viable to allocate some dedicated budget to train the tokenizer, say 20%? Is there any estimation of how the proposed algorithm compares to that?\n", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_n2wc"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_n2wc"]}, {"id": "H-g7KFpHMq", "original": null, "number": 1, "cdate": 1647855995395, "mdate": null, "ddate": null, "tcdate": 1647855995395, "tmdate": 1647855995395, "tddate": null, "forum": "rhz7nqYfF-q", "replyto": "rhz7nqYfF-q", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/-/Official_Review", "content": {"title": "The authors propose a method to train a 'matched' tokenizer alongside the decentralized and private federated learning of an NLP model over the client data.", "review": "The authors propose a method to train a 'matched' tokenizer alongside the decentralized and private federated learning of an NLP model over the client data. In particular, the authors consider the problem of having tokenizer for the NLP model that is reflective of the data on the clients that participate in the decentralized federated learning process. When the tokenizer is not matched with the private client, such as when the tokenizer is trained on a public dataset, the authors demonstrate a significant drop in accuracy of the trained model, compared to when using an oracle tokenizer i.e. when the tokenizer is trained on the client data itself. While having a matched tokenizer is essential, training tokenizer on the private client is quite challenging and can potentially cause additional privacy leakage over the existing leakage from DP based FL. Hence, the authors propose a new protocol that samples new datasets for tokenizer up dation using the language model trained using the DP based FL itself. This additional step is integrated into the existing federated learning protocol, and the authors claim that there is no additional privacy leakage. Experiments with many settings are provided that demonstrate that the proposed schemes can match the language model performance of the federated training with oracle tokenizer.\n\nWhile the problem considered is interesting and relevant, and the algorithm also has some novelty, the claim that there is no additional privacy leakage is not proved formally. In particular, when the tokenizer is modified during the private federated learning, it essentially splits the training into different stages with their own DP guarantees. I don't think the post-processing guarantee of DP applies in such a scenario. A composition analysis to bound the DP privacy budget is needed.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_gZjY"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper8/Reviewer_gZjY"]}]}, {"paper_url": "https://openreview.net/forum?id=H3NUh9Kft-c", "paper_id": "H3NUh9Kft-c", "reviews": [{"id": "SMlOUQ9Ffc", "original": null, "number": 3, "cdate": 1648104271805, "mdate": null, "ddate": null, "tcdate": 1648104271805, "tmdate": 1648105210926, "tddate": null, "forum": "H3NUh9Kft-c", "replyto": "H3NUh9Kft-c", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/-/Official_Review", "content": {"title": "Adapting intrinsic gradient compression in federated settings", "review": "Summary:\nA gradient compression technique for federated settings based on the intrinsic dimension concept is proposed. Three variations of the technique are implemented and their tradeoffs in terms of parameter exploration, federation performance and uplink and downlink cost are presented.\n\nStrong and Weak Points:\n\n(S1) Interesting adaptation of intrinsic dimension in federated learning settings for compressing clients' (local) gradients.\n(S2) Extensive empirical evaluation against different baselines and on multiple domains.\n(S3) Promising insights to employ intrinsic gradient compression techniques against inference attacks.\n\n(W1) Presentation of preliminaries, background, gradient compression and approximation, and algorithms can be improved.\n\nDetailed comments:\n(W1) In section 1, it would be better to cite the original intrinsic dimension work the first time it is discussed. In section 2 it would be better to create a table with all the notations you use throughout your work for faster notation indexing. Section 2.2 \"the data is averaged\", please change to \"gradients or weights are averaged\". Related Work: Federated Learning, please add some discussion on recent works on weight and gradient pruning in federated settings (e.g., [1], [2]). Please elaborate more on the concept of reconciliation; it is not clear what it is and what its challenges are (maybe pointing to specific lines of the algorithm will be helpful). In your time-varying gradient compression it is not clear why we need twice the bandwidth for downlink and where do the $\\theta^{final}$ stems from. For the choice of the compression matrix, why do you need an entire Dxd matrix and not consider the model parameters as a collection of smaller dense matrices? Figures 1 and 2 need to come before table 2 since they are discussed first in the paper. Also you compare against LocalTop-K but you never presented or discussed the technique in the paper.\n\nPlease be consistent with your notation, for instance in the static intrinsic gradient compression algorithm why use $\\mathcal{L}$ as loss. In section 2.1 wouldn't it be more appropriate to replace $\\theta_2$ with $\\theta^\\prime$; also does it hold that $T < L$? Moreover, why refer to $\\ell$ as a task when it has already been defined as loss, maybe another symbol could resolve this. A couple notations and concepts used in algorithm 1 are never presented in the paper (e.g., $A(\\sum_{t-1}$) - no need for parenthesis, $z_j$, sketches). In section 3, shouldn't be $A\\theta^\\prime + \\theta_0$ instead of $A\\theta^\\prime$ in the subscript of function f in the first line of equations? Also, how did you derive the A transpose multiplied with the gradient transpose from the previous line and in equation (5) why is $A\\theta_{t+1}^\\prime$ equal to $\\theta_{t+1}$?\n\n\n[1] Jiang, Yuang, Shiqiang Wang, Victor Valls, Bong Jun Ko, Wei-Han Lee, Kin K. Leung, and Leandros Tassiulas. \"Model pruning enables efficient federated learning on edge devices.\" arXiv preprint arXiv:1909.12326 (2019).\n\n[2] Bibikar, Sameer, Haris Vikalo, Zhangyang Wang, and Xiaohan Chen. \"Federated Dynamic Sparse Training: Computing Less, Communicating Less, Yet Learning Better.\" arXiv preprint arXiv:2112.09824 (2021).", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_S2Br"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_S2Br"]}, {"id": "rhMgz5JYYz9", "original": null, "number": 2, "cdate": 1648099210227, "mdate": null, "ddate": null, "tcdate": 1648099210227, "tmdate": 1648099210227, "tddate": null, "forum": "H3NUh9Kft-c", "replyto": "H3NUh9Kft-c", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/-/Official_Review", "content": {"title": "Adopting a classical sketching idea into federated learning applications", "review": "This paper proposes to use a classical sketching idea in federated SGD-like algorithms to improve the communication efficiency of federated learning algorithms. The proposed method has been used widely in centralized distributed SGD with good efficiency. Thus I am a bit concerned about the novelty of the paper.\n\nConceptually, I believe the sketching idea can also be adopted on top of federated averaging, i.e., conduct $A^\\top A$ over the model updates instead of gradient updates. How does that variant work? Moreover, the error feedback scheme seems to be always helpful for gradient/model compression, does it also help the proposed method?", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_MH3S"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_MH3S"]}, {"id": "H6Gg5eQ2HGq", "original": null, "number": 1, "cdate": 1647850225549, "mdate": null, "ddate": null, "tcdate": 1647850225549, "tmdate": 1647850225549, "tddate": null, "forum": "H3NUh9Kft-c", "replyto": "H3NUh9Kft-c", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/-/Official_Review", "content": {"title": "The authors propose a set of communication-efficient federated learning algorithms that are based on the prior idea of intrinsic dimension in theoretical machine learning. ", "review": "The authors propose a set of communication-efficient federated learning algorithms that are based on the prior idea of intrinsic dimension in theoretical machine learning. Essentially, it has been known in theoretical ML that in the overall parameter space of the ML model, there is an intrinsic subspace, with potentially much smaller dimension than the model parameter space, where optimization can be carried out. Exploiting this concept and related ideas on intrinsic dimension, the authors propose a set of three novel strategies that enables compression of updates communicated between the FL server and clients, reducing the communication load dramatically. The underlying idea is to use a projection matrix for compression at the clients/decompression at the server, so that both training and global update can be done in the model parameter space while communications can be done in the lower dimensional space. The first algorithm considers the projection matrix to be fixed throughout training, the other two consider different versions of variable projection matrices. Multiple experiments for NLP and vision tasks have been presented that demonstrate reasonable drop in accuracy even for very high (>1000x) compression rates.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_sQhs"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper7/Reviewer_sQhs"]}]}, {"paper_url": "https://openreview.net/forum?id=B2E4hqYfKWq", "paper_id": "B2E4hqYfKWq", "reviews": [{"id": "B_blH-rtTz9", "original": null, "number": 4, "cdate": 1648362749214, "mdate": null, "ddate": null, "tcdate": 1648362749214, "tmdate": 1648362893599, "tddate": null, "forum": "B2E4hqYfKWq", "replyto": "B2E4hqYfKWq", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/-/Official_Review", "content": {"title": "Concerns about the privacy definition", "review": "This paper proposed adaptive differential privacy. For a DP-SGD like algorithm, when adding noise, this paper proposed to use the \"frequency\" to scale the noise. The \"frequency\" is estimated by estimating perplexity based on a trustworthy language model. \n\nMy main concern is that the privacy definition is not clear to me. Is it possible to give a formal definition for adaptive DP and its accounting,  something similar to Def 2.4 in \"The Algorithmic Foundations of Differential Privacy\" and Theorem 1 of \"Deep Learning with Differential Privacy\". Without a definition, I cannot understand how the (\\epsilon, \\delta) bound is computed and compared. \n\nA relatively minor concern is that it is not clear to me how to get the trustworthy language model. If it is based on public data, why it can represent the private data?", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_7hxZ"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_7hxZ"]}, {"id": "BbNeQxtUtzq", "original": null, "number": 3, "cdate": 1648089323006, "mdate": null, "ddate": null, "tcdate": 1648089323006, "tmdate": 1648089323006, "tddate": null, "forum": "B2E4hqYfKWq", "replyto": "B2E4hqYfKWq", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/-/Official_Review", "content": {"title": "review", "review": "This paper proposes a novel look at differentially private training by focusing on adding more noise to data points that are rare and less noise to popular datapoints, e.g. making an adaptive noise. \n\nThis idea is interesting, however, it contradicts multiple important assumptions of differential privacy: \n1. DP says that removal of any point should result in roughly the same model, however from the proposed method not all the points are equal, e.g. some datapoints experience more noise than others. Therefore the proposed algorithm will not be differentially private.\n2. Noise is correlated against a pre-trained model assuming that the training dataset is also correlated with the dataset that the pre-trained model was trained on. For example, let's assume that the dataset that I want to train my model on contains password recovery questions and answers from the users -- any common phrase (from the pre-trained dataset) will then receive less noise, but since all of those pass answers are sensitive then it will violate privacy of these secret answers. This is the weird case, as you wouldn't want to train such a model but hopefully it shows that now the guarantees depend on some pre-trained model with a custom dataset.\n\nLastly the performance results in Table 1 demonstrate that if you increase privacy budget epsilon then the results improve which is trivially obvious. It might have been more correct to compare performance of your algorithm with budgets of the same value.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_JsH6"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_JsH6"]}, {"id": "Hlg0My8Kz5", "original": null, "number": 2, "cdate": 1648086806515, "mdate": null, "ddate": null, "tcdate": 1648086806515, "tmdate": 1648086806515, "tddate": null, "forum": "B2E4hqYfKWq", "replyto": "B2E4hqYfKWq", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/-/Official_Review", "content": {"title": "This paper scales the noise to be inversely proportional to sequence frequencies to reduce exposures of privacy data. This is an interesting idea, but part of the experiments needs more explanation and can be improved. ", "review": "Thanks for the submission! This paper proposes to treat privacy and non-privacy data differently to improve differentially private language modeling. More specifically, this paper first made a reasonable assumption that texts with privacy information do not occur frequently in a large dataset. Based on that, the algorithm estimates the privacy probability to be proportional to the perplexity of a specific sequence. Then, the authors introduce a privacy weight, representing the privacy probability, to scale the gaussian noise. Experiments show that the proposed algorithm achieved lower test loss/perplexity and at the same time reduced the exposure of canaries. \n\n1. Since the algorithm scales the noise based on the inverse of sequence frequency, I assume this means infrequent non-privacy sequences would also end up with high perplexity? Will this be a problem?\n2. Having privacy data like \u201cMy ID is 955320\u201d occurring 1000 times seems rare. Are there any statistics or related work describing what are the reasonable configurations for evaluations?\n3. I am curious about how the proposed algorithm compares to a slightly modified version which simply drops sequences below a certain frequency and then applies the same privacy weight to the rest of the dataset. \n4. DP-SGD seems achieved a lower exposure compared to the proposed algorithm when the canary count is 10. What is the reason for this? This seems to be a legit problem as it's likely that privacy data will occur less than 10 times, no?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_c46X"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_c46X"]}, {"id": "BfMxD7cC_f9", "original": null, "number": 1, "cdate": 1648056863437, "mdate": null, "ddate": null, "tcdate": 1648056863437, "tmdate": 1648056863437, "tddate": null, "forum": "B2E4hqYfKWq", "replyto": "B2E4hqYfKWq", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/-/Official_Review", "content": {"title": "Interesting topic and idea, but contribution is not clear", "review": "Overall, I think the topic of paper would be interesting for the workshop, but contribution of the paper is not clear to me. I am concerned whether there is a contribution in the method as it does not compare its proposed method with standard methods for detecting private data. I am also concerned about its empirical results as it only compares with a method published in 2016.\n\n\nBelow are some comments that I hope authors will find useful.\n\nPaper describes its motivation and contribution clearly. But the following statement was not convincing for me: \"There are some previous works detecting sensitive information in un-structured texts, but relying on labeled keywords or reference texts.\" \n\nInstead of using the above literature, authors claim that probability of data being private is inversely related to its occurrence frequency. While this might be a good rule of thumb, authors have not verified it. Authors mention this assumption to be one of their contributions \"we propose a method to automatically estimate the probability that a linguistic item contains privacy information...\". Why is this a contribution? Why is this proposed method better than those methods that use keywords and reference text? Does this estimation method based on frequency of the words perform better?\n\nAuthors give social security number as one example of private data. Does their method of inferring privacy based on occurrence frequency work well in detecting SSN? Would the method gather each and every number that appears once in the text? Why should we not use known references and keywords and adopt this proposed method? Is it because this method is faster or more accurate? Authors have not compared their method with standard methods for detecting private data.\n\nAuthors use the term \"non-privacy data\" over and over. perhaps they mean to say \"non-private data\"?\n\nThere is considerable repetition in Introduction and Related Work sections. \n\nContribution of Abadi et al (2016) is described many times in the paper.\n\nAlgorithm 1 is already in the literature except that one line of it is modified based on equation (5). It is not clear why it has to be provided in the main text of the paper.\n\nMethod is compared with Abadi's method published in 2016. There are more recent methods in the literature that authors can consider comparing with.  Results do not appear to be convincing.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_Zgb7"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper6/Reviewer_Zgb7"]}]}, {"paper_url": "https://openreview.net/forum?id=raDf3qKzYb5", "paper_id": "raDf3qKzYb5", "reviews": [{"id": "HrrghpUFKz9", "original": null, "number": 4, "cdate": 1648101059866, "mdate": null, "ddate": null, "tcdate": 1648101059866, "tmdate": 1648101059866, "tddate": null, "forum": "raDf3qKzYb5", "replyto": "raDf3qKzYb5", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/-/Official_Review", "content": {"title": "Review of the paper", "review": "This paper considers an important and timely problem in federated learning on knowledge graphs (KGs), especially developing an attack model which incurs privacy leakage in an existing work, named FedE, and proposing a new privacy-preserving embedding aggregation framework to protect the privacy against the attack.\n\nThis paper proposed the attack model which can reconstruct original entities and relations of individual client based on the local embedding matrix, which is an important finding in Federated Knowledge Graph Completion from the privacy perspective. It empirically demonstrates the effectiveness of the attack with a simple 3 clients-model. Then, this paper proposed a relation embedding aggregation framework to reduce the privacy leakage while it also reduces the required bandwidth to achieve the target MRR.\n\nIt is worth to discuss the proposed attack model and defense mechanism even though the reviewer has the following concerns. \n1.\tThis paper does not contain the system model of FedE and attack model in the main body. Before reading the Appendix C and D, I cannot capture the which information is communicated between the server and clients, which information is known to the server and colluding client, and how to reconstruct the private local information. It would be helpful to provide the system model (including definition of entity/relation embeddings and  local/global update equation, and \u2026 etc)\n2.\tIn addition to 1, it is unclear what is the global update equation based on the local relation embeddings in the proposed framework, FedR.\n3.\tThere are minor typos such as: 1) there is (?) in Appendix A 2) paris => pairs in Algorithm 1 in Appendix C.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_r89r"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_r89r"]}, {"id": "rRGeIu6HtGc", "original": null, "number": 3, "cdate": 1648086382253, "mdate": null, "ddate": null, "tcdate": 1648086382253, "tmdate": 1648086382253, "tddate": null, "forum": "raDf3qKzYb5", "replyto": "raDf3qKzYb5", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/-/Official_Review", "content": {"title": "Review", "review": "This paper proposed a novel reconstruction attack method to infer the client's data utilizing the model updates in a knowledge graph setting. The proposed method achieves strong attacking accuracy on previous baselines. To overcome this, the authors further proposed a new method called FedR robust to the proposed reconstruction attack method. \n\nThe method is interesting. The idea of sharing relation embedding rather than head/tail embedding for aggregation is novel and seems to effectively prevent exact inference of the user data. The experimental results seem strong and significantly outperform prior work on multiple benchmarks. Here are some of my concerns:\n- Rather than saying the proposed FedR is 'privacy-preserving', it seems that FedR is only robust to the proposed attacking method. There are a couple of things missing here: 1. How does the success rate of the attacking method transfer to the privacy level of the randomized algorithm to train KG? Could it transfer to any formal differential privacy guarantee? 2. How to evaluate the optimality of the attack evaluated in this work? Could there be stronger, defense-aware attack that could similarly break FedR? It would be great if the authors could provide additional details for these points.\n- Could the authors add a related work/background section to list relevant work on reconstruction attacks/FL on KG?\n- Could the authors add a clear algorithm description on FedR?\n- In the description of experiment, the authors claim each dataset is randomly split among clients? Does that mean the data are homogeneous among all the clients? In a typical FL setting, data are heterogeneous on each client. Could the authors add experiments on experiments under heterogenous data?", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_do3D"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_do3D"]}, {"id": "rc8larlpdGc", "original": null, "number": 2, "cdate": 1648050244777, "mdate": null, "ddate": null, "tcdate": 1648050244777, "tmdate": 1648050244777, "tddate": null, "forum": "raDf3qKzYb5", "replyto": "raDf3qKzYb5", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/-/Official_Review", "content": {"title": "Good idea, but some inaccuracies", "review": "I think overall, this paper would be interesting for the workshop, and authors have proposed an interesting approach. There are issues in presentation and claims which can be improved and fixed. Hopefully, discussions at the workshop can help authors gather more feedback and continue their work.\n\n\nBelow are some comments which I hope authors will find useful to improve their work.\n\nIt seems that authors are proposing to modify the FL setting, by assuming that server might collude with the clients. This is a modified definition of privacy for FL which is fine and interesting. However, in the abstract and introduction, authors seem to claim that they have found a severe privacy leakage for FedE method and they want to address that severe shortcoming. Contribution of this paper can be explained more clearly starting with the assumptions used in FL literature, FedE method, and authors' method.\n\nStatements like \"FedE is not privacy-preserving\" are meaningless without proper definition of \"privacy\". From authors' point of view, how many of the methods in FL literature can be considered \"privacy-preserving\"?\n\nPhrases like \"much more\" for communication efficiency seem to be overly vague.\n\nFunction f(h,r,t) is not defined properly.\n\nIt is not clear what authors mean by \"honest-but-curious\" server. If the server is honest why should we go through all these trouble to hide the data? Authors have to define what they mean by \"honest\" and how that affects their formulation.\n\nIf a client is a traitor and shares the data with the server, why would it share only a percentage of its data and not all of it?\n\nMethod is not presented in a coherent way. First, it is mentioned that \"To guarantee the data privacy in the FedE, FEDR adopts two main strategies\". Despite this guarantee, a paragraph later, it is mentioned that \"the server still can roughly infer the relation by comparing the uploaded relation embedding with the one stored...\". It is not clear what \"roughly\" entails here and how it can combine with the statements before. It sounds like authors do not have a clear definition of privacy in mind, are they are putting bandaids on various shortcomings that they consider. The word \"guarantee\" seem to lose its meaning.\n\nFigure 4 which provides the comparison with other methods does not depict the performance of proposed method. In the legend, proposed method is shown as a solid black line, but in the plot, there is no such line.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_rKgA"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_rKgA"]}, {"id": "Hd_euz_4Tbq", "original": null, "number": 1, "cdate": 1647294479841, "mdate": null, "ddate": null, "tcdate": 1647294479841, "tmdate": 1647294479841, "tddate": null, "forum": "raDf3qKzYb5", "replyto": "raDf3qKzYb5", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/-/Official_Review", "content": {"title": "Review on \"Efficient Federated Learning on knowledge Graphs via Privacy-Preserving Relation Embedding Aggregation\"", "review": "This work presents an extension of FedE, a recently proposed knowledge graph aggregation scheme in Federated Learning. Specifically, the authors tackle the privacy issue by aggregating relation embedding instead of directly aggregating the entity embedding.\n\nAlthough the idea is quite simple, it effectively addresses the privacy issue while maintaining the model performance. I appreciate this idea and advocate accepting the article in this workshop. I see a few things that can be improved as follows.\n\n1. The experimental settings can be improved. The number of clients is obviously too small. Federated Learning is a large-scale distributed learning paradigm. Considering the total number of entities in the benchmark datasets, the dataset can be distributed to more than 20 clients. If the number of clients is hundreds for example, would similar performance benefits still be available?\n\n2. Although FedE is the recently proposed representative work, comparing FedR to this single work does not provide useful insights. Additional comparisons to other works (especially referenced in FedE paper) will significantly strengthen the paper.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_XHJY"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper5/Reviewer_XHJY"]}]}, {"paper_url": "https://openreview.net/forum?id=ShNG29KGF-c", "paper_id": "ShNG29KGF-c", "reviews": [{"id": "rZ4gQC_bnM9", "original": null, "number": 3, "cdate": 1648265419434, "mdate": null, "ddate": null, "tcdate": 1648265419434, "tmdate": 1648265419434, "tddate": null, "forum": "ShNG29KGF-c", "replyto": "ShNG29KGF-c", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/-/Official_Review", "content": {"title": "Overall nice work analyzing different ways to scale federated training of transformers", "review": "## Summary\nThis paper primarily studies the effect of partial variable training, quantization, and their combinations to enable training large language models in a federated setup. These techniques allow training large language models in cross-device federated configurations. They show that quantizing the models before uploading and downloading can reduce training costs with marginal drops in performance. \n\n### Main Observations:\n- Model quantization before uploading from local learners is more effective than quantizing before downloading to the local learner.  \n- Partial variable training combined with quantization further reduces the training and communication load.\n- Transfer learning or pretraining can speed up federated training.\n\n## Suggestions:\nOverall, I like the paper's analysis of different options available for scaling up federated training for language models and the paper is well-written. However, it still lacks comparison with prior works and baselines. For example, an alternative approach to PVT could be model pruning. So, it would be nice to compare with model pruning baselines such as TPrune ([https://dl.acm.org/doi/10.1145/3446640](https://dl.acm.org/doi/10.1145/3446640)). \n\nAlso, please clarify the following in writing:\n- How was tokenization done for federated experiments --- centralized or federated? Please clarify. \n- Do you exchange model parameters or the changes in parameters for upload and download? While this may be a minor detail, it could affect quantization performance. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_kZQV"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_kZQV"]}, {"id": "SlxoQpwizc", "original": null, "number": 2, "cdate": 1648225570967, "mdate": null, "ddate": null, "tcdate": 1648225570967, "tmdate": 1648225570967, "tddate": null, "forum": "ShNG29KGF-c", "replyto": "ShNG29KGF-c", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/-/Official_Review", "content": {"title": "Official Review", "review": "**Summary Of The Paper:** This paper leverages several techniques for mitigating the communication and computation bottlenecks to train a Transformer in cross-device federated learning. They systematically evaluate partial model training, quantization, efficient transfer learning, and communication-efficient optimizers,\n\n**Strengths.**\n- This paper is easy to read and has good structure, and is complete and coherent.\n- The topic is interesting and important because the large transformer model has become mainstream in the NLP community. It is necessary to consider how to deploy this kind of large model in the client.\n- The design of experiments is sufficient and comprehensive.\n\n**Weaknesses.** \n- All the methods are general so it would be better to design a novel method. However, I think it is okay for an analytical paper.\n\nOverall, in my view, this is a high-quality paper.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_D9ht"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_D9ht"]}, {"id": "HBeeq_sEKMc", "original": null, "number": 1, "cdate": 1648081778327, "mdate": null, "ddate": null, "tcdate": 1648081778327, "tmdate": 1648081778327, "tddate": null, "forum": "ShNG29KGF-c", "replyto": "ShNG29KGF-c", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/-/Official_Review", "content": {"title": "review", "review": "**Summary**\nThe paper studies cross-device federated learning for the problem of language modelling. The paper conducts a series of empirical studies to show that large and high-performing language models can be trained in the cross-device setting, with large Transformers partially fine-tuned through federated updates and quantized communication achieving very good performance. \n\n**Overall comments**\nThe paper conducts a careful empirical study on how high-performing language models can be trained in the cross-device setting. While the techniques and methods employed in the paper already exist in the literature, the empirical results demonstrated in the paper has high practical value (and would therefore be considered as significant) to practitioners. The paper is therefore of high quality. The paper is also written clearly. I therefore recommend acceptance.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_HMNd"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper4/Reviewer_HMNd"]}]}, {"paper_url": "https://openreview.net/forum?id=SawenqFzFb9", "paper_id": "SawenqFzFb9", "reviews": [{"id": "BxWgKOs7az9", "original": null, "number": 3, "cdate": 1648339824967, "mdate": null, "ddate": null, "tcdate": 1648339824967, "tmdate": 1648339898825, "tddate": null, "forum": "SawenqFzFb9", "replyto": "SawenqFzFb9", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/-/Official_Review", "content": {"title": "Simple idea, strong empirical performance. Rigorous evaluation including interesting ablation analysis.", "review": "## Strengths\n- Simple approach, trivial to implement\n- Strong empirical performance\n- Thorough empirical evaluation: multiple benchmarks (including skewed version of Sent140), ablation over token lengths and types of user-ids, performance of unseen users\n- Privacy preserving. Rand.All can be implemented locally with no privacy loss (Def. and Num. cannot, but they don't work as well)\n\n## Weaknesses\n- No comparison against some other popular FL personalization schemes (like Ditto). UserAdapter is the only comparison, while something like Ditto or pFedMe are more established\n- It is not clear why trainable user embeddings perform worse (it is very unintuitive, at least to me). Authors mention that \"coupling learning problems in both domains is useful\", but a deeper analysis might help. \n- Their intuition on why UserIdentifier outperforms UserAdapter (collaborative learning and personalization is happening simultaneously). I don't understand how UserIdentifier performs any collaborative learning. Assume UserA and UserB behave \"similarly\", and a method that does collaborative learning might learn this and exploit it. In UserIdentifier, A and B would get random ids - so no collaborative learning would happen\n- Large, over-parameterized models like RoBERTa-base or BERT-base are not practical in FL (on-device constraints). Would their scheme work in smaller models, where the embeddings are smaller and less over-parameterized?\n\n## Suggestions\n- Consider expanding to harder FL-NLP problems outside of sentiment classification (e.g, LM)\n- Does this scale to a large #users, say millions? As the #users increase, almost all token embeddings will be modified by some user?\n- An interesting setting would be running UserIdentifier in the same setting as UserAdapter: personalization as a separate task after global training\n- On 'unseen' users: Another interesting setting would be to run local run train + eval on unseen users (instead of just eval, as you do)\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_XFKB"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_XFKB"]}, {"id": "rTPl3Dq-hfc", "original": null, "number": 2, "cdate": 1648265827802, "mdate": null, "ddate": null, "tcdate": 1648265827802, "tmdate": 1648265892110, "tddate": null, "forum": "SawenqFzFb9", "replyto": "SawenqFzFb9", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/-/Official_Review", "content": {"title": "   ", "review": "## Summary\n\nThis paper proposes learning a personalized sentiment analysis model from the text by appending or prepending a user-specific string (termed \"UserIdentifier\") to the input text. Then a single transformer model is finetuned on data from all the individuals. Incorporating user identifiers help learn a better and more personalized model for each individual. The proposed method is compared with three other approaches --- finetuning with original data, finetuning with original data followed by prefix-tuning, and finetuning with trainable user identifiers. The authors justified their choice of selecting user-identifiers by appropriate ablation experiments. The \"UserIdentifier\" approach outperforms other baselines on Yelp, Sent140, and IMDB datasets. \n\n## Strengths:\n- Although the solution builds upon recent findings that demonstrate parameter efficient finetuning/few-shot learning by prompting with task-specific texts or introducing trainable input embeddings, the idea of introducing user-specific strings is interesting. \n- I appreciate that the authors discussed different ways to assign user-identifiers and tried to partially explain the best choice in Sec A.3 and 4.3.\n- The paper also studied generalization to new users briefly. Interestingly, the model performance is almost similar to finetuning with no user-identifiers (though slightly lower), thus providing personalization without hurting. \n\n\n## Scope for Improvement:\n- **Federated vs. Centralized Setups**: \nSince we are eventually interested in a federated setup and personalized models, one of the baselines would be training a model per user, which is missing. While this may not be parameter efficient, each user will train its model on their local machine saving massive communication costs and maybe using similar or compute. The authors should discuss this scenario in the paper at least.  \n- **Writing**:\n     - a. The main paper is mainly motivated by federated learning & need for personalized models, but the experiments are performed in a centralized setup which is ok. However, this is not clarified until sec 4. It would be nice to have this clarified in the introduction. \n     - b. Sec 4.3 last paragraph ignores the L parameter in the discussion. The overlap will be much less even with just L=2 and sample space=400.\nMinor: Table 4 is in the appendix. Either use a different numbering convention or add a small note in brackets that it is in the appendix. \n- **Trainable Embeddings**:\nIt is counterintuitive that fixed prefixes outperform trainable embeddings, as Li & Liang (2021) and Hambardzumyan et al. (2021) show that it outperforms fixed prefixes. Even though the above references are not in the same context, ideally, more flexibility should help improve the model training. This raises the question if this can be explained by overfitting? Did the author compare training performance for these models? \nThe authors argue in the paper that simultaneous adaptation of parameters hurts learning. Would further \"embedding only training\" of the \"UserIdentifier\" approach improve or maintain performance? \n\n### Refs:\n- WARP: Word-level Adversarial ReProgramming (Hambardzumyan et al., ACL 2021)\n- Prefix-Tuning: Optimizing Continuous Prompts for Generation (Li & Liang, ACL 2021)\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_wnZb"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_wnZb"]}, {"id": "H87e-EbXYzc", "original": null, "number": 1, "cdate": 1648075049512, "mdate": null, "ddate": null, "tcdate": 1648075049512, "tmdate": 1648075218872, "tddate": null, "forum": "SawenqFzFb9", "replyto": "SawenqFzFb9", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/-/Official_Review", "content": {"title": "review", "review": "**Summary**\n\nThe paper proposes a data augmentation method to handle personalized prediction for text classification problems. \n\n**Overall comments**\n\nThe method is simple and seems to work well on the toy problems studied in the paper. The experiments are adequate for a workshop paper (but can be improved to provide more insight into the performance). The writing is clear. The paper is on topic. I list drawbacks below.\n\n**Cons**\n- The paper compares different methods on simple datasets for the task of sentiment classification. To make the empirical study more compelling, one may consider additional tasks (language generation) and datasets (GLUE, table2text, dialog, summarization).\n- It's unclear how the method improves upon baselines with better pre-trained models, e.g., Roberta*-large*. \n\n**Other suggestions**\n- The method could be combined with federated learning. \n- The paper explores different ways to create the user-identifier in text format, but one could easily imagine the user-identifier being prompt embeddings directly -- randomly sample high-dimensional gaussians for each user as their prompt embedding. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_RU41"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper3/Reviewer_RU41"]}]}, {"paper_url": "https://openreview.net/forum?id=B3z-nctzFZ5", "paper_id": "B3z-nctzFZ5", "reviews": [{"id": "SOdls4X7pzc", "original": null, "number": 3, "cdate": 1648337715124, "mdate": null, "ddate": null, "tcdate": 1648337715124, "tmdate": 1648337758626, "tddate": null, "forum": "B3z-nctzFZ5", "replyto": "B3z-nctzFZ5", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/-/Official_Review", "content": {"title": "Novel and interesting approach to personalization. Extension from mean estimation to non-convex loss is not clear. ", "review": "Originality: High. \nAdaPerFL uses a novel, interesting and rigorous Bayesian approach to evaluate Personalization in Federated Learning (FL). To motivate the framework, the authors assume a generative hierarchical Gaussian model. FL is used for mean estimation. The authors quantify the benefit of FL in this setting (compared to a local estimation) as Personalized FL gain. \nThe concepts of inter-client certainty and intra-client certainty are very natural and potentially useful.\nEquation (10) could be a very interesting approach to global model aggregation and feels natural (inversely weighting by variance of each local estimate)\n\nClarity: Low. \nThe first part of the paper is very clear - generative Gaussian model.\nEverything after Remark 2 is not very clear. And why should optimal initialization, learning rate and #steps that are useful for a specific convex problem (mean estimation in a hierarchical Gaussian) be applicable to non-convex deep learning? Why is equation (10) useful? How does convergence to a stationary point proceed if we use eq (10)?\n\nThe empirical evaluation is also not clear. On Sent140, the authors claim that AdaPerFL is better than Ditto, but the graphs shows test accuracy to be the same. A table here would make things much clearer. On Alexa, the main benefit seems to be using equal weighted averaging instead of example weighted averaging. The benefits between FedAvg-e and AdaPerFL is small, but the difference between FedAvg-e and FedAvg-w is very large (not observed by other papers).\n\nSignificance: Medium. \nThis is a very interesting direction and approach to FL and Personalization. However, the extension to non-convex problems is not clear. And the experimental evaluation can be improved.\n\nQuality: Medium. \nOverall, I'd say the quality is medium. There is an original and potentially significant contribution here. The authors could improve the quality by proving convergence behavior of equation (10), and showing why the choice of {LR, initialization, step size} for mean estimation are useful in completely different problems that are not even convex. The experimental evaluation can also be much better. \n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_RVNp"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_RVNp"]}, {"id": "H8ml0dlttf5", "original": null, "number": 2, "cdate": 1648099445595, "mdate": null, "ddate": null, "tcdate": 1648099445595, "tmdate": 1648104432716, "tddate": null, "forum": "B3z-nctzFZ5", "replyto": "B3z-nctzFZ5", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/-/Official_Review", "content": {"title": "Interesting Bayesian formulation of the personalized federated learning problem.", "review": "Summary:\nIn this work, the authors introduce a Bayesian formulation of the personalized federated learning problem and provide theoretical insights on how to quantify (inter- and intra-) clients uncertainty during federated training. Their propose solution, AdaPerFL, views the personalization problem from the lens of a two-layer Bayesian hierarchical model that can lead to an automatic determination of the local training steps of each client and a heterogeneous- and uncertainty-aware global model aggregation rule. \n\nStrong and Weak Points:\n\n(S1) Interesting Bayesian formulation of personalized FL.\n(S2) Evaluation over a range of existing baselines.\n\n(W1) Related work and additional background/preliminary information is missing.\n(W2) Provided evaluation does not show AdaPerFL's improved performance.\n(W3) Missing details on experimental evaluation.\n\n\n(W1) A section that provides more background knowledge in the context of personalized FL (e.g., [1]) \nand discussion on existing Bayesian Federated Learning formulations (e.g., [2]) is missing. \nSection 2 could be summarized and placed in an Appendix in favor of such a section. Within the \nproposed section it would also be better to discuss how your approach is compared to the experimental \nbaselines so that non-expert readers can understand the trade-offs of the different approaches. Moreover,\nin equation (1) it is not clear how the definitions are derived (sum over posterior distributions?). Also, \nhow is the local objective equation (3) derived? Even though the authors discuss uncertainty quantification \nthrough GAIN, the metric is never used in the rest of the paper. What is the update rule of LocalTrain \nin Algorithm 1? Is it the local update rule presented in equation (4)?\n\n(W2) Equally weighted FedAvg seems to provide the same performance as AdaPerFL in the wake-word detection task. \nSimilar for the DITTO-e. Can the authors elaborate more on these results? Moreover, there do not seem to be any \nimprovements on the sentiment analysis task both in terms of testing and training performance. Maybe, it would\nhave been better to demonstrate the results as in the case of the Alexa Audio domain by randomly sampling a set\nof clients from the available pool of 772 clients and showing the performance of the global and personalized \nmodels on a test dataset. Additionally, it is not clear why pretraining was required for both learning tasks \n(first task is reasonable since it is harder domain bit why for the second?), maybe that reasons the learning \nbehavior in the sentiment analysis task (i.e., similar performance for all approaches)? Table 1 and Figure 1 \nhave Self-FL as a method which is never introduced; I suspect that this the AdaPerFL.\n\n(W3) For the first task you only consider 5 clients for a federation. Why a so small number?  What is the distribution\nof training/valid/test sets at each client (s/th like {'train': #, 'valid': #, 'test': #} would be appropriate) in this task?\nMoreover, your proposed method is an adaptive learning approach, what is the distribution of local steps per client in your\nexperiments? Is there a particular range of local step values that each client or all clients follow? To assign the local steps\nto each client do you use the empirical estimations of equations (11) and (12) in equation (7)? What is the learning rate\nyou used for training?  \n\n[1] Wu, Jinze, Qi Liu, Zhenya Huang, Yuting Ning, Hao Wang, Enhong Chen, Jinfeng Yi, and Bowen Zhou. \n\"Hierarchical personalized federated learning for user modeling.\" In Proceedings of the Web Conference 2021, pp. 957-968. 2021.\n\n[2] Yurochkin, Mikhail, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia Hoang, and Yasaman Khazaeni. \n\"Bayesian nonparametric federated learning of neural networks.\" In International Conference on Machine Learning, pp. 7252-7261. PMLR, 2019.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_8xw5"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_8xw5"]}, {"id": "rSSgedRo8Gq", "original": null, "number": 1, "cdate": 1647914600267, "mdate": null, "ddate": null, "tcdate": 1647914600267, "tmdate": 1647914600267, "tddate": null, "forum": "B3z-nctzFZ5", "replyto": "B3z-nctzFZ5", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/-/Official_Review", "content": {"title": "Interesting perspective on personalized FL ", "review": "Summary: The work presents a framework to analyze personalized FL with bayesian models where the posterior mean for each FL (collaborative training) and local training are theoretically analyzed so that the uncertainty of each model can be quantified, and utilized for maximum personalized FL performance. With this framework, the paper gives theoretical insights into how PFL performance can be maximized by the proper initialization, number of local steps, and global model aggregation. Empirical experiments are done on Alexa Audio Data and Sent140 Data for validation of the proposed algorithm.\n\nPros: \n- The paper looks at an important problem of personalization in FL in the views of Bayesian models which has not been looked into a lot before.\n- The paper is clear to read including the mathematical notations and description of the algorithms. \n- The paper gives a concrete analysis into what kind of parameters (initialization, local steps, and aggregation) affect the personalized FL performance in a Bayesian framework and the exact forms of those parameters to maximize personalized FL performance.\n- The paper includes empirical validation on two different datasets.\n\nCons:\n- Although the theoretical insights are interesting, they are very difficult to implement in practice due to the pre-knowledge on the variance (uncertainty) for deciding the initialization and local steps. However, despite this difficulty, the AdaPerFL that the paper proposes is able to use the sample-variance to circumvent this problem and achieve reasonable performance, thus managing to compensate for this drawback. \n\n\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_S4x7"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper2/Reviewer_S4x7"]}]}, {"paper_url": "https://openreview.net/forum?id=S3ExnqKfF-9", "paper_id": "S3ExnqKfF-9", "reviews": [{"id": "HgezltOtG5", "original": null, "number": 3, "cdate": 1648097513970, "mdate": null, "ddate": null, "tcdate": 1648097513970, "tmdate": 1648097513970, "tddate": null, "forum": "S3ExnqKfF-9", "replyto": "S3ExnqKfF-9", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/-/Official_Review", "content": {"title": "Effective method for conducting backdoor attack of federated NLP tasks", "review": "This paper introduces a practical approach for injecting backdoor attacks into a federated learned model. The attackers only manipulate the embedding layers of a model for injecting the backdoor. Compared to the previously proposed backdoor attack on language models (where the attacker manipulates to change all layers' weights), the proposed attack is easier to inject and is harder to detect by the central server.\n\nExtensive experimental results indicate that the proposed attack is effective under various NLP tasks and transformer models. I'm convinced that the proposed attack is effective given the scales of the experiments.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_fc7i"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_fc7i"]}, {"id": "SW4x7e6q8zq", "original": null, "number": 2, "cdate": 1647910122707, "mdate": null, "ddate": null, "tcdate": 1647910122707, "tmdate": 1647910145731, "tddate": null, "forum": "S3ExnqKfF-9", "replyto": "S3ExnqKfF-9", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/-/Official_Review", "content": {"title": "Interesting topic and the method can be further improved", "review": "This work proposes a practical backdoor attack against NLP models in the Federate Learning scenarios by inserting malicious tokens in the word embeddings. The author demonstrates its effectiveness through many practical scenarios, e.g., large trigger tokens, etc. It would be better to explore inserting backdoor triggers in a more stealth manner, e.g., inserting incontinuous or dynamic backdoor triggers, inserting backdoor triggers without adding too many tokens besides the benign tokens. Since the attack method is adapted from CV methods, the robustness of the proposed method against potential defense mechanisms adapted from Image Classification tasks [1,2] should also be discussed.\n\n[1] Wang, Bolun, et al. \"Neural cleanse: Identifying and mitigating backdoor attacks in neural networks.\" 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 2019.\n\n[2] Guo, Junfeng, Ang Li, and Cong Liu. \"AEVA: Black-box Backdoor Detection Using Adversarial Extreme Value Analysis.\" ICLR (2022).", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_ECVk"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_ECVk"]}, {"id": "rKIg1FTULf5", "original": null, "number": 1, "cdate": 1647893879483, "mdate": null, "ddate": null, "tcdate": 1647893879483, "tmdate": 1647893879483, "tddate": null, "forum": "S3ExnqKfF-9", "replyto": "S3ExnqKfF-9", "invitation": "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/-/Official_Review", "content": {"title": "review", "review": "The paper presents a new attack extension of the embedding attack on NLP models to FL. Instead of training to optimize the whole model the attacker only focuses on a small single embedding of an unpopular token. \n\nI really liked the idea and think that it has a good potential impact, however I have a couple of concerns:\n\n1. Motivation -- FL in NLP is motivated by a smart keyboard application and therefore language generation task. I did not understand motivation under seq2seq tasks, neither summarization nor translation seem like would be good candidates for FL as there are no privacy constraints. I can understand classification, but not on the news dataset (which is hardly private) but rather some toxicity dataset.\n\n2. Experiments -- some details on seq2seq task would be great otherwise it's unclear what task exactly gets evaluated (I assume it's a summarization task as it uses ROUGE but still not clear). \"Trigger range\" discussion is also complex as it wasn't introduced before. \n\n3. Novelty -- the backdoor attacks on embeddings exist in literature as well as backdoor attacks on FL. Seems like it's a trivial operation to apply one to another. I cannot see why 3.3 is novel as it's the core assumption in all other backdoor FL papers -- other participants contributions can be ignored when computing backdoored model update.\n\nIn my opinion the key interesting part of the paper is that it can possibly evade norm-bound detection by modifying only a small model's embedding vector, however it has a very trivial way to defend -- simply check for norm updates of each embedding vector. \n\nOverall, I really like the idea but it needs more solid motivation and exploration. ", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_YEBb"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/FL4NLP", "aclweb.org/ACL/2022/Workshop/FL4NLP/Paper1/Reviewer_YEBb"]}]}, {"paper_url": "https://openreview.net/forum?id=SU5z8MKx_-9", "paper_id": "SU5z8MKx_-9", "reviews": [{"id": "rKIesg9stG5", "original": null, "number": 3, "cdate": 1648110066617, "mdate": null, "ddate": null, "tcdate": 1648110066617, "tmdate": 1648110727413, "tddate": null, "forum": "SU5z8MKx_-9", "replyto": "SU5z8MKx_-9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper19/-/Official_Review", "content": {"title": "Well written, Clearly communicated all complexities", "review": "This paper improves contextually relevant knowledge extraction by introducing common sense triple selection based on a ranking model.\n     \n[Strong]\nPaper is well written with detailed results and analysis demonstrating quality of the extracted schema graphs on two popular models (MHGRN, QA-GNN) and datasets (OpenbookQA, CommonsenseQA). Current papers triple selection based on reranker, iteratively finding the shortest path between any pair of concepts (using steiner tree approximations, pathfinding methods), employing lexical and embeddings based entity linking approaches for extracting schema graphs helps foster further research in knowledge extraction space.\n\n[Weak]\nThe current approach has lesser incremental gains on CommonsenseQA dataset vs baseline (signifying lesser transferability to other domains) when compared to OpenbookQA dataset vs baseline (signifying higher gains on indomain data) \n\n[Minor Typo]\nQA-GNN paper reference is wrongly mentioned in section 3.4\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_1Bkt"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_1Bkt"]}, {"id": "Sddg1jwpMfc", "original": null, "number": 2, "cdate": 1647658903132, "mdate": null, "ddate": null, "tcdate": 1647658903132, "tmdate": 1647658903132, "tddate": null, "forum": "SU5z8MKx_-9", "replyto": "SU5z8MKx_-9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper19/-/Official_Review", "content": {"title": "Simple, well-written contribution; appropriate fit for workshop", "review": "The authors introduce a triple selection method based on a ranking model and find that it improves QA accuracy over existing approaches. They also investigate methods to ensure that extracted triples form a connected graph. They argue that this connectivity is important both for model interpretability, and also because non-connectivity could limit the power of the GNN.\n\nOverall, the paper makes a nice contribution to the workshop and I recommend accept. It is relatively simple, and appropriate to its length. In a longer version, I would have liked to see a figure illustrating the intuition behind the approach, but due to page limits this may not have been possible.\n\nIt is also always good to include statistical significance results which seems to be missing here. ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_RBxX"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_RBxX"]}, {"id": "BLQe0dzjAZ5", "original": null, "number": 1, "cdate": 1647387253798, "mdate": null, "ddate": null, "tcdate": 1647387253798, "tmdate": 1647990042077, "tddate": null, "forum": "SU5z8MKx_-9", "replyto": "SU5z8MKx_-9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper19/-/Official_Review", "content": {"title": "Reasonable technical ideas, but lack of analysis, and question mark on reported gains", "review": "The paper discusses various ways to retrieve CSK statements for QA methods that rely on structured knowledge.\n\nThe ideas of zooming in on the retrieval part of the problem, in particular concerning lexical vs. embedding-based retrieval, and graph connectivity, is interesting. The technical content is reasonably presented, and the ideas are worth discussing at the workshop.\n\nAt the same time, there are critical issues:\n - Readability for all but a small expert circle is substandard, as the paper is devoid of examples\n - The analysis is narrow, on a single idiosyncratic KG, ConceptNet. The proposed methods would gain much credibility if shown to work not only on that, but also, e.g., on Quasimodo, Atomic, or Ascent.\n - There is no analysis of system outputs, only aggregate numbers. I understand that human evaluations of this task are hard, but I honestly wonder whether the authors ever looked at their data themselves. There should at least be hand-picked comparisons of system outputs. Are there any human insights on how the proposed methods do better (if they do)?\n - The reported gains are small, and it is unclear whether they are statistically significant. Having worked on this setting myself, I am skeptical of suggestions that CSKGs truly help in the problem (and the result tables should show a no-KG baseline). Moreover, there seem to be confounding factors, as different methods produce KGs of different size, which make attributing gains to the proposed methods even harder - perhaps the gains just come from finding the sweet spot of right KG size? \n\nMinor points:\n - The term \"schema graph\" appears odd. \"Schema\" to me rather refers to data organization, not to actual grounded triples.\n - \"We make our code available at anonymous\" - This isn't helpful - there are enough ways nowadays to anonymously share actual files, at a workshop I don't expect code sharing anyway, but at a conference I would not let this pass (if code/data sharing was a requirement).", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_NAhj"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper19/Reviewer_NAhj"]}]}, {"paper_url": "https://openreview.net/forum?id=H4xz8zteub9", "paper_id": "H4xz8zteub9", "reviews": [{"id": "BfxO5g9qM5", "original": null, "number": 3, "cdate": 1648169103607, "mdate": null, "ddate": null, "tcdate": 1648169103607, "tmdate": 1648169164923, "tddate": null, "forum": "H4xz8zteub9", "replyto": "H4xz8zteub9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper17/-/Official_Review", "content": {"title": "An interesting study with minor weaknesses", "review": "Summary:\n\nThe authors present a very interesting analysis of the extent to which common sense knowledge is embedded/used with large language models (LLMs) - on a narrative task. Specifically, authors aim to address the following key important questions: (a) aspects of common sense knowledge accessible to LLMs; (b) aspects of common sense that could be leveraged from signals obtained through external knowledge graph (KG) sources like COMET.  Experimental findings show that increasing size of the LLM model helps in capturing common sense better; incorporating external KG helps in improving model performance in answering questions that are not directly available in the narratives.\n\n\nStrengths:\n\nThe paper is well-organized, well-written and easy to follow. \n\nI thoroughly enjoyed reading this work and I am sure that this work would be a great fit for this workshop audience.\n\nExtensive experiments have been performed to draw several interesting insights on the problem setting. \n\n\nWeaknesses:\n\nI did not find any major weaknesses with this work.\n\nCan these findings be generalized to other datasets/domains? It would have been really great to have one more dataset (preferably on a similar but different task), to better quantify the conclusions made in the paper.\n\nIn section 6, I didn\u2019t exactly understand the differences between goal-seeking and desire categories. Are you planning to provide supplemental material with this effort? More fine-grained categories would make this analysis even stronger.\n\nI struggle to identify the differences between the experiment setup described in section 3.2.1 and 3.2.2. It would help to make this more clear, perhaps an example would help.  \n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_xGYV"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_xGYV"]}, {"id": "r5Ux_tFxcz9", "original": null, "number": 2, "cdate": 1648130432302, "mdate": null, "ddate": null, "tcdate": 1648130432302, "tmdate": 1648130432302, "tddate": null, "forum": "H4xz8zteub9", "replyto": "H4xz8zteub9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper17/-/Official_Review", "content": {"title": "Using COMET for TellMeWhy", "review": "In this paper, the authors study Why questions in the TellMeWhy dataset using COMET as a source of relevant commonsense relations. They analyze the relative improvements over a base T5 model when (a) increasing the model size, (b) injecting knowledge from COMET as part of the task input, and (c) asking the model to generate COMET relation type as an explanation in addition to its answer. Their results show that the larger model, as expected, yields substantial improvements over the base. Interestingly, they find that the question specific COMET relations can provide substantial improvements for both base and large models, with additional possible gains when asking the model to also generate COMET relation type.  So, they augment a large model with noisy hints from COMET and find that this improves performance on the  task. \n\nOverall this is decent work. I don't have any particular criticism, however, I have to bring this up that at this point using commonsense knowledge from COMET ATOMIC at the realm of reasoning in narratives is not particularly novel because several works have done this. such as abductive reasoning work by Bhagavatula et al. (2019) for abductive reasoning, and self talk by Shwartz et al. (2020)  \n\nThere are couple of follow up questions\n1) Since Tell me why is focused on narratives why not use ParaCOMET which is specifically designed for narratives and is discourse aware\n2) Did you also look into concept centric commonsense?\n3) Your related work on  Incorporating External Knowledge is great but there needs to be more discussion on prior work which used COMET such as\ni)  Ammanabrolu et al. (2020) for story generation,\n          Automated storytelling via causal, commonsense plot ordering\nii)  Majumder et al. (2020) for dialog generation\n         Like hiking? you probably enjoy nature: Persona-grounded dialog with commonsense expansions. \niii) Chakrabarty et al. (2020a; 2020b; 2022) \n         R\u02c63: Reverse, Retrieve, and Rank for Sarcasm Generation with Commonsense Knowledge\n         Generating similes effortlessly like a Pro: A Style Transfer Approach for Simile Generation\n         It\u2019s not Rocket Science: Interpreting Figurative Language in Narratives", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_w3mr"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_w3mr"]}, {"id": "rbNlbrm6QM9", "original": null, "number": 1, "cdate": 1647723320816, "mdate": null, "ddate": null, "tcdate": 1647723320816, "tmdate": 1647723320816, "tddate": null, "forum": "H4xz8zteub9", "replyto": "H4xz8zteub9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper17/-/Official_Review", "content": {"title": "Review", "review": "Summary\n- This paper considers the QA task of Why questions, which requires commonsense knowledge. The paper studies (1) what aspects of this knowledge is accessible to pretrained language models, and (2) what aspects can be made accessible via external commonsense resources such as COMET. The authors show that the QA performance can be improved by (a) increasing the LM size, (b) injecting knowledge from COMET as part of the task input, and (c) teaching the model to generate COMET relation type as output besides the answer. The paper conducts extensive experiments, and analyzes what types of commonsense knowledge pretrained LMs already have, and what can be augmented via COMET. \n\nReasons to Accept:\n- The paper asks interesting and important questions (what knowledge pretrained LMs already have, what can be gained from external knowledge, what knowledge remains inaccessible), and answers them with sufficient experiments.\n- The paper is clear and well-written. \n\nWeakness and questions:\n- Do you have an intuition why does the larger model (T5 11B) captures more COMET relations than smaller model (T5 base)? Was T5 11B trained on more data, or simply the model parameter count is larger and has more capacity to cover more relations? Why T5 11B is good at capturing particular relations (e.g. xReason) but not others (e.g. HasSubEvent)?\n\nTypos/grammar:\n- L234: \"both these\" -> \"both of these\"\n- L503: \"wee\" -> \"we\"", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_5cXn"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper17/Reviewer_5cXn"]}]}, {"paper_url": "https://openreview.net/forum?id=Bx-fUfKedZ5", "paper_id": "Bx-fUfKedZ5", "reviews": [{"id": "BlWe9_r8qGq", "original": null, "number": 3, "cdate": 1648153969995, "mdate": null, "ddate": null, "tcdate": 1648153969995, "tmdate": 1648154229976, "tddate": null, "forum": "Bx-fUfKedZ5", "replyto": "Bx-fUfKedZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper16/-/Official_Review", "content": {"title": "Simple and elegant approach to post-hoc error correction", "review": "### Paper Summary:\n\nThis paper focuses on improving GPT-3's performance post-deployment, without any retraining, via a growing repository of interactive user feedback. Through correcting GPT-3's misunderstanding of question intent via a key-value store of user questions and corrective feedback, the authors develop a system to edit prompts through such feedback from previously-asked, similar questions.\n\nEvaluating on 4 tasks (lexical relations, word scrambling, and 2 variations of ethics reasoning), the authors show that their method of maintaining a growing memory store coupled with dynamically injecting feedback into prompts is useful in improving GPT-3's accuracy over time.\n\n\n### Paper Strengths:\n\nThis paper takes a simple but effective step towards post-deployment error correction. Given that retraining (or, sometimes even large scale finetuning) may not always be tractable, the authors' conceptual framework of a lookup table for previously committed errors is straightforward and task-independent. \n\nIn addition, incorporating direct user feedback in future model interactions helps to improve interpretability of model output and the model's usability, given that small errors in intent understanding can be corrected post-hoc.\n\n\n### Paper Weaknesses:\n\n1. Evaluation of feedback: Given that the prompt is directly edited using feedback provided by users, it would be helpful to understand the model's sensitivity to the user feedback. For example, analysis of lexical sensitivity, robustness to noise in feedback, or other such analysis of user-provided feedback that did not aid accuracy/performance would help to understand the practical implications of using this framework with GPT-3. \n2. Evaluation of \"u\": Likewise, for more complex questions or tasks, it seems like a more thorough evaluation of the generated question intent (via something like a human evaluation study) would be useful. Given that this approach is using humans in the loop, robust evaluation of the model's \u201cunderstanding\u201d of the task and the sensitivity/role of user feedback would help contextualize the limitations or practical applications of the approach.\n3. Scalability: The key-value store (and thus the retrieval component) plays an instrumental role in the performance of the overall system design, but, to my knowledge, the paper does not include a discussion of the scalability of their approach. Given that the memory is simply expected to accumulate over time, this feels like an important dimension of analysis or discussion.\n\n\n### Overall assessment\n\nOverall, I think this paper is a nice step towards post-hoc correction of models with humans in the loop, and could be incredibly effective in certain practical settings.\n\n### Typos\n\n1. Line 176: add \"than the\"\n2. Line 428: \"improves\" --> \"improve\"", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_hT44"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_hT44"]}, {"id": "rcUl-GC-tM5", "original": null, "number": 2, "cdate": 1648070153115, "mdate": null, "ddate": null, "tcdate": 1648070153115, "tmdate": 1648070153115, "tddate": null, "forum": "Bx-fUfKedZ5", "replyto": "Bx-fUfKedZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper16/-/Official_Review", "content": {"title": "Solid paper with small writing issues.", "review": "### Pros\n\n* The paper presents a simple method that works.\n* The proposed method does not require model re-training which would be expensive.\n* The proposed method supports a natural user-machine interaction.\n\n### Cons\n\n* One downside of the paper is that it only studies the GPT-3 model. It would have been interesting to see if the results apply to the open-source equivalents: GPTNeo and GPTJ.\n\n### Minor things\n\n* Lines 127, 163: The citations should not be in parenthesis, as the authors' names are part of the discourse.\n* Line 428: \"Does pairing GPT-3 with MEM-PROMPT improves\" - Typo. It should say \"improve\".\n\n### Issues with the references \n\n* When possible, please add URLs to the references as the template uses them.\n* Johnson et al. (2017) \u2013 Cites preprint instead of the article's peer-reviewed version.\n* Liu et al. (2021a) and Liu et al. (2021b) are duplicates of each other.\n* Liu et al. (2021c) is missing the ArXiv ID.\n* Marcus (2021) is missing the URL and the title is not clickable. The web page's URL should appear.\n* Mitchell et al. (2021) is missing the ArXiv ID.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_bLgH"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_bLgH"]}, {"id": "Bzg0fHqUG5", "original": null, "number": 1, "cdate": 1647908117867, "mdate": null, "ddate": null, "tcdate": 1647908117867, "tmdate": 1647908117867, "tddate": null, "forum": "Bx-fUfKedZ5", "replyto": "Bx-fUfKedZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper16/-/Official_Review", "content": {"title": "A generally strong paper with some weaknesses to be addressed", "review": "The presented work proposes a straight-forward method for improving the performance of pre-trained LMs (PLMs) on a variety of tasks through corrective feedback. The feedback is first supplied by a (simulated) user and stored in a memory component. In the main experiments, such feedback contains information that is intended to correct the model's faulty reasoning, e.g. by elaborating on or clarifying the task that the user is expecting the model to perform. The feedback memory can subsequently be used as a source of additional information for new queries to the model, whereby corrective feedback is retrieved from the memory that was previously provided for queries that are most similar to the current one. The query and the retrieved feedback are subsequently combined with the task-specific prompt and given to the PLM as input, which has empirically been found to outperform baselines that either do no utilize the corrective memory at all, or employ a non-selective memory module. The experimental section includes lexical as well as ethical reasoning tasks, although the authors also describe the application of the proposed method to code-switched question answering and question answering with label feedback (as opposed to natural language corrections).\n\nOverall. the proposed method is compelling, easy to implement, and effective according to the provided experimental evaluation. The corrective feedback memory is a neat idea for leveraging and re-using user feedback in an efficient manner and could potentially be applied to many diverse tasks.\n\nThere are some minor issues with the paper that should be corrected:\n- Line 180: The notation is confusing  - does x_i/j represent the input or the error? \n- Line 308: It would be appropriate to provide citation for Social Chemistry 101, as well.\n- Figure 3: Some of the example questions / templates are oddly phrased, e.g. \"on the lines of\" which should probably be either \"in the vein of\" or \"along the lines of\"? Could the authors clarify?\n- Line 379: I assume this should be \"cosine similarity\" rather than \"cosine distance\", as the latter with a threshold of 0.9 would be extremely permissive.\n- Line 385: Concatenation is not a gating function (while gating may be explored in the future, it is not part of the presented approach); relatedly, the breakdown of the approach in section 3.1. makes it sound more complex than it actually is and is detrimental to the paper's clarity (e.g. both the \"prompter\" and the \"combiner\" are simple concatenation steps and don't really need extra terminology attached to them).\n- Line 428: improves -> improve\n- Table 2: Should be positioned under 4.1.1 header and does not have to include the GROW-PROMPT row. \n- Figure 4: Should get a better caption, e.g. one that explains that the legend denotes the likelihood of feedback being drawn from memory, as it does not to be explicitly stated anywhere else.\n- Figure 5: The authors should address why feedback retrieval likelihood of 0.5 performs similar to or better than 1.0.\n- Figure 6, caption: Should be \"for GROW-PROMPT and MEM-PROMPT\".\n\nIn closing, I think this paper is really neat, fits well within the body of commonsense reasoning research, and would be a worthy addition to the workshop.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_F7Sg"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper16/Reviewer_F7Sg"]}]}, {"paper_url": "https://openreview.net/forum?id=ShMlIzKgOW9", "paper_id": "ShMlIzKgOW9", "reviews": [{"id": "SNgeq8pz_Gc", "original": null, "number": 3, "cdate": 1648008530079, "mdate": null, "ddate": null, "tcdate": 1648008530079, "tmdate": 1648008530079, "tddate": null, "forum": "ShMlIzKgOW9", "replyto": "ShMlIzKgOW9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper15/-/Official_Review", "content": {"title": "Review of the paper", "review": "# Summary\nThis work investigates the augmentation of pretrained language models (LMs) with knowledge graphs (KGs) for the cause-effect relation classification and commonsense causal reasoning tasks. They verbalize the ATOMC-2020 KG triples into natural language which they use to continually pretrain BERT. Their results show that the continually pretrained LM outperforms non-continually pretrained ones on two commonsense causal reasoning benchmarks, COPA and BCOPA-CE, and a Temporal and Causal Reasoning (TCR) dataset.\n\n# Contributions\n1. They study pretrained LMs augmented with the ATOMIC-2020 knowledge graph in the commonsense reasoning domain.\n2. They perform experiments to show that these augmented LMs can outperform non-continually pretrained ones and other baselines on the cause-effect relation classification and commonsense causal reasoning tasks.\n\n# Pros\n1. The writing is generally very clear, which makes the paper easy to follow.\n2. The result on the TCR task looks very good!\n3. Approach the (causal) commonsense reasoning task, which is very important.\n\n# Cons\n1. The framework of continually pertaining LMs using verbalized KG triples is something that has been done previously [1]. The only things that are different in this paper is to apply this technique to a different KG (ATOMIC-2020) and to fine-tune on a few different tasks and benchmarks. So there is a lack of novelty.\n2. I find the result in Table 4 unsatisfactory. First, what is the b-l-reg baseline and why does the ATOMIC-BERT model underperform that baseline? Second, the fact that using all the categories for ATOMIC-2020 actually hurt performance but only using the event ones does not fit well with the claim of the paper that general commonsense knowledge helps the causal commonsense reasoning task. It may just be the case that the event triples in ATOMIC-2020 is in a closer domain to the BCOPA-CE and it is actually the in-domain further pertaining that is helping. Third, why not just try using the causal relations in ATOMIC-2020 (\"cause\", \"effect\" etc)?\n3. The standard deviations are not reported for all the experimental results.\n4. I know it is not a fair comparison to compare ATOMIC-BERT and T5 and DeBERTa, but looking at the latter two's numbers on the COPA-test, the task seems a solved one. I am not sure how significant/useful it is to continue working on this benchmark.\n\n# Other comments and questions\n1. An ablation study in the effect of different ways to verbalize the KG triples and e.g. whether the grammar correction step is necessary can be useful and interesting.\n2. Which split of ATOMIC-2020 is used?\n\n# References\n1. Guan, Jian, et al. \"A knowledge-enhanced pretraining model for commonsense story generation.\" Transactions of the Association for Computational Linguistics 8 (2020): 93-108.", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_Yi8h"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_Yi8h"]}, {"id": "B6PeGTiJuGc", "original": null, "number": 2, "cdate": 1647995834097, "mdate": null, "ddate": null, "tcdate": 1647995834097, "tmdate": 1647995834097, "tddate": null, "forum": "ShMlIzKgOW9", "replyto": "ShMlIzKgOW9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper15/-/Official_Review", "content": {"title": "Unique limited contribution of cause-effect models created by knowledge-augmented LM pretraining", "review": "This paper proposes a method for knowledge-augmented LM pretraining with cause-effect information. The method is targetted towards causal reasoning benchmarks (TCR, COPA, and BCOPA-CE). The method performs better than vanilla and existing system baselines on TCR, and below some baselines on the COPA/BCOPA-CE tasks.\n\nThe paper is overall interesting. Its novelty is limited as the method is already known in the literature, but the evaluation is unique which may be enough for a workshop paper.\n\nWeaknesses:\n* It is unclear how the citations in paragraph 1 of section 1 relate to the statement that PLMs have been leveraged in for understanding causality in language.\n* The statement that model performance is very dependent on the domain and downstream tasks is reasonable, but it is broad, and it is unclear how this paper addresses this challenge.\n* The evaluation contains various benchmark-specific adaptations which are not anticipated in the experimental setup, and feel like hacks to improve performance ad hoc. It would be good to give these configurations a better structure in the paper, ideally by stating them within the method description or within the experimental setup. Moreover, it would be good to clarify how each of these configurations relates to the research question investigated in this paper.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_G1op"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_G1op"]}, {"id": "HEelY6fTQGc", "original": null, "number": 1, "cdate": 1647723201157, "mdate": null, "ddate": null, "tcdate": 1647723201157, "tmdate": 1647723201157, "tddate": null, "forum": "ShMlIzKgOW9", "replyto": "ShMlIzKgOW9", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper15/-/Official_Review", "content": {"title": "Review", "review": "Summary\n- The technique of continually pretraining language models on commonsense knowledge graph triples has been shown useful for some downstream tasks, but it may depend on the specific domain and tasks. This work investigates the effect of this technique on the task of cause-effect relation classification. The authors verbalize the ATOMIC2020 knowledge graph and continue to pretrain BERT-large on it. The authors show that this simple method can boost the performance in cause-effect classification. \n\nReasons to Accept:\n- The effect of commonsense knowledge graphs for cause-effect relation classification is an interesting topic, but has not been studied systematically. This work performs an interesting investigation into this research question.\n- The paper is clear and well-written overall. \n- The authors will publicly release the knowledge graph verbalization codes and the trained models\n\nWeakness and questions:\n- Overall, I think that the experiments/analyses could be polished a bit more. Below are s few suggestions.\n- ATOMIC-BERT-large (Event, Physical, Social relations) underperforms the baseline BERT-large on two datasets (Table 2, 4). It'd be great if the authors could investigate more into why this is the case. Do Physical/Social relations have very different distributions of knowledge than the tasks of interest (i.e. cause-effect prediction)? Even though ATOMIC-BERT-large (Event) outperforms the baseline, it is a bit concerning that in order for the proposed method to work, it needs to identify what kinds of relations within ATOMIC2020 is useful or hurting for the task and remove the hurting relations. It'd be ideal if the authors could think about a bit more elegant method to address this issue.\n- Additionally, it is not clear why adding prompt helps for BCOPA-CE but hurts for COPA task. It'd be great if the authors could conduct more in-depth analysis for their results. \n\nTypos/grammar:\n- L184: redundant parenthesis in \"(MLM)\"?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_327F"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper15/Reviewer_327F"]}]}, {"paper_url": "https://openreview.net/forum?id=S6Pl8ztg_b5", "paper_id": "S6Pl8ztg_b5", "reviews": [{"id": "BbgP2-hYf9", "original": null, "number": 3, "cdate": 1648112046659, "mdate": null, "ddate": null, "tcdate": 1648112046659, "tmdate": 1648117215837, "tddate": null, "forum": "S6Pl8ztg_b5", "replyto": "S6Pl8ztg_b5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper14/-/Official_Review", "content": {"title": "a good benchmark paper overall", "review": "The paper proposes CIKQA, a commonsense benchmark, which unifies several commonsense task into QA format and associates them with relevant knowledge. Experiments shows that models can better learn inference and generalize across tasks with proposed formulation and usage of knowledge.\n\nStrength:\n1. the proposed benchmark can be a useful resource for the field. \n2. the experiments and analysis are comprehensive and give interesting insights. \n3. the writing is clear and easy to follow.\n\nWeakness:\n1. the coverage of proposed benchmark is limited, it doesn't include any physical or social commonsense tasks, like PIQA or SocialIQA.\n2. the idea isn't entire novel - unified task formulation and knowledge injection have already been well-studied in QA domain. \n3. missing related works: \n[1] Liu, Jiachen et al. \u201cGenerated Knowledge Prompting for Commonsense Reasoning.\u201d ArXiv abs/2110.08387 (2021): n. pag.\n[2] Shwartz, Vered et al. \u201cUnsupervised Commonsense Question Answering with Self-Talk.\u201d ArXiv abs/2004.05483 (2020): n. pag.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_9YV6"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_9YV6"]}, {"id": "SVhe50AXtf5", "original": null, "number": 2, "cdate": 1648078545728, "mdate": null, "ddate": null, "tcdate": 1648078545728, "tmdate": 1648112734757, "tddate": null, "forum": "S6Pl8ztg_b5", "replyto": "S6Pl8ztg_b5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper14/-/Official_Review", "content": {"title": "Commonsense benchmark paper - simple and well-presented", "review": "Overall the paper seems comparatively complete and solid to me. The authors propose the benchmark CIKQA with a clear task formulation and detailed steps on how to extract supporting knowledge, as well as a strong baseline that takes advantage of its format. Experiments are also well-executed to answer the authors' questions regarding leveraging provided knowledge, distinguishing gold knowledge, and model generalization ability on different tasks.\n\nHere are my comments:\n- It is a bit overclaimed to me that CIKQA can focus on learning to do the inference with the current task setting. \n- The related work discussion seems a bit sparse to me.\n- I am a bit concerned about the novelty as the unified format and injecting knowledge have all been discussed widely.\n- From Table 1, there are only 3,007 instances with gold knowledge, but for experiment results in Figure 3, even models with the suffix `_gold` could still be trained with $10^4$ training instances. Hope the authors could address the issue there.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_FcT2"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_FcT2"]}, {"id": "BOde3ZuhAZq", "original": null, "number": 1, "cdate": 1647392771915, "mdate": null, "ddate": null, "tcdate": 1647392771915, "tmdate": 1647392771915, "tddate": null, "forum": "S6Pl8ztg_b5", "replyto": "S6Pl8ztg_b5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper14/-/Official_Review", "content": {"title": "review", "review": "The authors propose a reformulation of commonsense reasoning QA tasks\nthat attempts to separate knowledge (e.g., facts as specified by a KG)\nfrom inference (i.e., reasoning over a given set of facts). Their\nsetup is to pair a small knowledge graph with each question that\ncontains the relevant knowledge to answer the question. They report\nexperimental results in this setting, showing that their model,\nJointI, 1) effectively incorporates the knowledge graph information in\na fewer-shot setting (e.g., 100-1000 points); and 2) transfers between\ntasks better than if the model didn't have explicit knowledge handed\nto it.\n\nI commend the authors for their attempt to solve a difficult problem:\nindeed, the distinction between factual knowledge and inference over\nthat knowledge is rather illspecified in the commonsense domain.  The\nproposed approach: converting and then augmenting existing QA datasets\nwith all the knowledge the might need gives a potentially nice\nsolution to this problem: i.e., by conditioning on \"all of the\nknowledge\", the algorithms can focus entirely on inference; similarly,\nby retrieving knowledge as a first step. I also think the results here\nregarding generalization are quite interesting! Because we expect that\nthe inference required for commonsense reasoning tasks may be shared,\nthe transfer results suggest that, moreso than a model without\nexplicit knowledge provided, an inference-focused model may generalize\nbetter.\n\nMy biggest concern is that I'm not entirely convinced that this setup,\nas the authors claim, fully separates the knowledge versus inference\nquestion. While the approach makes sense in theory (i.e., conditioning\non all needed knowledge), 1) there are still pieces of commonsense\nknowledge required to, e.g., interpret the small KGs that are paired\nwith each question. To take the example in Figure 2: one simple case:\nan algorithm must know that sleeping is a type of resting. And 2)\nmodels could simply ignore the given knowledge graph in this setup,\ne.g., if one was to use a pretrained language model that was already\nimparted with both knowledge and inferential capacity. The authors do\nuse BERT-Small in some experiments and performance improves when the\ngraph is included in the input, but, I suspect that if more powerful\npretrained models were used the large performance gaps presented\nbetween Table 2 (a) vs. Table 2 (b) might vanish.\n\nOverall, the authors report some interesting results for their new\nsetup, which may have practical promise for few-shot learning with\nsmall models. However, I do worry that CIKQA has limitations that need\nto be addressed if larger models were to be applied to such a task.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_MN7e"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper14/Reviewer_MN7e"]}]}, {"paper_url": "https://openreview.net/forum?id=rg-zrfteOZc", "paper_id": "rg-zrfteOZc", "reviews": [{"id": "BtZxxr8hqz5", "original": null, "number": 3, "cdate": 1648178744420, "mdate": null, "ddate": null, "tcdate": 1648178744420, "tmdate": 1648178744420, "tddate": null, "forum": "rg-zrfteOZc", "replyto": "rg-zrfteOZc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper11/-/Official_Review", "content": {"title": "Interesting paper of producing reasoning steps for QA", "review": "Strengths\n- The paper describes an interesting approach to producing an explanation, in the form of a knowledge base tuple, for a QA answer. This is potentially interesting to not only the commonsense reasoning community but also people interested in understanding the explicit reasoning steps behind model answers\n- The model achieves strong performance on two evaluation settings\n\nCons\n- It is hard to determine the quality of the manual annotation and the output without seeing some examples, and there appears to be only one in the paper.\n- There are some experimental details that should be clarified, especially on the input/output of the different components\n\nQuestions:\nL165: what is this way? It should be described here, so the paper is self-contained.\nL181: What would the actual relation from a database be here?\n3.3.: Not completely clear what the answer model is actually producing\n3.2: Do you use greedy search to select a relation to use here? Or do you compute the object model over all possible relations?\nL249: how do you get the explanation from the set of relations? how does the second baseline choose the most likely inference? I think I understand some about the baselines from looking at the results, but the actual description needs to be clarified when they are introduced.\nL269: do you compute any kind of agreement here? how do you check for quality?\n\nTypos:\nL180-181: \"the commonsense usually\" --> \"the commonsense that usually\"\nL182: \"physical entities\" --> \"physical attributes\"\nL243: should this be \"object model\" not \"relation model\"?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_anxb"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_anxb"]}, {"id": "HqgNkGVFMc", "original": null, "number": 2, "cdate": 1648079324216, "mdate": null, "ddate": null, "tcdate": 1648079324216, "tmdate": 1648079324216, "tddate": null, "forum": "rg-zrfteOZc", "replyto": "rg-zrfteOZc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper11/-/Official_Review", "content": {"title": "Interesting work but can be improved with clearer presentation", "review": "This work proposes a method for explainable question-answering for SocialIQA. The explanations are retrieved from ATOMIC, which contains (subject, relation, object) tuples that can provide helpful evidence/explanation for answering the question. The method trains a pipeline of generative models: i) for generating a relevant relation r in ATOMIC that could be useful for predicting the answer, ii) generating the object using r; and finally, iii) generating the answer using the generated + question and context.\n\nThe three-step approach achieves results comparable to a pre-trained model, but has the added advantage that it can provide the tuples used for answering the question, possibly adding to the explainability of the model.\n\nThe paper presents an interesting case of using KB information for commonsense question answering. \nHowever, the present version contains several shortcomings in both formulation and experimental design, listed next. \n\n* Trivial baselines: The baselines for retrieving knowledge from the external KB are pretty weak. For example, we can train a simple classifier for relation prediction by treating context in SocialIQA and subject in ATOMIC as exchangeable. Then, the prediction of the classifier can be used as an explanation. It appears that such an approach will work, and might be worth experimenting with in the future.\n\n* Clarity of presentation: Several important details are unclear. For instance, ATOMIC has tuples (s, r, o), and each QA sample is (c, q, a). As the authors mention, for SOCIAL-IQA, c determines s, but r and o are unknown. However, the method description mentions that the \"object model is learned first.\" How can the object model be learned without (r, c, o) tuples? This also holds for learning the relation model. I suspect it is trained by simply treating s == c in ATOMIC, but this is an important detail that should be made more explicit. Please also see possible corrections in the formulation.\n\n\n\n\n* Novelty: the main idea of leveraging external knowledge for commonsense reasoning has been explored in several works. The primary differentiation seems to be that the proposed method does not require hand-annotated explanations and uses dynamic KB. The difference with Bosselut 2021 (which the authors mention) is not completely clear. Further, see [1] for an approach that does not require explicit annotation and does not rely on fixed KBs. Overall, better positioning concerning the related work will help understand the core contributions of this work.\n\n\n\n### Possible corrections in the formulation:\n\n1. In the max_ equation, the object model should also condition on the question for the chain rule factorization to work. Currently, there is an implicit assumption that o is independent of q given c, which may or may not be valid. Consequently, the authors may try conditioning on the question in the object model as well. It might improve things! As a side remark, V* is not specified. The notation also changes from $\\theta$ to $\\theta\u2019\u2019$ without any explanation.\n\n2. L224: \"To get an explanation\u2026.\" The following equation appears to be incorrect. First, isn't z = (r, o), and thus the explanation should contain both the terms? Second, o is introduced in the equation on the RHS, but there is no marginalization over it. I suspect there's a typo/problem with the formulation. \n\n\n\n\n\n### Questions: \n\n1. L130: Due to 130 this ambiguity, humans tend to perform explicit 131 reasoning afterwards. Therefore, we consider the 132 explanation to come after an answer being chosen.\n\nWhat are the implications of this statement for your method? I don't think that the answer goes back to generating the input?\n\n\nOverall, I think the work highlights an important area of commonsense reasoning and thus will be a useful addition to the workshop. However, I hope the paper improves by adding the clarifications mentioned above.\n\n---\n\n[1] Madaan, Aman, Niket Tandon, Dheeraj Rajagopal, Peter Clark, Yiming Yang, and Eduard Hovy. \"Think about it! Improving defeasible reasoning by first modeling the question scenario.\" In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 6291-6310. 2021. \n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_F2Z9"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_F2Z9"]}, {"id": "SgZepnn-tfq", "original": null, "number": 1, "cdate": 1648069812581, "mdate": null, "ddate": null, "tcdate": 1648069812581, "tmdate": 1648069860481, "tddate": null, "forum": "rg-zrfteOZc", "replyto": "rg-zrfteOZc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper11/-/Official_Review", "content": {"title": "Review", "review": "# Summary\nThis work tackles the problem of explainable commonsense QA. They propose a latent-variable model that identifies what type of knowledge from an external knowledge base may be relevant to answering the question, computes the commonsense inferences and predicts the answer. The method can therefore learn to provide posterior rationales for why a certain answer was chosen. Experimental results show that the model can identify the correct reasoning step in twice as many examples compared to an existing unsupervised approach for producing explanations for the socialIQA task, while still maintaining comparable accuracy to end-to-end pretrained models.\n\n# Contributions\n1. Propose an explainable latent-variable commonsense QA model.\n2. Perform experiments to show that the model can accurately identify the reasoning steps for the socialIQA task, while also maintaining predictive accuracy.\n\n# Pros\n1. Tackle an interesting and important problem: explainability for commonsense reasoning.\n2. Thorough evaluation of the proposed model, including manually annotating the groundtruth reasoning steps of 500 examples in socialIQA test sets and evaluating the model's accuracy in identifying those reasoning steps.\n3. The proposed generative model is novel.\n4. The proposed model can accurately identify ground-truth reasoning steps.\n\n# Cons\n1. The writing is not that clear and the paper is hard to follow in general. Working through an example instead of just showing this plate notation in Figure 1 can help. Restructuring and rewriting of the paper are needed.\n2. I did not get the general message of the paper until I read it several times. I suggest in your writing you stress that the paper proposes a commonsense QA model that is **explainable**.  At the end of day, the paper proposes a model for commonsense QA. The ability of generate explanations is just one of its characteristics.\n3. The arguments that humans first reach an answer then work backwards to figure out the commonsense knowledge they use on line 122-132 are not that convincing to me. Maybe switch to a better example.\n4. Not sure what the \"KB-based\" baseline is for Table 3 even after reading the description on line 251-254. Does \"external KB\" here mean COMET?\n5. No standard deviations are reported in Table 2.\n\n# Other comments and questions\n1. On line 158, what does \"such that \\sum_zP(a,z|c,q)\" mean?\n2. On line 163-166, I am not sure how this computation is done even if I have read the Bosselut et al 2021 paper.\n3. The citation on line 189 is misformatted.\n4. Notation inconsistency for V* (line 159, 161 and 220)\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_GP1G"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper11/Reviewer_GP1G"]}]}, {"paper_url": "https://openreview.net/forum?id=BVelBzKlOWc", "paper_id": "BVelBzKlOWc", "reviews": [{"id": "HBrxEZA3cGc", "original": null, "number": 3, "cdate": 1648180732467, "mdate": null, "ddate": null, "tcdate": 1648180732467, "tmdate": 1648180732467, "tddate": null, "forum": "BVelBzKlOWc", "replyto": "BVelBzKlOWc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper9/-/Official_Review", "content": {"title": "Analysis of LM understanding of specific presuppositions and implicatures ", "review": "Strengths\n- Probing LM understanding of pragmatic meanings is an interesting area and the paper presents a new approach to doing this\n- the results as presented are promising, using data from cognitive science\n\nWeaknesses\n- there are many missing details that make parts of the paper difficult to understand (see questions below)\n- it is difficult to fully understand the results, due to lack of clarity around the experiment details (especially the metrics) and what is being computed. There is also an issue of whether the results are affected by co-occurrence, which is mentioned but not addressed. \n- There is no analysis of the types of errors the model is making, or even what the model outputs look like on examples. These are needed to fully understand the results and approach\n\n\nQuestions\nL049-050: What is this example with \"the\" saying? Is it just an example of a presupposition? If so, this should be made clear\nL052-053: Similarly to above, its not clear what the \"some\" sentence means.\nL081: what is N400? why is this relevant?\nL106: what is \"contrastive distribution\"?\nL117: what is \"percentage mean\"?\nL130: the experiments and data from Singh et al. are mentioned without any description. What is this study? What was it doing? We need this information to understand the end of the paragraph around L147.\nL200: why is this the measure of pragmatic skill?\nL212: what is the data from Nieuwland et al?\nL238: this would seem to raise questions about the strength of the conclusions being drawn. Why is this not the case? \n\n\nTypos/suggestions:\nL024: \"I\" --> \"we\" (and throughout the paper)\nL052-053: \"most people generally implies\" is not grammatical\nL074: \"survey\" --> \"surveys\"\nL083-084: this sentence is not grammatical\nL097: \"meaning\" --> \"meanings\"\nL129: \"card\" --> \"cards\"\nL166: \"shool\" --> \"school\"\nL184 and L186: \"succeed\" --> \"to have succeeded\"", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_CQLG"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_CQLG"]}, {"id": "SqLxUR_Xtfc", "original": null, "number": 2, "cdate": 1648077005707, "mdate": null, "ddate": null, "tcdate": 1648077005707, "tmdate": 1648077054262, "tddate": null, "forum": "BVelBzKlOWc", "replyto": "BVelBzKlOWc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper9/-/Official_Review", "content": {"title": "Interesting direction with analysis", "review": "This paper investigates whether transformer-based neural language models (LM) understand commonsense pragmatics and focus on presupposition and scalar implicature.\n\nStrength:\n- I really like the connection between commonsense reasoning in NLP and pragmatic semantics in this work. It provides a theory-supported lens for investigating the often vaguely-defined \"common sense\". \n- The datasets chosen to probe LMs are well-chosen and the paper provides sufficient details which I appreciate as a reviewer.\n- The experiments are direct and easy-to-follow.\n\nPlaces to improve:\n- The authors mention multiple times that these pragmatics often exist in conversations, but the actual dataset used to probe models is not conversational. I would be really interested to see how models perform in a conversation scenario in terms of commonsense pragmatics.\n- I would be very curious to learn more about the authors' explanations on some of the experimental results and further analysis (if page limit allows)", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_SiFm"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_SiFm"]}, {"id": "BavgpqwAOfq", "original": null, "number": 1, "cdate": 1648056212535, "mdate": null, "ddate": null, "tcdate": 1648056212535, "tmdate": 1648056212535, "tddate": null, "forum": "BVelBzKlOWc", "replyto": "BVelBzKlOWc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper9/-/Official_Review", "content": {"title": "Contradicting conclusions & some issues with experiment setting ", "review": "This short paper aims to evaluate DistillBERT and GPT-3\u2019s ability to make human-like pragmatic inferences, such as Scalar Implicature (SI) and Presupposition (Presp), through human behavioral and neural data.\n\nIn Section 5, the authors claim that:\n\n* DistillBERT has difficulty detecting Presp (a bit far from human rate), and its performance suffers further when fine-tuned on another Presp + Implicature dataset (ImpPress dataset [1]).\n\n* DistillBERT has difficulty detecting SI, but its performance improves to human-level when fine-tuned on the ImpPress dataset [1].\n\n* GPT-3 does not do well in either psycholinguistic task and fine-tuning helps.\n\n### Strengths\n\n* **Online human data motivation:** The paper\u2019s motivation of using human data for conversational implicature is well-grounded. LMs are not trained the same way through many dialogues, but rather with text found on the web.\n\n* **Good sanity check on noun co-occurrence:** The authors check whether the test datasets contain enough noun co-occurrence patterns that could make the LM find a likelihood pattern rather than reason to conclude what sentence is more plausible.\n\n* **Avoids the pitfall of comparing BERT and GPT-3 with the same metrics:** This is a positive thing as they are trained very differently, and a perplexity comparison would be inconclusive.\n\n### Weaknesses\n\n* **Important definitions/examples are not very clear:** \n    - If the reader doesn\u2019t know what SI or Presp is, they are left with definitions and examples that aren\u2019t very clear (ex: [line 50] \u201cby using the determiner \u2018the\u2019 most people typically presuppose the existence of such a thing in the context.\u201d) \n    - Similarly, in [line 142], it seems as if the uniqueness of the waiter affects the context, whereas it\u2019s the relevancy of the job to the place. If one said \u201ca waiter,\u201d the place could be a random location irrelevant to the person who is still unique but happens to hold that job.\n\n* **DistillBERT\u2019s SI implicature evaluation setting doesn\u2019t help answer the question:**\n    - By not penalizing that \u201csome\u201d can be above \u201call,\u201d in the case where both would be in the top 5 choices, we accept the model\u2019s choice as correct while it isn't.\n    - It\u2019s not surprising that \u201call\u201d doesn\u2019t show up as much as other options in the top 5 choices, as the model may put many adjectives like \u201cDirty,\u201d \u201cTall,\u201d and so forth. These have nothing to do with the implication, yet they still make sense given that the LM\u2019s learning algorithm uses masked loss. Instead, comparing whether \u201call\u201d is relatively more likely than \u201csome\u201d is more useful and would lead to more valid conclusions.\n\n* **GPT-3\u2019s success criteria calculation is not clear:** [Line 116-122] is a little confusing as to which mean we are calculating. It seems to be that the authors calculate the sequence log probability divided by the sentence length for several sentences and then calculate the mean of those.\n\n* **Contradictions in conclusions:** While the results in Section 5 state that GPT-3 doesn\u2019t do very well with psycholinguistic tasks [line 278], the authors say that LMs understand \u201cthe implied intent shared among most people\u201d in the abstract [line 019-022]. This is either because I misunderstood something or because even human decisions are as low as the LMs\u2019 rates. Including the human plausibility decision rates in the plots can make it easier to compare with LMs, although the authors may have stated these numbers at [lines 152-154].\n\n### Style - points that didn\u2019t affect the decision of acceptance/rejection but could be useful to the authors\n\n* This paper may be a single-author paper. It\u2019s still preferred if it\u2019s written with \u201cwe\u201d statements instead of \u201cI\u201d statements.\n\n* There are many places where previously cited references aren\u2019t referred to with LaTeX again when mentioned, and are instead typed out, which leads to typos (ex: [line 155]). In the future, it may lead to not being able to discern between different articles.\n\n### References\n\n[1] [Are Natural Language Inference Models IMPPRESsive? Learning IMPlicature and PRESupposition](https://aclanthology.org/2020.acl-main.768) (Jeretic et al., ACL 2020)", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_KJoU"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper9/Reviewer_KJoU"]}]}, {"paper_url": "https://openreview.net/forum?id=Se-xHMYg_bc", "paper_id": "Se-xHMYg_bc", "reviews": [{"id": "rO-gh60QKM9", "original": null, "number": 3, "cdate": 1648078532046, "mdate": null, "ddate": null, "tcdate": 1648078532046, "tmdate": 1648078532046, "tddate": null, "forum": "Se-xHMYg_bc", "replyto": "Se-xHMYg_bc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper8/-/Official_Review", "content": {"title": "Insightful Analysis on CCI", "review": "The authors present analysis on contextual commonsense inference (CCI) using GLUCOSE, a story dataset annotated with commonsense explanations. They argue that the conflation of CCI with language generation (used in original GLUCOSE task) hinders model performance and the evaluation protocol also has issues. They propose to separate CCI from NLG by proposing CIS^2 and show improvement.\n\nStrength:\n- It's always good to see (and enjoyable to read!) analysis papers that tackle a previously studied problem from a new angle and provide insights. CIS^2 looks at the CCI problem and critiques a previous task formulation which I think provides important reflections for other researchers working on this problem.\n- The experiment design is well-reasoned and thoroughly described. I really like the different diagnosis task settings trying to disentangle different factors that might influence CCI performance.\n- The analysis on evaluation metrics also provides interesting insights\n\nPlaces to improbe:\n- I do not have major weaknesses to point out, but I think some parts of the writings can be much more concise. Especially Section 3 where the authors spent 2 pages on reviewing and introducing a previous work's data and task (I know it's crucial background but think could be shortened)\n- Significance tests would be beneficial to be included for Table 4 and others.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_CzWL"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_CzWL"]}, {"id": "H5xM963Pfc", "original": null, "number": 2, "cdate": 1647984010425, "mdate": null, "ddate": null, "tcdate": 1647984010425, "tmdate": 1647984010425, "tddate": null, "forum": "Se-xHMYg_bc", "replyto": "Se-xHMYg_bc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper8/-/Official_Review", "content": {"title": "Interesting hypothesis \"Contextual Commonsense Inference should not be conflated with NLG as in GLUCOSE\" but not much evidence.", "review": "What the paper is about: The paper argues that for contextual commonsense inference (commonsense understanding in some story), the GLUCOSE task conflates a different skill of natural language generation, which also brings in the ills of BLEU metrics. They propose the task of CIS2 which instead of asking the model to generate a commonsense inference, merely asks it to pick/classify the correct sentence prediction. They compare with different diagnostics/ablations of the original GLUCOSE task by removing parts of the input. They find that models trained on these ablations of GLUCOSE-Original perform worse than one trained on CIS2 (note that all these variants are based on the same GLUCOSE dataset) -- when evaluating on CIS2 metric of classification.\n\nKey Shortcoming: There is no independent evidence that shows a classification task is better than generation task in training for \"contextual commonsense inference.\" The only evidence is on the same metric of CIS2 which seems biased. The argument sounds like \"Standardized Tests are not good benchmarks of creativity, so we propose instead teaching/testing students the skill of playing chess. We find that students preparing for different standardized tests are worse than students preparing for chess -- when evaluated on chess.\" The core hypothesis remains untested: whether chess playing (CIS2) is a better metric and task for creativity (commonsense contextual inference) than standardized testing (generation). Some ways that this could have been evaluated are:\n1. human studies - do annotators find one model to exhibit more commonsense than others in some way?\n2. independent downstream task - does the model trained on CIS2 outperform those trained on generation on some third task? ", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_S91P"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_S91P"]}, {"id": "StZxr-sTIf5", "original": null, "number": 1, "cdate": 1647921917505, "mdate": null, "ddate": null, "tcdate": 1647921917505, "tmdate": 1647921959919, "tddate": null, "forum": "Se-xHMYg_bc", "replyto": "Se-xHMYg_bc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper8/-/Official_Review", "content": {"title": "The paper pinpointed a valid issue with the existing CCI task formulation. However, the findings are somewhat obvious, and the newly designed task might not generalize to settings where the CS inference is implicit and not part of the given story. ", "review": "This paper critiques existing methods on Contextual Commonsense Inference (CCI), which conflates generation and reasoning tasks. The authors propose reframing the CCI task as a classification task (called Cis2) to isolate commonsense reasoning from the generation. This helps in evaluating the commonsense inference ability of a model irrespective of its generation performance. For this, they convert story sentences into output tags which avoids a partial match between input and output sequences. The model is then required to generate an abstracted output which contains story sentences' tags instead of full sequences. \n\nPros:\n* It is important to evaluate the reasoning abilities of models in isolation from their generation abilities and the author pinpointed a valid issue with original GLUCOSE task formulation.\n\n\nCons:\n* Most of the findings from the diagnostic tests are obvious and expected (see comments). \n* Too much content is provided about Mostafazadeh et al. 2020 which could be easily skipped and referred to the original paper.\n* It is not clear how the newly designed task formulation handles cases where the inference output Y is not explicitly stated in the given story.\n\nComments:\n1- How does your task reformulation handle cases where the inference output Y is not explicitly stated in the story? As the authors mention in Line 196, the CS inference Y might or might not be part of the story. And example from the original GLUCOSE paper is:\n\u201cGage wants safety\u201d Causes/Enables \u201cGage turned his bike\u201d, while \u201cGage wants safety\u201d is never stated in the story and should be inferred thus can not be replaced by a tag from the story.\n\n2- Line 259: while I agree with the authors that the original task formulation suffers from conflation of CCI and language generation tasks, I think this can be solved mostly by 1) removing the selected sentence X from the output, and 2) including a better evaluation metrics that accounts for semantic similarity such as BertScore. \n\n3- Line 367-369: Isn't this obvious? if in the training data, output always copy/paraphrase X, it's expected that the model learns this pattern and consequently the BLEU score would be high. The issue is why the model should generate X in the first place. Without including X in the output (no matter if X is in the input or not) the evaluation using n-gram overlap would be less unreliable.\n\n4- Line 380: In my opinion copying is an easier task.\n\n5- The first 5.5 pages are allocated for background and related work and only on page 6 the author started to talk about their proposed task Cis2. \n\n6- It is helpful to explicitly mention somewhere in the paper that you are using a generative classifier where the model GENERATES one of the 100 possible output sequences (using T5) and it\u2019s not a 100-way classification task.\n\n7- Line 449: For what portion of the original data could the authors find output Y explicitly mentioned in the input story? And why not discard those with very low similarity scores?\n\nTypo: \n\nLine 406: the The \u2192 The\n\nLine 407: footnote after punctuation.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_EoNj"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper8/Reviewer_EoNj"]}]}, {"paper_url": "https://openreview.net/forum?id=rTwMSztg_-q", "paper_id": "rTwMSztg_-q", "reviews": [{"id": "rBee5cxh9G9", "original": null, "number": 3, "cdate": 1648177297790, "mdate": null, "ddate": null, "tcdate": 1648177297790, "tmdate": 1648177424493, "tddate": null, "forum": "rTwMSztg_-q", "replyto": "rTwMSztg_-q", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper6/-/Official_Review", "content": {"title": "Interesting idea, but results are not significant", "review": "Summary:\n\nThe authors propose a novel commonsensical vision-language pre-training framework as opposed to the current SOTA models which mainly focus on learning semantic connections between visual and language features/objects. The key novelty of the paper is to propose new pre-training tasks masked common sense modeling and commonsense type prediction. Extensive experiments on VCR and VQA demonstrate the effectiveness of the proposed approach.\n\n\nStrengths:\n\nThe paper proposes an interesting way to enrich existing large language models with common-sense reasoning skills. This could be potentially adapted to other related tasks and domains.\n\nI really liked the idea of getting commonsense inferences from Visual COMET and then using it in the newly designed pre-training tasks.\n\nAlthough I am not fully convinced of the improvements shown in the paper, experiments sufficiently validate the conclusions drawn in the paper.\n\n\nWeaknesses:\n\nHere are my major concerns:\n\nAuthors showed improvements that are less than 2% in section 4.3. I worked with ViLBERT model before on both VCR and VQA and I found that any improvement < 2% cannot be considered as significant as it could simply be due to the variance in training. It would help (and is necessary) to present results with different seeds to validate the improvements.\n\nFor the VQA model, is Visual COMET really required? because most of the questions in VQA are not created to test the temporal aspect of the events. Maybe using the COMET (Jena Hwang et al., AAAI 2021) model might be a good choice here?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_qCsY"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_qCsY"]}, {"id": "SferD8QYMq", "original": null, "number": 2, "cdate": 1648076380731, "mdate": null, "ddate": null, "tcdate": 1648076380731, "tmdate": 1648076380731, "tddate": null, "forum": "rTwMSztg_-q", "replyto": "rTwMSztg_-q", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper6/-/Official_Review", "content": {"title": "Well-motivated novel pretraining method that shows some improvements but could benefit with some more setting clarifications/discussions.", "review": "This paper aims to improve downstream task performance on commonsense reasoning tasks with a pre-training scheme that involves both recognition and cognition tasks in an automated fashion (i.e., without needing more human annotation for the cognition part). \n\nThe paper treats the original MSCOCO [1] captions as \u201clow-level\u201d as they often involve solely recognizing objects/people/events. These low-level captions are augmented to high-level captions by using templates and a visual-linguistic GPT-2 model fine-tuned on VisualCOMET [2] without a <location> sense, but with the rest of the commonsense types such as <before>, <after>, and <intent>. **Therefore the 3 domains they consider in pre-training are: image, low-level captions, and high-level captions.**\n\nThe authors propose 3 new tasks/methods. The paper claims these methods improve pretraining incrementally (with VL-BERT) in addition to prior MLM & MRC schemes:\n\n* **Masked commonsense modeling (MCM):**\n    * The task of predicting a masked high-level caption domain token conditioned on the rest of the high-level tokens as well as the visual and low-level caption tokens.\n    * For the other 2 domains, the authors still use MLM & MRC, conditioned on all 3 domains at the same time.\n\n* **Domain-wise adaptive masking:** As the automatically generated high-level captions include parts of the low-level captions, the authors propose to adjust the masking ration between the two captions domains on their semantic similarity (cosine sim w/ BERT embeddings & some more processing).\n\n* **Commonsense type prediction (CTP):** The task of predicting the type of the high-level commonsense captions by masking all of the template phrases.\n\n\n### Strengths\n**Background + motivation well-formulated:** The authors motivate their work well with prior research that separates recognition from cognition. \n\n**Novelty:** They push forward that improvement in commonsense understanding has to start from pretraining rather than a fine-tuning scheme, which is a unique approach. They find novel methods to do so, by looking for ways to overcome specialization in a certain type of commonsense knowledge/ability.\n\n**Ease of usage / scalability:** Their methods are automated and therefore don\u2019t require more human annotation. Regardless of the automation, the results don't suffer form the basic templates.\n\n**Ablation study:** The authors show the possible improvement role of each proposed method.\n\n\n### Weaknesses\n**Improvement margin:** It\u2019s hard to tell from Table 2 whether the performance has improved vastly (~1% improvements). This gets harder with pre-training schemes combined with fine-tuning. It could be the case that a single point in accuracy improvement does matter. This is the case in many zero-shot learning tasks. However, in this approach the authors finetune on a separate set of the dataset tested. Therefore it\u2019s hard to say whether it\u2019s the finetuning that does most of the work and the pretrained embeddings are luckily well \"initialized\" with respect to the task or whether it actually improves the representations. I think that the human survey helps to back this to a certain extent, and that the method is interesting enough that a small margin doesn\u2019t affect the rest of the paper. However, non-finetuned results on all methods (non-pretrained, recogniton, cognition) or some comments on why this small improvement matters would have been helpful.\n\n**A little confused about the edge cases of masking even if it\u2019s domain-wise:** It\u2019s clear that MCM is conditioned on visual + low-level captions only, whereas MLM & MRC are conditioned on all three domains. But it\u2019s a little hard to understand whether they are conditioned all independently or they could be all masked at the same time. For example it\u2019s a little hard to understand from [lines 327-330] whether low-level captions and high-level inferences could be masked both at the same time, because of a combination of domain adaptive masking + MCM. It seems like no, and that\u2019s the point of making sure a connection between images and the high-level captions exists, but it could be confusing to the reader. I think the paper could benefit from a clarification on this.\n\n**Similarity of datasets:** It\u2019s clearly stated in the paper that a subset of the VCR dataset is in the VisualCOMET dataset. It\u2019s also stated that the high-level captions from VisualCOMET are mostly related to humans, while there is a \"val-human\" set separated from VQA. I wish there was a little more discussion on why this doesn\u2019t or does affect the results, whether the improvement lies in picking the right datasets or not.\n\n### Style\n**The term commonsensical:** Although I understand that this term is used to separate cognition-level tasks from recognition ones, a reader from a commonsense research background in NLP may be confused (while originally this definition at [line 071] aims to reduce confusion). I would either stick to commonsense and say here we are solely referring to it from a cognitive points of view, or completely let it go and use words related to cognition. I understand that it\u2019s hard to thread around what it might entail.\n\n**Backbone citation:** I would change the citation at [line 045] to the actual GPT-2 citation and then move the visual-linguistic pretraining citation of [2] to the end of the sentence, as the rest of the sentence cites the actual backbone papers.\n\n### References\n\n[1] Lin, Tsung-Yi et al. \u201cMicrosoft COCO: Common Objects in Context.\u201d ECCV (2014).\n\n[2] Park, Jae Sung et al. \u201cVisualCOMET: Reasoning About the Dynamic Context of a Still Image.\u201d ECCV (2020).", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_Zykj"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_Zykj"]}, {"id": "Hzgaz0qdzq", "original": null, "number": 1, "cdate": 1648041492724, "mdate": null, "ddate": null, "tcdate": 1648041492724, "tmdate": 1648041492724, "tddate": null, "forum": "rTwMSztg_-q", "replyto": "rTwMSztg_-q", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper6/-/Official_Review", "content": {"title": "The paper proposes a pretraining loss to improve commonsense reasoning in visual-text models.", "review": "The main idea of this work is to use a model that generates commonsense phrases on image, caption pairs, and then pretraining another model on the images and text (original and generated) with some standard technique (e.g. MLM).\nThe authors present experiments on the VQA and VCR datasets, and show small improvements for these datasets.\n\nThe idea is clever, and it\u2019s a nice use of existing dataset to improve commonsense reasoning to pretraining models.\nThe authors also present some analysis showcasing the benefits of their method\n\n\nThe paper is overall quite hard to read to my taste, it often gives details that focus on the low level, and doesn\u2019t depict the high level, and on the other hand, there aren\u2019t enough details to replicate this study.\nIn addition, the paper is somewhat overclaiming. The method for adding commonsense, is based on silver data (as it uses the output of another model), and is very limited - it only adds information about the timeline (whether the incident is before or after), and the possible intent. Not only these inferences can often be speculative and ungrounded, this is only a tiny bit of the commonsense space.\nAnother point to note is that the examples themselves (e.g. figures 1, 3) seem unnatural. This is fine if it eventually leads to improved performance, but it should be discussed in the paper.\nAnother point regarding the results is that these aren\u2019t state-of-the-art results. This is fine on its own, but should definitely be mentioned and discussed.\n\nThe writing should be improved in terms of clarity and scrutiny, as well as the overclaiming (as discussed above). There are some issues with the citing style (\\citet instead of \\cite, e.g. in L.75, L.199).\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_evpQ"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper6/Reviewer_evpQ"]}]}, {"paper_url": "https://openreview.net/forum?id=HI5M4MYedZ5", "paper_id": "HI5M4MYedZ5", "reviews": [{"id": "SaMg5B7TKM5", "original": null, "number": 3, "cdate": 1648116546197, "mdate": null, "ddate": null, "tcdate": 1648116546197, "tmdate": 1648117051880, "tddate": null, "forum": "HI5M4MYedZ5", "replyto": "HI5M4MYedZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper2/-/Official_Review", "content": {"title": "Interesting and original work but the proposed method might need further development before the resulting CSKB can be used as a reliable resource", "review": "This paper studies generating commonsense knowledge directly from pre-trained language models for two CSKBs - ConceptNet and Ascent++. The direction is interesting and original, and the paper is well written and easy to follow. However, \n\n1. The paper claims that \"up to now no materialized resource of commonsense knowledge generated via pre-trained language models is publicly available.\". However it's not true. West et al. (2021) construct AUTOTOMIC via GPT3 that's 10x larger than ATOMIC, and provide comprehensive and in-depth analysis and evaluation. \n2.  Lack of novelty: the proposed method directly applies previous COMET pipeline on two established CSKBs without further improvement or adaption. \n3. Evaluation shows a clear gap between proposed PLM generated CSKs and original human written CSKs. Without further filtering or purification, it's questionable whether the generated noisy CSKB can be used as a reliable resource. \n\nCitation:\nWest, Peter et al. \u201cSymbolic Knowledge Distillation: from General Language Models to Commonsense Models.\u201d ArXiv abs/2110.07178 (2021): n. pag.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_jbiB"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_jbiB"]}, {"id": "BdulVoYk_zc", "original": null, "number": 2, "cdate": 1647995291605, "mdate": null, "ddate": null, "tcdate": 1647995291605, "tmdate": 1647995291605, "tddate": null, "forum": "HI5M4MYedZ5", "replyto": "HI5M4MYedZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper2/-/Official_Review", "content": {"title": "Strong paper that fills a gap in current commonsense knowledge extraction work", "review": "This paper proposes to materialize neural commonsense predictions with COMET into concrete resources. The paper investigates two SotA knowledge bases (ConceptNet and ASCENT++) and two standard language models (GPT-2-XL and BART). The evaluation estimates the precision of the generated knowledge through salience and typicality, and the recall by comparison against a feature norms dataset, CSLB. The results indicate the promise of this approach, but also point to key obstacles in terms of redundancy, subject copying, and co-occurrence misreading.\n\nThe paper is overall well-written, original, and the evaluation is solid. The pointed challenges are thought-provoking. \n\nThe paper size is in between a short and a long paper, so it is unclear to me whether this paper qualifies as long of short. If this is meant to be a long paper, it would be good to include more discussion on how would the authors propose to circumvent the key challenges with this knowledge base generation method. These mitigation strategies are currently only briefly listed in the conclusion, which leaves many questions unanswered. Furthermore, some quantitative investigation of how would the downstream applications benefit from the created sources despite these challenges would be useful.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_8czw"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_8czw"]}, {"id": "HdWxPLfavf5", "original": null, "number": 1, "cdate": 1647985230680, "mdate": null, "ddate": null, "tcdate": 1647985230680, "tmdate": 1648231796467, "tddate": null, "forum": "HI5M4MYedZ5", "replyto": "HI5M4MYedZ5", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper2/-/Official_Review", "content": {"title": "Trained COMET models analyzed for precision+recall and used to generate new commonsense KGs -- but not clear why we need this resource?", "review": "What the paper is about: The authors offer a new resource generated from COMET models trained on commonsense knowledge graphs like ConceptNet and Ascent++. They study not just plausibility but also the precision (typicality and saliency) as well as recall of the models' predictions. They analyze different base LMs and datasets on these metrics and offer insights. Finally, they demonstrate a web interface with wider customizations than the original one hosted by AI2.\n\nKey shortcoming: The authors call it a resource paper (L043). However, the benefit of the new \"generated\" commonsense knowledge graphs is not well established. Section 4.3 hints at some use cases like aggregation, joins, ranking, and text search. But the benefit of having a static set of predictions (this new resource) is not clear. (1) How are these better than the base KGs like ConceptNet and Ascent++? Perhaps they are bigger but not always more salient/typical/exhaustive than the original KGs (see Table 2). (2) How are these better than retaining the trained COMET model, which can generate such inferences and many more, on demand?\n\nPros: good analysis + useful resource.\nCons: usefulness of the resource not demonstrated.\n\nEDIT: Reviewer jbiB rightly points to a major missing related work, which further challenges the paper's claim to novelty.\n\nMinor:\n- Should you be referring to Untypical as Atypical instead? I was fairly confident that the latter is \"correct\" but words have no inherent meaning anyway so this is up to the authors.\n- Saliency vs Typicality could benefit from a formal definition (in English, not just in a formula) each. Do they differ in just values of k for top k extractions?", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_Yejc"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper2/Reviewer_Yejc"]}]}, {"paper_url": "https://openreview.net/forum?id=BUclNGKxObc", "paper_id": "BUclNGKxObc", "reviews": [{"id": "rregRLcjYGc", "original": null, "number": 3, "cdate": 1648110165949, "mdate": null, "ddate": null, "tcdate": 1648110165949, "tmdate": 1648110857035, "tddate": null, "forum": "BUclNGKxObc", "replyto": "BUclNGKxObc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper1/-/Official_Review", "content": {"title": "Applied, Practical, Introduced new dataset, Multiple ablation studies are reported", "review": "This paper investigates commonsense knowledge acquisition in language models via classification and generation tasks.\n   \n[Strong]\nAuthors introduced  the first Story Cloze Test in Indonesian. Highly practical applied work with a lot of useful practical details. Detailed ablation results are presented.\n\n[Weak]\nNot novel", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_5PLE"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_5PLE"]}, {"id": "rKWerzAnvGq", "original": null, "number": 2, "cdate": 1647984141132, "mdate": null, "ddate": null, "tcdate": 1647984141132, "tmdate": 1647984141132, "tddate": null, "forum": "BUclNGKxObc", "replyto": "BUclNGKxObc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper1/-/Official_Review", "content": {"title": "Contribution of an interesting story cloze dataset in Indonesian; comprehensive experiments against multiple baselines.", "review": "This paper creates a story cloze dataset in the form of ROCStories in Indonesian. The authors present analysis on the dataset indicating the presence of cultural entities/names/etc. that highlight the importance of collecting datasets in the desired language directly rather than simply translating the English dataset.\n\nThe authors present results from a number of baseline models---n-gram similarity, fastText embedding similarity, mBERT, and IndoBERT--- on the last-sentence-selection classification task, demonstrating that the naive similarity methods are not significantly better than random, while IndoBERT achieves 81% accuracy, indicating the task is not solved. They perform analysis to show that the dataset does not have the artifacts that the original ROCStories dataset has-- experiments show that the full context (first 4 sentences) is generally needed to achieve the best performance on the classification task. However, I'd ask the authors to acknowledge in the text that the models receiving no context are still far better than the 50% baseline, indicating some form of spurious correlations in the dataset.\n\nOn the last-sentence generation task, the authors show that training on both the English + Indonesian data leads to good performance on the Indonesian test set using mBART, according to manual evaluation. They also test zero-shot cross-lingual transfer on the classification task by training and testing on different variants of their dataset (Indonesian), ROCStories (English), and machine translations of each, finding that both the English and Indonesian test sets don't seem to benefit from training on the other language, and including machine translations has mixed effect.\n\nThe data is an interesting and novel contribution, and the inclusion of detailed experiments makes promising progress on the task with high-quality analysis. My only concern is that last-sentence prediction and generation from 5-sentence stories are very simplified versions of creative storytelling, and many works in the research area (albeit in English) now focus on harder tasks such as generating entire stories from a single prompt or from scratch on more complex datasets. However I think this resource could be used for such goals and is thus useful to the community as a starting point.\n\nPossible missing citation: Abductive Commonsense Reasoning-- a variant of the story cloze task (https://openreview.net/pdf?id=Byg1v1HKDB)\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_1PxG"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_1PxG"]}, {"id": "SGe89mjvfc", "original": null, "number": 1, "cdate": 1647977357551, "mdate": null, "ddate": null, "tcdate": 1647977357551, "tmdate": 1647977406833, "tddate": null, "forum": "BUclNGKxObc", "replyto": "BUclNGKxObc", "invitation": "aclweb.org/ACL/2022/Workshop/CSRR/Paper1/-/Official_Review", "content": {"title": "Story Cloze Task using Indonesian short stories", "review": "In this paper, the authors follow the Story Cloze Test framework of Mostafazadeh et al. (2016) in evaluating story understanding in Indonesian, by constructing a four-sentence story with one correct ending and one incorrect ending. To investigate commonsense knowledge acquisition in language models, authors experimented with: (1) a classification task to predict the correct ending; and (2) a generation task to complete the story with a single sentence. They investigate these tasks in two settings: (i) monolingual training and (ii) zero-shot cross-lingual transfer between Indonesian and English.\n\n1) The authors put a considerable amount of effort into ensuring the quality of the data. Even though it's not huge it's still an important resource towards multilingual commonsense knowledge.\n2) Authors consider both generative and discriminative settings and use extensive baselines and particular both monolingual and cross lingual methods\n3) For classification the ablation with different contexts is really neat and gives the reader an idea of the difficulty of the dataset. 81% is still a lot lower than human performance. However, the high performance without showing context shows the dataset might not be free from annotation artifacts\n4) For the generation I appreciate authors showing both human and automatic evaluation. The human eval results for presence of commonsense and good narrative flow is slightly concerning\n5) The authors should mention the agreement of human evaluations", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_AtGC"], "readers": ["everyone"], "nonreaders": [], "writers": ["aclweb.org/ACL/2022/Workshop/CSRR", "aclweb.org/ACL/2022/Workshop/CSRR/Paper1/Reviewer_AtGC"]}]}, {"paper_url": "https://openreview.net/forum?id=8gDgxLAhrXK", "paper_id": "8gDgxLAhrXK", "reviews": [{"id": "6AneioDFCyhe", "original": null, "number": 3, "cdate": 1659623548789, "mdate": null, "ddate": null, "tcdate": 1659623548789, "tmdate": 1659623548789, "tddate": null, "forum": "8gDgxLAhrXK", "replyto": "8gDgxLAhrXK", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/-/Official_Review", "content": {"title": "Good paper that shows scientific significance, accept", "review": "**Summary** \\\nThis paper investigates the inductive bias in ViT and CNN models. The authors claim that the previous design of injecting convolution-like inductive bias into CNN models ignore that the optimal inductive bias depends on the data scale and fixed inductive bias may not be optimal. Experiments on different data scales of ImageNet illustrate that smaller data scale is needed for ViT to outperform CNN if more convolution-like inductive biases is included. The paper also proves that frequency characteristics can explain whether the inductive bias is closer to convolution or self-attention by conducting Fourier analysis. Then the authors show that the interpolation of inductive bias between CNN and ViT can be realized by adjusting the moment of reparameterization during training. Based on the above findings, a progressively reparameterization scheduling is proposed to make the front layers to act like convolution and the rear layer to act like self-attention. Experiments on CIFAR-100 show the effectiveness of PRS.\n\n\n\n**Strengths**\n- Investigating the inductive bias injected in CNN and ViT models is crucial and this paper presents a new idea of making the inductive bias flexible, which provides a new research direction.\n- The order of the paper and the logic in conducting this research is clear. The authors try to first understand the inductive bias by conducting the 'different data ratio' experiments and the Fourier analysis and then propose the scheduling strategy of reparameterization based on the previous findings.\n- The tables, equations and figures used to demonstrate the PRS is clear.\n- The paper is generally well-written. \n\n\n**Weaknesses**\n- The experiments used to verify the effectiveness of PRS is only conducted on CIFAR-100. It would be good if more datasets can be included.\n- The legend in Figure 3 is misleadings. The orange line should be Conv50, SA250?\n\n**Overall rating (1-10)** \\\n7\n\n**Justification of rating** \\\nThe scientific significance of this paper. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/Reviewer_kfrY"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/Reviewer_kfrY"]}, {"id": "1KJOJ8KSR87", "original": null, "number": 2, "cdate": 1658499935532, "mdate": null, "ddate": null, "tcdate": 1658499935532, "tmdate": 1658499935532, "tddate": null, "forum": "8gDgxLAhrXK", "replyto": "8gDgxLAhrXK", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/-/Official_Review", "content": {"title": "Interesting method, but concerns about motivating analysis", "review": "**Summary**\nThe authors use existing work that reparameterizes self-attention to be able to interpolate between self-attention and convolution, and propose a linear schedule that progressively switches over CNN modules to self-attention over training time. This method is motivated by a reproduction of the result that CNNs and ViT models with increased inductive biases are more data efficient than baseline ViT models, while ViT models can outperform CNNs at large data scales.\n\n**Strengths**\n- The proposed method is simple and easy to reproduce based on the paper.\n- The method is effective on CIFAR-100.\n\n**Weaknesses**\n- In my view, the analysis in sections 4 and 5 does not connect to the method. The relationship between the frequency response of convolution/self-attention and their inductive bias is not properly explained and not obvious to me. The cited work by Park et al. doesn\u2019t directly connect the two either. The claim that the frequency response is indicative of inductive bias is therefore, in my opinion, not substantiated.\n- Regardless of the validity of the analysis in sections 4 and 5, in my opinion sections 4 and 5 are not necessary to argue that inductive bias aids data efficiency, as that is an established property of machine learning models. Specifically for convolutions and self-attention thee are many works to cite (see the related works in this work and the work of Park et al.). As such, the chapters distract from the main contributions.\n- The main motivation for the method is improved accuracy on CIFAR-100, but a thorough description of the hyperparameter of the method and baselines is missing, which does not inspire trust in the results.\n- The method is not evaluated for its claimed benefit of adjusting to the data scale. For example, the authors could have evaluated on the ImageNet subsets of sec 4.2.\n\nRating: marginally below acceptance threshold\n\n**Justification**\nMy leading principle for this review is if I believe the paper disseminates useful information for the field. In the current form, I do not believe sections 4 and 5 should be published, as I do not agree with the claims on the relationship between frequency response and inductive bias, and they will confuse and distract uninformed readers. I can however see the value of the proposed linear schedule method, and think it would be a good fit for this workshop or another similar venue otherwise. I recommend the authors revisit the way they motivate and analyze their method, and resubmit to a similar venue.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/Reviewer_zxBu"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/Reviewer_zxBu"]}, {"id": "zvSK_YNGKik", "original": null, "number": 1, "cdate": 1658329640955, "mdate": null, "ddate": null, "tcdate": 1658329640955, "tmdate": 1659450639546, "tddate": null, "forum": "8gDgxLAhrXK", "replyto": "8gDgxLAhrXK", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/-/Official_Review", "content": {"title": "Good paper! Accept without doubt.", "review": "This paper first studies the inductive bias in convs and transformers using Fourier analysis. The amount of inductive bias is defined as the log-scale difference between the high and low frequencies. The observation seems to align with common sense that convs have much more bias thus being data-efficient, while transformers are the opposite.  Later, the authors study a progressive reparameterization schedule which allows a model to flexibly decide \"optimal\" the amount of bias needed during training by progressively converting convs to transformer blocks. In general, an interesting paper. \n\nHowever, I do have a concern about the lack of connection among frequencies, inductive biases, and data efficiency. The main argument is that MSA is low-pass while convs are high-pass. However, it is not clear how the high/low frequency contributes to data efficiency.  Is the frequency bias universal (applicable to other datasets/tasks)? Reviewer \"zxBu\" shares the same opinion, as indicated in \"The relationship between the frequency response of convolution/self-attention and their inductive bias is not properly explained and not obvious to me.\"  \n\nIn general, I think the ProgressiveReparameterizationScheduling is an interesting idea and the experiments on cifar show some inspiring results.  Despite the concerns on the Fourier analysis, I would still vote for acceptance.\n\nline 388 typo\nline 389: how are the frequencies normalized to [-pi, pi]? linearly?\nline 396: what is the 'normalized depth'?\nis it possible to show some qualitative analysis/visual examples on low/high frequencies? what are the low/high frequencies exactly? How do they differ in early and later layers? It might be beneficial to understand the inductive bias.\nfig 3 why is the orange line has the same configuration as the light blue line? is this a mistake? I would assume it is orange - conv100, SA200?\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/Reviewer_XLoE"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper11/Reviewer_XLoE"]}]}, {"paper_url": "https://openreview.net/forum?id=gNOtzlXS2oY", "paper_id": "gNOtzlXS2oY", "reviews": [{"id": "GdW5yAeyCz4", "original": null, "number": 2, "cdate": 1659732731979, "mdate": null, "ddate": null, "tcdate": 1659732731979, "tmdate": 1659732731979, "tddate": null, "forum": "gNOtzlXS2oY", "replyto": "gNOtzlXS2oY", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper10/-/Official_Review", "content": {"title": "The paper proposes a method that incorporates the traditional Laplacian pyramid method with a Zero-shot approach. The method provides convincing results on image quality in terms of detail, sharpness, colour and contrast.", "review": "#Summary:\n\nThe paper proposes a method that incorporates the traditional Laplacian pyramid method with a Zero-shot approach. The method provides convincing results on image quality in terms of detail, sharpness, colour and contrast.\n\n#Strengths:\n- Clarity and rigorousness\n- Performance\n- Ablation studies\n- Experiments on various input domains\n- The form of the loss function\n\n#Weakness:\n- Applying ZA-MLE only on underwater images. It could be nice to apply it to normal image enhancement tasks and we could see the generalizability of the method.\n \n#Some Questions and Remarks:\n- Fig 2: The method enhances the details, for sure, but also brings some artefacts. For instance, I cannot identify the scuba diver in the right image anymore and it looks like there is a dark region. If I run an object detector on that images, probably the detector misses him.\n- How does the method perform under very dark and noisy scenes? X_L and X_H are obtained from input images, I was wondering if the zero-shot technique might work under extremely dark and noisy setups.\n- What is the reason/motivation to use only X_H for l_rec calculation?   \n- Will the code be publicly available?\n\n\n#Suggestions:\n- Fig 1: Putting an emphasis on the lines in the middle of images and giving their reasons with a sentence in the caption can help the reader to realise the differences.\n- Table 1: Adding colour indicator information (blue, red) in the image caption.\n- Fig 6: Mentioning the reason for the red box in the image caption too.\n\n", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper10/Reviewer_to9H"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper10/Reviewer_to9H"]}, {"id": "tVsTPZm88AW", "original": null, "number": 1, "cdate": 1659646285909, "mdate": null, "ddate": null, "tcdate": 1659646285909, "tmdate": 1659647019439, "tddate": null, "forum": "gNOtzlXS2oY", "replyto": "gNOtzlXS2oY", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper10/-/Official_Review", "content": {"title": "Well-written paper, in general good work, impressive underware image enhancement visualization", "review": "In general, this paper is a good work for this workshop. It renovates Laplacian pyramid for zero-shot image enhancement. And also propose a zero-shot attention network with multiscale Laplacian enhancement. The qualitive results, e.g., under water images enhancement, are impressive and good. The authors conduct image enhancemnet experiments on mainly two datasets and evaluate the results with two metrics.\n\nQuestion:\nAuthors mention that MLE depends on hyperparameters, N, K, $\\sigma$. In section 3.4 and supplementary material, only limited qualitative results are provided. Do you have any quantitative results to prove that?\n\nMinor: Line 77, should \"on the other\" be \u2018on the other hand\u2019?", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper10/Reviewer_o9YT"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper10/Reviewer_o9YT"]}]}, {"paper_url": "https://openreview.net/forum?id=ewS9kxTKF7f", "paper_id": "ewS9kxTKF7f", "reviews": [{"id": "nSLnobQMXJ6", "original": null, "number": 3, "cdate": 1659448374736, "mdate": null, "ddate": null, "tcdate": 1659448374736, "tmdate": 1659711393279, "tddate": null, "forum": "ewS9kxTKF7f", "replyto": "ewS9kxTKF7f", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/-/Official_Review", "content": {"title": "Preliminary work with interesting future extensions ", "review": "The paper describes an approach for developing resource-efficient Counterfactual Generative Networks (CGNs) through Knowledge Distillation (KD) from black-box pre-trained CGNs to smaller TinyGANS. The approach is then named by the authors Source-free\nKnowledge Distillation of Counterfactual Generative Networks (SKDCGN).\nThe authors employ a TinyGAN for each of the independent mechanisms (i.e., shape, texture, background) in order to increase modularity and reduce the size of the overall model.\n\nPros:\n\n- The paper is eligible for the workshop since the concept of \u201cprior\u201d is applicable both to 1) the knowledge transfer from the teacher CGN and 2) the built-in approach of CGNs that employ inductive biases (i.e., shape, texture, and background) to generate realistic images. \n\n- The paper tackles two critical problems of modern deep learning literature, i.e., 1) reducing the size of state-of-the-art GANs and 2) learning from large pre-trained models through black-box access.\n\n- The paper is well written and clearly presents the objectives, methodology, and qualitative results.\n\n- The related work section provides a good overview of the literature concerning this paper (i.e., CGNs and KD).\n\n\nCons:\n\n- The paper employs and combines published techniques [3, 7] rather than proposing a novel method.\n\n- The evaluation of the approach is preliminary and needs extensions.\n\n  Section 4 mainly presents qualitative rather than quantitative results. It would be interesting to evaluate SKDCGN on Out-of-Domain (OOD) classification tasks as performed in [3]. The results would probably be less \n  compelling but still interesting to observe.\n\n  Furthermore, given that the objective of SKDCGN is to make current CGNs more lightweight, it would be better to report a plot/table in \n  which metrics quantify improvements. For instance, the reduction of the number of trainable parameters, GPU memory usage, etc.\n\n- As visible in Fig. 2, the texture mechanism is the one that suffers more from the reduction of size. Textures of Fig. 2 (b) generated by \n  SKDCGN are hardly distinguishable.\n  On the contrary, the shape and background mechanisms mimic quite well the original generations.\n  Future work should develop more on the texture generation mechanism. For instance, by including data augmentation or other \n  approaches that improve image synthesis for GANs.\n \n\nMinor issues:\n\n- The abstract is a bit lengthy and could probably be pruned.\n\n- Is the legend of Fig. 1 partially wrong? During inference, the TinyGANs should be \u201cfixed\u201d and during training \u201ctrainable\u201d. Further, the composition mechanism is said to be untrainable by default.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/Reviewer_hcve"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/Reviewer_hcve"]}, {"id": "YhP0JzLFHS8", "original": null, "number": 2, "cdate": 1658924267334, "mdate": null, "ddate": null, "tcdate": 1658924267334, "tmdate": 1659709436005, "tddate": null, "forum": "ewS9kxTKF7f", "replyto": "ewS9kxTKF7f", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/-/Official_Review", "content": {"title": "A knowledge distillation method with limited novelty", "review": "[Summary]\nThis paper presents a method that trained three tinyGANs from the Counterfactual GAN (CGNs) for shape, background and texture independent components respectively. The main novelty of this paper is the combination of the TinyGANs [7] and CGNs [3]. The author shows it is feasible to train the proposed method in the knowledge distillation way. \n\n[Paper strength]\n- The paper contributes to the combination of the TinyGANs [7] and CGNs [3]. The TinyGANs[7] train the one TinyGANs from one BigGANs, and the CGNs trained three BigGANs [4] for object shape, texture and background respectively. The proposed method in this paper trained three TinyGANs (using the way in [7]) from three BigGANs in the CGNs [3].\n\n-  The secondary contribution is the author uses the KL divergence as the additional loss compared to [7]. In section 4.4, the author shows that using KL divergency could improve performance.\n\n- In the experiment, the author shows that the proposed method could generate reasonable results on ImageNet and MNIST datasets. \n\n[Paper weakness]\n- The novelty contribution is limited. The proposed method is to train the TinyGANs [3] from the CGANs [3] model. The proposed architecture shown in Fig. 1 is similar to [7] except it is for three separated models, and the three separated models are introduced by [3]. The loss terms 1 to 3 are from [7] with the exact same equation and adapted text, and the loss term 4 is from [21]. I did not find any interesting technical contribution. \n\n- The experiment is limited in terms of the error metric and conclusion. There are only qualitative results for the main experiments in sections 4.3 and 4.4. The comparison between the proposed method and baseline can only be judged subjectively. In the related works [7], there are other metrics such as FID to compare different methods. From these qualitative results, I can only judge that the proposed method can generate the somehow similar results to the baseline but for sure is worse than the baseline. Compared to the results achieved in [7], the TinyGAN in [7] has comparable results with the BigGAN model.\n\n- Inappropriate baseline. The baseline method is CGN but each BigGAN is replaced by a TinyGAN. However, the author motivates the proposed method that the BigGANs in the original CGN is over-parameterrized (line 45). I expected the author would compare their method to the original CGN,  too. If we can train the CGN with the TinyGAN, I think we do not have the over-parameterized networks problem.\n\nOther minor issues:\n- I do not find the necessarily of section 4.5.\n- Misuse of the supplementary material. The author refers to supplementary on improving the method in section D. However, according to the author guideline of ECCV (https://eccv2022.ecva.net/submission/call-for-papers/), \"Reviewers will be encouraged to look at it (supplementary), but are not obligated to do so\", and \"It may not include results obtained with an improved version of the method\". ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/Reviewer_8nMo"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/Reviewer_8nMo"]}, {"id": "O-wM94CC6s0", "original": null, "number": 1, "cdate": 1658329705828, "mdate": null, "ddate": null, "tcdate": 1658329705828, "tmdate": 1658329705828, "tddate": null, "forum": "ewS9kxTKF7f", "replyto": "ewS9kxTKF7f", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/-/Official_Review", "content": {"title": "This paper studies an interesting task: learning less parameterized models from the bigGAN teacher using knowledge distillation. However, the paper itseld lacks clarity, especially in the exps.", "review": "\nThis paper aims to learn lightweight models from the bigGAN teacher using knowledge distillation (KL loss at both pixel/feature levels). The Introduction, Related work, and Approach are easy to follow and well explained. \n\nUnfortunately, I find the exp part poorly written, making it extremely hard to understand: does the result support the claim? I lost track completely there. The same also happens in the appendix. Please add concrete conclusions or take-aways for each figure and re-write the exp part.\n\nDespite the fact the task/problem addressed in the paper is both theoretically and practically meaningful, I would still recommend 'reject' given the flaws in the writing, especially the exp part. \n\n\n\nFig 1: left: are the modules in blue non-trainable? right: are the tinyGANs trainable during inference? Or there is a mistake in legend?\nline 223: Abuse of notation: \"S\" refers to the student model in eq2, while in eq4 it is defined as the generator\n\nline 344: what is the take-away from fig 2. I do not see a conclusion? It seems the SKDCGN generates less impressive results than the CGN.\n\n\nline 351: \"We realize that the student is as good as the teacher.\" where does this conclusion come from?\n\nline 356/358: Grammarly incorrect. I do not follow these claims. It seems this part (exp 4.4) is not in a good shape as a submission.\n\nAppendix B2/B3: It is unclear what the takeaways are in the figures? I find it hard to interpret\n\nappendix: line 226/227 typos. ", "rating": "4: Ok but not good enough - rejection", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/Reviewer_v3Nb"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper9/Reviewer_v3Nb"]}]}, {"paper_url": "https://openreview.net/forum?id=dXouQ9ubkPJ", "paper_id": "dXouQ9ubkPJ", "reviews": [{"id": "7QAQqN9VPRa", "original": null, "number": 2, "cdate": 1659735010229, "mdate": null, "ddate": null, "tcdate": 1659735010229, "tmdate": 1659735010229, "tddate": null, "forum": "dXouQ9ubkPJ", "replyto": "dXouQ9ubkPJ", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper6/-/Official_Review", "content": {"title": "Interesting idea, analysis missing", "review": "The proposed method, C-3PO, uses steerable group convolutions to achieve equivariance for the SO(2) group of continuous rotations for a learned keypoint detector based on R2D2. The method is evaluated on the HPatches dataset using rotated samples.\n\nStrengths:\n+ The method is very interesting and highly relevant in solving real-world computer vision problems. Investigating whether equivariance to continuous rotations yields any benefits compared to discrete groups in a local features setting is an excellent research question.\n+ The proposed method is indeed more robust to rotations in the input. Moreover, it does seem to perform comparable to the baseline on the 0-degree setting, despite using fewer channels in the network layers.\n+ The paper is clearly written and easy to read.\n\nWeaknesses:\n- It was not clear to me whether the network is still strictly rotation equivariant as it seems that the approximation of the inverse Fourier transform would prohibit this. Could the authors elaborate?\n- Although the network width has been scaled down, the proposed method still contains more trainable parameters than the baseline. Why did the authors choose not to further downsize the equivariant network or add more channels to the baseline to keep the number of parameters equal?\n- It is strange that the C8 and SO(2) networks have the same performance drop for rotations that are not multiples of 90 degrees. It would have been interesting to measure the equivariance error of the SO(2) network (as the MSE between feature maps of an upright and rotated input sample). \n- I expected a comparison with the baseline trained on rotated input samples. It would have been interesting to see its performance since in practice that is by far the easiest solution, even though it does not provide strict equivariance guarantees. It would also have been nice to include comparisons with [5, 17].\n\nJustification of rating: The problem setting and method are interesting and the paper is very pleasant to read. However, I would have expected some more analysis and comparisons with simple baselines.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper6/Reviewer_rcSk"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper6/Reviewer_rcSk"]}, {"id": "quH1qc1kFSO", "original": null, "number": 1, "cdate": 1658500455748, "mdate": null, "ddate": null, "tcdate": 1658500455748, "tmdate": 1658500455748, "tddate": null, "forum": "dXouQ9ubkPJ", "replyto": "dXouQ9ubkPJ", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper6/-/Official_Review", "content": {"title": "Simple, straightforward, effective", "review": "The authors integrate rotation equivariant convolutions, both discrete G-Convolutions and steerable convolutions, into state of the art image correspondence networks and achieve improved generalization to unseen rotations at test time.\n\nStrengths: simple method; excellent exposition of background, related works and method; strong empirical results; honest discussion of limitations.\n\nWeaknesses: no real concerns. For scope, it would have been nice to see some analysis on the failures of C8 and SO(2), but a limited scope is completely fine for a VIPriors paper.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper6/Reviewer_x4nc"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper6/Reviewer_x4nc"]}]}, {"paper_url": "https://openreview.net/forum?id=3d6PLMQm5Uj", "paper_id": "3d6PLMQm5Uj", "reviews": [{"id": "dJnEEk-bxXa", "original": null, "number": 2, "cdate": 1659656558791, "mdate": null, "ddate": null, "tcdate": 1659656558791, "tmdate": 1659711059923, "tddate": null, "forum": "3d6PLMQm5Uj", "replyto": "3d6PLMQm5Uj", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper5/-/Official_Review", "content": {"title": ".", "review": "1) Summary:\n\nThe paper reformulates Video Frame Interpolation (VFI) as a Continuous Image Transition task. The approach is based on Space Decoupled Learning (SDL) and it shows competitive results for VFI and for other CIT tasks.\n\n2) Strengths:\n- SDL simplifies VIF to a CIT problem without affecting performance and without requiring any human knowledge of the domain. Additionally, SDL works well for several CIT tasks.\n- Paper very well written.\n- Hypothesis supported by experiments.\n- In line with workshop.\n\n3) Weaknesses.\n- Figure 1 is usually an important figure in the paper. It seems a bit difficult to follow and to read.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper5/Reviewer_LjJr"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper5/Reviewer_LjJr"]}, {"id": "0d_qeoxtmsJ", "original": null, "number": 1, "cdate": 1659388706008, "mdate": null, "ddate": null, "tcdate": 1659388706008, "tmdate": 1659388784635, "tddate": null, "forum": "3d6PLMQm5Uj", "replyto": "3d6PLMQm5Uj", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper5/-/Official_Review", "content": {"title": "The SDL method introduced in the paper is a solid contribution as it can improve Continuous Image Transition (CIT) and be deployed for several CIT tasks. The paper seems technically correct, the experiments are exhaustive, the motivation is clear, the paper is well written. Because of this, I vote to accept the paper. ", "review": "Summary:\n\n- The paper aims to improve video frame interpolation (VFI) by reformulate as a continuous image transition (CIT) task. The authors propose a model based on Space Decoupled Learning (SDL) that can be used for multiple CIT tasks, including VFI. One of the advantages of SDL is that is does not require human knowledge of the data domain. Thorough experiments show that the proposed SDL achieves competitive results on a number of CIT tasks, including VFI, face ageing, face tonification, dog-to-dog morphing.\n\n\n\nPositive points:\n\n+ The Space Decoupled Learning (SDL) for Continuous Image Transition (CIT) proposed in the paper seems a solid contribution and can be effectively deployed for several tasks, including VFI, face ageing, face tonification, dog-to-dog morphing.\n+ The paper seem technically correct. Thorough experiments and ablation studies are performed to show the effectiveness of the proposed method. Experiments on four VFI datasets are included, on which SDL achieves competitive performance.\n+ The paper is easy to read, the motivation is clear and the literature review exhaustive.\n+ The proposed method is based on inductive priors which lead to decoupling the image space into tractable flow space and a non-tractable feature space, therefore this paper is a good fit for the VIPriors workshop.\n+ The paper seems reproducible. \n\n\n\nNegative points:\n- I did not find substantial flows in the paper.\n\n\n\nPer line comments:\n\n225-234: In figure 1, the font size is very small, which makes the text hardly readable. I think the figure and capture are currently not self explanatory. I would suggest adding an explanation on how to read the figure. \n\n315: In Table 1 the font size is very small. I suggest to increase it to make the table more readable. ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper5/Reviewer_mcgQ"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper5/Reviewer_mcgQ"]}]}, {"paper_url": "https://openreview.net/forum?id=O2eyumb2ATn", "paper_id": "O2eyumb2ATn", "reviews": [{"id": "gWEmW4d6abN", "original": null, "number": 2, "cdate": 1659630900431, "mdate": null, "ddate": null, "tcdate": 1659630900431, "tmdate": 1659631549853, "tddate": null, "forum": "O2eyumb2ATn", "replyto": "O2eyumb2ATn", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper4/-/Official_Review", "content": {"title": "In general, good work", "review": "Quality: Good work, intensive experiments with three tasks with two major datasets\n\nClarity: Clear problem statements, clear and tidy methodology by adding unsupervised k-means and corresponding loss\n\nSignificance: the methodology could ease the stated problems to some extend (e.g., if new unseen samples are far away from any local experts, so in this situation the hyper parameter K will be related with the performance. How can you determine this K? And what is the influence? Is there any optimal option on choosing K in general?)\n\nQuestions: \n\n1. In Fig. 6 \\& 7 right side, the mAP performance dropped with the large \\lambda (the rightmost square and star). And the caption for that is 'the method is stable regardless the choice of the parameters over various tasks'. Could you please give me some explanation on those two points? I think the trend of dropping of mAP with large \\lambda is clear. Do you still think it is stable?\n\n2. I find some typos or grammar mistakes, please check them. Line 66, 'evcaluate'. Line 112, 'where early on in the training'. Line 236, 'Thereof'. Line 493. 'both both'.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper4/Reviewer_6cuZ"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper4/Reviewer_6cuZ"]}, {"id": "lSSWSoD2hz", "original": null, "number": 1, "cdate": 1659345371196, "mdate": null, "ddate": null, "tcdate": 1659345371196, "tmdate": 1659345450701, "tddate": null, "forum": "O2eyumb2ATn", "replyto": "O2eyumb2ATn", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper4/-/Official_Review", "content": {"title": "A well written paper, with some interesting ideas. The results only show marginal improvement across different settings. ", "review": "Summary:\u00a0\nThe paper builds on the idea of Dynamic Routing (DR) in the context of mixture of experts. The authors propose an unsupervised\u00a0DR approach\u00a0(coined as DivDR) to train several\u00a0local experts on subsets of a training dataset. The paper is well written and well structured, even though it can benefit\u00a0from a proof read. The qualitative experimental results are promising and demonstrate the efficacy\u00a0of the proposed approach in clustering of data subsets and assignment\u00a0of correct local expats. The impact on the bottomline performance in different settings (object detection, semantic segmentation, and so) is rather marginal. The paper has a coherent story, but lacks solid theoretical deep dive into the mechanics of DivDR.\n\nMajor Remarks:\n- Any theoretical guarantees, or intuitive\u00a0analyses, on why the alternating between solving eq(3) and reclustering (3) would work? At least try to discuss this by drawing resemblance\u00a0with similar approaches in literature.\u00a0\n\n- Given that there is still enough space, I suggest summarizing the steps involved in Fig 2 and 3 (Subsection 3.2) in the algorithmic\u00a0form.\u00a0\n\n- $K$ seems to be an important\u00a0parameter. How to optimize or tune on this parameter? In Table 3, rather\u00a0contradicting results are reported. Is it better to increase, decrease or optimize $K$, and how?\u00a0\n \u00a0\u00a0\n- Looking at the result on semantic segmentation, the standard (no-DR based) baselines do not represent the state-of-the-art performance on Cityscapes. That said, the improvement offered by DivDR-X is rather marginal (within 1%). And, the reduction in computational complexity in FLOPS is also on the marginal\u00a0side. Even though the proposed approach does well in metric learning in the $\\mathcal{A}()$ space, the impact on the bottom-line performance seems to be marginal. How would you justify adopting DivDR for semantic segmentation, e.g.? Same can be said about Object detection results, btw.\u00a0\n\nMinor modifications:\n- Another proof read\u00a0would help to fix typos such as: \"evcaluate\" (Lines 66-67), and \"on subsets on subsets\" (Lines 102-3), \"of of accuracy\" (Line 178)\u00a0 and so on.\u00a0\n\n- Please define the acronyms for the first time: NAS (being neural architecture search), etc.\u00a0\n\n- What is $n$ in Line 167.\n\n-\u00a0 Please use references here \"As shown earlier, learning local experts can benefit performance both in terms of accuracy and computational cost\"", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper4/Reviewer_xpff"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper4/Reviewer_xpff"]}]}, {"paper_url": "https://openreview.net/forum?id=8VUywK1AT7d", "paper_id": "8VUywK1AT7d", "reviews": [{"id": "LngLEAd8d25", "original": null, "number": 2, "cdate": 1659656332373, "mdate": null, "ddate": null, "tcdate": 1659656332373, "tmdate": 1659656332373, "tddate": null, "forum": "8VUywK1AT7d", "replyto": "8VUywK1AT7d", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper1/-/Official_Review", "content": {"title": "Nice new idea to process video with GCNs", "review": "I can only recommend to accept this paper. It is highly related to the workshop due to many reasons.\n1) Authors propose GraphVid. A new idea based on GCN to process video in an efficient way. \n2) Apart from being a new and nice idea, it can offers state-of-the-art performance.\n3) GraphVid uses not only opt-flow as prior knowledge but also many new specific data augmentation methods to extract information from the data in the most efficient way possible.\n4) GraphVid allows to make a better use of the data and reduce the computational burden.\n5) All ideas are support by experiments.\n6) The paper is very easy to read.\n... Many others", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper1/Reviewer_1QBf"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper1/Reviewer_1QBf"]}, {"id": "-AYhRTcWDe5", "original": null, "number": 1, "cdate": 1659368158721, "mdate": null, "ddate": null, "tcdate": 1659368158721, "tmdate": 1659388884668, "tddate": null, "forum": "8VUywK1AT7d", "replyto": "8VUywK1AT7d", "invitation": "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper1/-/Official_Review", "content": {"title": "The idea presented in the paper is simple but can effectively speed up action recognition, therefore the paper should be accepted.", "review": "Summary:\n\n- The authors propose an efficient graph video representation, GraphVid, that can be used for action recognition with reduced time and memory requirements. GraphVid results in a large efficiency gain without decreasing the performance. \n\n\nPositive points:\n\n+ The idea presented in the paper is interesting and can facilitate future work on action recognition. \n+ Paper experiments 4 augmentation strategies to improve the model performance. \n+ Thorough experiments and ablation study show GraphVid effectiveness.\n+ Competitive results on two action recognition benchmarks, Kinetics-400 and Charades. \n\n\nNegative points:\n\n- Relevant related work is missing. GCN have been used for video modelling before.\n1) Yan, Sijie, Yuanjun Xiong, and Dahua Lin. \"Spatial temporal graph convolutional networks for skeleton-based action recognition.\" Thirty-second AAAI conference on artificial intelligence. 2018.\n2) Thakkar, Kalpit, and P. J. Narayanan. \"Part-based graph convolutional network for action recognition.\" arXiv preprint arXiv:1809.04983 (2018).\n3) Korban, Matthew, and Xin Li. \"Ddgcn: A dynamic directed graph convolutional network for action recognition.\" European Conference on Computer Vision. Springer, Cham, 2020.\n4) Papadopoulos, Konstantinos, et al. \"Vertex feature encoding and hierarchical temporal modeling in a spatial-temporal graph convolutional network for action recognition.\" arXiv preprint arXiv:1912.09745 (2019).\n...\n\n- Writing is sloppy and overly complex in places. The text can be simplified by removing sentences such as \"to be defined hereunder\" (line 207), \"The following is a description of how we utilize the superpixels to construct our video-graph representation.\" (line 202-203)...\n\n- Spatial edges and figure 5. It is unclear whether the spatial graph for each frame is complete. I do not see an explanation about edge selection, however, it seems that in figure 3 only \"neighbouring super pixels\" are connected. \n\n- Missing algorithm time complexity for graph generation (i.e. extraction of super pixels, graph construction).\n\n- Prior knowledge incorporation (line 369): I do not see how optical flow is currently encoded in the graph video representation, especially due to the absence of coordinates. For example, if an object moves fast within consecutive frames, the distance between the respective super pixels over time might be larger than d_proximity. This way, information about the object motion (direction) is lost completely. \n\n\nJustification:\nThe idea of using super pixels in combination with GCNs is, to my knowledge, novel. The experiments are thorough and show the effectiveness of the method. The paper needs some fixes in the text as indicated above. My rate is weak accept. ", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["thecvf.com/ECCV/2022/Workshop/VIPriors/Paper1/Reviewer_Uiac"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2022/Workshop/VIPriors", "thecvf.com/ECCV/2022/Workshop/VIPriors/Paper1/Reviewer_Uiac"]}]}, {"paper_url": "https://openreview.net/forum?id=xHP1W_Y0jF", "paper_id": "xHP1W_Y0jF", "reviews": [{"id": "2w-h-Ywl1Bv", "original": null, "number": 2, "cdate": 1596148568917, "ddate": null, "tcdate": 1596148568917, "tmdate": 1596564952874, "tddate": null, "forum": "xHP1W_Y0jF", "replyto": "xHP1W_Y0jF", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper28/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "10: Top 5% of accepted papers, seminal paper", "review": "The authors address the problem of cell-to-cell registration of the stereotypic specimen acquired by different imaging modalities. This is an important problem in developmental biology which has not yet received sufficient attention from the computer vision community. The task can be divided into two registration problems: registration between static samples and between static and time-lapse imaging. Shape context descriptors are used to represent different nuclei. The proposed method is compared to strong baselines, outperforming them on real and simulated data. The method is described in detail, including the outlook on potential future improvements.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "A difficult and important registration problem is solved by a creative combination of different algorithms."}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper28/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper28/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "ph8NKdPC_fW", "original": null, "number": 1, "cdate": 1596136959138, "ddate": null, "tcdate": 1596136959138, "tmdate": 1596564953353, "tddate": null, "forum": "xHP1W_Y0jF", "replyto": "xHP1W_Y0jF", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper28/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "10: Top 5% of accepted papers, seminal paper", "review": "The paper presents a methodology for registration of high-resolution gene expression data and live microscopy images of Platynereis dumerilii embrios in 3D. The method detects nuclei, computes descriptors, finds correspondences between cells and aligns the data. One of the core strategies used in this methodology is the ability to match single cells between two image sets, and by solving this, the registration is recovered accurately and efficiently.\n\nThe paper is very well written and tackles an important and challenging biological problem. The proposed methods are innovative and creative, and have shown to be effective for solving the task with the best precision possible. The evaluation is conducted in synthetic data as well as in real world images and the results are very robust. Clean study and elegant solution.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Excellent work"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper28/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper28/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=HdNVXBdk05", "paper_id": "HdNVXBdk05", "reviews": [{"id": "zzqj19mHRRq", "original": null, "number": 3, "cdate": 1596207612050, "ddate": null, "tcdate": 1596207612050, "tmdate": 1596564954872, "tddate": null, "forum": "HdNVXBdk05", "replyto": "HdNVXBdk05", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper26/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "8: Top 50% of accepted papers, clear accept", "review": "Summary\nThis paper addresses the problem of 3D MRI volume segmentation of images collected from patients with Alzheimer's disease. The motivation for the work comes from automating the classification task for assigning labels such as cognitive unimpaired (CU) and Alzheimer\u2019s disease (AD) to each patient based on the 3D MRI volume. The authors approach the problem by  leveraging a 3D to 2D conversion using dynamic images according to https://openaccess.thecvf.com/content_cvpr_2015/papers/Fernando_Modeling_Video_Evolution_2015_CVPR_paper.pdf and https://www.egavves.com/data/cvpr2016bilen.pdf and introducing an attention module in a transfer model with pre-training on ImageNet dataset. The evaluations include (a) matching feature dimensionality of the features extracted from four well-established architectures and the features coming from the dynamic image based conversion, (b) optimizing the steps in feature extraction and AI-based classification, (c) analyzing inclusion/exclusion of skull, and (d) comparing execution times when 3D vs 2D raw data are used as inputs into classifiers.\nStrengths:\nThe classification framework is very interesting.\nThe introduction of dynamic image and attention module is novel\n\nWeaknesses:\nThe experimental dataset is very limited.\nThe theoretical description is not very clear.\n\nComments:\nIs there any reason (e.g., based on visual inspection) to believe that the features of 2D dynamic images are of the same nature as the features extracted from ImageNet?\nLine 129: what do you refer to when mentioning the ImageNet resolution? \nLine 171: why did you choose three activation functions and 1x1 convolutional kernels? \nThe section 3.3 also did not explain the details in Fig 3. For example, why do you have in Fig 3 the same blocks but the tensor sizes are HxWx512 -> HxWx256 -> HxWx64? Shouldn\u2019t the last tensor size be HxWx128?\nWhat implementation did you use for the CAM attention module?\nWhat is the method in dynamic image based conversion that you are using to create 110 x 110 x 3 (i.e., 3 features)? The original paper in https://openaccess.thecvf.com/content_cvpr_2015/papers/Fernando_Modeling_Video_Evolution_2015_CVPR_paper.pdf refers to learning rank machines but your paper does not mention this important detail.\n\n\nMinor comments:\nFig 1 caption: you have one row of pictures but the caption refers to two rows.\nWhy applying dynamic image-based 3D to 2D conversion is preferred over z-axis? Is there any motivation to prefer one of the three possible planes, i.e., sagittal vs transversal vs coronal plane?\n \n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Dynamic Image for 3D MRI image Alzheimer's Disease classification"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper26/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper26/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "u13YPTNemJY", "original": null, "number": 2, "cdate": 1596183250459, "ddate": null, "tcdate": 1596183250459, "tmdate": 1596564955325, "tddate": null, "forum": "HdNVXBdk05", "replyto": "HdNVXBdk05", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper26/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "8: Top 50% of accepted papers, clear accept", "review": "Summary\n-------\n\nThis paper presents a method for Alzheimer's Disease (AD) classification from\n3D MRI scans. In contrast to earlier approaches, the 3D scans are first\nconverted into a 2D dynamic image, which is then processed by a 2D\nconvolutional neural network. The network consists of a pre-trained (and\nfine-tuned) feature extractor, an attention module, and subsequent fully\nconnected layers for the final classification. Results on MRI scans with\nstripped skulls demonstrate a significant increase compared to fully 3D\nbaselines, albeit using only 20% of the time needed for training.\n\nQuality and Clarity\n-------------------\n\nThe introduction, motivation, and technical description are very well written\nand easy to follow. The provided figures are helpful to understand the method\nand show qualitative results of the dynamic image generation.\n\nOriginality\n-----------\n\nUsing 2D dynamic images instead of the full 3D scan is a compelling idea\n(although already explored in other medical domains). The main contribution of\nthis paper lies therefore in the subsequent use of pre-trained 2D feature\nextractors, which are enabled by the 2D input images. Furthermore, the authors\ninvestigate the usefulness of an attention module between the feature\nextraction and classification network.\n\nSignificance\n------------\n\nThe results demonstrate consistent improvements over several baselines and\nvariations of the proposed model. On top of those improvements, the proposed\nmodel trains faster and requires less resources for prediction.\n\nThe authors mention that \"there is potential for mobile applications\" (line\n360). I am not sure what this could look like in a clinical setting and suggest\nthe authors elaborate if they want to make this point convincingly.\n\nMy main concern for a clinical application is that the improved results seem to\nbe achieved only on \"skull stripped\" MRI scans. From the paper, it is unclear\nwhether this is a manual, semi-automatic, or entirely automatic process. I\nwould appreciate if the authors could discuss this point in more detail to\nprovide context about the amount of manual labor needed in the proposed\npipeline.\n\nPros\n----\n\n* well written\n* elegant architecture\n* thorough comparison to baselines and model variations\n* significant accuracy improvement\n\nCons\n----\n\n* unclear how much manual intervention is needed for \"skull stripping\"\n\nMinor Comments\n--------------\n\n* title: capitalize \"image\" and \"classification\"\n* line 56: \"We\" -> \"we\"\n* line 144: \"association\" -> \"associated\"\n* line 283: \"choice\" -> \"choose\"\n* line 335: \"decrease if\" -> \"decrease in\"\n* Equation 4: What is $i$ running over? According to the text, $l$ and $I$ are label and image of a single sample.\n* Figure 4: It would be helpful to see same (or similar) images without skull in the same figure.\n* notation: $\\mathcal{R}$ vs $R$\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Simple and effective method to improve AD classification"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper26/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper26/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "q27Zj24LSqZ", "original": null, "number": 1, "cdate": 1596122307238, "ddate": null, "tcdate": 1596122307238, "tmdate": 1596564955795, "tddate": null, "forum": "HdNVXBdk05", "replyto": "HdNVXBdk05", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper26/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "5: Marginally below acceptance threshold", "review": "-----------------------------\nSummary\n-----------------------------\nThe authors present a novel method for the diagnosis of Alzheimer's disease from MRI volumes.\nThe first compress the 3D volume to a 2D 'dynamic' image, which is then fed into a pre-trained features extractor.\nFinally, the resulting feature vector is subject to an attention mechanism and processed by a fully connected MLP to predict a probability for the disease. \nThe method is evaluated against various baselines and achieves competitive results.\n\n-----------------------------\nStrengths\n-----------------------------\n\n- The paper is for the most part clearly written and structured.\n- The method outperforms its baselines, which are adequatly choosen as far as I can tell.\n\n-----------------------------\nWeaknesses\n-----------------------------\n\nMy main concern is the unclear explanation of the dynamic image compression.\nThis would not be a big issue, since they say they are using an existing method [3].\nHowever, looking at [3], I am not sure the equation they give (Eq. 3) corresponds to what is presented in [3] and if it is really correct.\nTo be more precise, Eq 3 computes simply an averaged image using fixed weights \\alpha_t. It does not even make use of the feature representation.\nIn contrast, the method in [3] averages the computed feature representations, as far as I understand.\nI am really not sure if this is just a typo in Eq 3 or if the authors are simply averaging the images with fixed weights and overselling it as a more sophisticated method.\n\nThe mathematical notation is not very clear.\nIn line 140 'd' is used as the dimension of a feature vector. In line 143 it is itself a feature vector.\nIn Section 3.2 the 'I' denotes an input image, but in Section 3.3  the same symbol is used for the feature image produced by the network.\nThroughout the paper, various symbols are used for the set of real numbers.\n\n-----------------------------\nFinal Recommendation \n-----------------------------\n\nEven though the paper seems highly relevant and generally solid, I am really concerned about the computation of the dynamic image.\nI thus see the paper as borderline.\nHowever, as I am not an expert on dynamic images, it might be that I simply misunderstood this part or that it can be explained as a typo.\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "An interesting moslty solid contribution with some problematic unclear aspects."}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper26/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper26/AnonReviewer3", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=3_2Zf8Rr1N", "paper_id": "3_2Zf8Rr1N", "reviews": [{"id": "baEU5z6Hw9r", "original": null, "number": 2, "cdate": 1596157964046, "ddate": null, "tcdate": 1596157964046, "tmdate": 1596564957376, "tddate": null, "forum": "3_2Zf8Rr1N", "replyto": "3_2Zf8Rr1N", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper23/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "Cell tracking is an important but challenging step for many biological research. By combining VR and eye tracking, the authors developed a new method for tracking cells in 3D and time. With the help of the two devices, users can generate cell trajectories by simply looking at a cell in a 3D movie. In the manuscript, detailed usage and user study data are provided. From what described, this new approach appears to be a great addition and can potentially make cell tracking annotation faster and enjoyable as stated by the authors.\n\nMajor comments:\n- The manuscript is well written with details that are necessary, the limitations are clearly stated. \n- Although it is hard to grasp the actual user experience without trying the device, the user study results seem promising and reflect a good overall experience.\n- Although the authors provide user estimation of a 10x speed up with the new approach, it would be more convincing to actually measure the time for conventional methods and compare them with the new.\n- Since the user can only look at one cell at a time with the new approach, this will likely limit the overall annotation throughput. Instead of focusing on generating trajectories cell-by-cell, I would encourage the authors to explore ways to use the new hardware to fix and curate trajectories generated by automated algorithms. Similar to what is mentioned in the end of the manuscript, it would be also interesting to see how this can be combined with machine-learning algorithms.\n\nMinor comments:\n- The provided supplementary video is quite helpful to the understanding of the approach, it would be helpful also to mention the video in the manuscript.\n- When describing the hardware, could you provide detailed information about the eye tracking resolution? For users who are not familiar with the device, it is better to get some feeling about how accurate the eye tracking device is.\n- Could you also discuss how the cell size impacts the tracking performance? When the cell is big, should the user look at the center of the cell? Is there an optimal display cell size for the device?\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "A new approach for annotating 3D+T cell tracking data"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper23/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper23/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "eqhIbb1DVh", "original": null, "number": 1, "cdate": 1596120546210, "ddate": null, "tcdate": 1596120546210, "tmdate": 1596564957901, "tddate": null, "forum": "3_2Zf8Rr1N", "replyto": "3_2Zf8Rr1N", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper23/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "### Summary\n- The paper proposes an approach for the \u201cmanual\u201d tracking of 3d+t datasets of biological cells that is carried out in virtual reality and cells are tracked via eye. The approach, that the authors call Bionick Tracking, offers an alternative to the established method of manually tracking cells (and lineage trees) on a 2D screen with mouse click.\n\n- The authors investigate the question whether using eye gaze and the movement in virtual reality can facilitate cell tracking. In order to be able to infer the cell track from the tracked eye gaze, they propose to use a graph-based algorithm. They carry out a study with seven users to test their set-up with regards to usability and accuracy.\n\n- They find that all users overall had a positive tracking experience. The users also stated that they believe that tracking with Bionick Tracking speeds up the tracking process.\n\n### Major strengths of the paper\n- The paper is understandable with a clear line of thought; Limitations are clearly stated.\n- The authors set-up a pipeline for eye-tracking of cells in time-lapse videos with a focus on using commodity hardware. With this focus, chances are higher that the setup will actually be adapted by other labs.\n- The authors carried out a user study with promising results including very positive feedback from the users.\n- The approach is novel and addresses important challenges in the cell tracking community (visualization of 3D time-lapse videos and annotation of cell tracks).\n- The authors provide a video that nicely explains the usage of their setup and their algorithm, which facilitates the understanding of the entire paper.\n\n### Major weaknesses of the paper\n- The extraction of the path from the gaze involves smoothing, but how to handle real jumps or datasets that are difficult to register? In this context, the ground-truth path has to contain real jumps that would potentially be smoothed out by the algorithm that they propose in the paper.\n- The study is limited as they only tested their setup on seven users, but this limitation is clearly stated.\n- There is no quantitative comparison of annotation time of conventional methods versus their method. The observation that their method is faster in tracking cells than conventional methods is based on the user\u2019s opinion. This is an important finding, but should be backed up with further quantitative experiments.\n\n### Language\nSome sentences use vague or colloquial language:\n  - \u201cThe initial setting for the scale of the dataset is to make it appear about 2m big.\u201d (about 2m big)\n  - \u201cand a kind of Midas touch problem [10] remains\u201d (a kind)\n  - \u201cAt the moment, the calibration of the eye trackers can still be a bit problematic\u201d (a bit)\n  - \u201cOne could imagine just having one or two eye tracking-enabled HMDs as an institute\u201d (One could imagine just\u2026.)\n\nUnclear sentences and minor mistakes\n- Line 42: \"The 3D images the lineage trees are usually created based on fluorescence microscopy images.\"\nUnclear sentence;\n- Line 94: Unclear sentence, please split into two sentences.\n- Line 129: \"The occur when following a stimilus\" \u2192 They occur when following a stimulus\n- Line 391: \"This corresponds to distances larger than double the standard deviation of all distances the hedgehog.\"\nUnclear sentence\n- Line 539: \"Our method does not only accelerates the process, but makes\"; Incorrect grammar (--> Our method does not only accelerate the process \u2026)\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Interesting direction for tracking of cells in time-lapse video based on eye-tracking, with a small but promising user study."}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper23/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper23/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=7G1GGjdzrde", "paper_id": "7G1GGjdzrde", "reviews": [{"id": "RqgzlTzFLBA", "original": null, "number": 2, "cdate": 1596183069153, "ddate": null, "tcdate": 1596183069153, "tmdate": 1596564959517, "tddate": null, "forum": "7G1GGjdzrde", "replyto": "7G1GGjdzrde", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper21/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "8: Top 50% of accepted papers, clear accept", "review": "Summary\n-------\n\nThis paper presents a feedback mechanism for U-Nets, which re-uses the output\nof the U-Net for a second round of processing. For the incorporation of the\noutput into an earlier feature map of the U-Net, the authors propose two\nattention mechanisms (source-target-attention and self-attention). On an\nelectron microscopy dataset of neural tissue, experiments demonstrate\nconsistent improvements of the self-attention version of the proposed method\nover several baselines, including a vanilla U-Net and a feedback U-Net. In\nfurther ablation studies, the authors investigate the two proposed attention\nmechanisms, the choice of the injection point of the output, and the usefulness\nof the second round of processing.\n\nQuality and Clarity\n-------------------\n\nThe technical description of the method is very clear and the provided figures\nhelpful.\n\nOriginality\n-----------\n\nReusing the output of a U-Net for a second round of processing is not an\nentirely new idea (as acknowledged by the authors in the Related Work section).\nThe main contribution here is therefore the addition of an attention mechanism\nand the re-use of the same weights for the second round of processing.\n\nSignificance\n------------\n\nThe experimental evaluation is thorough (albeit on only a single\ndataset) and addresses key questions about the proposed method. Qualitative\nresults (especially the attention maps generated by the two proposed\nmechanisms) are helpful to understand the contributions of the method.\n\nPros\n----\n\n* clear presentation\n* elegant architecture\n* convincing results\n* thorough analysis of method components in ablation study\n\nCons\n----\n\n* evaluated on only one dataset\n\nMinor Comments\n--------------\n\n* line 44: \"cell image segmentation is a difficult task because [...] there is not regularity compared to other datasets such as automatic driving\" I would personally argue that the opposite is true\n* line 420: \"menbranes\" -> \"membranes\"\n* line 437: \"firrst\" -> \"first\"\n* line 487: \"We\" -> \"we\"\n* no \".\" after \"Equation\", \"Table\", or \"Figure\"\n* line 71: \"we evaluate the proposed method on two kinds of cell image datasets\" results are only presented on one dataset\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "title": "Simple and effective U-Net feedback extension"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper21/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper21/AnonReviewer3", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "6WF3tHl0DIa", "original": null, "number": 1, "cdate": 1596112777383, "ddate": null, "tcdate": 1596112777383, "tmdate": 1596564960064, "tddate": null, "forum": "7G1GGjdzrde", "replyto": "7G1GGjdzrde", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper21/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "8: Top 50% of accepted papers, clear accept", "review": "### Quality\nThis work approaches the addition of a feedback attention mechanism into a U-Net based segmentation method with commendable rigour. While the authors only demonstrate their method on one dataset, they do so in a methodical manner whereby the carefully validate what sort of feedback works best, and also offer explanations as to why this is the case. The authors also validate which layers of the network work most effectively for their chosen network architecture, and that the improvement in segmentation performance is indeed due to the addition of feedback attention rather than just from running data through the U-Net twice.\n\nThe figures are generally good quality. The attention maps in Figure 4 are particularly striking and are a good demonstration of the difference between the two proposed feedback attention methods introduced here.\n\nI would have been very interested to see the authors look closer at the attention maps and performance for the mitochondria and synapse classes, as these classes display the most striking segmentation accuracy improvement over the other methods compared. It would also have been interesting for the authors to have discussed cross-applicability of this approach to other microscopy modalities, for example digital pathology data.\n\n### Clarity\nIt took me a few reads of the paper in order to sufficiently understand the method, and there are quite a lot of grammatical errors and typos throughout.\n\nI personally found that the Query/Key/Value terminology was quite clunky and detracted from my ability to understand section 3.2. For example, the phrase \u2018the $i$th Query\u2019s impact\u2019 (line 255) threw me for a while, as I was unclear which dimension (C, H, W) $i$ was indexing. This may well be my own unfamiliarity with the field, but being slightly more explicit in the explanation of the indices would have helped me understand much quicker.\n\nIt also felt like there was too much unnecessary repetition between the explanations of the Source-Target-Attention and Self-Attention methods. Again, if I understand correctly, the Source-Target-Attention and Self-Attention methods are identical except for the \u2018Query\u2019 being identical to the \u2018Key\u2019 in the latter case? If so, this could have been displayed in a more compact mathematical way.\n\n### Originality\nThis work appears to be the first instance in which attention is integrated into a U-Net via a feedback mechanism. I am not an expert in this field, but a cursory literature search retrieved a [paper discussing the use of attention in medical image segmentation via attention gates](https://arxiv.org/abs/1804.03999) \u2013 perhaps this should have been mentioned as \u2018Related Work\u2019\n\n### Significance\nHigh-quality semantic segmentation is an undoubtedly significant and impactful challenge for microscopy. The technical merit of this work has been made clear, but I think that the authors could have expanded on the significance of the improved performance in the field of cell imaging. For example, the conclusion does not mention the application at all, and more dwells on further technical adaptations, which feels a little short-sighted. For that reason I also have concerns regarding deployment of this technique and ensuring that biologists are actual able to reap the benefits for their research.\n\n### Pros\n* Excellent technical rigour demonstrated in investigating novel method through ablation studies\n* Significant increase in segmentation performance achieved with this method\n\n### Cons\n* The sections describing the generation of attention maps were quite difficult to follow and understand\n* While the performance is very good, the authors do not discuss a route by which this method can actually be used for the benefit of the application demonstrated.", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "title": "Thoroughly-investigated addition of feedback attention to U-Net segmentation"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper21/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper21/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=Br3_V9RBB", "paper_id": "Br3_V9RBB", "reviews": [{"id": "L91ubZi2JX7", "original": null, "number": 3, "cdate": 1596223037940, "ddate": null, "tcdate": 1596223037940, "tmdate": 1596564961690, "tddate": null, "forum": "Br3_V9RBB", "replyto": "Br3_V9RBB", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper20/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "This paper investigates a simple pre-processing method and a modified U-Net architecture for the task of retinal vessel segmentation. The pre-processing combines CLAHE and Ben Graham's algorithm. The modification to the U-Net consists in the use of subpixel convolutions in the down- and up-sampling paths. Results are presented on three public datasets and show consistently improved results over competing methods.\n\nQuality and Clarity\n-------------------------\n\nThe paper is generally well written and easy to follow. The related work section, however, would benefit greatly from a discussion of the differences to the proposed method.\n\nFurthermore, the experimental evaluation lacks a detailed description of where scores of competing methods come from (did the authors run experiments themselves, or are they from other publications?) as well as a discussion of the results (only a table with all the numbers is given). I suggest the authors use the extra space they still have to expand this section.\n\nOriginality\n-------------\n\nThe novelty of the proposed method is somewhat limited. None of the introduced methods is new (CLAHE and Ben Graham's pre-processing, subpixel convolutions). Nevertheless, the application of those methods to the task of retinal vessel segmentation is sensible and worth studying.\n\nSignificance\n----------------\n\nResults are presented on three datasets (Drive, Chase, and Stare) and compared against several competing methods. Due to non-standard splits of the Chase and Stare dataset (and no further information about whether the authors reimplemented competing methods), the results for those are hard to compare. On the Drive dataset, however, the method shows a consistent improvement in accuracy (under several metrics).\n\nPros\n------\n* largely well written\n* convincing improvements on several datasets\n\nCons\n-------\n* unclear comparison to competing methods\n* lack of discussion in related work and experimental results\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "title": "Limited novelty, lack of discussion, but good results"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper20/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper20/AnonReviewer3", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "OC_zuy34T33", "original": null, "number": 2, "cdate": 1596175990669, "ddate": null, "tcdate": 1596175990669, "tmdate": 1596564962130, "tddate": null, "forum": "Br3_V9RBB", "replyto": "Br3_V9RBB", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper20/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "3: Clear rejection", "review": "This paper focuses on a longstanding problem in medical image analysis: retinal vessel segmentation. The authors propose to apply a subpixel residual U-Net to segment the retinal vessels in preprocessed images fusing contrast enhancement and average color subtraction. Performance is evaluated on three public data sets.\n\nIn this reviewer's opinion, the work is out of scope, as the workshop is about biological image analysis rather than medical image analysis. But more importantly, the paper has too many shortcomings:\n\n- Section 2 is a rather monotic enumeration of recent works in the field, one by one, without an overarching discussion of trends including solved aspects and remaining challenges. This lack of insights into the strengths and weaknesses of the discussed works makes it hard to appreciate the value of the proposed method or even why a new method is needed at all.\n\n- Section 3.2 combines two well-known preprocessing methods (CLAHE and average color subtraction) and performs well-known data augmentation approaches.\n\n- Sections 3.3-3.4 propose a deep neural network architecture that consists of well-known concepts (U-Net, ResNet, batch normalization, ReLU, subpixel convolution, BCE-Dice loss). It is not clear from the description what is really new, except for minor technical details, whose effects on the final results are not evaluated.\n\n- Section 4 presents the training approach and the test results \"as is\", without any discussion of the experimental design or the findings, and the sensitivity of the latter to the system hyperparameters. Tables 1-3 show the results of an ablation experiment suggesting there is an advantage in using information fusion. Table 4 simply repeats the best results from Tables 1-3. A comparison with some of the methods listed in Section 2 is shown in Tables 5-7, suggesting the proposed method is superior, but no discussion is presented as to why the proposed method would be better. Nor is it clear that the differences in performance between any of the different methods is statistically significant.\n\n- Section 5 states that the method outperforms \"state-of-the-art models with a much simpler architecture with lesser parameter (~20M) with a fast inference speed of 0.5 seconds on a 512x512 full image\". No numbers (parameters, speed) are given for the other models, so the claims are not substantiated.\n\nAll in all this paper is missing too much information to make it valuable to the community.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Marginal work leaving much to be desired"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper20/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper20/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "oHms6BOc0g", "original": null, "number": 1, "cdate": 1596097364582, "ddate": null, "tcdate": 1596097364582, "tmdate": 1596564962726, "tddate": null, "forum": "Br3_V9RBB", "replyto": "Br3_V9RBB", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper20/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "### Summary\nThe authors propose an approach for the segmentation of retinal vessels. With their modifications, that they introduce in this paper (modified pre-processing, a combination of two losses, subpixel convolution modules for up-and downsampling in the U-Net), they achieve state-of-the art results (although interpretation of comparison with other studies is limited in my opinion). The new introduction of using subpixel convolutions also for down-sampling (it is usually used only for up-sampling) improves the method.\n\n\n### Major strengths of the paper\n- The paper is clear, results are presented nicely, and the paper is easy to understand.\n\n- The authors try out different model parameters and present the results nicely in an ablation study, such that the reader can see the individual contributions.\n\n- The results the authors achieve with their new method are better than other methods, but interpretation of results are limited (see next section). The authors use different modifications (such as pre-processing, loss combination, subpixel convolution) that improve the method, that are clearly presented such that it is easy to learn from this paper.\n\n### Major weaknesses of the paper\n- In this paper, the authors compare their results to results of other studies, but this comparison has several problems:\n  1. Inference and Evaluation is done on a resized image (512x512) from sizes (584x565, 999x960, 700x605) for the three datasets. Evaluation on a downscaled ground-truth version makes it difficult to compare with other studies (this is not so relevant for the first or third dataset, but especially for the second dataset with a downscale factor of ~2). It is also unclear whether the downscaling of the ground-truth was carried out in a way to preserve thin vessels with only a 1-pixel diameter.\n  2. In their results table, they provide results from other studies, but for two out of three datasets, there is no predefined train-test splitting (this is clearly not the author's fault but the benchmark is problematic). Instead, they use a random splitting meaning that their test-split likely differs and the results are only comparable in a very limited way. Only results on the Drive dataset are directly comparable.\n  3. There is no validation set (but only training and test set), and it is unclear whether hyperparameter tuning was carried out on the training set or test set. They use their best performing model on the test set to compare with other models, which demonstrates some tuning on the test set. Overall, this seems to be a general problem of the community as the size of datasets that are available are limited and no clear & clean benchmark is set up.\n  4. Given that results are good on all datasets and that all versions of their models achieve competitive results, it is still likely that results are indeed good, but caveats of the comparison should be addressed more clearly in the discussion part.\n\n- Captions of the figures are too short (sometimes only a few words) which makes it difficult to understand the figures or to spot the relevant aspects of the figure.\n\n### Detailed suggestions\n- Figure 3 caption: Caption is too short, it would be nice to have a little walk-through in such a caption. Eg. guide the reader to the relevant things, mainly what are the contributions of the paper.\n\n- Line 404: in the following tables \u2192 replace with the actual tables.\n\n- Reference for DICE-loss is missing (in section 3.4).\n\n### Language\n\"combined with Ben Graham\u2019s [2] pre-procesing method of subtracting the local average colour\"\nPre-procesing \u2192 pre-processing\n\nLine 263 & 285: \"In this the image\" \u2192 In this image\n\nLine 343: \"vessel vs non-vesel pixels.\"\nNon-vesel \u2192 non-vessel\n\nLine 400: \"around an hour and a half on an average\"\nTakes an hour and a half on average\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Easy to read paper with small but nice contributions, although comparison with other studies is limited."}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper20/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper20/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=5PSL-CjHeP4", "paper_id": "5PSL-CjHeP4", "reviews": [{"id": "PPSWy4Upd0", "original": null, "number": 2, "cdate": 1596191526279, "ddate": null, "tcdate": 1596191526279, "tmdate": 1596564965164, "tddate": null, "forum": "5PSL-CjHeP4", "replyto": "5PSL-CjHeP4", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper19/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "8: Top 50% of accepted papers, clear accept", "review": "The authors present multi-cryoGAN, a generative adversarial neural network for reconstruction of continuous molecular conformations. The method is an extension of cryoGAN, which can perform the reconstruction task for single conformations only. Understanding the continuous motion between individual conformations is important for the understanding of biological mechanisms. The authors evaluate their method on a synthetic dataset, once for a continuous range of conformations and once for two discrete conformational states.\n\n# Strenghts\nThe practical value of such a method is very high and there is certainly demand in the field. \nThe related work section nice reviews existing work in this field.\n\n# Weaknesses\nThe paper is missing a comparison to other state-of-the-art methods like cryoDRGN (https://www.biorxiv.org/content/10.1101/2020.03.27.003871v1), which is mentioned in the introduction but not compared to. \nIt would be interesting to see the FSC curves for reconstruction from different methods, even if they are only able to reconstruct a single conformation.\n\n# Comments\n* In the theory part the authors mention the possibility of reconstructing conformations with translation/shift errors i.e. not perfectly picked locations. Later, in the experiments, this option is disabled, therefore not testing the ability of the proposed method to handle translations/shifts.\n* In the experiments only Gaussian noise is used. It would nice if also Poisson noise would have been used. Is there any problems to expect when switching to real data (and the associated noise sources)?\n* Figure 4a: it would be quite interesting to see the resolution of the reconstructed particles for each different conformation at 0.5 FSC.\n* Figure 5a: the reconstruction seems to have a tendency to prefer the two extreme conformations -- why do you think that is? And how would an experiment of discrete conformations with a 50-50 split look like in comparison?\n* Will the code for this work be available online? If so, the authors should point to it in a footnote or so...", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Interesting and potentially very useful extension of existing cryoGAN work. Solid paper!"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper19/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper19/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "2QY1ITTJczq", "original": null, "number": 1, "cdate": 1596122473188, "ddate": null, "tcdate": 1596122473188, "tmdate": 1596564965635, "tddate": null, "forum": "5PSL-CjHeP4", "replyto": "5PSL-CjHeP4", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper19/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "9: Top 15% of accepted papers, strong accept", "review": "## Summary\n\nThe paper builds on an existing method (CryoGAN) that reconstructs a 3D density of a biomolecule from random 2D tomographic Cryo-EM projections and extends it to the case when the biomolecule is present in multiple structural conformations. Specifically, the authors propose to use a generator module G(z) over a latent space z that parameterized a distribution of possible 3D molecule densities. The sampled densities  together with a forward model produce synthetic 2D tomographic projections which are together with real 2D projection are used to train a discriminator/critic as part of a Wasserstein GAN like approach. The paper then demonstrates that for a synthetic dataset that both with a discrete and a continuous conformation space can be recovered.   \n\n## Strengths\n\n- Approach is original and interesting\n- Provides strong theoretical foundation of the method\n\n## Weaknesses\n\n- Description of latent code -> conformation manifold could be made clearer \n\n## Overall \n\nThe paper is clearly written, the presented approach is interesting and well described, and the results are convincing. The approach of using a GAN like generator in conjunction with a realistic forward model that generates 2D tomographic samples from the 3D density and then to train a critic on the latter (i.e. CryoGAN) seems to be a very powerful and flexible method.  Just a few issues:\n\n- As far as I can tell (cf Algorithm 2), the actual training scheme is simply a WassersteinGAN (with a differentiable forward model on top of the generator), or? That could be made a little bit clearer in the text. \n- For the latent code  \"pz ~ Uniform (z0 , z1 ), where z0, z1 in R^{32,32,32} are randomly chosen from Uniform(0,0.025)\"\nWhy was that specific initialization chosen?\n- Meaning of the latent space: In the paper the latent code is affinely mapped to the conformation space via (1-a)*z1 + a*z2 . Why would that be the correct mapping? As far as I understood the latent space is of size 32x32x32 (is that correct?) and there must be many latent paths that would correspond to a path in conformation space. If the conformation space is now 2 or 3 dimensional, which subset of the latent space would one choose then? What would happen, if the conformation manifold does not even admit a single global chart (e.g. if the molecule has a subunit that can freely rotate around an angle 0...2pi)?\n\n\n## Minor comments\n\n- typos: \"carries\", \"space f\", \"versiond\"\n- \"called a hypermolecule, which is characterized by a basis of hypercomponents\" -> that's a bit hard to understand.\n- \"they rely on 3D clustering to deal with structural variations of protein complexes\" -> why 3D clustering? In which space (poses, conformations) is clustered?\n- line 402: is there alpha missing before z_1? \n- what would be if orientations are not uniformly distributed on SO3? Would the reconstruction simply be worse?\n\n\n\n\n\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Original and well described method for multi-conformation Croy-EM reconstruction   "}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper19/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper19/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=DkCvYVwJHjb", "paper_id": "DkCvYVwJHjb", "reviews": [{"id": "4mSjleXq18l", "original": null, "number": 2, "cdate": 1596165291151, "ddate": null, "tcdate": 1596165291151, "tmdate": 1596564967317, "tddate": null, "forum": "DkCvYVwJHjb", "replyto": "DkCvYVwJHjb", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper15/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "Summary:\nThis paper addresses the problem of nucleus classification based on its morphological characteristics. The problem is motivated by the need to automate analyses of ROIS extracted from whole slide images and classifying the ROIs into tumor and non-tumor regions based on the shapes of nuclei. The authors approach the problem by \n\u2022\tdetecting boundaries of nuclei in ROIs, \n\u2022\tverifying the boundaries against ground truth centroids in BreCaHAD dataset from the paper accessible at  https://bmcresnotes.biomedcentral.com/track/pdf/10.1186/s13104-019-4121-7, \n\u2022\tapplying a medial axis transform (MAT) to nuclei, \n\u2022\tdefining 20 features derived from MAT-based skeletons, and \n\u2022\tclassifying the ROIs based on the features using SVM with RBF kernel.\nThe experimental results include comparisons of the proposed method against other subsets of features and CNN-based methods applied to raw images.\n\nStrengths:\nThe method for preparing training data based on the available BreCaHAD dataset is very creative\nThe 20 features derived from MAT-based skeletons is novel.\n\nWeaknesses:\nThe authors argue at the beginning about the importance of model interpretability. However, that argument is never mentioned in the experimental section. The reader would expect the argument to be developed in Table 2 (add a column for model interpretability). In addition, the authors should demonstrate that they designed all features to have a physical meaning while many other man-constructed features can have very hard to interpret meaning, for example, many texture features (GLCM, wavelet, Zernike, etc.) are very hard to explain to biologists.\nThe paper would benefit from a discussion about feature construction (i.e., physical meaning, link between the biological observations and feature construction), feature dimensionality (i.e., why 20 features?), and feature selection (i.e., ranking of all features from all methods as shown in Table 4 for top 5).\n\n  \n\n\nMain Comments:\nThe paper would really benefit if you could create synthetic data demonstrating the performance of individual features for a range of nucleus shapes\nThe work would also be better received if you would create a visualization (as hinted in your conclusion section) that has a pseudo-colored spatial graph of nuclei. The reason for my comment is that your classification can take into proximity information depending on whether tumor nuclei are interleaved with non-tumor nuclei or tumor nuclei form spatially isolated colonies.\n\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "title": "Classifying Nuclei Shape Heterogeneity in Breast Tumors with Skeletons"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper15/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper15/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "aj3qt_1bdcq", "original": null, "number": 1, "cdate": 1596017973550, "ddate": null, "tcdate": 1596017973550, "tmdate": 1596564967860, "tddate": null, "forum": "DkCvYVwJHjb", "replyto": "DkCvYVwJHjb", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper15/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "This work introduces the use of the properties of skeletonised nuclei for classifying whether nuclei should be classified as tumour or non-tumour in the context of breast cancer diagnosis.\n\n### Quality\nThe work should be commended for taking care to discuss the aims, limitations, and potential extensions of the approach. The authors also acknowledge the limitations of the test data set and steps taken to mitigate bias. While the MAT skeleton features method introduced by the authors does not numerically outperform other methods in measures of accuracy or specificity, it offers a noticeable improvement in sensitivity. The major criticism that I have with regard to quality is that the use of skeletonization as a descriptor is heavily dependent on the initial segmentation of the nuclei in the image. Although the authors have performed ablation to disentangle the contribution of different skeleton descriptors to overall accuracy/sensitivity/specificity, the impact of initial segmentation quality was not taken into consideration. This is slightly worrisome as this is the foundation upon which the entire method is based, and the authors themselves in the caption of Figure 1 describe the segmentation performance as only \u2018fairly accurate\u2019. Again, the caption of Figure 1 acknowledges the merging of nuclei together, which will then of course dramatically alter the skeleton(s) in that region. An interesting experiment would have been, for example, to compare results between an expert manual segmentation for one or two regions of interest with the U-net based segmentation.\n\n### Clarity\nOn the whole the paper is very clearly written and presented and is easy to read and comprehend. However, there are a few instances where this is not the case. There is a little confusion with regard to the advantages of this approach compared to related works. Specifically, the authors explain that segmentation of nuclei is a downside (lines 133-136), yet their approach necessarily requires segmentation. A major shortcoming in clarity is in how the method deals with nuclei that are annotated as neither tumour nor non-tumour (i.e. the four additional classes listed in lines 163-164); this is not discussed. A diagrammatic representation of the features in Table 1 may have added value to the paper, as would have addition of the segmentation boundaries and skeletons to the images in Figure 3.\n\n### Originality\nThe authors do not introduce any novel algorithms or metrics, rather they integrate established segmentation methods (modified U-net), transforms (medial axis transform), and descriptors (ribbon, taper, separation). The application to classification of breast biopsy nuclei does appear to be novel.\n\n### Significance\nOne of the biggest strengths of this paper is the focus on what is necessary in an image analysis tool for pathologists diagnosing breast cancer. The authors clearly outline the need for interpretable and tangible metrics (e.g. shape descriptors rather than the \u2018black box\u2019 of deep learning methods), and they clearly weigh the benefits of this interpretability against methods that may \u2018score\u2019 better. This strength (in my opinion) outweighs the need for a leap in computational novelty.\n\n### Pros\n* The work is focused towards a specific application and integrates the needs of that application (both from an analytical standpoint and a practical standpoint) into the method\n* The performance of the method is generally good\n* The added value, limitations, and future extensions of the skeleton-based approach are explored and discussed.\n\n### Cons\n* The method is necessarily dependent on the initial segmentation quality, and this is not sufficiently explored\n* The method performs a binary classification on the detected nuclei (tumour/non-tumour) when in fact there are six possible classes in the ground truth data; it is unclear how this is resolved in this method.\n", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "title": "A promising method, but the reliance on the initial segmentation is not sufficiently explored"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper15/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper15/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=BcAWplCftE", "paper_id": "BcAWplCftE", "reviews": [{"id": "QYc-df1qQzD", "original": null, "number": 2, "cdate": 1596167334352, "ddate": null, "tcdate": 1596167334352, "tmdate": 1596564969659, "tddate": null, "forum": "BcAWplCftE", "replyto": "BcAWplCftE", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper14/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "The paper addresses the problem of denoising of microscopy images and the fact that traditional methods as well as various recent supervised deep learning methods make assumptions about the noise statistics that may not hold. The authors advocate the use of self-supervised deep learning methods, as high-quality paired training data is often not available to properly train supervised methods. But they observe that self-supervised methods typically produce high-frequency artifacts and achieve inferior results compared to supervised methods. To remedy this, they propose to exploit the fact that the images are usually diffraction-limited, by adding a convolution with a point-spread function model to an existing self-supervised deep learning-based denoising method (Noise2Void) and training it accordingly. Experimental results on a range of microscopy images illustrate the potential of the proposed method.\n\nThis paper is well written and the presentation is easy to follow. While the idea is interesting, I am not convinced it is theoretically sound. As explained (in Section 3.3 and also in Section 3.4), the Noise2Void method estimates the image s. Since s=z*h (Section 3.1), this makes it a denoising method, not a deconvolution method, and that is indeed how the method was designed. Thus, simply processing the estimated s by convolution with an assumed PSF model h (Figure 1 and Section 3.4) is questionable. Of course, doing so will force Noise2Void to behave more like it, and you can claim to \"view the direct output before the convolution as an estimate of the phantom image ... i.e. an attempt at deconvolution\" and get some visually pleasing results, but that does not make the approach theoretically right. Rather, it seems a practical trick that apparently happens to work to some extent.\n\nOther specific comments:\n\n- Section 4.1: Synthetic data is generated using a Gaussian PSF and pixel-wise additive Gaussian noise, but that is not realistic. As the authors admit elsewhere (multiple times), the dominant sources of noise are Poisson photon noise and Gaussian readout noise (Sections 1 and 3.1).\n\n- Section 4.2: \"Our implementation is based on the pytorch Noise2Void implementation from [10]. We use the exact same network architecture, with the only difference being the added convolution with the PSF at the end of the network.\" This, combined with the above major concern, make both the theoretical and the practical contribution of the paper rather limited.\n\n- In Section 2 many methods are discussed but the comparison in Figure 2 is limited to only N2V (and a variant). Are there really no available software implementations of other methods to compare with?\n\n- Section 4.3: The only quantitative measure used is PSNR. It is tricky to make the entire quantitative comparison hinge on a single measure that is known to be questionable. It would be good to also evaluate using other measures, such as SSIM.\n\n- The authors claim \"considerable visual improvements\" (Figure 2) and even \"stunning visual improvement (Section 4.4). These are subjective statements that in my opinion are not supported by the provided evidence.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Interesting practical method but questionable concepts and results"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper14/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper14/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "Nvrr9fDQt34", "original": null, "number": 1, "cdate": 1596047814132, "ddate": null, "tcdate": 1596047814132, "tmdate": 1596564970259, "tddate": null, "forum": "BcAWplCftE", "replyto": "BcAWplCftE", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper14/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "In this work, the authors present an extension to the Noise2Void denoising framework that incorporates convolution with a point spread function in order to better approximate the image formation process in microscopy.\n\n### Quality\nThe premise of the work is very solid and represents a shift towards making denoising approaches specific to bioimaging data rather than just the direct translation of computer vision techniques originally formulated for e.g. photographs, video data. This is an important conceptual advancement in the field.\n\nThe performance of the new method is assessed in comparison to a selection of other denoising frameworks, and when measured by the PSNR metric is shown to out-perform comparable self-supervised methods. However, I find the general reliance on the PSNR as a performance assessment to be problematic, as this does not take into account the structural content of the images post-denoising. For example, in Fig. 2 there appears to be some structural discrepancies in the \u2018Flywing\u2019 data. While the \u2018N2V (conv.)\u2019 image has a lower PSNR than \u2018ours\u2019, the visual agreement between the N2V (conv.) and ground truth data appears better than that between ours and ground truth. As a sanity check for myself, I thresholded and skeletonised these images and while the N2V (conv.) and ground truth skeletons matched well, the \u2018ours\u2019 skeleton deviated substantially at the central junction. Apologies if this seems facetious, but I think it underlines the necessity for another measure of performance, especially as the ultimate goal of denoising microscopy images is to produce a better baseline from which quantitative measurements of structure can be made (rather than just a visually pleasing image).\nI would suggest that the authors remove the phrase \u2018stunning visual improvement\u2019 (line 443) as this is rather subjective \u2013 for example, using the positivity constraint in the mouse actin deconvolution does not improve the prevalence of patterned noise (which can be seen if the images are Fourier-transformed).\n\nSection 4.5, wherein the effects of the PSF size are investigated, seems a little abrupt. Although the PSF size parameter is clearly critical for the performance of the method, this section would have benefitted from additional discussion of e.g. a non-uniform PSF throughout the image or tolerance to the PSF deviating from a Gaussian function, as these are both relevant considerations in real-life microscopy applications.\n\n### Clarity\nThe paper is overall incredibly clear and I managed to understand the majority of what was written on my first pass (in contrast to my general experience reading papers in this field).\n\nThe repeated use of the phrase \u2018diffraction-limited\u2019 is somewhat misleading and may even be doing the work a disservice, This phrase is normally used in the context of referring to conventional widefield or confocal fluorescence imaging data; however there is no reason that the application of this method is limited to this regime. For example, given that the condition of a point spread function whose spatial distribution can be approximated by a Nyquist-sampled Gaussian distribution of known width, this approach could be readily applied to some super-resolution data such as STED images. For this reason, the authors may wish to reconsider the use of the phrase \u2018diffraction-limited\u2019 although this is just a suggestion.\n\n### Originality\nThe work described here is a very similar concept to that described in [Kobayashi et al (2020)](https://arxiv.org/abs/2006.06156). However the authors acknowledge this work in their discussion and given that there was less than one month between the submission of the work by Kobayashi et al and the BIC submission deadline I do not see this as shortcoming in originality (rather, unfortunate timing). Setting aside the paper by Kobayashi et al, this paper displays interesting conceptual novelty. In comparison to the paper by Kobayashi et al, this work (in my opinion) is much better focused toward the application of fluorescence microscopy and is reported in such a way that I feel it is more likely that a microscopist would preferentially use the method presented here. \n\n### Significance\nThe overall conceptual significance \u2013 integrating knowledge about the image formation process into the denoising method \u2013 is high, as I mentioned above. I am still not entirely convinced, however, that there is a *significant* increase in performance, as the PSNR values represent fairly marginal gains over to Noise2Void (alongside my above concerns regarding structural fidelity).\n\n### Pros\n* The paper is very well written, explained, and presented\n* The theoretical benefits of the approach are substantial, and again the explanation of these is well-integrated into the paper\n* The discussion of the paper shows that this work is a starting point and that the authors have thought about concrete ways to extend and improve it going forward. \n\n### Cons\n* The authors have not convinced me from a quantitative point of view that the results are superior to existing self-supervised methods.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Theoretically and conceptually very strong, but I have concerns regarding the performance"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper14/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper14/AnonReviewer3", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=UWm7zRhPoMX", "paper_id": "UWm7zRhPoMX", "reviews": [{"id": "4Bm6O4UDw7G", "original": null, "number": 2, "cdate": 1596165371323, "ddate": null, "tcdate": 1596165371323, "tmdate": 1596564949022, "tddate": null, "forum": "UWm7zRhPoMX", "replyto": "UWm7zRhPoMX", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper8/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "9: Top 15% of accepted papers, strong accept", "review": "Summary\nThis paper addresses the problem of image segmentation and denoising when a very few training segmentation masks are available. The problem is motivated by the need to train neural networks with a high capacity (millions of coefficients) while having only tens of ground truth segmentation masks. The authors approach the problem by combining the self-supervised denoising task with the segmentation task in one neural network optimized using a joint loss. The joint loss is a weighted contribution of denoising and segmentation loss contributions. The authors develop the joint denoising and segmentation framework as an extension to the Noise2Void work accessible at https://openaccess.thecvf.com/content_CVPR_2019/papers/Krull_Noise2Void_-_Learning_Denoising_From_Single_Noisy_Images_CVPR_2019_paper.pdf\n\nStrengths:\nThe practical value of training a segmentation model with very few ground truth segmentation masks is very high.\nThe novelty lies in formulating a joint loss and delivering denoised images as well as segmentation masks.\n\n \nWeaknesses:\nThe paper is missing an assumption paragraph which is misleading for a reader who would like to use this technique.  For example, one of the assumptions is the i.i.d. property of the noise. Another assumption is that the very few ground truth segmentation masks must be representative of the dataset. The authors showed the performance on three datasets that have spatially distributed very similar pattern/content and thus sampling is very easy. \n\nComments:\nHow did the authors decide on the size of the blind spot patches? The paper focused on Noise2Void is using patches of 64 x 64 pixels while this work is using patches of 128 x 128 pixels.\nLines 249 \u2013 257: The authors refer to patches and then to images. Please, verify the terminology\nLines 314, 345-350: It is not clear how delta is computed. Is it AP(alpha=0.2) \u2013 AP(alpha=0.5) or AP(alpha=0.2) \u2013 AP(alpha=0.7) compared to AP(alpha=0.5)? Please, clarify. I could not follow the Figure 6 vertical axis (you might include an equation for delta).\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "DenoiSeg: Joint Denoising and Segmentation"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper8/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper8/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=3HQMxxEmiJn", "paper_id": "3HQMxxEmiJn", "reviews": [{"id": "7KFxnpBYI7K", "original": null, "number": 2, "cdate": 1596150686097, "ddate": null, "tcdate": 1596150686097, "tmdate": 1596564972190, "tddate": null, "forum": "3HQMxxEmiJn", "replyto": "3HQMxxEmiJn", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper6/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "9: Top 15% of accepted papers, strong accept", "review": "I think the presented approach of improving segmentation results of glands in histopathological images by additionally taking clues from textual descriptions is a great idea and the proposed method is indeed improving compared to a baseline not using the additional text.\nThe proposed method does, in fact, reach state-of-the art performance on two well known public datasets.\n\nThe paper is at times a bit confusing (e.g. numberings in Figure 2 and caption is confusing me a lot, or the floats are at quite far away from the main text talking about them) and expects the reader to know quite a lot about the medical problem at hand (lots of expert lingo). Also the technical parts are not leaving me with total clarity. If this was not a workshop paper I would value these issues significantly higher.\n\nAnyway, I liked the paper, it is absolutely hitting the BIC spirit, and I would love to hear a talk about this work.", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Solid work, great approach, good results"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper6/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper6/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "PhEJOz6FhT9", "original": null, "number": 1, "cdate": 1596098285731, "ddate": null, "tcdate": 1596098285731, "tmdate": 1596564972730, "tddate": null, "forum": "3HQMxxEmiJn", "replyto": "3HQMxxEmiJn", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper6/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "6: Marginally above acceptance threshold", "review": "### Summary\n- The authors propose a new approach called DoubleU-Net for gland instance segmentation in the context of cancer diagnosis. The classification results (different stages of cancer) from the first phase are reused to enhance the instance segmentation in a second phase. The doubleU-Net has a text-image encoding path, that incorporates the classification results in form of text (word2vec) and combines it with the original image to finally produce an attention map that is applied to the bottom of the U-Net for instance segmentation.\n\n- The authors can show that their approach indeed improves the instance segmentation results greatly when compared to state-of-the art methods and their own method without using the text-encoding path.\n\n### Major strengths of the paper\n- The results are impressive and are better than current state of the art. The authors can clearly demonstrate that segmentation results improve when intermediate classification results (text) are presented to the network in a second iteration.\n\n- The text-(image)-encoding path of the author's proposed method is flexible such that it can potentially be enriched with more meta-data about the patient. Their research thus goes in an important direction, that is very relevant and not explored yet in the field.\n\n### Major Weaknesses of the paper\n- The introduction and motivation is difficult to understand, and written in a very difficult and cumbersome language (see language section for more constructive feedback). \n\n- It would be important to stress out that the presented model even without using a text input already outperforms most state-of-the-art methods. To make this more visible in the paper, results from Table 4 row \u201cWithout Text encoder\u201d could also be added to the summary results Table 2.\n\n- The method is not described in full detail or it is difficult to understand. There are thus still some unclear parts about how the method actually works:\n  1. In the method section, it is not described how to get from the output of the network (a softmax map) to the final instance segmentation (each object being represented with a different ID).\n  2. There are two training iterations (1) and (2) (described in Figure 2), but it is unclear whether in training iteration (2), the image-encoding path is trained from scratch or retrained (eg. weights are initialized from training (1)).\n  3. For cancer classification/grading (results Table 3), is the network after training phase (1) or (2) used? If (1), why do results improve with text encoding? If (2), how can grading get better if during phase (2), the network is only trained on L_seg and not the grading loss anymore?\n  4. Word embedding: Based on the dataset, I assume that there is a very limited amount of words for each image (and I can\u2019t recognize any sentences), but in the section about word embedding, an embedding is described that involves the summation of multiple words for each sentence and the combination of multiple sentences. It is also unclear how the final textual feature vector v (whose length depends on n) always meets the length of 300 described in section 4. Implementation details (--> The dimensionality of each word vector is 300).\n\n### Detailed suggestions\nIs equation (3) (fusion of images and text) done once or multiple times? It would be easier for the reader, if the paper says that equation 3 is repeatedly used in the encoding path of the text. Additionally, to improve clarity, you could add a figure reference into the text (for instance to line 280): this fusion block is displayed in green in Figure 3. It is probably misleading if the text-encoder is called text-encoder, since both text and image are encoded.\n\n### Language\n- \"It is determined by pathologists on Hematoxylin and Eosin (H&E) stained tissue specimens.\"\n  Preposition \"on\" seems wrong / or unclear sentence.\n\n- \"The morphological information of intestinal glands, like architectural appearance and gland formation, is one of the primary features in clinical to inform prognosis and plan the treatment of individual patient.\"\n  in clinical seems wrong\n\n- \"Besides the initial gland segmentation, we offer cancer diagnosis and greatly improved segmentation results as full-scale assistance for pathologists according to the clinical routine.\"\n  as full-scale assistance seems wrong\n\n- \"Unannotated image data can be utilized effectively by the proposed deep adversarial network [32] for considerably better results.\"\n\u2192 Unlabeled image data\n\n- Line 129\n  model for lesion Detection, tagging, and segmentation.\n\u2192 model for lesion detection, ... (no capital letter)\n\n- Line 289 \"Without thorough incorporation, text data contains no object localization could fail to guide the visual features on the pixel level.\"\n  Unclear sentence;\n\n- Line 311 \"from the text encoder, we perform two-dimensional softmax to the each channel of the feature maps\"\n  Remove \u201cthe\u201d\n\n- Line 330 \"which validates our explanation that the clinical text data controls and emphasizes the glandular structure and morphology.\"\n  Unclear sentence\n", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "title": "Difficult to read paper and thus difficult to understand, but with an interesting approach and impressive results."}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper6/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper6/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=Hjw2saQPB5G", "paper_id": "Hjw2saQPB5G", "reviews": [{"id": "aeldYbZ-DWc", "original": null, "number": 3, "cdate": 1596202888587, "ddate": null, "tcdate": 1596202888587, "tmdate": 1596564950716, "tddate": null, "forum": "Hjw2saQPB5G", "replyto": "Hjw2saQPB5G", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper2/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "7: Good paper, accept", "review": "While the submitted manuscript is indeed aiming a a joint denoising and superres task, there is quite a body of work that was not included in the related work sections or in the comparative parts of the paper (CARE, N2V, PN2V, etc.).\n\nI have the feeling that the utility of the data should be valued higher than the incompleteness of comparisons, but if the camera-ready version could at least acknowledge the broader existing literature it would certainly be a positive.\n\nWith respect to the data, it appears that the availability of it is still pending to some degree. From the GitHub repo of the paper:\n```\nTo those who have cloned or forked our repository, we now removed the png data and are working with the raw data pre-processed only with a single global z-score normalization. All the consequent modifications are being made. The full raw data will be made public very soon, and pretrained models (with raw data) will be made available by mid July.\n```\n\nIn my opinion it would be highly desirable to bring the work on this public dataset to completion together with the submission of the camera-ready version.\n", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "title": "Potentially VERY useful public dataset, some questions regarding neglected related work"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper2/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper2/AnonReviewer3", "thecvf.com/ECCV/2020/Workshop/BIC"]}, {"id": "fZd1fypw4uY", "original": null, "number": 1, "cdate": 1596146551087, "ddate": null, "tcdate": 1596146551087, "tmdate": 1596564951200, "tddate": null, "forum": "Hjw2saQPB5G", "replyto": "Hjw2saQPB5G", "invitation": "thecvf.com/ECCV/2020/Workshop/BIC/Paper2/-/Official_Review", "content": {"reviews_visibility": "I agree that my anonymized review is made publicly visible, if the submission is accepted.", "rating": "9: Top 15% of accepted papers, strong accept", "review": "The authors address the problem of denoising and image resolution improvement in microscopy. A new public benchmark dataset is presented, much more extensive than the currently available alternatives.The authors perform a detailed evaluation of the existing denoising and super-resolution algorithms and finally propose their own which handles both tasks and out-performs the others. All code and data is available. ", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "title": "An extensive new dataset and a new state-of-the-art algorithm for denoising and super-resolution."}, "signatures": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper2/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/BIC/Paper2/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/BIC"]}]}, {"paper_url": "https://openreview.net/forum?id=N-SJaozl-3f", "paper_id": "N-SJaozl-3f", "reviews": [{"id": "vBqp6KxKREM", "original": null, "number": 2, "cdate": 1595837700106, "ddate": null, "tcdate": 1595837700106, "tmdate": 1596013647167, "tddate": null, "forum": "N-SJaozl-3f", "replyto": "N-SJaozl-3f", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper20/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes  human instance segmentation method which has two main modules: (i) mutual refinement between optical flow and segmentation, (ii) skeleton refinement module. \n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n- Refinement modules\n- Performance\n- Robustness to occlusion\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n- It is emphasized that the method does self supervised learning, but it is not clear how and where it happens. \n- There is no clear information about online collected videos, their labeling process, how they are used during training and the contribution of this dataset.\n\n#### 4. [Overall rating] Paper rating\n6\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \nA nicely engineered paper which uses some prior knowledge and refinements to improve the performance.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n- L.82: If the priors can only function as weak constraints how do they help in this paper?\n- L.124: GBSR, TPR and Pose2Seg are not mentioned before and in this line, abbreviation is given. It can be better to give full form.\n- Fig.3: Loss term is not visible.\n- L.269: \"..if without occlusion.\"\n- L.455: How exactly are the annotations generated?\n- L.462: What are those benchmark datasets?\n- No explanation of Table 2 in the text.\n- What are the limitations?\n- What are the failing cases?\n- How are memory and time consumption?\n\nTypos:\n- L.23: Unlabeled\n- L.41: instance\n- L.87: vectors\n- L.279: subscripts of 'l' are different than on the Eq.2.\n- I guess there is no reason to write methods and backbones twice in Table 1.\n\nCitations:\n- L.88: Wasserstein metrics", "title": "A Self-Supervised Framework for Human Instance Segmentation", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "6: Marginally above acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper20/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper20/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "Pf2HGvmjKAr", "original": null, "number": 1, "cdate": 1595406042655, "ddate": null, "tcdate": 1595406042655, "tmdate": 1596013647222, "tddate": null, "forum": "N-SJaozl-3f", "replyto": "N-SJaozl-3f", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper20/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors use temporal consistency through pose estimation and optical flow estimation to improve human instance segmentation. Though this approach technically does not qualify as self-supervision, the temporal inductive priors are strong and show clear improvements over baselines.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\n- Simple, powerful idea to use temporal consistency prior.\n- Decent implementations of each contribution, with proven results.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n- This method is not a self-supervision method. Self-supervision is when a DNN learns from mistakes in predictions on the input data. This method instead uses prior knowledge to fill in missing information within the model.\n- Related to the previous point: the motivation is poorly formulated. It relies on a unfounded claim that self-supervision is superior to using prior knowledge, while the paper actually uses prior knowledge, specifically the temporal consistency prior. As a result the introduction uses vague statements without supporting evidence.\n\n[Overall rating] Paper rating: Weak accept\n\n[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- N_{GBSR} has zero influence in table 3 & 4. Why do the authors not discuss this? Why do they show it in tables 3 & 4?\n- Unsubstantiated claims: lines 73\n- Fourth contribution is not a contribution. The experiments serve to prove your first contribution.\n- Line 398: not clear why the different modules get \"different data\".\n- Grammar: lines 39 \"have\", \n- Typos: lines 87 \"vetors\"\n- Line 486: \"subjective\" = not a fact != about subjects\n- Start new sentences instead of using comma: lines 43, 70, 312, 403, \n- Premature end to sentence: line 396\n- Capitalization: line 398, 434", "title": "Good implementation of temporal consistency, but motivation needs work", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "6: Marginally above acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper20/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper20/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=ZHT0ZpxQO5E", "paper_id": "ZHT0ZpxQO5E", "reviews": [{"id": "FbJQoBG3hq", "original": null, "number": 2, "cdate": 1595922516773, "ddate": null, "tcdate": 1595922516773, "tmdate": 1596013648233, "tddate": null, "forum": "ZHT0ZpxQO5E", "replyto": "ZHT0ZpxQO5E", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper13/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\n In this paper, authors propose guidelines to build proper datasets for object proposals that can offer good generalization when training models on them. Concretely, the paper introduces the idea of prototypical classes as the sufficient and necessary classes to achieve good generalization. To proof this, they conduct a series of experiments on OIV4 and COCO datasets. As oracles, they choose Faster RCNN and RetinaNet. \n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\n -\tThe paper is very well written. Story is very easy to follow.\n -\tGeneralization typically has been study from the model perspective. However, interpreting the problem from the data perspective is very interesting.\n -\tAlthough authors focus on data, they also offer a study of what is happening with the models to validate the results.\n -\tIn particular, prototypical classes seems pretty interesting.\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n -\tThe effect of space granularity has a weird interpretation. The model used for this experiment is class specific Faster RCNN. Have the authors tried the class agnostic version?\n -\tVisual and Semantic diversity seems obvious. It would be interesting to study also the amount of samples, as well as how similar they are.\n\n\n4. [Overall rating] Paper rating.\n\n 7\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\n The whole paper is interesting. Even more from the efficiency perspective. Prototype classes play an important role. \n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n", "title": "What leads to generalization of object proposals?", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper13/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper13/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "wSGF2FAiLW6", "original": null, "number": 1, "cdate": 1595339899098, "ddate": null, "tcdate": 1595339899098, "tmdate": 1596013648177, "tddate": null, "forum": "ZHT0ZpxQO5E", "replyto": "ZHT0ZpxQO5E", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper13/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors propose to learn object localizations using only prototype classes. They explore what defines prototype classes and experiment with many ablations and hyperparameters to their method.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nPowerful idea; clear definitions; practical modeling choices for determining prototypical classes; extensive experimentation.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nMarginally related to visual inductive priors.\n\n[Overall rating] Paper rating: Accept", "title": "Prototype classes can be sufficient to localize in object detection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper13/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper13/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=Vh-OGLzvNeo", "paper_id": "Vh-OGLzvNeo", "reviews": [{"id": "84scRy_UewO", "original": null, "number": 2, "cdate": 1595836549678, "ddate": null, "tcdate": 1595836549678, "tmdate": 1596013648343, "tddate": null, "forum": "Vh-OGLzvNeo", "replyto": "Vh-OGLzvNeo", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper12/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper smartly combines different loss functions and augmentation techniques to overcome the problem of small classification dataset. In addition, it proposes new dual architecture by using Selective Kernel convolution.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n- Proposed model\n- Performance\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n- Clarity (explanation of models, experiments and results)\n\n\n#### 4. [Overall rating] Paper rating\n7\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n- Please explain why each related work part is related to the paper.\n- L.115: (Fig.1) The notations in the figure are not same in the equations. Fig.1 is not refered in the text.\n- Please explain each notation in each equation.\n- Please explain each proposed method.\n- L.161: How do you choose \u03bbi? Is it dropped from one side in each time? Is there any cases that both SK-branches can be kept or dropped?  \n- L.344:In the conclusion part, it is said that DSK-net is robust to translations. Is there any experiments to show that?\nMissing citations:\n- L.28: \"image classification[???], object detection[???], semantic segmentation[???]\"\n- L.37: what are those \"few pre-trained models\"?\nTypos:\n- L.15: effiective -> effective or efficient\n- L.17: \"A\" loss (lowercase)\n- L.147, 221, 347: Starting the sentence with \"And\" (problem)\n- L.176: possible\n- L.180: a loss\n- L.271: the word is not fitting into line.\n- L.344: robust to translations.", "title": "A visual inductive priors framework for data-efficient image classification", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper12/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper12/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "NyrhTWVQa8m", "original": null, "number": 1, "cdate": 1595419681277, "ddate": null, "tcdate": 1595419681277, "tmdate": 1596013648397, "tddate": null, "forum": "Vh-OGLzvNeo", "replyto": "Vh-OGLzvNeo", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper12/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes the Dual Selective Kernal residual building block consisting of Selective Kernel convolutions [17] and BlurPool layers [35]. Furthermore, a novel positive class loss is introduced motivated by the low number of samples per class and possible label errors, and a tree supervision loss to incorporate semantic relationships amongst the ImageNet classes. Different models are trained and evaluated on the VIPriors classification dataset where significant performance improvements are shown.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* The method seems effective\n* Ablation studies have been performed to show the effectiveness of the individual contributions (i.e. DSK and PSL)\n* Apart from several unclarities in the method section (see 3.), the paper is easy to read.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* The method section contains some unclarities:\n * (lines 128-129) What are the the two transforms $\\mathcal{\\hat{F}}$ and $\\mathcal{\\tilde{F}}$ and where are these in Figure 1? Do you first perform regular 3x3 and 5x5 convolutions, followed by depthwise convolutions? I also don't see the Batch Normalization and ReLU layers and $\\mathcal{U}$ in Figure 1.\n * (line 132) \"a compact feature $s$...\"\n  $s$ should be $z$ according to Figure 1?\n * (line 135) \"soft attention across channels is conducted\"\n  It is unclear how the softmax operation is applied. Is it applied per channel between $\\hat{\\omega}$ and $\\tilde{\\omega}$ or across all channels of $\\hat{\\omega}$ and all channels of $\\tilde{\\omega}$ separately? The former seems more reasonable but the text is not very explicit about it.\n * $\\lambda$ in equation (2) and lines (160-162) is $\\alpha$ in Figure 1?\n * lines (168-169) \"compactness of intra-class\" sounds a bit ambiguous. Could you elaborate on this?\n * Can you explain the positive class loss as introduced in equation (5)? What is the motivation behind chosing the cosine loss? Please elaborate.\n * What is $l$ in equation (7)? Where do you extract $w_{i,j}$ and $x$ from? Can you intuitively explain how the loss function works and what is optimized?\n * What are the motivations for the model choices? It seems a bit arbitrary that ResNeXt is combined with PSL and CL but not with TSL, and ResNeSt is combined with TSL but not with PSL and CL.\n* The method is only evaluated on a single dataset. It would have been nice if the authors had shown that their method also generalizes to other settings.\n\n#### 4. [Overall rating] Paper rating\n6. Marginally above acceptence threshold.\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nThe methods introduced by the authors seem effective and therefore I am willing to accept the paper, in the hope that the authors will clarify and extend the method section for the camera-ready version.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n* See unclarities in 3.\n* Please combine multiple references in a single bracket, i.e. [1][2][3] should become [1,2,3] and use ~\\cite{} instead of \\cite{} for extra spacing.\n* Small typos:\n * line 18: \"VIFP\" --> VIPF\n * line 88: architecture --> architectures\n * line 128: \"Then we two transforms\" --> remove \"we\"\n * line 131: \"element-wise sum of u-hat and u-hat\" --> one of them should be tilde\n * line 138: same as above: one of u-hat should be u-tilde\n * etc. Please check your writing for the camera-ready version.", "title": "Interesting method, unclear explanations", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "6: Marginally above acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper12/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper12/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=v_KSmk9B5kt", "paper_id": "v_KSmk9B5kt", "reviews": [{"id": "HYmu4hrx4m", "original": null, "number": 2, "cdate": 1595921785272, "ddate": null, "tcdate": 1595921785272, "tmdate": 1596013649009, "tddate": null, "forum": "v_KSmk9B5kt", "replyto": "v_KSmk9B5kt", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper7/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\n The paper describes an object classification pipeline to better generalize in difficult occluded scenarios. It is composed of three main concepts: prototype learning, partial matching and top-down modulation. Experiments show the benefits of the pipeline at different levels of occlusion in a simulated scenario, as well as in a real scenario. \n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\n -\tThe paper is well motivated and clear.\n -\tThe incremental experimental set-up helps understand the benefits of each of the concepts.\n -\tIn the concrete experimental set-up authors propose (vehicle images), the pipeline works.\n -\tThe paper clearly studies how to include visual inductive priors to the network to improve generalization performance.\n\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n -\tThe paper seems to have a very controlled experimental set-up, using only vehicles. It would be interesting to study how the method performs with different objects.\n -\tAdditionally, a comparison with state-of-the-art approaches in this task would add value to the paper.\n -\tLines 440-451: \n\t- Why 512 dictionary components? Why does it work for all datasets?\n\t- Have authors tried to use a different model, apart from VGG?\n\n\n4. [Overall rating] Paper rating.\n\n 7\n\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\n Readability and use of inductive priors, very positive. Weaknesses are further questions to the paper.\n\n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n -\tLine 528: Table ??\n -\tTables are extremely small. Is there any way to change this?\n -\tLine 533-539: Shape of prototypes. This would be quite interesting to have it in the main paper, not in the supplementary material\n", "title": "TDMPNet: Prototype Network with Recurrent Top-Down Modulation for Robust Object Classification under Partial Occlusion", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper7/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper7/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "SAKI6_BvtI5", "original": null, "number": 1, "cdate": 1595333216187, "ddate": null, "tcdate": 1595333216187, "tmdate": 1596013649064, "tddate": null, "forum": "v_KSmk9B5kt", "replyto": "v_KSmk9B5kt", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper7/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors propose modifying an image classification CNN to add prototype matching with support for partial matches to be more robust to object occlusions. An additional top-down feedback module helps reduce the artefacts caused by occlusions.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nExtensive experimentation including ablation studies; great amount of analysis to give insight into results.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nAmount of related works included in comparisons is limited; there are better models than VGG to use as baseline; experiments on real occlusions (i.e. COCO) are limited and complex in setup.\n\n[Overall rating] Paper rating: Accept\n\n[Confidence] /5\n\n[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- Speculation: line 295-296\n- Line 437: details on \"insufficiency of images\" are needed\n- Table 2: replace numbered accuracies with some description in the table header\n- Grammar: line 119, 285-286\n- Typo: line 437 \"occulded\"\n- Line 528: table reference broken\n- Multiple places: \"Experiments will show\" -> \"Experiments in section x show\", or alternatively consider reorganizing the paper to not (have to) refer to future sections.\n", "title": "Occlusion-aware CNN for image classification", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper7/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper7/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=PnuDpxJvR0q", "paper_id": "PnuDpxJvR0q", "reviews": [{"id": "u0RjwgESs9N", "original": null, "number": 2, "cdate": 1595837447877, "ddate": null, "tcdate": 1595837447877, "tmdate": 1596013649501, "tddate": null, "forum": "PnuDpxJvR0q", "replyto": "PnuDpxJvR0q", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper4/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nAuthors in this paper described a modification of the embedding clustering method (DeepCluster) presented in [2]. Different from DeepCluster, this work proposes a unified pipeline, where clustering is directly performed using an image classification task. Experiments show first that their method achieves same or better performance than that of DeepCluster.\n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nThe authors found out that the embedding clustering phase in the previous method DeepCluster [2] can be avoided and its two phases can directly be performed using a classification task.\nThe method is pretty simple but it obtains state-of-the-art results.\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nThe paper seems a bit difficult to read. I found it a bit difficult to follow the story.\nThe whole paper is built on top of the work of [2], when considering the results, it could be described as a contribution to the field by itself.\nAlthough authors propose to use different visual data augmentation (at the beginning only random crop and then further extending it with SimCLR techniques), and claim efficiency as they avoid storing embeddings, the work does not seem to be very much related to study visual inductive priors.\n\n4. [Overall rating] Paper rating.\n\n6.\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\nWith a simpler method, the paper shows good results. However, readability, structure and out of scope possibility lower the score. \n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\nI suggest the authors to increase the size of Fig. 1, 2 and 4.\n", "title": "Unsupervised Image Classification for Deep Representation Learning", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "6: Marginally above acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper4/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper4/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "YhkqVW_6bCH", "original": null, "number": 1, "cdate": 1595432891444, "ddate": null, "tcdate": 1595432891444, "tmdate": 1596013649578, "tddate": null, "forum": "PnuDpxJvR0q", "replyto": "PnuDpxJvR0q", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper4/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a simple method for unsupervised deep clustering by iteratively (1) generating pseudo-labels by performing a forward pass through a CNN and (2) training the CNN using the generated pseudo-labels. The method is evaluated on ImageNet and performs competitively with other unsupervised learning methods.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* The method is surprisingly simple and seems to perform competitively with clustering in latent space, which is much more computationally expensive.\n* The paper is well written and easy to understand.\n* The performed experiments are sound and demonstrate the effectiveness of the method.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* The bold numbers in Table 3 are rather misleading as they do not actually denote the best performance.\n\n#### 4. [Overall rating] Paper rating\n* 8: Top 50% of accepted papers, clear accept\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nThe method is simple and effective and the paper is well written.", "title": "Simple and effective method for unsupervised feature learning", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper4/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper4/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=8V9lE-zP0ZL", "paper_id": "8V9lE-zP0ZL", "reviews": [{"id": "uR3Et0GqHR", "original": null, "number": 2, "cdate": 1595836825959, "ddate": null, "tcdate": 1595836825959, "tmdate": 1596013649906, "tddate": null, "forum": "8V9lE-zP0ZL", "replyto": "8V9lE-zP0ZL", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper2/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe method has two stages: (i) a teacher network is trained with contrastive learning to obtain feature representation, (ii) the knowledge of the teacher network is transferred to student network by distillation, in the meantime, the student network is also finetuned with labels. \n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n- 2-stage method\n- Using a margin to overcome the small bank size problem \n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n- No conclusion and discussion section.\n\n\n#### 4. [Overall rating] Paper rating\n7\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- How is the margin value chosen? In the text, it is given as 0.6 but in the table, the value is 0.4.\n- Related works: Why is there any margin loss part?\n- Missing citations:\n\t> L.29:\".. simply memorize the dataset and can not generalize well to unseen data..\"\n\t> L.31:\"..some works..\" (only given one)\n", "title": "Distilling Visual Priors from Self-Supervised Learning", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper2/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper2/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "JrNhSHBHn8", "original": null, "number": 1, "cdate": 1595489752211, "ddate": null, "tcdate": 1595489752211, "tmdate": 1596013649961, "tddate": null, "forum": "8V9lE-zP0ZL", "replyto": "8V9lE-zP0ZL", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper2/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes to use contrastive pre-training to construct a visal prior (i.e. the model weights) and subsequently initializes both a teacher and student model with the pre-trained weights to finetune the student network on the dataset while  imposing an additional distillation loss between the frozen teacher and unfrozen student networks.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* The paper is clear and is easy to understand\n* The method is interesting and seems to perform well\n* The ablation studies clealy show which portion of the performance gain can be accredited to the proposed method and which portion is due to additional tricks, such as data augmentation.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* It would have been nice to include experiments on an additional (toy) dataset such as MNIST or SVHN to show that the method generalizes to other tasks.\n* Conclusion section is missing; the paper is ending rather abruptly.\n\n#### 4. [Overall rating] Paper rating\n8: Top 50% of accepted papers, clear accept\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nThe method is interesting and seems to perform well. In addition, the paper is well-written. Please consider extending the paper with a \"Conclusion\" section.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n* What is $\\tau$ in equation (1)?", "title": "Interesting method, well-written paper", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper2/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper2/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=A4ft_k1rJ1C", "paper_id": "A4ft_k1rJ1C", "reviews": [{"id": "jLzzv_mC5uO", "original": null, "number": 2, "cdate": 1595837627772, "ddate": null, "tcdate": 1595837627772, "tmdate": 1596013650107, "tddate": null, "forum": "A4ft_k1rJ1C", "replyto": "A4ft_k1rJ1C", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper1/-/Official_Review", "content": {"review": "\n\n#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a method which constrains search space by using question type information as prior information and utilizes different attentions to obtain better results.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n- Search space constraints according to question types\n- Using multiple attention mechanisms\n- Performance and better attention maps\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n- Question types are prior knowledge yet not visual prior knowledge.\n\n#### 4. [Overall rating] Paper rating\n7\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- Fig.3: Some of the notations are not visible. In addition, you can show modules with dashed areas with different colors.\n- Table 4: Why did you make your results as bold?\n- The effectiveness of multi-hypothesis interaction learning proposed\nin Section 3.3: The explanation in the subsection makes confusion because the order of showing the results. It can be better to have a paragraph for each result (table).\n\n- Limitations and failing cases.\n- Time and memory usage\n- Will you share the code and models?\nTypos:\n- L80: constraint\n- L.436: not fitting in the line\n- L.590:modality", "title": "Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper1/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper1/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "55X_xqBL_N", "original": null, "number": 1, "cdate": 1595260121522, "ddate": null, "tcdate": 1595260121522, "tmdate": 1596013650161, "tddate": null, "forum": "A4ft_k1rJ1C", "replyto": "A4ft_k1rJ1C", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper1/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors propose a VQA method that jointly optimizes question answering and answer type classification using an ensemble of existing attention-based VQA methods. Prior information about the answer types is integrated into a weighted loss. Modalities are fused by first merging visual and linguistic features, then merging in question type features.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nThe authors use prior information on answer types while allowing the model to account for outlier questions. The authors perform extensive experiments to show all aspects of their works.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nIt is not clear how significant the individual performance increases of each contribution are. Crucial design choices for the VQA loss are not motivated (e.g. where to integrate awareness matrix). Presentation needs work (typos, grammar, typesetting).\n\n[Overall rating] Paper rating: Accept (tentative rating, subject to revision until deadline)\n\n[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- Please review the paper for typos, incorrect grammar and typesetting. Specifically lines 40 (grammar), 114, 178, 260 \"constraints\", 264, 287 (capitalizing VQA), 389 \"standardly\", 436 end of line, 590 \"modaality\"\n- Table 4: your method is not the highest (LXMERT is), so please do not use bold numbers. See also the claim on line 594.\n- Algorithm 1 should be expressed in math, like the other equations.\n- Source for claim on line 153", "title": "An ensemble of VQA methods with prior knowledge on question types", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper1/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper1/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=tqz0rQvz_58", "paper_id": "tqz0rQvz_58", "reviews": [{"id": "cheeQJYRCK", "original": null, "number": 2, "cdate": 1595957966568, "ddate": null, "tcdate": 1595957966568, "tmdate": 1596013647850, "tddate": null, "forum": "tqz0rQvz_58", "replyto": "tqz0rQvz_58", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper16/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\n This paper proposes to adapt several data-level augmentation techniques from image field to videos. To study the effects of such techniques, authors conduct experiments on the action recognition topic. Results showcase that some of the proposed techniques helps improve the performance. Additionally, they described their participation in the 1st VIPriors Action Recognition Challenge.\n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\n -\tRegarding the results, the paper is really well motivated and clearly understandable. The story is clear and is very easy to follow.\n -\tAuthors clearly described how they have adapted all the techniques to video.\n -\tThe results are marginal (or even worse than baseline) in some situations. However, I like the fact that authors recognise it and discuss it in Section 4.6, suggesting some interesting reasons.\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n -\tResults are marginal (or even worse than baseline) for some augmentation techniques.\n -\tAuthors talk always about temporal distortions. However, it seems that basically they apply frame distortions during a concrete temporal window. For me, this is not a temporal distortion. Authors can check the paper \u201cLearning Temporal Action Proposals With Fewer Labels\u201d. In this paper, data augmentation on videos is performed by modifying the temporal information accumulated by the features. Concretely, they use time warping and Time masking. \n\n4. [Overall rating] Paper rating.\n\n 7\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\n Despite weaknesses, the paper is well written, and very well discussed.\n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n - Line 198: augmentation operation(s).\n - Line 350: consists (of)\n", "title": "Simple, effective and very well discussed", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper16/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper16/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "H51e35VND6", "original": null, "number": 1, "cdate": 1595342297293, "ddate": null, "tcdate": 1595342297293, "tmdate": 1596013647903, "tddate": null, "forum": "tqz0rQvz_58", "replyto": "tqz0rQvz_58", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper16/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors extend popular data augmentation methods to the temporal domain in a straightforward manner. Experiments show minor improvements over the spatial data augmentations.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nSimple, powerful idea; simple implementations; clear explanations; self-critical in analyzing the magnitude of their contribution; extensive evaluations.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nMarginally related to workshop topic.\n\n[Overall rating] Paper rating: Strong accept\n\n[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- Grammar: lines 40, 254, 521 (whole paragraph needs revision)\n- Typos: line 130 \"squre\", 141 \"researches\"\n- Figure 2 could have been pseudocode\n\n", "title": "Good execution of a simple idea", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper16/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper16/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=f75kMo1dnKD", "paper_id": "f75kMo1dnKD", "reviews": [{"id": "HTjATmcpkQJ", "original": null, "number": 2, "cdate": 1595922080112, "ddate": null, "tcdate": 1595922080112, "tmdate": 1596013648848, "tddate": null, "forum": "f75kMo1dnKD", "replyto": "f75kMo1dnKD", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper8/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\n The paper tries to mitigate overfitting and generating easy captions by introducing prior knowledge from the dataset during training. To this end, authors propose to add visual-semantic relation prior knowledge by defining a series of Latent Topics, and semantic prior knowledge by training a Seq2seq module with the text. While the former is introduced in the training procedure as a self-attention with image region features, the latter is utilized to remove visual biased on semantic structures. Apart from increasing results of state-of-the-art approaches, they demonstrate that with their approach, image captioning models can rely on less data when training.\n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\n -\tThe paper is easy to read. Ideas are easy to follow.\n -\tIt is very well motivated.\n -\tBenefits of both modules (CLTA and SAE Regularizer) are clearly demonstrated in the experiments.\n -\tThe implementation is very well explained in detail.\n -\tThe benefits of adding prior knowledge (visual and semantic) is showed.\n -\tAdditionally, authors demonstrate the relevance of prior knowledge as it allows to train models with less data.\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n -\tAlthough the improvement exists, in some situations it is marginal.\n\n4. [Overall rating] Paper rating.\n\n 9\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\n Good paper. Well written, well motivated, simple method and positive results. On top of that, very much in line with the workshop.\n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n", "title": "Injecting Prior Knowledge into Image Caption Generation", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper8/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper8/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "YX_-csi7T0R", "original": null, "number": 1, "cdate": 1595335199007, "ddate": null, "tcdate": 1595335199007, "tmdate": 1596013648898, "tddate": null, "forum": "f75kMo1dnKD", "replyto": "f75kMo1dnKD", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper8/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors propose two adding to prior knowledge based modules to image captioning models. One module uses prior knowledge on the association of keywords to image regions. The other module regularizes generated captions to be more realistic.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nSimple but powerful ideas; clear methods; topical submission; excellent writing.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nBy nature of the method experimental settings are complex; \n\n[Overall rating] Paper rating: Strong accept\n\n[Confidence] 4/5\n\n[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- Grammar: lines 40, 189\n- Formatting: line 221", "title": "Powerful implementation of prior knowledge into image captioning models", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper8/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper8/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=S4kvQ7_XBxP", "paper_id": "S4kvQ7_XBxP", "reviews": [{"id": "ekxbEp0upuB", "original": null, "number": 2, "cdate": 1595429003942, "ddate": null, "tcdate": 1595429003942, "tmdate": 1596013649173, "tddate": null, "forum": "S4kvQ7_XBxP", "replyto": "S4kvQ7_XBxP", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper6/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a novel, computationally efficient artificial \"strong neuron\" for sparse neural networks that combines low-level features through AND and OR operations and a corresponding training strategy. The resulting networks are evaluated on the GTSRB (German traffic sign) and SVHN datasets and show competitive results in both classification error and adversarial stability.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* The proposed \"strong neurons\" are definitely a novel and interesting idea and the motivation is clearly explained through Figure 1.\n* The method seems effective on the evaluated datasets.\n* The paper is generally well written and easy to follow.\n* Code is made available which will hopefully spark interest for research into alternatives to traditional CNNs.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* The optimization method is based on a lot of heuristics to simplify the otherwise intractable brute force approach. Although the optimization method seems effective (based on the performance), it is hard to evaluate the possible negative effects of these simplifications on the model performance.\n* The training strategy not allowing to use mini-batches seems like a major drawback for training on large-scale or high resolution datasets like ImageNet or CityScapes.\n\n#### 4. [Overall rating] Paper rating\n* 8. Top 50% of accepted papers, clear accept\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nThe authors have proposed a novel and interesting alternative to traditional CNNs and have shown its effectiveness.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n* Combine multiple references into same brackets, i.e. ([1], [2], [3]) should be [1,2,3].\n* What do $k$ and $i$ represent in equation (1) and line 125/126?\n* The paper would be easier to read if a conclusion would be included in the image captions (i.e. what point is the image trying to make).", "title": "Interesting and novel idea", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper6/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper6/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "3aOnr3cnP9C", "original": null, "number": 1, "cdate": 1595320096228, "ddate": null, "tcdate": 1595320096228, "tmdate": 1596013649226, "tddate": null, "forum": "S4kvQ7_XBxP", "replyto": "S4kvQ7_XBxP", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper6/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors propose a new type of neuron designed for contour recognition. They detail an extensive algorithm for training these neurons without back-propagation. They show their method can outperform convolutional methods in low FLOWs regime and is more robust against adversarial attacks.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nCreative approach to a hard problem (replacing the convolutional neuron); builds on related work where possible; solid experiments.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nMany heuristics are needed to optimize the strong neuron, while the effect of the heuristics are not analyzed or explored. In the same vein, an ablation study, including the effects of the unsupervised backbone, would have helped to make the work more solid.\n\n[Overall rating] Paper rating: Accept\n\n[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- Lines 156-157, 189-190 are unclear to me\n- Section 7.1 addresses the reader as \"you\". Use of more formal \"one\" would be advised.\n- Change brackets to separate sentences (e.g. lines 370-371)\n- Minor typos: lines 490 \"shalow\"\n\n", "title": "A novel approach to counter recognition", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper6/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper6/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=yc54rY6_tX6", "paper_id": "yc54rY6_tX6", "reviews": [{"id": "aKDO6W78L6C", "original": null, "number": 2, "cdate": 1595837587169, "ddate": null, "tcdate": 1595837587169, "tmdate": 1596013649383, "tddate": null, "forum": "yc54rY6_tX6", "replyto": "yc54rY6_tX6", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper5/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThis paper addresses the task of unsupervised learning of video representations for action recognition. Following current trend for image representation learning, authors propose first to adapt [46] and [49] for video instance recognition and local aggregation respectively. Since results prove that these methods do not capture motion, which is clearly important for action recognition, they proposed to force a 3D ConvNet to learn embeddings from IDTs. Experiment results justifies their framework.\n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nThe whole paper is well written and motivations are very well stated.\nAlthough authors obtained promising results by correctly adapting [46] and [49], they went further and analyzed errors.\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nA strong hypothesis of the paper is that motion is important to recognize actions in videos. And current 3D convnets models cannot learn it, while they tend to only learn appearance. For this reason, authors use IDTs.\nThis hypothesis seems unfair since 3D convs can be trained with flow, or even two-stream.\nHave authors try their Video IR and Video LA using directly optical flow, or introducing a two-stream model? (C3D, I3D, R(2+1), TSN,\u2026)\n\n4. [Overall rating] Paper rating.\n\n6\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\nGood research story, good experimental set-up but arguable assumption.\n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\nDo authors plan to release supplementary material they claim to have in the paper?\n", "title": "Unsupervised Learning of Video Representations via Dense Trajectory Clustering", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "6: Marginally above acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper5/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper5/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "S_ANbhtQKN8", "original": null, "number": 1, "cdate": 1595836670209, "ddate": null, "tcdate": 1595836670209, "tmdate": 1596013649333, "tddate": null, "forum": "yc54rY6_tX6", "replyto": "yc54rY6_tX6", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper5/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a method which uses IDT descriptor and 3DConvNet to obtain action clusters and learns the unsupervised video representation.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n- Using IDT as prior knowledge\n- Effective motion capturing\n- Performance\n- Extensive related works and ablation study\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n- It requires training with other big dataset.\n- Do the authors have any evidence of the performance without the usage of any other dataset?\n\n#### 4. [Overall rating] Paper rating\n9\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \nThe paper has nice analyses and the proposed method outperforms other methods by using IDT descriptors and 3DConvNet.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n- L.318: Can you elaborate with the fine-tuning stage?\n- Can you please clarify for the Table 3 if you train your network with Kinetics-400 or 600? Most of the methods (DPC, 3D-Puzzle, PMAS) in the table use Kinetics-400 for self supervised training.\n- What are the limitations?\n- Do you have any memory usage and time analyses?\n\nTypos:\n- L.406: first\n- L.507: Kinetics", "title": "Unsupervised Learning of Video Representations via Dense Trajectory Clustering", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper5/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper5/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=LvOKdhutM-r", "paper_id": "LvOKdhutM-r", "reviews": [{"id": "GQ_eUPM8zXU", "original": null, "number": 2, "cdate": 1595836895997, "ddate": null, "tcdate": 1595836895997, "tmdate": 1596013649720, "tddate": null, "forum": "LvOKdhutM-r", "replyto": "LvOKdhutM-r", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper3/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe paper describes a new lighter and more efficient model (ATTP) for the problem of Compressed Video Action Recognition. As backbone, the adopt the EfficientNet network. To better use the information of frames, motion and residuals, the authors also introduce a temporal fusion module (Trilinear Pooling) and a feature alignment method. Experiments show ATTP can reach state-of-the-art results by using a lighter model. Ablation experiments also demonstrate the benefits of all the modules.\n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nThe whole paper is well written and the motivations are well stated.\nThe set of experiments is very readable and clear.\nThe authors clearly demonstrate they can achieve state-of-the-art results using a lighter model.\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\nMore than clear weaknesses, I miss some little further justifications:\n-\tIt is clear that feature alignment improves accuracy but interestingly the lambda parameter of the whole ATTP loss (Eq. 10) is set to 1. I would also have appreciated an experiment varying this parameter to see the actual influence of it.\n-\tRegarding the type of frames used, although Fig. 4 seems pretty informative, it would also be interesting to see how I, B and P frames affect to computation efficiency, with an experiment like in Table 1.\n\n4. [Overall rating] Paper rating.\n\n8\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\nAforementioned strengths and weaknesses explain the rating, but to clarify: good readability, well motivated, sufficient set of experiments and results. \n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\nThe Action Localization experiment that authors indicated to be in the supplementary material seems interesting. I wonder if authors plan to release the supplementary material as well.\n\n", "title": "Lightweight Action Recognition in Compressed Videos", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper3/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper3/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "Zhcf-1FXH_o", "original": null, "number": 1, "cdate": 1595836736186, "ddate": null, "tcdate": 1595836736186, "tmdate": 1596013649779, "tddate": null, "forum": "LvOKdhutM-r", "replyto": "LvOKdhutM-r", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper3/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a lightweight action recognition model which can run on embedded AI devices with compressed videos.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n- Lightweight model and can fit embedded AI device\n- Speed, efficiency and accuracy\n- Extensive related works and ablation study\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n- Although some of information are refered as \"in the suppl. material\", nothing is sent as supplamentary materials.\n\n#### 4. [Overall rating] Paper rating\n8\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- Can the proposed method work with raw videos as well?\n- L.429: Are all the baselines use the same spatial size of the proposed method?\n- L.600: The improvement of B-frames is not significant. Is there any other evidence to show B-frames are more important than P-frames?\n- What are the limitations of the work?\nTypos:\n- L.154: compressed\n- L.175: utilizes\n- L.178: combines\n- L.438: giving full form of FPS", "title": "Lightweight Action Recognition in Compressed Videos", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper3/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper3/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=UPbbSsBzfEW", "paper_id": "UPbbSsBzfEW", "reviews": [{"id": "WXbCRelZ0ZC", "original": null, "number": 2, "cdate": 1595836285156, "ddate": null, "tcdate": 1595836285156, "tmdate": 1596013646581, "tddate": null, "forum": "UPbbSsBzfEW", "replyto": "UPbbSsBzfEW", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper23/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper shows an ensemble of multiple models, which are trained with various augmentation techniques, improves the performance of image classification and segmentation tasks.  \n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n- Performance on classification and segmentation tasks\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n- There is no proper Related Works section.\n- The structure of the paper is hard to follow and there are jumps from a topic to another.\n- A lot of missing citations\n\t\n#### 4. [Overall rating] Paper rating\n5\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n \nThe paper is more technical report than an academic paper.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n- Missing citations:\n\t> L.37-39: '..tasks..'\n\t> L.45: 'Methods' (only one method)\n\t> L.56: 'augmentation methods'\n\t> L.73: 'recently several works..'\n\t> L.78: 'frequency weighted model ensemble'\n\t> L.361: '..widely know..'\n\t> L.367: 'Conventional semantic segmentation models..'\n\t> L.400: 'RMSProb.'\n- L.217: The second part of formula is not explained.\n- L.267: No need for \"Please..\"\n- L.298: What is \"m\" in the formula and Fig 2?\n- L.313: \"TTA\" can be given in paranthesis. \n- L.337: It is not clear if the sentence is about the segmentation or both classification and segmentation.\n- L.355, 356, 368 etc: Future tense can be changed as simple present tense.\n- L.343, 344, 347, 352: Frequency can be misunderstood, instead, frequent or occuring etc can be used.\n- L.374: HRNetV2 and Object Contextual Representation methods should be in Related works section.\n- L.399: Link can be footnote.\n- L.478: 'Tab.'. There should be a consistency about refering the tables. In some cases they are as 'Table' and for other cases as 'Tab.'\n- L.516: Did the authors train the segmentation networks 4840 epochs or it is a typo?\n- L.579: \"We observed several interesting phenomena..\" It is not clear that what are those findings.\n- Please remove intermediate horizontal lines in the tables (booktabs latex)", "title": "Diversification is All You Need: Towards Data Efficient Image Understanding", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "5: Marginally below acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper23/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper23/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "7_yYlIfvOWR", "original": null, "number": 1, "cdate": 1595332818328, "ddate": null, "tcdate": 1595332818328, "tmdate": 1596013646654, "tddate": null, "forum": "UPbbSsBzfEW", "replyto": "UPbbSsBzfEW", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper23/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a combination of extensive data augmentation and model ensembling to train deep neural networks in a data efficient manner. Experiments are performed on small-size classification and segmentation datasets and performance improvements are shown.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* Clarity: the paper is clear and easy to read.\n* Effectiveness: the method seems effective on small-size datasets.\n* Reproducibility: the experiments are well documented and include relevant hyperparameters.\n* Experiments: the effectiveness of the method is empirically demonstrated through ablation studies.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* The papers mostly makes use of existing data augmentation techniques and therefore lacks novelty. The only seemingly novel contribution is the Frequency Weighted (FW) model ensemble method for dealing with the imbalanced class distribution in the semantic segmentation experiments.\n* (l. 334-359) The paper claims that FW model ensembling is beneficial for low frequency classes but does not support this claim with empirical results. The authors should have included a comparison of per-class IoU scores between the baseline method and the proposed method.\n* (l. 147-149) \"...mixup extends the training distribution by incorporating the prior knowledge that linear interpolations of feature vectors should lead to linear interpolations of the associated targets.\"\nThe argument of the proposed method for incorporating prior knowledge is fairly weak and is related to existing work (Mixup). The paper therefore seems to fall outside of the intended scope of this workshop.\n\n#### 4. [Overall rating] Paper rating\n* 5: Marginally below acceptence threshold\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nDespite the effectiveness of the data augmentation and model ensembling techniques, the proposed method is mainly not novel and the argument for incorporating prior knowledge is weak.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n* A table including per-class IoU scores and class occurances should be included for the segmentation experiment.\n* It would be nice to see example images for the proposed data augmentation method for image classification as well.", "title": "Effective method but lack of novelty and out of scope", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "5: Marginally below acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper23/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper23/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=s-OSwnzXvEi", "paper_id": "s-OSwnzXvEi", "reviews": [{"id": "A4pQ704i_FC", "original": null, "number": 2, "cdate": 1595836393260, "ddate": null, "tcdate": 1595836393260, "tmdate": 1596013646774, "tddate": null, "forum": "s-OSwnzXvEi", "replyto": "s-OSwnzXvEi", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper22/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes new U-Net architecture which uses MobileNetV3 blocks.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n- New Unet\n\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n- Only changing the architecture and no prior rather than generic data augmentation\n- It is more like technical report.\n#### 4. [Overall rating] Paper rating\n4\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating. \n\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n- Why the 'related works' are related to the paper is missing.\n- L.32: Is any meaningful pretraining available for medical data?\n- Simple present tense instead of past tense\n- Fig.1 image resolution\nTypos:\n- L.173: 10 at .\nMissing citations:\n- L.24: \"..appoaches..\" (only one is given.)\n- L.26: \"..various problems..\"\n- L.34: \"..newly emerging..\". What are those fields?\n- L.57: classifying objects[?,?,?], detecting objects[?,?,?], estimating pose[?,?,?]\n- L.72: easy-to-access applications[?,?,?]\n- L.61: offline[?,?,?].., real-time[?,?,?]", "title": "EfficientSeg: An Efficient Semantic Segmentation Network ", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "4: Ok but not good enough - rejection"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper22/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper22/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "6bsEQIMLR-c", "original": null, "number": 1, "cdate": 1595336439525, "ddate": null, "tcdate": 1595336439525, "tmdate": 1596013646835, "tddate": null, "forum": "s-OSwnzXvEi", "replyto": "s-OSwnzXvEi", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper22/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a novel CNN architecture for semantic segmentation based on U-Net and MobileNetV3 blocks. The proposed architecture is applied on the MiniCity dataset and performance improvements are shown.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* Clarity: the paper is clear and easy to read.\n* Effectiveness: the method seems effective on small-size datasets.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* Scope: The proposed architecture change is motivated by computational efficiency and parameter reduction rather than incorporating prior knowledge. Prior knowledge is only considered to motivate the techniques used for data augmentation, which are generic and widely used techniques.\n\n#### 4. [Overall rating] Paper rating\n* 5. Marginally below acceptance threshold\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nDespite being effective, the proposed architecture is not motivated by incorporating prior knowledge but rather by computational efficiency and therefore the paper falls outside of the intended scope of this workshop.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n(line 173) \"We divide the learning rate by 10 at . \"\nMissing word.\n(line 177) \"poll\" --> pole", "title": "Effective method, out of scope", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "5: Marginally below acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper22/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper22/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=R6YWiPVOQBo", "paper_id": "R6YWiPVOQBo", "reviews": [{"id": "4h9aSdxR3Kq", "original": null, "number": 2, "cdate": 1595923706361, "ddate": null, "tcdate": 1595923706361, "tmdate": 1596013647350, "tddate": null, "forum": "R6YWiPVOQBo", "replyto": "R6YWiPVOQBo", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper19/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\n This paper introduces a data-efficient pipeline to address the problem of action recognition. It is based on a two-stream model that utilizes an enhanced C3D network. The convolutions in the C3D are modified to include a 3D Temporal Central Difference Convolution term. Instead of working with RGB, authors proposed to use Rank Pooling guided with Optical Flow. Additionally, this work is ranked 2nd in de VIPriors Action Recognition Challenge.\n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\n -\tModification of the convolution, integrating a new term.\n -\t2nd Position in the challenge.\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n -\tThe paper feels more like a technical report than a proper paper.\n -\tThe introduction needs more motivation.\n -\tExperiments are very much focused on the challenge. Only modifying the convolution would need more justification. A deeper study.\n\n\n4. [Overall rating] Paper rating.\n\n 4\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\n Weaknesses of point 3 justify the rating.\n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n Please, include Rank Pooling citation, it seems is introduced by the authors.\n", "title": "2nd Place Scheme on Action Recognition Track of ECCV 2020 VIPriors Challenges: An Efficient Optical Flow Stream Guided Framework", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "4: Ok but not good enough - rejection"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper19/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper19/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "LRjWnSfYA-6", "original": null, "number": 1, "cdate": 1595403870389, "ddate": null, "tcdate": 1595403870389, "tmdate": 1596013647404, "tddate": null, "forum": "R6YWiPVOQBo", "replyto": "R6YWiPVOQBo", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper19/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a new temporal convolution operator (3D TCDC), that combines a vanilla 3D convolution operator with a \"Temporal Central Difference\" term, and an optical flow guided Rank Pooling operation to compress the raw RGB input stream to a more compact single vector. A two stream network leverages both optical flow and the rank pooling representation to perform the task of action recognition. The method is evaluated on the VIPriors action recognition dataset and significant performance improvements are shown.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* I like that the authors propose 3D TCDC as a new fundamental building block for 3D CNNs; the method seems interesting.\n* The method seems effective on the dataset it has been evaluated on.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* The paper is too compact and omits some prerequisites that would make the method much more easy to understand. Especially section 3 would benefit from a more detailed explanation:\n * What does the temporal CD term in equation (1) do and what is the motivation behind it? It would have helped to provide a short recap of [13].\n * Similarly for the Rank Pooling operation: what is the motivation behind equation (2)? Which variable is optimized and what does the optimization represent? What are $\\omega$, $\\delta$, $\\xi$? The authors could have at least referred to previous work on rank pooling.\n * How are the two streams fused, i.e. what is \"Probability fusion\" in Fig. 1?\n* It would have been nice if the method would have been evaluated on multiple datasets. \n\n#### 4. [Overall rating] Paper rating\n* 6. Marginally above acceptance threshold\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nThe proposed method seems interesting and effective. However, the paper provides too little explanation on the method. Nevertheless, I'm willing to accept the paper in the hope that the authors can further elaborate on the for the camera-ready version.\n\n#### 6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n* The abbreviation \"C3D\" is never explained.\n* (line 202) \"We assume it\u2019s caused by the irrelevant features with local optima.\"   \n Unclear explanation.\n* See 3. for additional comments.", "title": "Interesting method, unclear explanation", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "6: Marginally above acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper19/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper19/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=GHaQlkoNM-p", "paper_id": "GHaQlkoNM-p", "reviews": [{"id": "HrUuPN_T1y8", "original": null, "number": 2, "cdate": 1595406899893, "ddate": null, "tcdate": 1595406899893, "tmdate": 1596013648012, "tddate": null, "forum": "GHaQlkoNM-p", "replyto": "GHaQlkoNM-p", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper15/-/Official_Review", "content": {"review": "#### 1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\nThe paper proposes a multi-scale version of CutMix that boosts the occurance of scarce data classes and combines it with scale attention. Significant performance improvements are shown on the Minicity segmentation dataset.\n\n#### 2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n* The method seems effective.\n\n#### 3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n* The technical contribution is marginal and does not have a scientific motivation.\n* The explantion of the method is not very clear:\n * How are the classes divided into the buckets based on the label distribution?\n * Why is it necessary to compute the label distribution if the classes are redistributed based on the model performance?\n * How does the scale attention part of the method work? It would have been nice to explain it in the report.\n* There are no ablation studies showing the individual effect of multi-scale CutMix and scale attention on the segmentation performance and therefore it is not clear what makes this method effective.\n\n#### 4. [Overall rating] Paper rating\n4. OK but not good enough - rejecion\n\n#### 5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\nAlthough the proposed method seems effective, the contribution is marginal and is not scientifically motivated.", "title": "Effective method, but weak scientific contribution", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "4: Ok but not good enough - rejection"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper15/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper15/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "2VWYNe-Bw8", "original": null, "number": 1, "cdate": 1595340859060, "ddate": null, "tcdate": 1595340859060, "tmdate": 1596013648069, "tddate": null, "forum": "GHaQlkoNM-p", "replyto": "GHaQlkoNM-p", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper15/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors combine a novel variant of CutMix augmentation, designed for long-tailed datasets, with multi-scale attention. They show their method outperforms a trivial baseline.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\n- Good submission as a technical report to the challenge.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n- Not a good paper for the workshop paper track: marginal contribution; no hypotheses; no experiments other than final model vs. challenge baseline\n- Not related to visual inductive priors\n- Incorrect format\n\n[Overall rating] Paper rating: Clear reject\n\n", "title": "Good technical report", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "3: Clear rejection"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper15/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper15/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=iN5F7NK9ipZ", "paper_id": "iN5F7NK9ipZ", "reviews": [{"id": "ZwCzf5YvHIR", "original": null, "number": 2, "cdate": 1595922209148, "ddate": null, "tcdate": 1595922209148, "tmdate": 1596013648685, "tddate": null, "forum": "iN5F7NK9ipZ", "replyto": "iN5F7NK9ipZ", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper9/-/Official_Review", "content": {"review": "1. [Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\n This paper describes a method based on GANs to generate fashion images with different textures.\n\n2. [Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\n\n3. [Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n -\tThe structure of the paper is not clear.\n -\tFashion related works exist. Authors do not mention anything about it. Only background for GANs.\n -\tOther topics where GANs are used similarly?\n -\tIt lacks research motivation.\n\n4. [Overall rating] Paper rating.\n\n 3\n\n5. [Justification of rating] Please explain how the strengths and weaknesses aforementioned were weighed in for the rating.\n\n Weaknesses from point 3 justify rating\n\n6. [Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n", "title": "Handcrafting Generative Adversarial Networks for Fashion Design Generation", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "3: Clear rejection"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper9/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper9/AnonReviewer2", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}, {"id": "wpsCe0vIYn5", "original": null, "number": 1, "cdate": 1595336800692, "ddate": null, "tcdate": 1595336800692, "tmdate": 1596013648737, "tddate": null, "forum": "iN5F7NK9ipZ", "replyto": "iN5F7NK9ipZ", "invitation": "thecvf.com/ECCV/2020/Workshop/VIPriors/Paper9/-/Official_Review", "content": {"review": "[Summary] In 2-3 sentences, describe the key ideas, experiments, and their significance.\n\nThe authors propose to modify GANs by augmenting the generator outputs according to visual priors on their fashion dataset. The results are visually more appealing.\n\n[Strengths] What are the strengths of the paper? Clearly explain why these aspects of the paper are valuable.\n\nStrong idea; topical submission.\n\n[Weaknesses] What are the weaknesses of the paper? Clearly explain why these aspects of the paper are weak.\n\n- Presentation needs a lot of work (see detailed comments);\n- Incremental contribution over existing works;\n- Lack of quantitative evaluation.\n\n[Overall rating] Paper rating: marginal accept\n\n[Justification] The idea is very interesting and applicable to the workshop. Please take the time to revise the final version of your paper using the detailed comments.\n\n[Detailed comments] Additional comments regarding the paper (e.g. typos or other possible improvements you would like to see for the camera-ready version of the paper, if any.)\n\n- Section headers should be revised to match paper conventions (i.e. Related Works, Method, Experiments, Discussion)\n- Equations in section 2 either need more explanation or need to be replaced by references\n- Sections 1 and 2 contain very broad and imprecise phrasing, e.g. \"The notion of a virtual generator which produces images of desired properties has been introduced\", \"[...] transforms a generated image to the one with specified properties to other related problems.\"\n- Figures should be close to their place in the text\n\nMinor comments:\n\n- Vague phrasing: lines 48 \"them\"\n- Line 227: where is this term added?\n- Line 333: \"coherant\"", "title": "Good idea, but execution needs work", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "6: Marginally above acceptance threshold"}, "signatures": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper9/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["thecvf.com/ECCV/2020/Workshop/VIPriors/Paper9/AnonReviewer1", "thecvf.com/ECCV/2020/Workshop/VIPriors"]}]}, {"paper_url": "https://openreview.net/forum?id=bAVVYLysfJ", "paper_id": "bAVVYLysfJ", "reviews": [{"id": "iNLz-HVmZRf", "original": null, "number": 3, "cdate": 1601497789002, "ddate": null, "tcdate": 1601497789002, "tmdate": 1601497789002, "tddate": null, "forum": "bAVVYLysfJ", "replyto": "bAVVYLysfJ", "invitation": "ACM.org/IVA/2020/Workshop/GENEA/Paper2/-/Official_Review", "content": {"title": "Interpreting and Generating Gestures with Embodied Human Computer Interactions", "review": "This paper spans several different interesting issues. However it would have been better if it covered one in detail. It makes a case for Embodied HCI as a two-way situated interaction, which the paper argues for convincingly but I also believe it is widely accepted in this community. It demonstrates EHCI in a system, VOXWorld, discusses the design of the system, the formative studies/evaluations that informed that design, as well as a preliminary evaluation of the system's nonverbal behavior. Many of the issues it raises about EHCI have been addressed by others going quite far back, for example  two examples that come to mind is Hannes Vilhjalmsson's phd and the Max system by Wachsmuth, Kopp etc. The technical details and experimental are sparse which makes any systematic evaluation of technical contributions difficult.\n\nBut frankly none of the above would have mattered to this reviewer if they had succeeded in another way, because an entirely different way to look at this paper, which is how the authors at times describe their contribution, is as providing a platform for research in EHCI with virtual agents. Describing the platform, the feasibility of others using it would have made the paper a sufficient contribution to the workshop. But I am not getting a strong sense from reading the paper that it is feasible for other to use it, to incorporate their own components into it, etc. For example it is not clear that it uses SAIBA standards. \n\n", "rating": "6: Marginally above acceptance threshold"}, "signatures": ["ACM.org/IVA/2020/Workshop/GENEA/Paper2/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/IVA/2020/Workshop/GENEA", "ACM.org/IVA/2020/Workshop/GENEA/Paper2/AnonReviewer2"]}, {"id": "brH7BVXsDV", "original": null, "number": 2, "cdate": 1601490830376, "ddate": null, "tcdate": 1601490830376, "tmdate": 1601490860847, "tddate": null, "forum": "bAVVYLysfJ", "replyto": "bAVVYLysfJ", "invitation": "ACM.org/IVA/2020/Workshop/GENEA/Paper2/-/Official_Review", "content": {"title": "The argument and approach is reasonable and viable, but it has been adopted already by lots of previous work.", "review": "The paper presents an overall approach to simulate embodied communication with am avatar in VR. The authors correctly argue for the missing ecological validity of many communication modeling attempts and that co-situatedness, co-attention, and co-intent are needed. They argue that this can be reinstantiated in a VR-based situated interaction with virtual avatars. This argument and approach is reasonable and viable, but it has been adopted already by lots of previous work (as old as 25 years). The second half of the paper presents a rather shallow way how different kinds of communicative behavior are tracked or generated, respectively. Finally, a first study is reported in which human raters judged the naturalness of the generated behavior, showing only that multimodal referring expressions are perceived as more natural. Overall, the research direction is fine and I\u2019m glad to see people taking it further. At the same time, however, it is not yet clear what the novel contribution of the present work is going to be. Also, most of the descriptions of how behavior is generated is too superficial. Mostly the design of the behavior is described, not how it is (or can be) generated. I would recommend the authors, given the preliminary state of the work, to focus on situating the work in the larger research field and in relation to related work. The first part of the paper does a decent job in arguing for the overall approach. The latter part, however, misses a lot of related work and aptly position the work and point out its potential contributions. For example, you may want to check out:\n- Le\u00dfmann, N., Kopp, S., & Wachsmuth, I. (2006). Situated interaction with a virtual human - perception, action, and cognition. In G. Rickheit & I. Wachsmuth (Eds.), Situated Communication (pp. 287-323). Berlin: Mouton de Gruyter. doi:10.1515/9783110197747.287\n- Wachsmuth I, Lenzen M, Knoblich G, eds. Embodied communication in humans and machines. Oxford: Oxford Univ. Press; 2008.\n- T Pfeiffer (2010). Understanding multimodal deixis with gaze and gesture in conversational interfaces.\n- Callaway, J. (2001). Cosmo: A Life-like Animated Pedagogical Agent with Deictic Believability.", "rating": "4: Ok but not good enough - rejection"}, "signatures": ["ACM.org/IVA/2020/Workshop/GENEA/Paper2/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/IVA/2020/Workshop/GENEA", "ACM.org/IVA/2020/Workshop/GENEA/Paper2/AnonReviewer1"]}, {"id": "YcrZHX2bvP", "original": null, "number": 1, "cdate": 1600886137777, "ddate": null, "tcdate": 1600886137777, "tmdate": 1600886137777, "tddate": null, "forum": "bAVVYLysfJ", "replyto": "bAVVYLysfJ", "invitation": "ACM.org/IVA/2020/Workshop/GENEA/Paper2/-/Official_Review", "content": {"title": "The authors present an overview of complex studies. As such it remains at a very high level of descriptions. Many capabilities implementing in the virtual agent are not described. ", "review": "The authors present an overview of complex studies. As such it remains at a very high level of descriptions. Many capabilities implementing in the virtual agent are not described. \nThe authors do not compare their work with existing ones. There is no state of the art section in the paper. Generating multimodal behaviors have been addressed a lot in the IVA community. It would be interesting to know how the proposed work differs from them, what does it bring compared to previous works\u2026 For example, regarding deixis, how does the presented work differ from works by James Lester or by Dirk Heylen? It is not clear to me why the authors do not use BML to represent the different gestures.\nThe authors do not mention \u2018timing\u2019 while presenting the generated behaviors for the agent, neither for the facial expressions, nor for the gesture. However, timing is crucial. A lot of work has been done in synchronizing gesture, facial expression, gaze and speech for an agent. Nothing is said in the paper how gesture, facial expression, gaze and language are synchronized with each other. \nIt is not clear how the agent decides on the action (behavior) to undertake? How the decision model works? It is not clear to me how ambiguity in referencing objects is dealt with.\nThe authors use the term \u2018avatar\u2019 or IVA or agent interchangeably. However, \u2018avatar\u2019 is used differently in the IVA community. The authors should mention at the start of the paper the use of these different terms to mean virtual agent.\nIn the formalization of the communicative act, how do the authors encode context? How does their formalization differ from Isabella Poggi\u2019s work?\nThe authors mention three configurations to link gesture and language: how are they represented? How the generation model computes which one is to be displayed?\nRegarding the third configuration, I do not understand why the truly mixed model expression requires both modalities to contribute \u2018equally\u2019 to the meaning.\nThere are few typos. \n-\tOr both and speech and gesture\n-\tPredicatble\n-\tCollaboarative\n-\tCharactehr\n\n", "rating": "5: Marginally below acceptance threshold"}, "signatures": ["ACM.org/IVA/2020/Workshop/GENEA/Paper2/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/IVA/2020/Workshop/GENEA/Paper2/AnonReviewer4", "ACM.org/IVA/2020/Workshop/GENEA"]}]}, {"paper_url": "https://openreview.net/forum?id=fO_Q4q1dFAA", "paper_id": "fO_Q4q1dFAA", "reviews": [{"id": "274ifC9_31k", "original": null, "number": 2, "cdate": 1659966269353, "mdate": null, "ddate": null, "tcdate": 1659966269353, "tmdate": 1659966269353, "tddate": null, "forum": "fO_Q4q1dFAA", "replyto": "fO_Q4q1dFAA", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper18/-/Official_Review", "content": {"title": "A generally well written paper with an interesting approach beneficial to the gesture generation community. Style control is emphasised, but lacks examples in the text. The method is limited by not predicting hand motion and some details are missing for reproducibility. ", "review": "### Overview\n\nThe authors introduce a new method to generate stylised gestures using a zero-shot learning approach to create a style embedding. A variational framework allows many different animations to be produced from a single example of audio and a motion sequence for style transfer. Some results are discussed but readers are also referred to the main GENEA paper.\n\nThe zero-shot learning of styles is an interesting approach providing scientific value and performed well in the challenge. The \u201cSystem Overview\u201d and \u201cTraining & Losses\u201d sections are fairly detailed and well presented. There is a good discussion on the benefits of data processing. The figures are clear and well presented. However, I have some questions that could be addressed in the text. Some extra detail and figures could be useful to reinforce some claims as detailed below:\n\n### Comments and Suggestions\n\n1. There is a lot of emphasis on style control, however, there are no examples provided. For example, could a figure of sequences using the same audio input, but different style conditions be included? e.g. Conditioned from the same speaker identity but two different sequence samples and a style sequence from a different speaker identity.\n2. There are claims the model can generate gestures for unseen speaker styles. There are currently no results or examples shown. While these are not tested in the challenge evaluation itself, could further results/discussion be included regarding the style transfer? Are unseen speaker styles well described by the embedding or is there a strong bias to training speaker styles? Were any speaker identities held out from the training data to strengthen this claim?\n3. The style encoding is generated from \u201cone sample of each speaker\u201d (L221). Could more information on the sampling process be provided for reproducibility? For example, is this sampled from the training motion data? At test inference time, was a different sample used for each sequence?\n4. L261 The removal of hand/finger motion is a major limitation of the system in regards to the challenge. Could a discussion/justification of this design choice be included?\n5. L247 \u201cLoss terms are empirically weighted\u201d These weight values would be good to include for reproducibility.\n6. In the \u201cData Preparation\u201d section, it is noted that the audio and animation data are normalised. It is unclear what method of normalisation is performed here and may limit reproducibility. Could these methods be included?\n7. Participant IDs are not explicitly stated in the results for cross-referencing the main GENEA paper. These should be included in the text.\n8. L301, \u201cWhile ranking **second and third** in the human-likeness subjective evaluations\u201d Only second in the full-body tier was mentioned in the results section. Was this method submitted to both the full-body and upper-body tiers? Could the results be updated to reflect this along with the participant IDs?\n9. L274 Describes deriving root position and rotation from the second spine and hip joints respectively. Two different joints were chosen to represent the position/rotation of the root instead of a single joint. It is unclear why this method was used rather than the root joint provided in the dataset. Could justification be provided in the text?\n10. L261 \u201clow average hand velocity to remove data\u201d to ensure reproducibility, could the threshold used to describe low average hand velocity be included here and preferably how that threshold was derived?\n11. L206 missing the citation for FiLM. [1]\n\n[1] Perez, Ethan, et al. \"Film: Visual reasoning with a general conditioning layer.\"\u00a0*Proceedings of the AAAI Conference on Artificial Intelligence*. Vol. 32. No. 1. 2018.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper18/Reviewer_E7jV"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper18/Reviewer_E7jV"]}, {"id": "_FQ_356GvZD", "original": null, "number": 1, "cdate": 1659892094565, "mdate": null, "ddate": null, "tcdate": 1659892094565, "tmdate": 1659892094565, "tddate": null, "forum": "fO_Q4q1dFAA", "replyto": "fO_Q4q1dFAA", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper18/-/Official_Review", "content": {"title": "Gesture generation system with gesture style control through short examples.", "review": "Quality:\nMost of details about the methods were explained, but diagrams with evaluation results and their discussion is missing. Also some details for training and generating samples for evaluation are missing, in specific information on how the zero-shot examples are used.\n\nClarity:\nPaper is well written.\n\nOriginality:\nTransferred recent developments of using examples to control speech styles from speech synthesis to gesture synthesis.\n\nSignificance:\nFull-body model ranked second for human-likeness. \n\nPros:\n- Method obtained very good results for human-likeness evaluation.\n\nCons:\n- Result section lacks evaluation results and detailed discussion of the outcomes.\n- Some normalization details on data preparation are missing.\n- It is not clear how the different examples are used in the style encoder during training. \n- It is not clear how different examples were used to generate the motion for evaluation.\n\n\nSuggestions for improvement:\n- More emphasis on contributions, in specific model characteristics which are different from SOTA (abstract and related work).\n- Given that authors saw significant improvement after applying data preparation, it would be good to include more details on that step. What were the parameters for audio normalization? What was the threshold used to distinguish low average hand movements?\n- Include evaluation diagrams and discuss results in more detail.\n- Describe how different examples are used in the style encoder during training. Is one example used to train with all data? Is a different example used for each data sample? \n- Describe how different examples were used to generate the motion for evaluation. For each generated sample a different example?\n- Some typos: Line 9 \"embedding. The\", line 193 \"This yields the parameters...\", line 216 add superscript for e^-4, line 329 \"alleviates\", line 330 \"an fine-grained\".\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper18/Reviewer_G94b"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper18/Reviewer_G94b"]}]}, {"paper_url": "https://openreview.net/forum?id=AYMDEx97qPN", "paper_id": "AYMDEx97qPN", "reviews": [{"id": "thz-AxGaq4u", "original": null, "number": 3, "cdate": 1659773254227, "mdate": null, "ddate": null, "tcdate": 1659773254227, "tmdate": 1659773254227, "tddate": null, "forum": "AYMDEx97qPN", "replyto": "AYMDEx97qPN", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper8/-/Official_Review", "content": {"title": "A novel attempt for gesture generation based on an RNN-Transducer", "review": "This paper proposes a novel model based on RNN-Transducer for audio-to-gesture generation with preliminary experimental results showing the feasibility of the proposed model.\n\nThe technical descriptions are simple but clear enough to understand the proposed approach. The performance of the approach is not satisfactory but it is a valuable contribution to the workshop in two points: 1) a novel model using RNN-T is proposed, 2) some comments on the challenge dataset is made which could contribute to the improvement of the challenge.\n\nSome comments for improving the paper:\n1) The paper needs editorial improvements. A thorough proof-reading is recommended. ex) a missing citation number in the 2nd paragraph of section 2.3.\n2) It could have been more informational if the benefit of using statistical loss terms had been explained with quantitative or qualitative evaluations.\n3) In section 4, it is mentioned that the challenge \"dataset contains a non-negligible amount of non-gesticulated frames.\" Presenting more details on the issue in a separate section would be an invaluable contribution to the challenge and the workshop.\n4) As mentioned by the authors in section 1, RNN-T model can process input in a streaming fashion. The authors need to elaborate some more to explain why this property of RNN-T is beneficial in gesture generation.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper8/Reviewer_KsvN"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper8/Reviewer_KsvN"]}, {"id": "FjhGRXMZnQq", "original": null, "number": 2, "cdate": 1659301510149, "mdate": null, "ddate": null, "tcdate": 1659301510149, "tmdate": 1659301510149, "tddate": null, "forum": "AYMDEx97qPN", "replyto": "AYMDEx97qPN", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper8/-/Official_Review", "content": {"title": "An interesting approach, but questions remain on the quality of the network's convergence", "review": "## Strengths\n- The proposed approach is sound, well-motivated, and well-explained.\n\n- The ability to predict gestures with partial audio inputs (aka the \"streaming\" approach) is particularly and can be potentially useful for real-time applications down the line.\n\n## Weaknesses\n- Many missing references:\n\n[A] Taras Kucherenko, Patrik Jonell, Sanne van Waveren, Gustav Eje Henter, Simon Alexandersson, Iolanda Leite, and Hedvig Kjellstr\u00f6m. \"Gesticulator: A framework for semantically-aware speech-driven gesture generation.\" In Proceedings of the 2020 International Conference on Multimodal Interaction, pp. 242-250. 2020.\n\n[B] Uttaran Bhattacharya, Nicholas Rewkowski, Abhishek Banerjee, Pooja Guhan, Aniket Bera, and Dinesh Manocha. \"Text2gestures: A transformer-based network for generating emotive body gestures for virtual agents.\" In 2021 IEEE Virtual Reality and 3D User Interfaces (VR), pp. 1-10. IEEE, 2021.\n\n[C] Uttaran Bhattacharya, Elizabeth Childs, Nicholas Rewkowski, and Dinesh Manocha. \"Speech2affectivegestures: Synthesizing co-speech gestures with generative adversarial affective expression learning.\" In Proceedings of the 29th ACM International Conference on Multimedia, pp. 2027-2036. 2021.\n\n[D] Ylva Ferstl, Michael Neff, and Rachel McDonnell. 2021. ExpressGesture: Expressive gesture generation from speech through database matching. Computer Animation and Virtual Worlds 32 (6 2021), e2016. Issue 3-4. https://doi.org/10.1002/CAV.2016\n\n[E] Jing Li, Di Kang, Wenjie Pei, Xuefei Zhe, Ying Zhang, Zhenyu He, and Linchao Bao. 2021. Audio2Gestures: Generating Diverse Gestures from Speech Audio with Conditional Variational Autoencoders. 2021 IEEE/CVF International Conference on Computer Vision (ICCV) (10 2021), 11273\u201311282. https://doi.org/10.1109/ICCV48922.2021.01110\n\n[F] Shenhan Qian, Zhi Tu, Yihao Zhi, Wen Liu, and Shenghua Gao. 2021. Speech Drives Templates: Co-Speech Gesture Synthesis with Learned Templates. 2021 IEEE/CVF International Conference on Computer Vision (ICCV) (10 2021), 11057\u201311066. https://doi.org/10.1109/ICCV48922.2021.01089\n\n[G] Ikhsanul Habibie, Mohamed Elgharib, Kripashindu Sarkar, Ahsan Abdullah, Simbarashe Nyatsanga, Michael Neff, and Christian Theobalt. 2022. A Motion Matching-based Framework for Controllable Gesture Synthesis from Speech. In SIGGRAPH \u201922 Conference Proceedings.\n\n- The approach of using statistical losses is not fully clear to me. Based on Eqs. 2 and 3, the statistical losses depend on the mini-batch size $m$. Did the authors perform experiments to observe any potential correlations between the stability of their statistical losses and the value of $m$?\n\n- 10 epochs seems to be an unusually low number of epochs for the validation loss to saturate at. Did the authors use any regularization loss on the network parameters or incorporate any weight decay in their optimizer?\n\n- \"We tuned the hyperparameters [...] manually\": what range of hyperparameters did the authors experiment with?\n\n## Minor Comments\n- Sec 2.3, para 2: \"as done in [].\" The reference number is missing here.\n\n## Overall\nWhile the paper presents a decent approach to synthesizing co-speech gestures, the design of the statistical losses (especially with the dependence on the mini-batch size) and the very early convergence (within 10 epochs) indicates a potentially bad convergence of the network to a sub-optimal local minimum. The comparatively poor performance on the evaluation benchmarks potentially provides further evidence of the said bad convergence.", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper8/Reviewer_Gozb"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper8/Reviewer_Gozb"]}, {"id": "0LFfv-eDhiF", "original": null, "number": 1, "cdate": 1659206557934, "mdate": null, "ddate": null, "tcdate": 1659206557934, "tmdate": 1659206557934, "tddate": null, "forum": "AYMDEx97qPN", "replyto": "AYMDEx97qPN", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper8/-/Official_Review", "content": {"title": "No need for correction", "review": "Overall, the paper does require any correction. The provided approach is clear and observations of predicted motion behavior are also presented. However, there are some aspects to discuss.\n\nIn Kucherenko et al. 2020 authors provided an approach reminiscent of your. It also used auto-regressive input to predict the subsequent pose. Furthermore, authors faced the same problem with collapsing to the mean pose. They solved it  with a special teacher-forcing strategy. It seems that only adding losses on mean and variance is not enough to solve this problem. Your model could be just trained to continue motion and do not extract information from audio. Maybe changing the training strategy will fix it. ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper8/Reviewer_MC6E"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper8/Reviewer_MC6E"]}]}, {"paper_url": "https://openreview.net/forum?id=gMTaia--AB2", "paper_id": "gMTaia--AB2", "reviews": [{"id": "iYDzLm47aOS", "original": null, "number": 3, "cdate": 1660046338000, "mdate": null, "ddate": null, "tcdate": 1660046338000, "tmdate": 1660046976549, "tddate": null, "forum": "gMTaia--AB2", "replyto": "gMTaia--AB2", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper7/-/Official_Review", "content": {"title": "An interesting approach with constrained attention and combined input features", "review": "Paper strengths:\n- Overall, the paper is well written and easy to follow.\n- The locality constraint attention is simple but efficient and well adapted to the task of gesture generation.\n- The combined multiple audio features and additional silence/laughter labels help the model capture audio-gesture alignment.\n- The proposed system receives the highest matched rate in the full-body tier, only second to the natural motion.\n\nComments and questions:\n- What is the benefit of using both \\hat{y} and \\hat{y}_dec in the loss function? Also, it could be more helpful if \\hat{y} and \\hat{y}_dec are depicted in Fig. 1.\n- The use of velocity constraints is a bit unclear. In line 173, why is the velocity constraint used only for upper body gestures? Does \u201cupper body gestures\u201d mean \u201cupper body tier\u201d? Or did the authors use masks for lower body joints during velocity loss calculation?\n- How did the authors label the additional silence/laughter information? Since the authors state \u201cthese two additional features are necessary\u201d, providing the details of the labeling process would be very helpful to readers.\n- It would be better to include the box plots and bar plots of the evaluation results, if there is enough space. The plots help readers intuitively understand the results.\n\nMinor points:\n- The paper title should be \u201cThe YOUR_TEAM_NAME entry to the GENEA Challenge 2022\u201d.\n- Line 35: Reference [20] may be mismatched in the sentence \u201c... [7, 20] approach it using audio as the only input\u201d. The reference [20] is about a review of evaluation practices of gesture generation.\n- Line 135: The second a_i^1 should be a_i^2.\n- Audio sample rate: 44100 -> 44100 Hz", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper7/Reviewer_wmS3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper7/Reviewer_wmS3"]}, {"id": "I1ftsU3C8OA", "original": null, "number": 2, "cdate": 1659953243533, "mdate": null, "ddate": null, "tcdate": 1659953243533, "tmdate": 1659953243533, "tddate": null, "forum": "gMTaia--AB2", "replyto": "gMTaia--AB2", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper7/-/Official_Review", "content": {"title": "A Tacotron2 Based Method for Co-Speech Gesture Generation With Locality-Constraint Attention Mechanism", "review": "# A Tacotron2 Based Method for Co-Speech Gesture Generation With Locality-Constraint Attention Mechanism\n\n## Description\n\nThe paper describes a gesture generation system for the GENEA Challenge 2022. The method adapts Tacotron2, a model originally designed for text to speech synthesis.\nThe model is LSTM based with locally constrained attention. The model takes as input: audio features, word embeddings, and one-hot speaker embeddings. The output is exponential map rotations. The audio features are combined MFCC, mel-spectogram and prosodic features.\n\n## References\n\nThe paper includes references to the most relevant recent work. I do not see the need to extend the references.\n\n## Clarity of Exposition\n\nThe paper is generally well written, and the exposition was properly explained.\nThe authors include the evaluation for the participants of the GENEA challenge, and also, their own evaluation comparing jerk and acceleration.\n\nThe proposed method uses some modifications to Tacotron2. It would be interesting to include an ablation test to demonstrate the effect of the locality constraint.\n\nDuring text processing, the authors add a label for laughter and silence. It would be interesting to see the ablation - particularly for laughter.\n\n## Reproducibility\n\nEven without releasing code, I am confident the work could be reproduced from the description.\n\n## Conclusion\n\nA well written paper that modifies an existing framework, Tacotron-2, in a logical way for this task. It would be interesting to see some ablation tests, but this is not necessary for inclusion.\n\nThe additional evaluation for jerk and acceleration is welcome, and could be extended to demonstrate the effectiveness of the modifications to the back-bone.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper7/Reviewer_rTfn"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper7/Reviewer_rTfn"]}, {"id": "WgbLmNp1Gvb", "original": null, "number": 1, "cdate": 1659940168408, "mdate": null, "ddate": null, "tcdate": 1659940168408, "tmdate": 1659940168408, "tddate": null, "forum": "gMTaia--AB2", "replyto": "gMTaia--AB2", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper7/-/Official_Review", "content": {"title": "There is not much novelty in the proposed approach and the results are also not significantly good.", "review": "This paper presents a Tacotron2-based method for co-speech gesture generation with locality constraint attention mechanism.\nThe architecture is based on the Tacotron2, which is largely used in TTS (text-to-speech) tasks. \nIn the proposed method, speech and subject id are added to the input along with the text information, in order to output the gesture sequences.\nThe methodology is straightforward and not so novel, but the application to the gesture generation task can be considered novel. \nAverage human-likeness below 50% have been achieved, indicating that the proposed approach was not enough to generate natural gesture motions.\n\nNo ablation studies are conducted.  \nNo video samples should be provided (for example, through anonymous github links). \n\nEq.(6): it is not clear which decoder (LSTM or PostNet) is being referred.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper7/Reviewer_rZs5"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper7/Reviewer_rZs5"]}]}, {"paper_url": "https://openreview.net/forum?id=-2HZD-e6pX7W", "paper_id": "-2HZD-e6pX7W", "reviews": [{"id": "TnlCF5dGq9M", "original": null, "number": 3, "cdate": 1660049654244, "mdate": null, "ddate": null, "tcdate": 1660049654244, "tmdate": 1660049654244, "tddate": null, "forum": "-2HZD-e6pX7W", "replyto": "-2HZD-e6pX7W", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper6/-/Official_Review", "content": {"title": "A combined transformer and RNN for gesture generation", "review": "Paper strengths:\n- Combining a transformer encoder and an LSTM decoder is interesting.\n- In objective evaluation, the proposed system produces gesture motions close to the natural motion in terms of the average jerk, acceleration, and global CCA.\n\nComments and questions:\n- While the authors do not clearly state, not only the curriculum learning strategy but also the model architecture seems to be heavily inspired by [17], i.e., transformer encoder + LSTM decoder. Therefore, an adequate reference and description should be added in Sec. 3.\n- Lines 325-326: \u201cour system was one of the top 4 systems that have achieved the highest levels of human-likeness\u201d: For me, this sentence sounds a bit overrated. In Fig. 2, the difference between FSF (\u201cour system\u201d) and FSG is marginal.\n- Lines 352-353: \u201cour system is \u2026 one of the top 3 systems when it comes to Global CCA and Hellinger distance scores\u201d: However, in terms of Hellinger distance, the lower, the closer to the natural motion. Thus, FSF is the 8th in the Hellinger distance evaluation.\n\nMinor points:\n- In Fig. 1, the images of the virtual agent are unnaturally stretched. The aspect ratio should be fixed.\n- Line 223: l_1 -> L_1\n- Sec. 4.2.1 and 4.2.2 are too short to be separate sub-subsection. It would be better to use \\noindent{\\textbf{Human-likeness.}} instead.\n- Line 311: motion -> motion. (add period)\n\nOverall:\n\nAdapting a dance generation model to gesture generation is promising, and the proposed system produces gesture motions having close properties to the natural motion in some objective evaluation metrics. On the other hand, the paper seems to be a bit exaggerated in terms of the novelty of the model architecture and evaluation results.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper6/Reviewer_suXb"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper6/Reviewer_suXb"]}, {"id": "1_O-_bGyhuK", "original": null, "number": 2, "cdate": 1659839569424, "mdate": null, "ddate": null, "tcdate": 1659839569424, "tmdate": 1659839713398, "tddate": null, "forum": "-2HZD-e6pX7W", "replyto": "-2HZD-e6pX7W", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper6/-/Official_Review", "content": {"title": "Combining a transformer-based encoder and a RNN-based decoder paid off with nice performance.", "review": "The paper describes a novel attempt to combine a transformer-based encoder and a RNN-based decoder to build a hybrid model for audio-to-gesture generation, which showed promising performance with rankings in subjective evaluations higher than average.\n\nThe proposed model is clearly presented in the paper with details. Presenting a novel way of fusing different models with experimental results is a nice contribution to the challenge.\n\nSome comments to improve the paper:\n1) According to the authors, one of the rationale behind using a transformer-based encoder is to better capture the para-verbal features like intonation, prosody and loudness. But it is not explained in the paper how such para-verbal features contribute to the performance of gesture generation. Some explanations would help better understand the benefits of the proposed model.\n2) In section 3, the authors mention that curriculum learning is employed to overcome the problem of error accumulation. More details would be helpful for the readers.\n3) In conclusion, it is mentioned that the proposed hybrid encoder-decoder model could generate gestures that better capture the individual styles of different speakers. Any quantitative or qualitative results that support the comments would be interesting because modeling personalized gesticulation style could be one of the ultimate goals of gesture generation technology.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper6/Reviewer_hoQP"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper6/Reviewer_hoQP"]}, {"id": "JDHYo8bxRBk", "original": null, "number": 1, "cdate": 1659203874238, "mdate": null, "ddate": null, "tcdate": 1659203874238, "tmdate": 1659203874238, "tddate": null, "forum": "-2HZD-e6pX7W", "replyto": "-2HZD-e6pX7W", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper6/-/Official_Review", "content": {"title": "Some clarification required.", "review": "Overall, the presented approach is quite interesting. However, some clarification will strengthen the paper. First of all, it is not entirely clear how the decorer works. Is it replicate the pipeline of Huang et al. 2020 - does it generate motion frame by frame feeding previously generated poses (in a non teacher-forcing case)? By Figure 1 it  looks like it generates the whole sequence from given input. Also, it is not clear how output features of decoder (Z) are incorporated with input poses. Are they concatenated before the first LSTM layer or there is another strategy? \n\nFurthermore,  there are several questions that are interesting to discuss. As mentioned in the data preparation section, only gestures relevant to actual speech were used. It is interesting how the proposed model works in cases when the target person is silent and listening to the conversation partner. Second, it is interesting how much GPU memory is utilized by self-attention for such long sequences? For example, in Huang et al. 2020 the local self-attention was used to optimize memory consumption. Finally, some observations on generated motion would be also useful. What could be improved?\n\nI hope the comments above would help you to strengthen the paper and clarify some aspects. Also, in my opinion, the word \"innovative\" is not very suitable in this case, since it is very similar to  Huang et al. 2020.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper6/Reviewer_tdQF"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper6/Reviewer_tdQF"]}]}, {"paper_url": "https://openreview.net/forum?id=zEqdFwAPhhO", "paper_id": "zEqdFwAPhhO", "reviews": [{"id": "gGKnp-Z5Nn", "original": null, "number": 3, "cdate": 1660049645502, "mdate": null, "ddate": null, "tcdate": 1660049645502, "tmdate": 1660049645502, "tddate": null, "forum": "zEqdFwAPhhO", "replyto": "zEqdFwAPhhO", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper4/-/Official_Review", "content": {"title": "This paper presents a new method for co-speech gesture generation using VQ-VAE to learn a probability distribution on latent codes, which naturally models the one to many mapping from speech to gesture in the training data.", "review": "Well written paper with some good ideas. Nice to see a VQ-VAE approach being used for this problem. While the results are still not reaching close to ground truth gesture motions, it is a promising approach and the authors have a good discussion on the limitations and potential solutions, given additional time. \n\nIt will be interesting in future work to see if the authors can overcome the issues of codebook collapse using more robust training, etc.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper4/Reviewer_Tzsn"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper4/Reviewer_Tzsn"]}, {"id": "FU9iO0ytBOF", "original": null, "number": 2, "cdate": 1659998488393, "mdate": null, "ddate": null, "tcdate": 1659998488393, "tmdate": 1659998586043, "tddate": null, "forum": "zEqdFwAPhhO", "replyto": "zEqdFwAPhhO", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper4/-/Official_Review", "content": {"title": "The DeepMotion entry to the GENEA Challenge 2022", "review": "The paper introduces a framework inspired by the VQ-VAE model and the GPT-2 transformer to generate body gestures. In the first stage, the VQ-VAE network is trained to extract gesture tokens from raw input gestures. In the second stage, gesture tokens, text, and audio features are fed to GPT-2 model to produce body motion outputs.\n\nStrength:\n1. This is a well-investigated paper. The proposed approach is also interesting and novel. The authors have implemented the VQ-VAE model into the gesture generation domain. The GPT-2 transformer is also an interesting implementation. \n\n2. The paper is very well-written and organized. The explanations of the designed framework are sufficient. It allows readers to fully understand the techniques implemented and possibly, reproduce the results. \n\nWeakness:\nI would suggest several points that the authors may consider in the final paper version as well as future works:\n\n1. Visualization results - There are several discussions in Section 6. Results and Discussion, for example, \"our method tends to produce a lot of weight shifting movements in the lower-body. (L393-394)\". In this case, it would be more informative if the authors could include an example of generated gestures to support that statement.\n\n2. Further analysis - an ablation study could be included to better verify the model components, for example, the codebook size. Indeed, several objective metrics (introduced in the previous GENEA workshops) can be implemented rather than relying on the reconstruction loss for tuning the codebook size. I assume that the objective metrics would allow the authors to have better ideas about the quality of generated motion.\n\n3. Technical concerns - 3D CNN for encoding/decoding motions: although CNN can also be implemented for the time series data, the placement of joint and time sequence in CNN should be carefully designed to ensure the spatial-temporal presentation of motion.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "nominate_for_a_reproducibility_award": "The explanations of the designed framework are sufficient for readers to understand the techniques implemented and possibly reproduce the results. I would like to recommend this work for a reproducibility award if the authors can submit their code and related data in the final submission."}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper4/Reviewer_EMmU"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper4/Reviewer_EMmU"]}, {"id": "i_ZZlGdVfCm", "original": null, "number": 1, "cdate": 1659297757410, "mdate": null, "ddate": null, "tcdate": 1659297757410, "tmdate": 1659300384286, "tddate": null, "forum": "zEqdFwAPhhO", "replyto": "zEqdFwAPhhO", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper4/-/Official_Review", "content": {"title": "A sound and well-motivated approach that performs well on the evaluation benchmarks", "review": "## Strengths\n- The proposed methodology of using VQ-VAE-based gesture tokens to train a GPT2-Transformer-based mapping from audio to gestures is sound and well-motivated.\n- The paper is well-written and easy to follow.\n- The approach shows good performance on the evaluation benchmarks.\n\n## Weaknesses\n- Missing references:\n\n[A] Taras Kucherenko, Patrik Jonell, Sanne van Waveren, Gustav Eje Henter, Simon Alexandersson, Iolanda Leite, and Hedvig Kjellstr\u00f6m. \"Gesticulator: A framework for semantically-aware speech-driven gesture generation.\" In Proceedings of the 2020 International Conference on Multimodal Interaction, pp. 242-250. 2020.\n\n[B] Uttaran Bhattacharya, Nicholas Rewkowski, Abhishek Banerjee, Pooja Guhan, Aniket Bera, and Dinesh Manocha. \"Text2gestures: A transformer-based network for generating emotive body gestures for virtual agents.\" In 2021 IEEE Virtual Reality and 3D User Interfaces (VR), pp. 1-10. IEEE, 2021.\n\n[C] Uttaran Bhattacharya, Elizabeth Childs, Nicholas Rewkowski, and Dinesh Manocha. \"Speech2affectivegestures: Synthesizing co-speech gestures with generative adversarial affective expression learning.\" In Proceedings of the 29th ACM International Conference on Multimedia, pp. 2027-2036. 2021.\n\n- It is not clear to me how the interpolation works on the overlapping frames between sliding windows (Ln. 308-311):\n    - What is the interpolation methodology? For example, if it is an affine combination, what are the per-term coefficients?\n    - Does the interpolation only take place on the overlapping segment? Or does it also propagate (e.g., with some decaying of the interpolation coefficients) to the subsequent frames? In other words, how do the authors ensure there are no discontinuities at the interpolation boundaries?\n\n## Minor comments\n- The paper has some grammatical inconsistencies, such as\n    - Ln. 257: \"we applies\" -> \"we apply\"\n    - Ln. 259: \"a random values\" -> \"random values\"\n    - Ln. 293: \"based previous tokens\" -> \"based on previous tokens\"\n    - Ln. 308: \"When inference\" -> \"When inferring\"\n\nI recommend another round of proofreading the paper.\n\n## Overall\nThe paper presents a detailed, sound, and well-motivated approach to synthesizing co-speech gestures. The results are promising and have performed well on the evaluation benchmarks. For completeness, please add the missing references and clarify the interpolation procedure.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper4/Reviewer_NP7P"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper4/Reviewer_NP7P"]}]}, {"paper_url": "https://openreview.net/forum?id=atWaELmguNj7", "paper_id": "atWaELmguNj7", "reviews": [{"id": "0ICb-yNAnSM", "original": null, "number": 3, "cdate": 1659939665924, "mdate": null, "ddate": null, "tcdate": 1659939665924, "tmdate": 1659939665924, "tddate": null, "forum": "atWaELmguNj7", "replyto": "atWaELmguNj7", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper3/-/Official_Review", "content": {"title": "The proposed method is somehow novel, but it lacks of ablation studies to validate the effects of using single modalities and cross-modality subspaces.", "review": "This paper presents a speech-driven gesture generation method based on multimodal representation learning. Each modality is projected to two distinct subspaces: modality-invariant and modality-specific. Gradient reversal layer based adversarial classifier and modality reconstruction decoders are used during training.\nAverage human-likeness ratings below 50% have been achieved, indicating that the proposed approach was not enough to generate natural gesture motions.\n\nAblation studies should be included to show the effects of modality-invariant only, or modality-specific only.\nThe video sample in the anonymous webpage shows an example of the generated motion.\nI'm not aware of how the other dialogue segments used in the evaluation are, but in the sample, the target speaker is basically in listening mode, so that the instants the co-speech gestures are generated are very short.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper3/Reviewer_77RM"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper3/Reviewer_77RM"]}, {"id": "xLHEdlL0d-h", "original": null, "number": 2, "cdate": 1659917083314, "mdate": null, "ddate": null, "tcdate": 1659917083314, "tmdate": 1659917083314, "tddate": null, "forum": "atWaELmguNj7", "replyto": "atWaELmguNj7", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper3/-/Official_Review", "content": {"title": "The evaluation and sub-materials show good results.", "review": "The paper proposed a gesture generation method by incorporating representation learning into previously proposed network architectures. Six representations for audio, text, gesture (two per modality) are used. The method takes audio, text, and seed gestures as input and output is a sequence of gesture.\n\nThe paper is well organized and written but it is easier to read if put new lines after sub-sub-section titles. \n\nThe technical descriptions are well written and the experiments would be reproducible.\n\nSome research, such as [10], have already addressed the importance of the audio or human-pose representations for gesture generation. So, the contribution is incremental, but having modality-mixed representations is somewhat novel.\n\nThe evaluation and sub-materials show good results. Having ablation study, also, help us to better understand the effects of proposed method. However, the effects of proposed representations were not very significant.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper3/Reviewer_bVz8"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper3/Reviewer_bVz8"]}, {"id": "fI2ieuFwR9J", "original": null, "number": 1, "cdate": 1659792412416, "mdate": null, "ddate": null, "tcdate": 1659792412416, "tmdate": 1659862476998, "tddate": null, "forum": "atWaELmguNj7", "replyto": "atWaELmguNj7", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper3/-/Official_Review", "content": {"title": "Novel and interesting paper with a little unclarity.", "review": "The paper proposes a novel deterministic speech to gesture generation model by learning a modal-invariant and modal-specific features for different modalities used as inputs, i.e., audio, text, and seed poses. Ablation study showed that this method could improve the accuracy of the generated gestures.\n\nStrengths:\n1. Although the paper was not the best among proposed systems, the ablation study showed that the separation for modal-invariant feature and modal-specific feature were helpful to the accuracy of the generated gestures, i.e., a lower Hellinger distance and FGD on raw data space. This indicates that the proposed method is more effective to determine the gesture shape than purely mixing different modality features.\n2. The using of WavLM, as a pre-trained neural network for audio feature extraction, improves the jerk and acceleration of the generated gestures, even though the pitch, energy and volume were used at the same time. This shows that prosodic features of audio, i.e., pitch and energy, are not enough for predicting the rhythmic movements in the gestures.\n\nPotential issue:\nThe paper uses an autoencoder-like training scheme to help learn the hidden feature space. However, the reconstruction error was computed on the reconstructed results and the output of one of the hidden layers, whose parameters are being updated when training. This could lead to an undesired behavior that the encoder and decoder agree with each other while not considering the original input at all. A more common approach for training an autoencoder is to compute the reconstruction error on the original input or a transformation of the original input.\n\nWeaknesses:\n1. More details are necessary for understanding the domain learning. While the authors propose to extract modal-invariant features from modalities as in [5], they did not use the original similarity loss for these features. Instead, they propose to use domain learning to reach this goal. Although this could be one of the originalities of this paper, the authors did not thoroughly explain how domain learning works and how it can achieve a similar effect as central moment discrepancy (CMD) loss, or its potential advantages and disadvantages compared with CMD.\n2. The authors claims that the reconstruction loss is used to ensure the hidden representations to capture the details. However, no ablation was provided for this. Thus, it is unclear that how much or if this loss is useful.\n3. The authors did not use traditional feature extraction method on the audio such as mel-spectrogram, which is more common in the literature. The difference between using WavLM and basic features is unknown.\n\nQuestions:\n1. The scales of coefficients for different loss terms ranges widely, e.g., alpha is 300 and epsilon is 0.1 in equation (5). How did the authors adjust the hyper-parameters and reach such a different scale?\n2. Why did the author choose 3 seconds as the length for generation? Any reference for this?\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "nominate_for_a_reproducibility_award": "No comment as the authors has not uploaded their code yet."}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper3/Reviewer_CmXk"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper3/Reviewer_CmXk"]}]}, {"paper_url": "https://openreview.net/forum?id=RZP6nErM2Xa", "paper_id": "RZP6nErM2Xa", "reviews": [{"id": "MUm75L5B9NZ", "original": null, "number": 3, "cdate": 1660052398823, "mdate": null, "ddate": null, "tcdate": 1660052398823, "tmdate": 1660052398823, "tddate": null, "forum": "RZP6nErM2Xa", "replyto": "RZP6nErM2Xa", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper2/-/Official_Review", "content": {"title": "A simple and effective framework", "review": "### Summary:\nThe paper presents a Bi-Directional LSTM framework for speech-to-motion prediction. The proposed method is simple and effective. An interesting part of this paper is the LSTM-based multi-head decoders for different body parts. According to the user study results, the proposed model performs well in terms of appropriateness, whereas the scores of human likeness are relatively lower due to the issue of extreme rotations.  \n\n### Strengths:\nThe technical details are presented in a straightforward manner. It's nice to see the analysis regarding the unconstrained rotations and foot contact, which definitely provides more insights into the prediction results. \n\n### Weaknesses:\nHowever, a weak part of the work lies in the fact that the multi-head decoders do not work well for the full body speech-to-motion prediction. Besides, I do have some concerns/comments listed below.\n\n- The LSTM-based multi-head decoders are inspired by the multiple decoders used in Habibie et al. Therefore, the framework itself is not new and the novelty is somewhat incremental. \n\n- Since the proposed system is a deterministic model, it would be better if the authors could provide some quantitative comparison with the ground truth, e.g., MSE.\n\n- The data processing pipeline is not very clear. What are the feature sizes of the audio, text and speaker embeddings? How are these three modalities aligned?\n\n- According to the paper (line 53), using the PASE+ [12] speech embedding is one of the contributions. In this sense, the comparisons with other commonly-used audio features, e.g., MFCC, would have been useful. \n\n- Various loss functions have been applied (Eq 1). It would be helpful if the authors can provide more analysis on the effects of different terms.\n\n### Minor:\n- Is there any post-processing (e.g., smoothing etc.) that was applied to the predicted motion?\n- In Eq 1, please indicate the meaning of f().\n- Line 229-234: what\u2019s the number of training epochs?\n\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper2/Reviewer_PYyD"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper2/Reviewer_PYyD"]}, {"id": "17Oq_iVLGHi", "original": null, "number": 2, "cdate": 1660028637611, "mdate": null, "ddate": null, "tcdate": 1660028637611, "tmdate": 1660028637611, "tddate": null, "forum": "RZP6nErM2Xa", "replyto": "RZP6nErM2Xa", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper2/-/Official_Review", "content": {"title": "Review of Anonymous entry to the GENEA Challenge 2022", "review": "Strong related works section and could even dive deeper into the long history of these models. (1) it hasn\u2019t always been deep-learning only and (2) could describe the effects and purpose of adding word embeddings e.g. gestures carry semantic and communicative meeting relating to text. \n\nDetailed description of data pre-processing which is crucial in this dataset. \n\nSection 5.2: want more discussion of \u201cappropriateness.\u201d How was appropriateness evaluated and why does the model perform so well? What about the evaluation and model implementation helped it do well in this category? This seems like the punchline of the paper and both this and Human-likeness are only very lightly discussed. Please provide some interpretation or insight into why this model would be expected to perform well in this section. \n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "nominate_for_a_reproducibility_award": "Detailed description of models, background behind parameters chosen, and implementation. Assuming the code is released this could be nominated for this award."}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper2/Reviewer_d6NA"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper2/Reviewer_d6NA"]}, {"id": "X1VMZdn0C-o", "original": null, "number": 1, "cdate": 1659976231686, "mdate": null, "ddate": null, "tcdate": 1659976231686, "tmdate": 1659976231686, "tddate": null, "forum": "RZP6nErM2Xa", "replyto": "RZP6nErM2Xa", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper2/-/Official_Review", "content": {"title": "Anonymous entry to the GENEA Challenge 2022", "review": "This paper presents an approach using Bi-directional LSTM to generate human body gestures. The model receives audio, text transcription, and speaker ID as the inputs to produce human motion represented by joint rotation values. The authors applied the full-body framework for generating outputs submitted to the full-body tier, while the part-specific decoder was implemented in the upper-body tier.\n\nStrength:\n1. Overall, the paper is well-organized, allowing readers to catch up on the ideas quickly. \n2. The paper presents several exciting ideas like encoding speaker ID and dividing a human body into sub-parts. However, I was expecting to see more in-depth discussions concerning the motivation and the effectiveness of those approaches to the generated motions. \n\nWeakness:\n1. Paper clarity: the authors should explain the proposed framework in more detail. In particular, the network architecture of the Speaker Embedding, Encoder, and Decoder. What is the motivation/benefit of adding the speaker embedding module to the network? Also, in the case of the part-specific decoder?\n\n2. Technical concerns: How does the speaker embedding network update its weight values for distinguishing speaker IDs? Did the authors include the (classification?) loss in the total loss function? In terms of the part-specific decoders, it turns out that the four decoders (of the head, upper body, hands, and lower body) are independent networks. If that is the case, how did the authors guarantee the synchronization of the generated full body motion? \n\n3. In-depth analysis: It would be more informative to have in-depth discussions about performance. Possibly, the author can conduct an ablation study (even with objective metrics) to discuss the effectiveness of the speaker embedding and the part-specific decoder. ", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper2/Reviewer_bskq"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper2/Reviewer_bskq"]}]}, {"paper_url": "https://openreview.net/forum?id=PHadbLGjHRL", "paper_id": "PHadbLGjHRL", "reviews": [{"id": "6LBaMIClDq", "original": null, "number": 3, "cdate": 1660201017711, "mdate": null, "ddate": null, "tcdate": 1660201017711, "tmdate": 1660201017711, "tddate": null, "forum": "PHadbLGjHRL", "replyto": "PHadbLGjHRL", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper1/-/Official_Review", "content": {"title": "Interesting direction of gesture motion maps", "review": "### Summary\n\nThe authors propose a gesture generation model that is conditioned on speech audio and text transcriptions. The key idea here is derived from ChoreMaster, which relies on the constructed motion graph to generate relevant gestures given speech and language inputs. This generation model is optimized in a dynamic programming setting, which makes it computationally efficient. This model is evaluated using subjective evaluation metrics to measure naturalness and appropriateness of generation.\n\n### Strengths\n- This method would generate very natural gestures as the generated gestures are taken directly from the ground truth recordings. \n- The optimization of this approach is computationally efficient as it can be solved using a dynamic program\n\n### Weaknesses\n\n- My main concern is with the data preparation where each phase is defined as the gesture where a word was spoken more than 0.4 seconds. \n  - Why is this definition of phase useful? Some experiments in support of this design choice would have been useful\n  - A common definition of gesture phase involves looking at the fine grained structure of a gesture. There are pre-gesture, main gesture, post-gesture and neutral phases which is quite different from the definition in this paper. It might be good to clarify the differences in the definition of gesture phase here.\n\nSome suggestions:\n- In eq 3, one of the cost function is the distances between rhythm signatures between audio and gesture. Are the rhythm signatures between audio and gestures similar? A small experiment to verify this fact could add a lot of value to this paper.\n- The naturalness of the generation is high which is not a surprise as the sequence of body motions are taken from the ground truth. But the appropriateness is still lesser that 0.5 indicating that the gestures, although natural looking, might be random. The readers might be interested to hear more about appropriateness as well.\n- The literature review on co-speech gesture generation is practically missing from the paper\n- I would also cite motion matching papers which have the same basic ideas on generating body motion by choosing the relevant collection of snippets from ground truth data.\n- It would increase the readability of the paper if the baselines in this paper were defined or cited\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper1/Reviewer_MmEw"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper1/Reviewer_MmEw"]}, {"id": "JqAY81jFWDj", "original": null, "number": 2, "cdate": 1660040721289, "mdate": null, "ddate": null, "tcdate": 1660040721289, "tmdate": 1660040721289, "tddate": null, "forum": "PHadbLGjHRL", "replyto": "PHadbLGjHRL", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper1/-/Official_Review", "content": {"title": "This paper presents an alteration to ChoreoMaster for gestures, which involves finding gesture phases and using a rhythm embedding.", "review": "Nice idea to adapt Choreomaster to gestures, and a promising approach taken using gesture phases, rhythm embeddings and graph search.\n\nA few issues that should be addressed to improve the paper:\n\nNo related work section, and authors are missing a lot of citations to back-up their statements and observations about gestures. The authors are working in the area of gesture synthesis, but have made some decisions about gesture phasing and labeling words as beats, which need to be justified and compared to prior work in the area. Particularly other papers that use phase-based approach to human motion (e.g., Phase-functioned neural networks for character control, Holden et al.) and gestures (e.g., Adversarial gesture generation with realistic gesture phasing, Ferstl et al.).\n\nIdentifying actual gesture phases (rest position, preparation, stroke, hold, retraction/recovery, and partial recovery) is a complex task and the authors claim to be splitting into gesture phases but they are actually just splitting by time intervals of words larger than 0.4 seconds in the text transcripts, which is not clear to me how these are classified as gesture phases. More details on gestures phases and how this is done are required. Or authors should change the name to something more appropriate. Please also refer to the gesture phasing in Ferstl et al. and how this method compares. Please also discuss how your method compares to others that use gesture phasing and graph-based search (see ExpressGesture: Expressive gesture generation from speech through database matching).\nHow did you handle the transitions in the graph search? \n\n-Lots of typos in the text, please run a spell check.\n-One that should be fixed for future experiments is 'How human-likeness does the gesture motion appear?' which should be 'How human-like does the gesture motion appear?'\n-A justification for the unusal scale of 0 to 100 should be made also, 1-5 or 1-7 point Likert scales are more common for these types of questions.\n-More details on the statistical tests you performed are needed. \n-Graphs in Figure 5 are not standard and require more explanation.\n-How many participants took part in the experiment? \n-Did you check on Prolific if they were native English speakers and were able to assess the appropriateness of the speech to the gestures? \n-Did you include some attention checks to be sure they were completing the experiment correctly, which is common for crowd-sourced experiments?\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper1/Reviewer_CSSm"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper1/Reviewer_CSSm"]}, {"id": "UyaWJC1k2y", "original": null, "number": 1, "cdate": 1660029719723, "mdate": null, "ddate": null, "tcdate": 1660029719723, "tmdate": 1660029719723, "tddate": null, "forum": "PHadbLGjHRL", "replyto": "PHadbLGjHRL", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper1/-/Official_Review", "content": {"title": "Review of GestureMaster entry to the GENEA Challenge 2022", "review": "Few minor typos. E.g. Section 1p3 \u201c. This database consists of gesture phases split from training gesture motion by an automatically split algorithm. T\u201d and Section 2 p2 last sentence accidentally capitalized \u201cWe.\u201d There are a few others throughout the paper and although it does not impact the comprehensibility of the paper, the readability of the paper would benefit from a thorough proofread.  \n\n2.1 It is unclear to me from the paper whether beats were recovered manually or algorithmically, and if algorithmically what algorithm was used \u2013 off the shelf, previously published, or a part of this work. \n\n3 \u2013 very comprehensive discussion of motion graph and optimization algorithms. Could use some introduction to the motion graph concept before this as as it reads now it jumps directly into some gritty details without first describing how it will be used in an overarching algorithm. Providing a bit of pseudo-code or a high-level algorithmic description before jumping in and then sign-posting to sections in that generative algorithm would be very helpful. \n\n4 \u2013 good explanation of results and evaluations. In Table 1 highlighting the models described in this paper would improve readability and immediate understanding of this paper\u2019s contributions and place in the rankings. It would also be helpful to understand why this model performed so well. The authors provide some insight into why these could be expected to perform well for human-likeness, but why so well with semantic appropriateness? As I don\u2019t see any place semantic content is included in the generation, why did this model perform so well? \n\nClearly very strong algorithm but needs deeper discussion into why the authors think it performed so well. I think this paper should be accepted provided those additions. ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper1/Reviewer_3ZhP"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper1/Reviewer_3ZhP"]}]}, {"paper_url": "https://openreview.net/forum?id=T5ei7IeQUMK", "paper_id": "T5ei7IeQUMK", "reviews": [{"id": "XNMe9aQcnLP", "original": null, "number": 2, "cdate": 1660820017384, "mdate": null, "ddate": null, "tcdate": 1660820017384, "tmdate": 1660820017384, "tddate": null, "forum": "T5ei7IeQUMK", "replyto": "T5ei7IeQUMK", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper16/-/Official_Review", "content": {"title": "Solid perception study re verbal and non-verbal expressiveness in virtual humans", "review": "The paper presents two experiments, where users participate in zoom-interviews with a virtual human, with or without non-verbal expressions or extra verbal embellishments (follow-up questions), and study how these affect behavioural measures as well as self-reported measures of the users. Results show significant effect of both types of modifications.  \n\nThe paper is very well-written and easy to follow. The experiments are presented in a clear and structured way, and the results are clearly presented. \n\nRegarding the tool pipeline: Beat gestures are generally co-occurring with prominent/stressed words in the speech. it is stated that generation of beat gestures is based on RAKE score extracted from the text - how does this compare to the actually realized TTS output in VHToolkit? (It would seem naiive to assume that the TTS system and RAKE always would choose to emphasize the same words), please add some clarification or comment re. this. \n\nA couple of possible manuscript improvements:\n\n4.1 I would be good to mention at the onset of this section that the experiment really consists of two separate within-subject experiments, control vs VB and control vs NVB.\n4.2.2 some missing words in first sentence\n\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper16/Reviewer_CdjV"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper16/Reviewer_CdjV"]}, {"id": "AUffc0zJ0os", "original": null, "number": 1, "cdate": 1660646484378, "mdate": null, "ddate": null, "tcdate": 1660646484378, "tmdate": 1660646484378, "tddate": null, "forum": "T5ei7IeQUMK", "replyto": "T5ei7IeQUMK", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper16/-/Official_Review", "content": {"title": "Review", "review": "This paper presents results of a study conducted on interviewees behavior toward an interviewing virtual agent that uses both non-verbal and verbal behavior cues.  The authors set up a platform with an avatar with verbal and non-verbal capabilities, conduct experiments where subjects conduct interviews with agents capable of non-verbal behaviors and capable of generating follow-up questions, and analyze users' self-assessed perceptions of the interaction. \n\nThe paper cites a lot of relevant related work, demonstrating how this work is situated relative to the rest of the field.  One other work the authors should compare to (although the domain is not interviewing) is:\n\n\u2022\u00a0Wang, H., Gaddy, V., Beveridge, J. R., & Ortega, F. R. (2021). Building an emotionally responsive avatar with dynamic facial expressions in human\u2014computer interactions. Multimodal Technologies and Interaction, 5(3), 13.\n\nThe methods are described quite clearly and executed with appropriate control conditions.  There some issues with self-reporting, of course, and I wonder if the authors can related thee results reported using the self-reporting metrics with the more direct quantitative results (e.g., from the top half of table 1), to validated what emerged from the self-reported data.  However, overall, the paper is well-written and presented with both quantitative and qualitative analysis with examples, which I appreciate. \n\nOne small issue: The title doesn't seem grammatical to me: \"Understanding Interviewees\u2019 Perceptions and Behaviour to Verbally and Non-verbally Expressive Virtual Interviewing Agents\" - it seems like \"to Verbally\" should be \"toward Verbally\"\n\nOne big issue: This has less to do with the technical content of the paper and more with the premise of the entire paper, and pertains to larger issues in the field as a whole -- the situation here is a virtual interview, where the avatar at least notionally is not a peer to the human subject, but holds a position of power.  Should virtual interviewers even be a thing we as a community should encourage though research?  Does presenting a potential hire with a fake human instead of a real human interviewer not dehumanize the interviewee from the get go?  This strikes me as a way to reproduce old, exploitative patterns of the labor market at larger scale, and seems like a bigger issue than whether the avatars gestures or not.  Do the authors consider some of these ethical issues with the motivation beyond the technical capabilities?", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper16/Reviewer_rtb3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper16/Reviewer_rtb3"]}]}, {"paper_url": "https://openreview.net/forum?id=vaOobiePUy", "paper_id": "vaOobiePUy", "reviews": [{"id": "jrnxO5gR4E", "original": null, "number": 2, "cdate": 1660682708586, "mdate": null, "ddate": null, "tcdate": 1660682708586, "tmdate": 1660682708586, "tddate": null, "forum": "vaOobiePUy", "replyto": "vaOobiePUy", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper14/-/Official_Review", "content": {"title": "see below", "review": "The paper describes a new database to study breathing while speaking. The paper presents the design of the corpus, a description of the corpus, and a preliminary analysis of the data. Overall, this is an interesting, well-written paper. It fits the scope of the workshop, since this data can be used to synthesize virtual agents expressing realistic breathing patterns.\n\nThe paper discusses several results reported on previous studies about the relation between \u201cemotional classes\u201d and respiration, some of them reporting conflicting results. My view on this issue is that several realizations of an \u201cemotion\u201d can be quite diverse. For example, cold anger is quite different from hot anger. Similar observations can be made for happiness, when several varied behaviors can be clustered under the term \u201chappiness.\u201d In this context, some strong manifestations of an emotion can produce a breathing change, but more mild versions the emotion may not.  \n\nCan we change emotion so quickly from one emotion to another by just listening 90min music? \n\nThere is also potential bias on the self annotations. If you ask me what are the songs that make me feel \u201chappy,\u201d and then you play that song to me and ask me how I feel, chances are that I am going to say happy. I understand that you are annotating arousal and valence, but this is still a problem. \n\nAnother concern is the lack of temporal resolution on the annotations. They provide a single ranting for the entire time that they spoke. Emotions fluctuate when we interact with other. This variations are not captures by the labels. \n\nThe size of the corpus is quite small.\n\nIs the study of personality suggested in the conclusion even possible with this corpus? did you collect personality information from your speakers? You only have 20 subjects, which is small for studying the role of personality. \n\n\n\nMinor comments:\n\n\u201cIn an interesting 73 study, Terzio\u011flu et al. have shown\u201d add reference. \n\n\u201cModelling realistic emotionality\u201d What do you mean?\n\n\u201cuser will also contain significant importation about their emotional state\u201d importation -> information\n\n\u201cif the addition of realistic breathing adds to more rapport and natural perception of a virtual agent\u201d (I believe this sentence reads better if \u201cto\u201d is removed)\n\n\u201cthe separate song values are not displayed in this paper\u201d can you add this in the appendix? \n\n\u201cbut due to brevity reasons\u201d ?  space constraints?\n\n\u201cSad music probably has the same effect, but this needs further research.\u201d If your results do not show this, my recommendation is do not speculate. ", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper14/Reviewer_dy6G"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper14/Reviewer_dy6G"]}, {"id": "5eAnJqe7rI", "original": null, "number": 1, "cdate": 1660027695689, "mdate": null, "ddate": null, "tcdate": 1660027695689, "tmdate": 1660027695689, "tddate": null, "forum": "vaOobiePUy", "replyto": "vaOobiePUy", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper14/-/Official_Review", "content": {"title": "Review of Emotional Respiration Speech Dataset", "review": "This paper describes a new dataset that was elicited by having participants listen to self-chosen music while being monitored, and using self-reported emotion data. The purpose of this is to create a dataset of affective respiration that could be used to improve social non-verbal communication between humans and VAs or robots. \n\nI come in skeptical that \u201cmusic-induced emotion\u201d is the same as conversational emotion, so it seems like the task and dataset doesn\u2019t relate to the intended application. \n\nBut interesting core concept of paralinguistic cues. \n\nEnjoyed the introduction; good overview of problem space and appropriate background and context for the challenge. However, \u201cNeither of these types of emotional datasets replicate the conversational or spontaneous speech, and lack in ecological validity\u201d \u2013 I feel that then proposing listening to music to elicit emotion doesn\u2019t address these challenges very well. \n\nEspecially appreciated the related work section. As a NVB researcher not very familiar with paralinguistic cues it provides a strong overview of the state of the field, as well as the impetus behind the behavior (ANS and emotion regulation). \n\nIn section 2.3, I would note that forced-choice emotion evaluation is notoriously fickle \u2013 being able to distinguish beteween 3 or 4 emotions is not the same as using those cues in real life, especially with such a small-dimensional expression such as respiration. For example, the authors themselves mention both digust and pleasure elicit slower breathing, whereas anxiety and anger both elicit shallow rapid breathing. I find these studies dubious, and the authors put a lot of emphasis on them. The main takeaway \u2013 \u201cthey do make clear that humans use some sort of induction of one\u2019s emotions be observing the respiration\u201d seems like the big takeaway and should be emphasized more. Especially since the evaluation of the dataset does not depend on this forced choice emotion recognition. \n\nOn that note \u2013 authors use \u201cemotion detection\u201d quite often but is it genuine detection? Detection would be unprompted emotion recognition, whereas the tasks the authors often describe seems to me to be forced-choice emotion recognition. \n\nWhy not use existing speech datasets annotated with emotional information and using respiration patterns detected from microphones/video? \n\n3 Experiment \nHaving people select their own music reinforces individual differences in emotion interpretation and understanding; not only will the music differ but what \u201chappy\u201d means to each participant islikely extremely different, especially in the context of music. \nUniversity-student study is not representative of population at large; also absolutely necessary to say where the students are from as expression of emotion varies hugely between e.g. Europe (even countries within) and Japan. \n\n4 Results\nAsking people to self-report their emotions after listening to the songs they said would elicit those emotions is not a strong design; they are severely biased to believe they are in the emotional state they said they\u2019d be in because they chose the song. \n\nOverall while the concept for this database is strong and the authors provide a good case for it in VA research, the elicitation and evaluation methods are not suitable for the task. While it is, again, an interesting concept that just needs some work, it also does not seem relevant to the GENEA gesture challenge. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper14/Reviewer_GCab"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper14/Reviewer_GCab"]}]}, {"paper_url": "https://openreview.net/forum?id=TmR8Q20jL-", "paper_id": "TmR8Q20jL-", "reviews": [{"id": "Lx0T9J4sisG", "original": null, "number": 3, "cdate": 1660815377995, "mdate": null, "ddate": null, "tcdate": 1660815377995, "tmdate": 1660815377995, "tddate": null, "forum": "TmR8Q20jL-", "replyto": "TmR8Q20jL-", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper12/-/Official_Review", "content": {"title": "AI-driven animation with dubious validity", "review": "This paper describes experiments with generation of the movements of an avatar using two different ML-models - one probabilistic (GAN) and one deterministic. The models are trained using data from different people, recorded under varying conditions, that have been tracked using OpenFace and then evaluated according to some objective metrics and through a user study. \nThe paper is clear and easy to follow, and the machine learning models are sensible for the intended purpose. Source code is provided which is a big plus. \nHowever, the validity of the experiments are dubious, for a number of reasons. First of all, the training data comes from 89 different speakers recorded under different conditions, with an average of under 3 mins per speaker, which are then used to train one model. Most likely this is too little and diverse data for any model to learn consistent behaviours? Also it is generally a bad practice to train a behaviour generation model on multiple people because at best the models will learn to produce an oversmoothed average behaviour which doesn't represent the behaviour of a real person. It is also not specified in the paper if the test/train division is done on a per-speaker basis so that no same person appears in both sets. \n\nLooking at the provided video clip of ground truth makes me question the quality of the training data. It appears choppy and noisy, which most likely is a consequence of home-webcam quality and the openface tracking used. In combination with the multi-speaker nature of the data this must make a very hard task for the networks to learn. With that in mind it is unsurprising that heavy post-smoothing is required to produce the final videos.\n\nIn the subjective evaluation, subjects were asked \"is the behaviour natural? is the behaviour smooth?\". First, these are two rather different things, Natural behavior is not always smooth, but secondly, since the ML-generated movements were explicitly smoothed whereas the GT was not (?), there is no surprise there either that the M2 is prefered over GT.\n\nI also severely question the decision to smooth the eye movements with a savitzky-golay filter - saccades un-smooth by nature so smoothing gaze will effectively make it very un-natural. I believe this is evident also from the provided examples - in the ground truth, the agent is looking at the camera for the most part, whereas in the models, gaze just follows wherever the head points, which is again not what a real person would do (in fact it is very difficult to move your head without fixating your gaze on anything).\n\nIn summary, the pros of the paper is that it is well written and compares both probabilistic and deterministic methods, and includes a subjective evaluation and source code. The downside is that it is impossible to draw any conclusions from these experiments since my feeling is that the model outputs are largely random, which ultimately seems to go back to the training data.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper12/Reviewer_tdHb"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper12/Reviewer_tdHb"]}, {"id": "mYcG053fck", "original": null, "number": 2, "cdate": 1660780938095, "mdate": null, "ddate": null, "tcdate": 1660780938095, "tmdate": 1660780938095, "tddate": null, "forum": "TmR8Q20jL-", "replyto": "TmR8Q20jL-", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper12/-/Official_Review", "content": {"title": "Great contribution", "review": "In this paper, the authors build and compare two different ML models for jointly generating head, gaze, and facial movements from an input speech signal (acoustic), including a GAN and an adversarial encoder-decoder. Data from the CMU Multimodal Opinion level Sentiment Intensity corpus is used for training and testing the models. Face/head features are extracted with OpenFace, and speech features are extracted with OpenSmile. The models are evaluated both objectively (examining the loss functions, kernel destiny estimation, and PCA reduction) and subjectively (in a user study with 31 people). The encoder-decoder architecture was judged to perform best in terms of perceived naturalness. \n\nThis paper represents a very impressive piece of work, and it will be a great fit for the workshop. The methods are described very clearly, and the results are convincing. I particularly appreciated the structure employed when presenting the relevant related work and state of the art, which was very informative.\n\nA few questions and comments:\nI did not fully understand the need for the \"smoothing of data\" presented at the end of Section 5. The authors state that \"The speed of the generated behaviours is higher than real behaviours.\" But why was that the case? What is the intuition behind this? Why would the generated speeds be any different from the statistical distribution of the dataset used to train the models? The authors should also provide more justification for why the eyebrow AUs need to be smoothed, but not the other ones.\n\nI would caution against the characterization that some of the generated behaviors were perceived as \"more natural than the ground-truth,\" which is a quite suspicious statement to make in the first place. The authors do acknowledge some important caveats about the ground truth, which is not completely faithful in reproducing human behavior due to limitations in the platform and tools used. Combined with the limitations in evaluation (e.g., the length of the video clips that were evaluated without any other context), I would suggest entirely avoiding any claims about the model performing \"better\" than ground truth.\n\nOne suggestion I have when deciding which directions to pursue in future work, is to be guided by the potential applications and scenarios for these sorts of models. Interactive autonomous virtual agents immediately come to mind. But such agents will undoubtedly require speech synthesis in addition to generated nonverbal behaviors. How well would these models work when driven by *synthesized* speech, rather than recordings of natural speech?", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "nominate_for_a_reproducibility_award": "This work is potentially deserving of the reproducibility award. An openly available dataset was used, and all tools used were open source. They have released all code on GitHub with fully detailed procedures."}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper12/Reviewer_QTWx"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper12/Reviewer_QTWx"]}, {"id": "xtT_ErTlwn_", "original": null, "number": 1, "cdate": 1660590792963, "mdate": null, "ddate": null, "tcdate": 1660590792963, "tmdate": 1660590792963, "tddate": null, "forum": "TmR8Q20jL-", "replyto": "TmR8Q20jL-", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper12/-/Official_Review", "content": {"title": "The paper presents two architectures to generate head movement and facial expressions from speech.", "review": "\nThe authors use OpenFace to extract Action Units. The extracted data can be quite noisy. The authors do not provide information on the data processing they applied. The authors also do not say which AUs they consider. In the videos, the mouth is blurred. In the 'smoothing of the data' section, why the authors only smooth the eyebrow AUs and not the others?\nHow gaze is defined? Is it defined as eye direction? How is it detected? OpenFace does not distinguish between head and eye movement.\nIn the objective study, the authors compare their results with those of Sadoughi and Busso. But Sadoughi and Busso do not model facial expression. So how meaningful is such a comparison?\n\nThe subjective evaluation is weak. Only 7 stimuli from each condition were used. It is a too small number that does not allow having reliable results. \nHow long were the stimuli? Where there any attention checks?\nHow the participants were recruited? \nThe stimuli are in English but the participants are French. Could it create bias  in the perception of the animations? \n\nThe animations of the agent are not very good: the head is tossing quite a lot, making sequences of rather similar movements. The eyebrows are flickering. There is not an eyebrow action with a higher amplitude that would mark a pitch accent.\n\nThere are no comparisons with the previous models. So it is not possible to judge if the presented model is better than the state of the art.\nThe paper has several details missing which will make replication of work very hard.", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper12/Reviewer_bC8y"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper12/Reviewer_bC8y"]}]}, {"paper_url": "https://openreview.net/forum?id=by_w1j6XAwr", "paper_id": "by_w1j6XAwr", "reviews": [{"id": "bpsiVYgRqbA", "original": null, "number": 2, "cdate": 1660587018981, "mdate": null, "ddate": null, "tcdate": 1660587018981, "tmdate": 1660587018981, "tddate": null, "forum": "by_w1j6XAwr", "replyto": "by_w1j6XAwr", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper10/-/Official_Review", "content": {"title": "description of a study on backchannel perception. The backchannels are displayed on the Furhat robot.", "review": "The paper presents a perceptive study of the Furhat robot displaying backchannels while a 'voice' is telling a story.\nThe authors aim to validate the perception of bakchannel meaning.\nThe choice of the nonverbal behaviors is grounded on previous studies.\nThe state of the art section is ok. But it is missing some references. The generation of backchannels has been well studied for ECAs and robots. I recommend the authors to look at the works of Gratch (Virtual Rapport 2.0) and of Buschmeier and Kopp, to name a few.\nI would also suggest to distinguish between works studying the perception of backchannel signals (eg [5]) and works aiming to generate where to place a backchannel (eg [7]).\nIt is not clear to me why the authors added the function 'disinterest'. What was there hypothesis for this function? Why not considering the function 'interest' to balance the choice of functions?\nIt is not clear to me how the backchannels have been placed in the stimuli. Backchannels do not appear systematically on pauses. \nHow many backchannels were produced in each stimulus. It seems there is only one backchannel. Thus each stimulus must be extremely short. It would be worth to indicate their length.\nThe authors should mitigate their conclusion: the perception of backchannels may vary with more information on the context of the interaction (cf work on rapport building).\n", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper10/Reviewer_37K6"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper10/Reviewer_37K6"]}, {"id": "RVG1VIrP7xk", "original": null, "number": 1, "cdate": 1659818113242, "mdate": null, "ddate": null, "tcdate": 1659818113242, "tmdate": 1659818113242, "tddate": null, "forum": "by_w1j6XAwr", "replyto": "by_w1j6XAwr", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper10/-/Official_Review", "content": {"title": "Interesting paper that presents a work that is a good contribution to the community but still needs some design thinking especially regarding evaluation", "review": "The authors present a study on backchannel behaviours using a FurHat robot where they verified the accuracy of a given set of backchannel behaviours for the understanding (positive) and confusion (negative) groundings. The backchannel behaviours were designed based on literature and on FurHat's own limitations. The study shows that the behaviours were mostly correctly understood, with the positive ones working slightly better than the negative ones.\n\nThe paper is well written and easy to understand.\nI enjoyed reading the introductory section and literature review.\nHowever I feel a little skeptical about the soundness of the study for these particular behaviours.\nThe authors do mention they plan to perform a new study where the participants are direct listeners, and not uninvolved ones.\nThe main question I have is whether the fact that the participants are able to think about the agent's behaviour, and assess it post-interaction, does also mean that they would understand it properly and immediately during the actual interaction.\nI understand that is one of the major challenges in such a study, so I must add that my doubts are not towards the authors or their capabilities, but regarding the overall study goal and study design.\nFrom my previous thoughts and experiments on backchannel behaviour, it seems like a more direct observation methodology may provide a higher fidelity of results - i.e., if the backchannels are correctly interpreted during interaction, then it will be fluid, otherwise, the interaction may seem broken or confusing to the user, therefore leading to unexpected pauses or breaks.\nIn that sense it may seem like a good idea to evaluate indirectly - a set of participants A interact with the robot directly, the robot performing backchannel behaviours.\nThe actually study is then having another set of participants B who watch the recordings of the interactions between robot and A, and evaluate whether or not the participants A understood and reacted promtly to the robot's backchanneling behaviours.\n\nMy recommendation is for acceptance of this paper into the workshop but hoping that the authors may comment on these issues during the presentation of their work.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper10/Reviewer_J3n3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper10/Reviewer_J3n3"]}]}, {"paper_url": "https://openreview.net/forum?id=uX86IlhiHNx", "paper_id": "uX86IlhiHNx", "reviews": [{"id": "mOrAQYN-REs", "original": null, "number": 3, "cdate": 1659946258798, "mdate": null, "ddate": null, "tcdate": 1659946258798, "tmdate": 1659946258798, "tddate": null, "forum": "uX86IlhiHNx", "replyto": "uX86IlhiHNx", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper5/-/Official_Review", "content": {"title": "ReCell: replicating recurrent cell for auto-regressive pose generation", "review": "# ReCell: replicating recurrent cell for auto-regressive pose generation\n\n## Description\n\nThe paper describes an auto-regressive gesture generator, ReCell, for the GENEA Challenge 2022. The approach is trained and tested only using the provided data, which is modified from Lee G. et al. (2019) Talking with Hands. The work uses MFCC audio features, and a one-hot encoding of text symbols.\n\nThe authors develop their solution by first developing a seq2seq model, then resolving some short comings of that model, to arrive at the ReCell model.\n\nThe seq2seq model generated a single frame of motion for a sequence of audio features. The authors note the pose as unstable, so return the previous motion frame to concatenate with the current audio frame. Thus forming the auto-regressive model.\n\nThe motion data is compressed with an auto-encoder to provide an embedding of the rotation values.\n\n## References\n\nI suggest including the following work, which uses an auto-regressive approach:\n\nAlexanderson S, et al. (2020). Style-Controllable Speech-Driven Gesture Synthesis Using Normalising Flows.\n\n## Clarity of Exposition\n\nI was not clear on how the authors incorporate the speaker identity on the model.\nLine 83 mentions \"distinguishing target speakers...\" but only describes an encoding of text.\n\nThe authors do not describe their own evaluations of the model.\nOn line 141, they discuss some problems with convergence, but don't show this in any understandable way.\n\nThe lack of comparative evaluation is the main weakness of the paper, please include the evaluations from the GENEA challenge and use as part of the discussion.\n\n## Reproducibility\n\nThe description of the method is quite high level. To enable reproduction please show a detailed description of the final model. I suggest replacing the figure of the seq2seq model that was not used.\n\n## Conclusion\n\nThe paper describes an approach for gesture generation from speech features. The authors develop an earlier model, but do not show clearly what motivated the development. Too much of this paper describes a method that was not used. The paper also needs to include more comparative evaluation.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper5/Reviewer_ozsj"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper5/Reviewer_ozsj"]}, {"id": "pVWKc90xxg", "original": null, "number": 2, "cdate": 1659924188110, "mdate": null, "ddate": null, "tcdate": 1659924188110, "tmdate": 1659924321600, "tddate": null, "forum": "uX86IlhiHNx", "replyto": "uX86IlhiHNx", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper5/-/Official_Review", "content": {"title": "Practical work but the novelty is unclear.", "review": "The authors propose an auto-regressive gesture generation model by inputting mel-frequency cepstral coefficients and character level word embeddings. \n\nStrengths:\n1. The authors start from a fundamental sequence-to-sequence model and provide their solutions to each problem they have encountered during the implementation: 1) apply auto-regressive generation to stabilize the output motions; 2) propose a training algorithm to make the model not converge to rest pose; 3) propose a windowed auto-encoder for the unrealistic poses for left shoulder.\n2. The paper used character level word embeddings, unlike most works for gesture generation using text as input which use word level embeddings. Although the authors did not discuss much about this point, this could potentially be valuable for analyzing the difference between using character level embedding and word level embedding.\n\nWeaknesses:\n1. The novelty is unclear. This is due to mainly two reasons: 1) although the authors used techniques as mentioned in Strengths-1, they are not original (except Strengths-1-3). Strengths-1-(1,2) has been used in [7]. Although Strengths-1-3 is different from auto-encoder used in [6], the authors did not provide the comparison between these methods. 2) the author\u2019s discussion for the proposed systems is not comprehensive. For instance, at line-163-164, while the authors wrote \u201cDuring our tests, this modification produced better results\u201d, it is unclear what is \u201cbetter results\u201d. Additionally, for the proposed windowed auto-encoder, no ablation was provided; thus, it is difficult to determine if or how much this component is useful.\n2. Some details are missing. 1) At line-194, the authors used 10 epochs for zero-out. It is unknown that why it was 10 epochs. 2) For the auto-encoder, why the authors chose 60 as the final dimensionality. \n3. The English writing requires efforts to understand. For instance, at line-194, the authors wrote \u201c\u2026 as well as some frames between iterations.\u201d The authors need to clarify what they are referring to with \u201cbetween iterations\u201d.\n4. Figures that compare the proposed model and other systems has not been presented to better illustrate the results. Also, the results for objective evaluation were not presented.\n5. No video was provided for examining the generated results.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper5/Reviewer_VXha"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper5/Reviewer_VXha"]}, {"id": "6016-fV62Fe", "original": null, "number": 1, "cdate": 1659917756050, "mdate": null, "ddate": null, "tcdate": 1659917756050, "tmdate": 1659917756050, "tddate": null, "forum": "uX86IlhiHNx", "replyto": "uX86IlhiHNx", "invitation": "ACM.org/ICMI/2022/Workshop/GENEA/Paper5/-/Official_Review", "content": {"title": "I like the idea of using auto-regressive input, but how much did it improve the stability of prediction? ", "review": "The paper explores two models to generate co-speech gesture. The one is seq2seq model proposed in previous research[5] and the other is new \"ReCell\" model that is based on a model proposed in [6].\n\nBoth models predict human pose or a sequence of poses as 3-dimensional axis-angle rotation vector from audio and text input. \nThe paper uses the MFCC feature as audio representation. The paper also uses text information where each character is represented as a one-hot vector.\n\nThe paper might need some work in organization. For example, In the section \"3.2 ReCell\" include some description about \"seq2seq\" model that should be written in the section \"3.1 seq2seq\".\n\nThe main contribution of the paper is proposed \"ReCell\" model that is modification of the previously proposed model with adding auto-regressive input. The change in proposed method is incremental.\n\nI like the idea of adding auto-regressive input. I believe it could produce more time consistent predictions. The paper also stated it improved stability of the prediction. However, the paper did not provide any evidences such as quantitative analysis or sub-materials.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["ACM.org/ICMI/2022/Workshop/GENEA/Paper5/Reviewer_3Ybz"], "readers": ["everyone"], "nonreaders": [], "writers": ["ACM.org/ICMI/2022/Workshop/GENEA", "ACM.org/ICMI/2022/Workshop/GENEA/Paper5/Reviewer_3Ybz"]}]}, {"paper_url": "https://openreview.net/forum?id=VFAwCMdWY7", "paper_id": "VFAwCMdWY7", "reviews": [{"id": "Nq4bD0M0IFc", "original": null, "number": 3, "cdate": 1615838960352, "ddate": null, "tcdate": 1615838960352, "tmdate": 1617290889372, "tddate": null, "forum": "VFAwCMdWY7", "replyto": "VFAwCMdWY7", "invitation": "ML_Reproducibility_Challenge/2020/Paper88/-/Official_Review", "content": {"title": "Good Report! Especially appreciated the improvements from trying different KG embedding and Question embedding models.", "review": "In this report, the authors investigate the ACL 2020 paper by Saxena et al. on knowledge base embeddings. \n\nReproducibility Summary : Major findings are included in the summary.\n\nScope of reproducibility - Scope was clearly delineated and adhered to.\n\nCode: Reused author repository, but made some changes to improve the code (enhance modularity) and make it easy to swap in pertained models for the question and knowledge graph embedding modules.\n\nCommunication with original authors: There was communication with the first author of the paper (virtual meetings). Efforts were made to try to address the parts of the paper that could not be reproduced, though the relation matching part of the code wasn't used which plays a part in the gap.\n\nHyperparameter Search: No hyper parameters sweep. Used default values. However they did tune hyper-params in their extended experiments. Things were especially difficult as little information about hyperparam values was provided in the paper and by the authors.\n\nAblation Study: Did do ablations over substituting the knowledge graph and question embedding modules.\n\nDiscussion on results: Descriptions on what was easy and difficult were provided. The scope of the reproduction was to reproduce results in the original paper which they were able to get close on one dataset (MetaQA) but remain far apart on the second (WebQSP) dataset, 11.7 percent absolute despite correspondence with the authors (although the reason is lack of relation matching)\n\nThe authors did extra work to test different knowledge graph embedding models and different transformer models for question embeddings. They found improvements by using TuckER and Sentence Bert respectively.\n\nOverall organization and clarity: Paper is clear and organized and easy to read. It feels complete to me as well, showing what can be reproduced and what cannot - although more discussions on where the divergence for QebQSP could've been provided and the experiments without the relation matching make it unclear how close reproduction was performed for WebQSP.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper88/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper88/AnonReviewer3"]}, {"id": "K162Rp7g1vo", "original": null, "number": 2, "cdate": 1614904980447, "ddate": null, "tcdate": 1614904980447, "tmdate": 1617290889487, "tddate": null, "forum": "VFAwCMdWY7", "replyto": "VFAwCMdWY7", "invitation": "ML_Reproducibility_Challenge/2020/Paper88/-/Official_Review", "content": {"title": "Review #1", "review": "The report reran the open-sourced codes from the original paper and managed to reproduce most of the results presented in the original paper. The authors also experimented with different question encoder and achieved an improvement over the original results.\n\nThe authors also cleaned up the codes, added comments, and provided command line functions. \n\nThe paper also reported hardware requirement and experiment run time.\n\nIt's glad to see that the authors try additional models beyond the original implementation. However, the authors mostly reused the default hyper-parameters, as well as the open-sourced codes from the original paper. This challenge recommends authors to either re-implement the original codes, or conduct hyper-parameter sweep. This paper failed to follow the instructions carefully.  \n\nTo improve the report:\nCould you please provide more details about the \"relation matching\" module?  It's claimed that this is the key issue that causes 22.5% drop in performance in MetaQA KG-Full 3 hop questions, but it's not discussed in the report at all. I think briefly introducing this module will make this report stand alone and help reader understand why it causes a huge drop in performance.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper88/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper88/AnonReviewer1"]}, {"id": "mKqU7f_wGfu", "original": null, "number": 1, "cdate": 1614638408232, "ddate": null, "tcdate": 1614638408232, "tmdate": 1617290889599, "tddate": null, "forum": "VFAwCMdWY7", "replyto": "VFAwCMdWY7", "invitation": "ML_Reproducibility_Challenge/2020/Paper88/-/Official_Review", "content": {"title": "Good work, additional experiments are helpful", "review": "Authors replicated the work of Saxena et al. [2020] on multi-hop question answering over knowledge graphs using KB embeddings. Glad to see the core work was reproducible. The added experiments on the use of other recent KB embeddings and use of transformer architectures for question embeddings were helpful to highlight the impact of other methods on the overall framework. The absence of sufficient documentation and unavailability of hyperparameter values made the task difficult. The relation matching experiment was not possible to be replicated due to similar issues. Overall, the work appeared to be solid and would be beneficial to the community.   ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper88/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper88/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=Zszk4rXgesL", "paper_id": "Zszk4rXgesL", "reviews": [{"id": "v-p3ce5ZBMG", "original": null, "number": 3, "cdate": 1614810099445, "ddate": null, "tcdate": 1614810099445, "tmdate": 1617290890211, "tddate": null, "forum": "Zszk4rXgesL", "replyto": "Zszk4rXgesL", "invitation": "ML_Reproducibility_Challenge/2020/Paper86/-/Official_Review", "content": {"title": "Significant effort on an important yet opaque paper", "review": "Arguably, learning how physical systems work is one of the key unsolved problems in machine learning. The present report investigates an attempt to solve such a problem with significant results but one that doesn't reveal a lot about it's inner workings. The author(s) do a great job in reproducing, replicating, and presenting the challenges. The report also communicates the core problem very well and their contact with the authors of the original paper is transparent. \n\nWhat would improve the paper:\n- testing hyperparameter sensitivity would be useful. using exactly as the ones indicated is good for replication but not enough to understand the scope of the sensitivity of the model. \n- testing extra environments is a great addition, and I think it would also benefit a lot from understanding failing cases a bit deeper. \nIt seems the authors are aware of possible improvements and some of them can be standalone work by themselves.\n\n====\n\ntrivial typos:\nline 45 an \u2014> and\nline 214 or \u2014> our", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper86/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper86/AnonReviewer1"]}, {"id": "UTiRjXtrhs", "original": null, "number": 2, "cdate": 1614348223742, "ddate": null, "tcdate": 1614348223742, "tmdate": 1617290890339, "tddate": null, "forum": "Zszk4rXgesL", "replyto": "Zszk4rXgesL", "invitation": "ML_Reproducibility_Challenge/2020/Paper86/-/Official_Review", "content": {"title": "Good reimplementation with some differences due to unknown Lagrage multiplier", "review": "The report clearly summarizes the problem statement of the original paper \"Hamiltonian Generative Networks\" (HGN) as scope of reproducibility: learn a Hamiltonian dynamics from a image sequence. As no source code was available, the authors reimplemented the program for the experiments from scratch based on the description in the original paper and questions about implementation details answered by the original authors.\n\nThe code is available on GitHub as a Python program based on Pytorch. It is properly documented and cleanly written. All dynamical systems from the original paper have been implemented and the experiments replicated. Results are comparable with the original paper in autoencoder mode, where training happens with the full input sequence. But using only the first five frames for training the HGN leads to significantly worse results for two systems (mass-spring and pendulum), but not for the other two (two-body and three-body). This difference is not discussed, only the average over all four systems. I suspect that this is caused by the choice of the Lagrage multiplier, as the authors did not obtain sufficient information about the automatic optimization of this hyperparameter.\n\nAdditionally, the authors present successful results using other integrators and extra dynamical systems. They also show that the calculation of the derivatives for the Hamiltonian equations of motion by backpropagation can be replaced by a network which learns them directly.\n\nThe discussion clearly indicates the state of reproducibility and summarizes the easy and difficult parts of that task. There were no explicit recommendations for better reproducibility, but the authors describe, what information missing in the original paper could have been helpful.\n\nThe reproducibility report is well written. I recommend to add a discussion about the differences of reproducibility between the dynamical systems and to make an explicit recommendation to the original authors for improving reproducibility.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper86/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper86/AnonReviewer3"]}, {"id": "8EhxtDq_Ju5", "original": null, "number": 1, "cdate": 1613682320395, "ddate": null, "tcdate": 1613682320395, "tmdate": 1617290890442, "tddate": null, "forum": "Zszk4rXgesL", "replyto": "Zszk4rXgesL", "invitation": "ML_Reproducibility_Challenge/2020/Paper86/-/Official_Review", "content": {"title": "Good Reproducibility Project", "review": "The authors have chosen to reproduce results related to Re-Hamiltonian Generative Networks. The code was built from scratch in Pytorch, based on the description of the original paper. Results are consistent with the original ones for similar testbenches, but show sub-optimal behavior on new data. It is also found that results are highly dependent on hyper-parameter tuning.\n\nThe reproducibility report is very well written, the problem is first formulated, the methodology is clearly presented, and the results are well described. The authors also indicate communications with those of the original paper, which is good to see.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper86/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper86/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=p1BXNUcTFsN", "paper_id": "p1BXNUcTFsN", "reviews": [{"id": "XFQMDcXxvL", "original": null, "number": 2, "cdate": 1614652511228, "ddate": null, "tcdate": 1614652511228, "tmdate": 1617290893567, "tddate": null, "forum": "p1BXNUcTFsN", "replyto": "p1BXNUcTFsN", "invitation": "ML_Reproducibility_Challenge/2020/Paper75/-/Official_Review", "content": {"title": "The reviewer did a great job reviewing and reporting details of this paper. ", "review": "Introduction is quite intuitive, giving a high-level context to the paper being reviewed. \nThe Scope of reproducibility was well highlighted,clear and concise.\nAll claims identified were supported by experiments.\nAlthough reviewer reproduced the paper using Tensorflow keras contrary to the original paper, The results obtained was still similar to the original paper, although not 100%.\n\nThe overall reproduced paper is concise, explanatory and of good quality.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper75/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper75/AnonReviewer3"]}, {"id": "Wl2Cr2DwEXD", "original": null, "number": 1, "cdate": 1614596347830, "ddate": null, "tcdate": 1614596347830, "tmdate": 1617290893670, "tddate": null, "forum": "p1BXNUcTFsN", "replyto": "p1BXNUcTFsN", "invitation": "ML_Reproducibility_Challenge/2020/Paper75/-/Official_Review", "content": {"title": "Review of \"A Reproduction of Ensemble Distribution Distillation\"", "review": "Summary:\nThis work reproduces the results  for \"Ensemble Distribution Distillation\" which uses a Dirichlet parametrization to distill deep ensembles to preserve uncertainty. The reproducibility report shows an extensive evaluation of CIFAR-10, ablation studies on ensemble size and temperature annealing and also includes visualization for uncertainty.\n \nStrengths:\n* Detailed reproduction Ensemble Distribution Distillation for CIFAR-10\n* Report included also all baseline models which offers also relative comparisons\n* Nice simplex visualization for classification experiments.\n\nWeaknesses:\n* I only have comments about clarity of the paper below. \n\nDetailed comments and questions:\n* Reproducibility summary: The scope of reproducibility is rather a description of the claims of the paper and is a bit vague. From my understanding, this should describe the scope of this work.\n* Reproducibility summary: \"Most of the authors' experiments on the CIFAR-10 dataset\" were reproduced -> I think this should rather go to 'scope of reproducibility'. Here, it would be also good to mention any pre-trained models that you used, e.g. VGG16.\n* Section 2 (Scope of reproducibility): What is not included in this work? Which experiments were not run that were included in the original paper?\n* Claims 3-5: What does the original paper claim here in comparison?\n* Table 3 & 4: Arrows up and down indicating \"higher is better\" or \"lower is better\" would be useful for all the metrics shown.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper75/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper75/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=PCpGvUrwfQB", "paper_id": "PCpGvUrwfQB", "reviews": [{"id": "qZQiCThfRle", "original": null, "number": 3, "cdate": 1614713571404, "ddate": null, "tcdate": 1614713571404, "tmdate": 1617290895440, "tddate": null, "forum": "PCpGvUrwfQB", "replyto": "PCpGvUrwfQB", "invitation": "ML_Reproducibility_Challenge/2020/Paper68/-/Official_Review", "content": {"title": "Sensible validation of BPnP", "review": "The report aims to verify the effectiveness of using Backpropogatable PnP (BPNP) on a pose estimation task with drones. Following the original paper, the setup uses heatmap regression, from which the object pose is extracted and refined through PnP, given 3D geometry. The incorporation of geometric constraints (e.g. the projection loss from the BPnP [1] paper) is claimed to improve estimation of keypoints. \n\nIn addition to BPnP, the report also examines the effect of scale aggregation from the HigherHRNet paper which proposes a scheme to bottom up scheme for aggregation in stacked hourglass type setups for heat map computation. The report goes about doing this through two types of drones of varying sizes - Mavic (larger) and Tello (smaller) using the dataset UAVA which contains ground truth annotations needed (e.g. 6D pose).\n\nBPNP scheme is compared with a reference differentiable implementation (EPnP) via PyTorch3D. \n\nThe report was well written, and the experiments thoughtfully carried out. In general, the numbers show improvements in keypoint estimation after incorporating the the projection losses. The comparison with EPnP is also quite favourable. They also show that the 'faster' version of BPnP reduces computational time without loss of accuracy. \n\nPros: Major ideas in paper explained clearly, with cogent implementation results. I would be keen on using BPnP for practical tasks. \n\nCons: Hyperparameter sweep tries not touched upon in detail. In particular, how does one chose the weighting parameters? Were any stability issues encountered? I would have liked to see a more varied list of scales as in the original paper rather than just the two drones, and (please correct me if I am not reading it correctly) the numbers are not markedly better/worse across implementations (Table 4).\n\n[1] BPnP: https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_End-to-End_Learnable_Geometric_Vision_by_Backpropagating_PnP_Optimization_CVPR_2020_paper.pdf", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper68/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper68/AnonReviewer1"]}, {"id": "i2Gx-IyRfk", "original": null, "number": 2, "cdate": 1614572428350, "ddate": null, "tcdate": 1614572428350, "tmdate": 1617290895542, "tddate": null, "forum": "PCpGvUrwfQB", "replyto": "PCpGvUrwfQB", "invitation": "ML_Reproducibility_Challenge/2020/Paper68/-/Official_Review", "content": {"title": "results beyond the original paper", "review": "Two papers are reproduced here: backpropagatable PnP & HigherHRNet, for the problem of 6DOF object pose estimation. The results are evaluated in the UAVA dataset. \nThe work contains the mentioned points, including communication with original authors, and discussion of the reults. Overall, the results are meaningful. They even present results beyond the original paper, such as section 4.2. \n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper68/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper68/AnonReviewer2"]}, {"id": "VXrtfnmDUh", "original": null, "number": 1, "cdate": 1614239618565, "ddate": null, "tcdate": 1614239618565, "tmdate": 1617290895632, "tddate": null, "forum": "PCpGvUrwfQB", "replyto": "PCpGvUrwfQB", "invitation": "ML_Reproducibility_Challenge/2020/Paper68/-/Official_Review", "content": {"title": "BPnP for end-to-end 6DOF object pose estimation is a reproducible result", "review": "**Reproducibility Summary**:\nThe authors have provided a detailed summary meeting the requirements.\n\n\n**Scope of reproducibility**:\nYes, the reproducibility report has clearly and concisely stated the scope of reproducibility.\n\n**Code**:\nYes, the authors have re-used the original author's code repository and also tried with another differential PnP (i.e EPnP) module as described in the reproducibility report.\n\n**Communication with original authors**\nYes, the authors connected with one of the BPnP paper's original authors through their Github repo.   The authors did not reach out to HigherHRNet paper's original authors. \n\n**Hyperparameter Search**:\nYes, the authors have attempted to reproduce the hyperparameter search, but the $\\beta$ coefficient from the original author's (BPnP)'s code did not work for the authors of the reproducibility report.\n\n**Ablation Study**:\nYes, the authors used an alternative implementation of the BPnP module to review the results and reproducibility.  The authors tried ignoring the higher-order derivatives of the BPnP.\n\n**Discussion on results**:\nYes, the reproducibility report contains a brief discussion on the state of reproducibility of the original papers, but does not highlight which parts are easy to reproduce or which parts were harder.  They could have mentioned the difficulty with the $\\beta$ parameter here.\n\n**Recommendations for reproducibility**:\nNo, the authors did not provide any recommendation to the original authors for improving reproducibility.\n\n**Results beyond the paper**:\nThe authors have tried additional differentiable PnP implementation (EPnP) to verify the claim.  That is a good point.  Another good point is that the authors tried to reduce the complexity and run time of the model using a faster BPnP, then evaluated the results and provided the detail pros and cons of using the technique; bonus point to the authors for that.  The authors include significantly more quantitative and qualitative results than the original paper.\n\n**Overall organization and clarity**:\nNicely written and coherent.\n\n**Pros**:\nSignificantly more quantitative and qualitative results.\n\n**Con**:\nThe authors highlight the best results in the tables using a red color.  A better choice would be green or yellow or just to leave it uncolored.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper68/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper68/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=bhiGno-Cxq", "paper_id": "bhiGno-Cxq", "reviews": [{"id": "ZhbUTWFl--", "original": null, "number": 2, "cdate": 1614662057855, "ddate": null, "tcdate": 1614662057855, "tmdate": 1617290895798, "tddate": null, "forum": "bhiGno-Cxq", "replyto": "bhiGno-Cxq", "invitation": "ML_Reproducibility_Challenge/2020/Paper67/-/Official_Review", "content": {"title": "This paper provides a detailed description and well discussion about reimplementation of BayesBNN. It also provides the results of extended task (semantic segmentation), which may help understanding the limitation of BayesBNN.", "review": "This paper summarizes the reproducibility of BayesBNN and gives a clear scope of reproducibility. It provides a re-implemented codebase to reproduce the results of the original paper. In addition, this paper also discusses the extended results for semantic segmentation. The paper is well-written and easy to understand. Couples questions:\n\n1. For the case of unmatched CIFAR-10 results, I am wondering why the Batch-Norm layers may cause a large-cap of test accuracy.\n2. For the semantic segmentation task, is it possible the limited size of training data may affect the model performance?\n3. Line 183, what do you mean by \u201ccleaner deep learning\u201d? \n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper67/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper67/AnonReviewer3"]}, {"id": "_OI9Js_T45r", "original": null, "number": 1, "cdate": 1614618990406, "ddate": null, "tcdate": 1614618990406, "tmdate": 1617290895910, "tddate": null, "forum": "bhiGno-Cxq", "replyto": "bhiGno-Cxq", "invitation": "ML_Reproducibility_Challenge/2020/Paper67/-/Official_Review", "content": {"title": "Successful reproduction, but report quality not good enough to be part of rescience journal", "review": "# Reproducibility Summary : \nComplete\n\n# Scope of reproducibility:\nClearly defined\n\n# Code: \nRe-implemented.\n\n# Communication with original authors\nReports one communication exchange with original authors.\n\n# Hyperparameter Search\nThe report mentions the need to do some random search on unmentioned hyperparameters (such as momentum coefficient). There is no clear mention of hyperparameter search, what was the search space, budget and algorithm used for the main hyperparameters however. What I understand is that they re-used the original ones.\n\n# Ablation Study:\nThere is no ablation study\n\n# Discussion on results\nThe reproduction of the results is well detailed and the table help understand what was reproduced and what was not.\n\n# Recommendations for reproducibility\nThere is no clear recommendations.\n\n# Results beyond the paper\nThey tried applying the model on a task that was not in the original paper, the semantic segmentation. The dataset was however extremely small which makes me uncertain about how insightful the results are.\n\n# Overall organization and clarity\nThe overall organisation of the paper and the presentation of the results is clear. There is many mistakes (see minor comments below) that should be corrected. Section \u2018Methodology\u2019 is hard to understand and brings no value with respect to original paper. Pointing the reader to original paper to better understand the maths beyond BayesBiNN would make a better job in my opinion.\n\n# Comments\n\nAlgorithm 1 is difficult to understand without more explanations.\n\nThe \u2018Methodology\u2019 section was difficult to follow. The explanations of the equations are too succinct, lack motivations and explanations. Looking at the original paper, I find it easier to understand the equations based on their explanations, so I am wondering what is the value of the presentation of the equations in this report.\n\nLine 145:  However, the results were against our intuition and the result of segmentation were a zoomed segmented image of the input with lots of noise.\n\nIt\u2019s not clear what is meant here. What was the intuition? What is the result and what should it have been? Should it not be zoomed?\n\n# Minor comments\nLine 36. STE and BOP acronyms should be introduced.\n\nLine 100. by a randomly -> by randomly\n\nLine 118. reporduce -> reproduce\n\nLine 120: but the validation split is made 0. I don\u2019t understand what it means to make a split 0.\n\nLine 136 Semantic Semantic -> Semantic Segmentation\n\nLine 137 it\u2019s full-precision -> its full precision\n\nLine 138 it\u2019s performance -> its performance\n\nLine 140 we have use -> we have used\n\nLine 167 The gave -> They gave\n\nLine 178 in it\u2019s total -> in its total\n\nLine 184 that it\u2019s -> that its", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper67/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper67/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=Vqtf4kZg2j", "paper_id": "Vqtf4kZg2j", "reviews": [{"id": "gQST3uLfAl", "original": null, "number": 2, "cdate": 1615382347947, "ddate": null, "tcdate": 1615382347947, "tmdate": 1617290896083, "tddate": null, "forum": "Vqtf4kZg2j", "replyto": "Vqtf4kZg2j", "invitation": "ML_Reproducibility_Challenge/2020/Paper66/-/Official_Review", "content": {"title": "Good Job in Reproducing the Paper.", "review": "Good job in reproducing the results. The original paper carries out methods for generating causal post-hoc explanations of black-box classifiers based on a low-dimensional representation of input data. This paper tries to reproduce those results in detail and provide a more efficient implementation. While reproducing the results of the original paper, the authors of this paper take a further step ahead:\n1. They provide a higher resolution transition for the first causal factor for MNIST 1/4/9 classifier.\n2. They also dive into hyperparameter search for the Principled procedure for selecting (K, L, \u03bb) as explained by the original paper.\n3. They have also tried out the proposed method on the SST text dataset and tabulated the duration for both text as well as for image datasets.\n\nAlso, the resulted figure from this implementation is similar to the figures reported in the original paper. \n\nThey have also mentioned that they have not found this method to be scalable in contrary to the original paper but they have not mentioned any ideas on how to scale up but they are relying on future papers to do so.\n\nOn a final note, this is a solid work and will be very helpful to gain insights if the original paper is reproducible or not and to what extent can the algorithms mentioned in the paper can be used to solve the explainability problem of black-box classifiers.\n\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper66/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper66/AnonReviewer3"]}, {"id": "6u1gVwmmsw", "original": null, "number": 1, "cdate": 1614632618966, "ddate": null, "tcdate": 1614632618966, "tmdate": 1617290896192, "tddate": null, "forum": "Vqtf4kZg2j", "replyto": "Vqtf4kZg2j", "invitation": "ML_Reproducibility_Challenge/2020/Paper66/-/Official_Review", "content": {"title": "Solid work but need more claims about the solution to reduce algorithm complexity", "review": "Thank you for your great paper!\n\nThe paper successfully proves that the original paper is reproducible and it could provide the post-hoc casual explanations for black-box classifiers through the casual reference. Furthermore, the paper establishes its own evaluation system to evaluate the original paper from different aspects. Moreover, the paper extends the application domain from images to texts, which is great for generalization. However, I think it would be good if you can add more details about what is different between your implementations and the original paper's, like the solution to reduce algorithm complexity. Last but not least, adding a few figures about the models' architecture would be great for readers!", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper66/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper66/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=P30M7d9DyXw", "paper_id": "P30M7d9DyXw", "reviews": [{"id": "9tMunyG4eq5", "original": null, "number": 2, "cdate": 1615203645922, "ddate": null, "tcdate": 1615203645922, "tmdate": 1617290896356, "tddate": null, "forum": "P30M7d9DyXw", "replyto": "P30M7d9DyXw", "invitation": "ML_Reproducibility_Challenge/2020/Paper65/-/Official_Review", "content": {"title": "A good work", "review": "The authors did well by reproducing the original work even though there was no readily available data.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper65/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper65/AnonReviewer3"]}, {"id": "5a6Y7TJ5w6M", "original": null, "number": 1, "cdate": 1614638722243, "ddate": null, "tcdate": 1614638722243, "tmdate": 1617290896452, "tddate": null, "forum": "P30M7d9DyXw", "replyto": "P30M7d9DyXw", "invitation": "ML_Reproducibility_Challenge/2020/Paper65/-/Official_Review", "content": {"title": "Very good points to question but needs more evidence", "review": "Thank you for your great paper!\n\nSummary: The authors tried to reproduce the original paper which claimed that complex-valued DNNs effectively increase the difficulty of inferring inputs for the adversary attacks compared to the baseline and the proposed privacy-protecting complex-valued DNN effectively preserves the accuracy when compared to the baseline, but did not get the satisfying results. Moreover, the authors proposed certain good points to question about the original paper.\n\n- Pros: \n1. The authors are really rigorous to provide certain good points to doubt the original paper (Section 5 Discussion in this paper). It proves that the authors read the papers carefully and devotes themselves to designing the experiments.\n2. The authors describe the details of the experiment very carefully, and the idea is clear to me.\n\n- Cons: \n1. The authors haven't carried out the whole experiments (such as the authors did not successfully implement VGG-16 / Alexnet and the inference attacks)\n2. The result section is confusing to me as I can't figure out which one is the new results without ReLU in the generator\n\nOverall, I really appreciate the discussion section, so I would clearly recommend the paper to be accepted!\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper65/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper65/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=hq3TxQK5cox", "paper_id": "hq3TxQK5cox", "reviews": [{"id": "OOrtUjVQqs", "original": null, "number": 2, "cdate": 1615414021731, "ddate": null, "tcdate": 1615414021731, "tmdate": 1617290896602, "tddate": null, "forum": "hq3TxQK5cox", "replyto": "hq3TxQK5cox", "invitation": "ML_Reproducibility_Challenge/2020/Paper64/-/Official_Review", "content": {"title": "Good Report exposing limitations but needs structuring", "review": "### SUMMARY\nThe paper claims that: \n- The common data exploration workflow (of learning low dimensional representations, identifying features which help examine differences across clusters to determine what they represent as they correlate to an unobserved concept of interest) is treated as an interpretable machine learning problem where:\n    - Global Counterfactual Explanations (GCE's) ensure pair-wise explanations for all points within a cluster \n    - Transitive Global Translations (TGT's) generalize the above compressed sensing solution to find the complete set of explanations are both symmetrical and transitive among all groups simultaneously and empirically demonstrate the same with the following datasets: synthetic, UCI (Iris, Boston Housing and Heart Diseases data) as well as single-cell RNA data with adequate correctness and coverage\n- TGT's identify explanations that accurately explain models while being relatively sparse and reportedly match underlying patterns in the data.\u00a0 \n\nThe submitted report addresses the above claims as follows:\n- _Re-execution_ of existing code along with re-written code variants (upgraded to TF 2.x, Pytorch and without external dependencies such as on scvis) on all the above mentioned datasets establishes correctness, coverage, and sparsity, thus verifying both claims. \n- Additionally, experimentation with other linear and non-linear dimensionality reduction algorithms (truncated SVD, sparse PCA, Gaussian variational autoencoder, kernel PCA, manifold dimensionality reduction algorithms like isomap and local linear embedding) on the following additional datasets -(seeds, Wine and Glass. dataset excluding single-cell RNA) - explored along with dynamic scaling of data in latent spaces for the purpose of achieving a certain amount of variance in order to test applicability to differing data structures, uncovers the following limitations:\n    - Constrained variable freedom interferes in manifold mapping where matrix based explanations/explanations beyond translations (such as with rotation/scaling) may be necessary. \n    - Structure of the data produces different type of clusters and hence, structure, shape, method of cluster annotation and variance in the latent space affects algorithmic performance. \n     - Highly non-linear dimensionality reduction algorithms perform worse in terms of explainability (probably due to sparsity).\n\n### MERITS\nThe additional experimentation is rather impressive and the report reflects an intuitive understanding of concepts such as coverage, correctness, and counterfactual explanations.\n\n### MINOR CORRECTIONS\n- In Methodology, \"Exprimentation was done on a Macbook\"; **Correction:** \"_Experimentation_ was done on a Macbook\"\n- In Section 1 - Introduction, for the argument regarding algorithmic decisions that involve grouping of data, the reviewer recommends improving the context of the statement by clarifying settings (for instance,\u00a0 the original paper discusses naturally arising grouping under the context of encoders or decoders)\u00a0or by supporting this claim through citations.\n- In Section 2 - Scope of Reproducibility, \"do do not use the model\"; **Correction:** \"_do_ not use the model\"\n- In Section 3.1.1 - Linear Methods, \"SPCA reduce the dimentionality in a linear fashion\"; **Correction:** \"SPCA reduce the _dimensionality_ in a linear fashion\" \n- In Section 3.1.2 - Non-Linear Methods , \"While Isomap could be seen as a extension of KPCA, LLE can be understood as a combination of PCAs ran on local neighborhoods.\"; **Correction:** \"While Isomap could be seen as _an_ extension of KPCA, LLE can be understood as a combination of PCAs _run_ on local neighborhoods\"\n- In Section 3.3 - Datasets, \"sigmoidial Kernel-PCA procedure\"; **Correction:** \"_sigmoidal_ Kernel-PCA procedure\"\n- In Section 3.5 - Experimental setup and computational requirements, \"Exprimentation was done on a Macbook\"; **Correction:** \"_Experimentation_ was done on a Macbook\"\n- In Section 5 - Discussion, \"latent space will yield different different mappings\"; **Correction:** \"latent space will yield _different_ mappings or inconsistently different mappings\"\n- In Section 5.1 - What was easy, \"set up was the obtaining the right version\"; **Correction:** \"set up was _obtaining_ the right version\"\n- Optionally, formatting of references can be enhanced: Explaining groups of points in low-dimensional representations -> Explaining Groups of Points in Low-Dimensional Representations.\n- In general, the reviewer is of the opinion that the report could be structured in a more organized fashion:\n    - In Section 5.1 - What was easy, it's recommended to move the discussions pertaining to \"the hardest part\" to Section 5.2.\n    - Reduce the redundancy within the paper. For example, footnote 3 and footnote 1 essentially the same. \n    - In Figure 1, it might be helpful to reuse the author's notations of ````````````` $R_{initial}$, $R_{target}$ representations and  $X_{initial}$, $X_{target}$ preimages etc. \n    - For consistency, move all links to footnote. (For example: link in Section 3.5)\n    - Reduce the back and forth between the report and paper. (For example: restate equation 9 in Section 3.4)\n\n### RECOMMENDATIONS\n- Please anonymize your submission. Also, note that your summary **must fit** in the first page. \n- The original authors of the paper consider a **similarity metric** across explanations which has not been examined in this reproducibility report. Kindly address the same.\n- Optionally, you could consider discussing the best set of hyperparameters from the experiments that resulted in reported results. \n- Optionally, you could also demonstrate causal structures of the data and the inability of the [Plumb et al model](https://openreview.net/forum?id=MFj70_2-eY1) to capture the same (specifically with differently structured data, higher dimensional data or varying cluster variance, shape etc) to further strengthen your argument regarding shortcomings - similar to Table 1 of original paper. \n- As per the [Machine Learning Reproducibility Checklist](https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf), you could include statistics of the datasets in a tabular form and a tabulation of important results in the README file on [your github repository](https://github.com/giguru/fact-ai).\n- As far as the creative insight on compressions is concerned, this space has been fairly explored before, [even in the context of compressed sensing](https://ermongroup.github.io/blog/uae/). I hence recommend moving the discussion to applications or perhaps reviewing this discussion in context of a specific dataset or application like, in the case of [complementary biological representations](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02021-3). \n- For explanations beyond translations (x\u2032=Mx+\u03b4), the reviewer *appreciates the effort taken in this new direction* but critically, the argument of \"incorporating rotation as an explanation that comes at the cost of explainability\" sounds delicate. \n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper64/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper64/AnonReviewer3"]}, {"id": "hr86Vqw9RsI", "original": null, "number": 1, "cdate": 1614626331085, "ddate": null, "tcdate": 1614626331085, "tmdate": 1617290896696, "tddate": null, "forum": "hq3TxQK5cox", "replyto": "hq3TxQK5cox", "invitation": "ML_Reproducibility_Challenge/2020/Paper64/-/Official_Review", "content": {"title": "A good report, results could be more clear and missing a few important information (how code was re-implemented, Hyperparameter selection).", "review": "\n# Reproducibility Summary \nMain summary not clear. Is it the objective of the original paper, or the objective of the reproduction? The rest of the summary is clear.\n\n# Scope of reproducibility\nThey reproduce results from original paper, and test with additional dimensionality reduction algorithms as well as on additional datasets.\n\n# Code\nWas extended with additional DR algorithms and re-implemented in PyTorch. It is not clearly mentioned however whether the algorithms were re-implemented solely based on information found in the paper or if the code has been used as a reference.\n\n# Communication with original authors\nNo major communication, only to assert the dependencies needed to run the original cod.\n\n# Hyperparameter Search\nThe hyperparameters are described but there is no mention of hyperparameter optimization.\n\n# Ablation Study\nThe results are tested on additional DR algorithms. I would consider this as an ablation study since it verifies the effect of one of the components of the whole procedure.\n\n# Discussion on results\nThe results are well described and compared with original work. The results section is more difficult to read than the rest of the report. The figures should be better described, it is very difficile to make sense of Figure 5 in particular\n\n\n# Recommendations for reproducibility\nNone\n\n# Results beyond the paper :\nThe method is tested with different DR and on 3 additional datasets. The comparison on the additional datasets is interesting because these have no low-dimensionality manifolds and thus should be trickier for the DR methods.\n\n# Overall organization and clarity\nThe paper is very clear and especially well written with the exception of the results section. The figures lack explanation. See minor comments for grammatical errors.\n\n\n\n# Comments\n\nSection 3: Methodology\nIt should be made clear whether the re-implementation has been attempted with only looking at information available in the paper or if they used the available code-base as a reference. This makes an important difference for the reproduction as looking at the code-base could lead to re-implementation of important tricks that were not mentioned in the paper. \n\nIt would be good to cite the work behind the linear and non-linear models listed in 3.1.1 and 3.1.2.\n\nI don\u2019t understand the role of the digression. I feel it states in different words what has already been said implicitly in the prior sections. \n\nFootnotes 14 and 15: I was clueless about what I should do to make the comparisons. Ideally these results should be integrated in the paper and presented clearly.\n\n# Minor comments\nFigure 1\u2019s caption: I don\u2019t understand the sentence: 'the difference between point 1 and 3 is explained each data point can be seen as an individual cluster. '\n\nSection 3.5: we have ran -> we have run\n\nSection 3.5: All experiments are ran -> All experiments were run\n\nFootnote 13: be only using -> by only using\n\nSection 5.1: set up was the obtaining > set up was obtaining\n\nSection 5.2: Since we are aim -> Since we were aiming", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper64/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper64/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=cqAHExg2f", "paper_id": "cqAHExg2f", "reviews": [{"id": "qhLATnRLVP2", "original": null, "number": 3, "cdate": 1614704748254, "ddate": null, "tcdate": 1614704748254, "tmdate": 1617290897994, "tddate": null, "forum": "cqAHExg2f", "replyto": "cqAHExg2f", "invitation": "ML_Reproducibility_Challenge/2020/Paper59/-/Official_Review", "content": {"title": "Rather good in content but can be improved in clarity", "review": "The report is on reproducing the paper \"Explaining Low dimensional Representation\" by Plumb et al. Overall, the submission does rather thorough reproduction and even go beyond the original paper to add some extension (though missing parts such as hyperparameter search). However, writing of the report can be largely improved as currently it looks more like a student's report rather than a work that can be published in the special issue of a journal.\n\nReproducibility Summary: is provided and adequately reports the major finding of the submission\n\nScope of reproducibility: is clearly stated and followed later\n\nCode: the authors of this submission both used the code provided by the original authors and then re-implemented it from scratch. The github link to the code gives an error (potentially because the repository hasn't been made public yet). In anyway there was no opportunity to check the code of the submission or its docs.\n\nCommunication with original authors: the reports mentions communication with original authors regarding a choice of epsilon hyperparameter, but the authors emphasised the difficulty of selecting clusters, but no mentioning whether this question was attempted to clarify with the original authors.\n\nHyperparameter Search: in the experiments with the original code the authors only used the same hyperparameters as in the original paper. No hyperparameter sweep has been performed.\n\nAblation Study: No ablation study has been done\n\nDiscussion on results: the discussion at the end is rather well done with discussions which claims from the original paper were confirmed and which were questioned during reproduction. However, presentation of the results themselves is the poorest part of the report from the presentation point of view. The results sometimes not thoroughly discussed but the text just refer to corresponding tables and figures, which in itself is not satisfactory, moreover, those tables and figures are also missing some details and can be unclear.\n\nRecommendations for reproducibility: the only recommendation left is in terms of this selection of clusters, which seems to cause the main issue with reproducibility\n\nResults beyond the paper: the report provides results beyond the paper when the authors investigate a more expressive transformation than considered in the original paper. Though the results show that this extension does not actually bring significant benefits it is interesting to see these results and negative results are also very useful for the community\n\nOverall organisation and clarity: the part that can be mostly improved. As mentioned before, the results section is the poorest here lacking the good presentation.\n\nSome particular points (mostly on organisation and clarity):\n1.\tLines 5-6, \u201cThey show their method \u2026\u201d \u2013 the sentence is not grammatically consistent\n2.\tLine 43, x_s is not defined\n3.\tNotation x for a low-dimensional representation in Introduction is not very suitable as it is later used to denote a point in the input space in Methodology\n4.\tLines 197-198, \u201cSince the clusters in the Tensorflow\u2026\u201d \u2013 the sentence is not grammatically consistent\n5.\tSection 5.3.2 and 5.3.3, \u201cdeltas\u201d and \u201clogit gammas\u201d appear without introduction (translation and scaling were not called like this before). They are being explained only later in Section 5.3.4\n6.\tSection 5.3.5, G is not defined and j is reused here as it denoted the group in lower dimensional space before\n7.\tLine 252, \u201cBased on the reproduction\u2026\u201d \u2013 unfinished sentence \n8.\tSection 6.1, first paragraph \u2013 translation of jupyter notebook into python scripts doesn\u2019t seem to be a problem\n9.\tLine 268, \u201cThis also means \u2026\u201d \u2013 something wrong with this sentence\n10.\tSection 6.2 is redundant as this idea has been discussed at the beginning\n11.\tFigures 5-10 require more explanation, axes are not labelled, missing legend and overall explanation what is going on. \u201c0th dimension\u201d does not look good in the text\n\nMinor:\n1.\tLine 171, there seems to be a typo and the second x_2 should be x_3\n2.\tFigures 2 and 3 \u2013 make all subfigures of the same size\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper59/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper59/AnonReviewer2"]}, {"id": "ynnSNjagrfq", "original": null, "number": 2, "cdate": 1614525297311, "ddate": null, "tcdate": 1614525297311, "tmdate": 1617290898104, "tddate": null, "forum": "cqAHExg2f", "replyto": "cqAHExg2f", "invitation": "ML_Reproducibility_Challenge/2020/Paper59/-/Official_Review", "content": {"title": "We have some concerns", "review": "This paper checks the original paper's four claims (listed in lines 97--103) on the algorithm TGT (Transitive Global Translations). As pointed out (lines 105 - 107) by the authors, the original paper's claims are investigated via the original paper's original code. The authors of this report use new code instead to verify some extended experiments. We doubt whether this is a well-focused reproducibility investigation.\n\nWe list our concerns below.\n\n1. Language. There are quite a few grammar problems, and the paper appears carelessly composed.\n\n2. In the 'methodology' paragraph, by putting 'We also replicate their findings by re-implementing the authors' method in PyTorch...' does it mean that all or only a part of the computing in the original paper is re-implemented?\n\n3. Given that the communication with the original authors does not yield meaningful result and is only because of misunderstanding, why is that paragraph still listed?\n\n4. Could the problem with the deprecated software package be solved by Docker or Anaconda? Note that any software package shall be deprecated at some time point in the future.\n\n5. For the clustering's uncertainty, the authors reported in the 'What was difficult' paragraph, is it because of the random seed or different implementation techniques? Is the final result sensitive to different initialisation of random clustering? It seems to us that the paper only reports the observation but has not paid any effort to uncover the cause.\n\n6. What does 'GCE' stand for? (lines 80 & 83)", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper59/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper59/AnonReviewer1"]}, {"id": "Na2xLkKJn3Y", "original": null, "number": 1, "cdate": 1613874898046, "ddate": null, "tcdate": 1613874898046, "tmdate": 1617290898220, "tddate": null, "forum": "cqAHExg2f", "replyto": "cqAHExg2f", "invitation": "ML_Reproducibility_Challenge/2020/Paper59/-/Official_Review", "content": {"title": "Explaining Low Dimensional Representation, a reproduction", "review": "This report reproduces the paper \"Explaining Low dimensional Representation\" [1]. A detailed reproducibility summary is provided summarizing the results obtained using the implementation based on the codebase of the original authors along with a new PyTorch implementation from the efforts of this reproduction report authors. Communication with original authors (how to choose the \u03b5 hyper-parameter), hyperparameter search, discussion on results, recommendations for reproducibility and results beyond the paper (replicated the algorithm in PyTorch, new datasets and the use of more complex transformations to explain differences between clusters) are also properly constructed. Overall, this reproduction is well-constructed. Possible stretches could be the discussion of the evaluation metrics being used with respect to their suitabilities, additional metrics for a more comprehensive report and providing recommendations to the original authors for improving reproducibility.\n   \n\n\n[1] Gregory Plumb, Jonathan Terhorst, Sriram Sankararaman, and Ameet Talwalkar. Explaining groups of points in low-dimensional representations, 2020.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper59/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper59/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=ysFCiXtCOj", "paper_id": "ysFCiXtCOj", "reviews": [{"id": "4R-UHmcEyj", "original": null, "number": 3, "cdate": 1615416229385, "ddate": null, "tcdate": 1615416229385, "tmdate": 1617290899658, "tddate": null, "forum": "ysFCiXtCOj", "replyto": "ysFCiXtCOj", "invitation": "ML_Reproducibility_Challenge/2020/Paper54/-/Official_Review", "content": {"title": "Extensive coverage of the experiments corroborating the original work", "review": "The presented report is well organized, systematic, clear and concise with most of the major experimental results reproduced and reported. To begin with, authors have clearly mentioned the key claims to be investigated in the scope of reproducibility with the focus on the properties of  the activation functions and their behaviour in the experiments reported in the original paper. It has also been proposed to conduct additional experiments beyond what is already covered in the source paper. These includes DCGAN for handwritten digit generation and LSTM model for sentiment analysis, each modified to include the proposed snake activation function. It is however to be noted that when result plots for different cases are not reported in the same graph, it helps to report them on the same scale, wherever possible (e.g. Figure 12 and 13), for easier comparison.\n\nDue to the unavailability of the source code from the author's of original paper, the current authors, in consultation with the original authors, have done a good job of replicating the results, which is matching qualitatively to a great extent with the ones reported in the original paper. While the architectural details were available in the original text, the hyper-parameters and any other information missing were assumed and arrived at with trial and error.\n\nMost of the results from the main content of the original paper has been reported and are found to be qualitatively matching. Figure 1 has demonstrated the inability of learning periodicity outside of the training region and thus substantiates the claim 1 of the scope of reproducibility. These reporting also matches with the corresponding figure in the original work for the widely used activation functions - ReLU and Tanh.\n\nTo substantiate claim 2 which states that the proposed snake activation function captures periodicity outside of the training samples and also maintains favourable optimization properties such as loss reduction comparable to or better than ReLU activation, corresponding results from original work has also been reproduced. Although the frequency of the sin wave used in the experiment appears to be different, it is helpful in demonstrating that even though periodicity is observed, significant deviations can still occur at far away places from the training samples. Nevertheless, differences in implementations can be a source of difference.\n\nIn addition to the demonstrations on synthetic datasets discussed earlier, the authors have further reproduced results on real-world/application oriented datasets that includes performance reporting of ResNet18 on CIFAR-10 dataset, atmospheric temperature prediction in Minamitorishima island (Japan), patient body temperature prediction and Wilshere 5000 index prediction. All these reported results corroborates the points in the original paper across varying and diverse datasets.\n\nFinally, the authors have reported results for a few experiments from the Appendix section such as the one showing the effect of various value of $a$. It is also admirable that they have reported results and discussed implications of use of snake activation function in other scenarios such as training DCGANs and LSTMs. While the snake activation was shown to have reasonable and comparable training speed and test performances as evidenced by Figure 2 and 4, the extra experiments on non-toy datasets helped in highlighting the relatively slow training speed.\n\nThus, overall, the authors have tried to cover extensive set of experiments demonstrating pros and cons of the proposed snake activation function and have reproduced the results qualitatively to a great extent. The difficulty in reproducing some of the work such as comparison with RNN on regressing a Simple Periodic function where the details were missing and the data points had to be inferred from the graphs have been mentioned. Similarly, it is also suggested to clarify the implementation details for showing variance correction using ResNet101 on CIFAR-10 for better reproducibility.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper54/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper54/AnonReviewer3"]}, {"id": "m9yHiIMA6ow", "original": null, "number": 2, "cdate": 1614289984834, "ddate": null, "tcdate": 1614289984834, "tmdate": 1617291084415, "tddate": null, "forum": "ysFCiXtCOj", "replyto": "ysFCiXtCOj", "invitation": "ML_Reproducibility_Challenge/2020/Paper54/-/Official_Review", "content": {"title": "Review", "review": "__Summary__\n\nThe original paper (OP) proposes a new activation function, snake. Snake is claimed to be usable with datasets both with and without cyclicity, on the contrary to previous activations. Experiments include low-dimension regression to illustrate the limitations of conventional activations, and applications of snake and baselines to timeseries to illustrate their ability (or not) to deal with cyclic data. \nSnake is also evaluated on common benchmarks (CIFAR10) to show that it performs well compared to baselines even when the dataset is not cyclic.\nThis reproducibility report (RR) reproduces all the experiments of the OP and confirms the OP's findings.\nThe RR also extends the study to two new settings (image generation and sentiment analysis), both non-cyclic, in which the performance of snake is studied.\n\n__Positive points__\n- The OP's code was not publicly available and the authors recoded all of the experiments themselves, which needs to be commended.\n- Similarly, the authors optimized hyperparameters to make the implementations work despite the fact that they were missing in the original paper.\n- The authors performed additional experiments with elaborate models. Both the feedforward and recurrent architectures that were used were not tested in the original paper, which demonstrates the applicability of the original idea to new settings and  adds value to the original idea from the OP.\n- I appreciated the exhaustive replication of the several experiments that this paper contained.\n- The RR authors contacted of the OP authors to get additional information on the points of the paper that lacked clarity, and used this information to replicate the OP results.\n- The format of the reproducibility report was respected, and the report is overall clear. The authors clearly state that the results are reproducible. The report is overall well written and concise.\n\n__Negative points__\n- The general experiments are reproduced, but I find that a finer analysis is absent from the RR. The results are reproduced through a figure, but this figure is often not referred to. A small conclusion about the reproducibility of the specific experiment is systematically absent. No quantified metric on the closeness to the original performance is given, or commented, even though the paper gave quantified results for the financial experiment (OP's Tab.2). For instance, when the performance is illustrated through a graph, I would have expected a comment on the closeness between the accuracy of the OP's model and the RR's model.\n- I find that the report lacked precision. For instance: (1) I am not sure which optimizer was used for most of the experiments, or what initialization; Sec 4.1 is an example of this. (2) p.6, l.146: \"orders of magnitude\": how many? Can you give an estimate of the time in each case? (3) p.7, l.159: can you be more precise than \"reasonably realistic samples\"? Are there metrics that exist that could quantify by a number the quality of the images produced? (4) p.8, l.163: took much longer: can you be more precise? etc.\n- I find that overall, the report does not take a step back w.r.t the experiments it makes. As a consequence, the RR did not reflect on some of the differences, notably Fig.3 (the snake network starts to diverge, on the contrary to OP's Fig. 4) and Fig.5 (the snake network does not fit the training points): how can these differences be explained? \n- The RR mentions having to find / guess some hyperparameters (Sec 3.3), but does not comment on the value that was ultimately found and used in the report, or the range of hyperparameters that was tested. It is true that the code is available on Github, but an explicit reference to it would help lift the doubt on certain implementation details. For now, the reader does not gain the knowledge missing from the OP by reading the RR.\n- It was often difficult to separate the RR's conclusions from the OP's (for instance, it is confusing on a first read if the last paragraph of p.5 contains conclusions from the RR's authors or the OP's authors, or even if the experiment itself was in the OP (since the experiment does not appear in the main paper, but in the appendix)).\n\n===\n\nOverall, I believe the report could be improved by introducing each experiment better, providing the implementation details, and giving a conclusion on the reproducibility of each experiment. Adding numerical results indicative of reproducibility (was the reproduced end accuracy of the model within X% of the OP's results?) for each experiment would help ground the report, and help it discuss in more details the state of reproducibility of the OP.\n\n===\n\n__Additional comments__\n- Some figures are not referenced (ex: Fig.2, Fig.3, Fig.4,). This is problematic because this reinforces the idea that the experiment was run in the RR without an analysis of its results and its significance. How can you tell that the results were indeed replicated?\n- The RR mentions that reimplementing the initialization was not obvious from the paper and that one of the OP's authors helped. An additional comment about what was the problem / what was the solution found (or at least a pointer to the RR's code) would be useful.\n- Regarding the discussion of Fig.8: it seems to me that the difference between the RNN and the MLP could simply be due to a regularization effect: the RNN also seems to learn the right lower frequency. \n- The authors mention in the reproducibility summary that they reimplemented everything from scratch, though looking at the code, it appears that some implementations (of the LaProp optimizer or of the base code for the GAN) were based on existing codebases. While obviously the authors are not expected to recode *everything* from scratch, it would be more transparent to indicate that some parts of the code were built on top of existing code in the RR. \n- A mention of the software used (Pytorch for the neural networks) would have been useful, as all libraries do not have necessarily the same default hyperparameters. Similarly, the authors mention in Sec. 3.5 that many experiments could be run locally: more details on the local hardware (which CPU for instance, a minima an indication on the quality of the \"local\" computer that was used) would be welcome.\n- The RR mentions that making the parameter  a learnable was not properly explained in the OP. Here too, a pointer to the solution found would be appropriate.\n- The introduction is extremely close to the one in the OP. I would suggest reformulating the introduction more, or possibly shorten it, to avoid repeating the OP.\n- The figures were overall well made and close in design to the original paper, which helps when comparing results. Possible improvements could be to respect the color attribution for different models (Fig.2) and making sure that the scale of two plots coincide to make comparisons easier (Fig.10 top left and bottom left, Fig.13 for instance).", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper54/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper54/AnonReviewer1"]}, {"id": "tD4Iw6XV_Jb", "original": null, "number": 1, "cdate": 1614006946732, "ddate": null, "tcdate": 1614006946732, "tmdate": 1617290899863, "tddate": null, "forum": "ysFCiXtCOj", "replyto": "ysFCiXtCOj", "invitation": "ML_Reproducibility_Challenge/2020/Paper54/-/Official_Review", "content": {"title": "valuable confirmation", "review": "The paper is well written and clearly structured.\nIt is a valuable confirmation of the original paper.\nI only have a few formatting criticisms:\n\nsin, cos, and snake should not be italic, but rather \\sin or {\\rm sin\nI think, \u201e4e -4\u201c should be relaced by 0.0004 or 4\\cdot 10^{-4}\nIn Section 4.4 \u201eEffect of \\alpha$, use \\boldmath{\\alpha}\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper54/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper54/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=-rn9m0Gt6AQ", "paper_id": "-rn9m0Gt6AQ", "reviews": [{"id": "eljNeO7NAxn", "original": null, "number": 3, "cdate": 1615375615345, "ddate": null, "tcdate": 1615375615345, "tmdate": 1617290900022, "tddate": null, "forum": "-rn9m0Gt6AQ", "replyto": "-rn9m0Gt6AQ", "invitation": "ML_Reproducibility_Challenge/2020/Paper53/-/Official_Review", "content": {"title": "Well written and concise submission", "review": "The paper is well written and easy to follow. Authors seem to understand the original paper very well and have done a good job in organizing the content. Given one of the classification dataset was not publicly available, reproducing for one task was not feasible. Apart from which authors have experimentally verified the claims on other tasks/datasets.\n\nAuthors have been in constant touch with original paper authors and it is appreciable that original authors have helped in reproducing the experiments by providing data/code as requested by authors along with providing more details/clarifying queries.\n\nIt is good that the authors had re-implemented BERT model (as the source code was not available initially) and discussed the challenges in re-implementing with information provided in paper which is important for Reproducibility challenge. However, they were not able to replicate the results. Once the source code for BERT experiments was provided by original authors they were able to reproduce the results and verify authors claims. It would have been interesting if the authors could have identified the reason for performance drop in their re-implementation setting. \n\nIn table 4, it is interesting to note that there is no change in accuracy for 'Embedding model' on occupation prediction task which is not expected as removing impermissible tokens negatively impacts performance. Any explanation for this behavior w.r.t impermissible tokens ?\nTable 5 includes accuracies from paper and reproduced results, however the original paper does not report accuracy for the task 'En-De MT' - where do these numbers come from ?\n\nAdditionally, authors experiment with different embedding sizes hoping to counter the performance drop as \u03bb increases - however it was inconclusive. Having said that authors provide another insight into why they believe could be the reason for performance drop. It would have been interesting to see the impact of the way to remove impermissible tokens on performance trend.\n\nOverall, the paper provides good discussion points and clearly outlines what was provided, what was challenging to infer based on the information in paper/code. They perform all the experiments mentioned in the original paper and verify the claims along with providing insights and implementation aspect. This work helps in understanding the internal details required to reproduce the original paper. Hence, I would recommend to accept this paper.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper53/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper53/AnonReviewer3"]}, {"id": "OZZHhpm4CvF", "original": null, "number": 2, "cdate": 1614904669249, "ddate": null, "tcdate": 1614904669249, "tmdate": 1617290900119, "tddate": null, "forum": "-rn9m0Gt6AQ", "replyto": "-rn9m0Gt6AQ", "invitation": "ML_Reproducibility_Challenge/2020/Paper53/-/Official_Review", "content": {"title": "The author reproduces the result of original paper very precisely. They follow the structure well. there are no result beyond the original paper.", "review": "The authors follow the Reproducibility Summary very well.\nThe authors re-used the original code repository. They also ported the code to PyTorch Lightning to make it easier to reproduce the research in the future.\nThey did not change any hyperparameters and used the same value in the original paper.\nThe authors had fair contact with the authors of original papers and they had discussed minor issues.\nThere are no changes in hyperparameters. The implementation results are the average of five-run times of training the model. They used all datasets except the Reference Letters, due to privacy concerns.\nThe authors added two Blue scores in the seq-seq model for translation.\nThey do not propose any beyond results or improving the original paper, but they have a good discussion that can describe the deep understanding of the paper.\nThere are minor grammar typos.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper53/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper53/AnonReviewer2"]}, {"id": "jaCswCeC9sD", "original": null, "number": 1, "cdate": 1614729151505, "ddate": null, "tcdate": 1614729151505, "tmdate": 1617290900215, "tddate": null, "forum": "-rn9m0Gt6AQ", "replyto": "-rn9m0Gt6AQ", "invitation": "ML_Reproducibility_Challenge/2020/Paper53/-/Official_Review", "content": {"title": "A good replication study that's clear about strengths and difficulties about reproducing the original work. ", "review": "*Scope of reproducibility:*\n\nThe authors clearly state the scope of their experiments (reproducing the embedding experiment, restricted-self attention with BERT and the sequence-to-sequence experiments), and cleanly execute on them. \n\n\n*Code:*\n\n In some instances, the authors re-used code from the original authors, and in some instances, they wrote their own. I did not see a reference to the code written for this paper. \n\n\n*Communication with original authors:*\n\nThe paper authors reach out to the original authors. It looks like a good discussion took place, and the original authors were helpful in clarifying some of the ambiguities that arose through the paper (and also in providing code + datasets). \n\n\n*Hyperparameter Search:*\n\nNeither the replication study nor the original paper used a hyperparameter search. However, the replication study included results on the variance between the 5 random seeds (original paper reported the mean). \n\n*Ablation Study:*\n\nI don't believe the replication study performed any ablations. \n\n*Discussion on results:*\n\nThe replication study presented an excellent description of the reproducibility of the original paper and made clear when the results reproduced and did not reproduce. They clearly stated that some details were ambiguous, but that they were ultimately able to resolve those details. \n\n*Recommendations for reproducibility:*\n\nThe replication study authors and original paper authors seem to have clarified some ambiguities during their discussion. Those would be useful to add to the original paper. \n\n*Results beyond the paper:*\n\nThe replication study investigates the idea that under-parameterization of the models could lead to a decrease in test accuracy when the hyperparameter controlling attention mass on impermissible tokens increases (less able to pay attention to impermissible tokens). They investigated this by increasing the embedding dimension and found it did not improve test accuracy. \n\n*Overall organization and clarity*\n\n* I appreciated the reproduction of the tables from the paper with the author|reproduced! It made it easy to follow along with. \n* Thank you for including the breakdown of the computational requirements for running each task (table 2). This is great. \n* I think the explanation of the seq2seq tasks makes sense if you have read the original paper, but could be confusing if someone has not. Please try writing more on this!\n\n\t\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper53/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper53/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=lE0wqKGROKa", "paper_id": "lE0wqKGROKa", "reviews": [{"id": "6awdmdiUV_C", "original": null, "number": 2, "cdate": 1615236478436, "ddate": null, "tcdate": 1615236478436, "tmdate": 1617290901726, "tddate": null, "forum": "lE0wqKGROKa", "replyto": "lE0wqKGROKa", "invitation": "ML_Reproducibility_Challenge/2020/Paper47/-/Official_Review", "content": {"title": "Stellar report! Goes above and beyond, and very well written!", "review": "* Reproducibility Summary\n\n  The report contains a well-defined and articulate reproducibility summary as prescribed by the challenge.\n* Scope of reproducibility\n  \n  The report contains well-defined scope involving two central claims of the original paper - attention weights not being faithful in plausible explanations in LSTM, and methods to reduce the conicity in order to increase the plausibility of the explanations.\n* Code: whether reproduced from scratch or re-used author repository.\n\n  Authors provide their own codebase link, which consists of the code re-used from the original repository. The codebase is well structured with proper README in the appropriate places.\n* Communication with original authors\n\n  The report mentions that they have contacted the original authors, but they did not hear back from them. This is unfortunate but sadly happens quite frequently. I applaud the author's effort to reach out to the original authors despite the no reply.\n* Hyperparameter Search\n\n  It does not appear that the authors performed an additional hyperparam search than what was reported in the original paper.\n* Ablation Study\n\n  The authors compute several extra experiments as part of the ablation of the original work. They add a new evaluation method to clarify the conclusions of the original paper further using LIME. This is a splendid idea, and the correlation results with Pearson correlation (funny it's a correlation of a correlation!) and JS divergence shows the need for such study. The results are mixed, as the main selling point of the paper (Orthogonality and Diversity) does not correlate well with LIME. I would be curious to hear from the authors if they read this review.\n  The authors also tested for generalization using Bidirectional LSTM to test the author's claims further (and add a note on why other mechanisms, such as Transformers, are not straightforward to evaluate in the same setting). The authors find the proposed methods do not unconditionally improve the explanations. These kinds of cross-architecture robustness experiments add tons of value to the original paper, and I commend the authors for doing the same.\n* Discussion on results\n\n  The report provides a clear and concise discussion of their findings. The authors provide faithful results, both of which experiments worked and which did not. The authors summarized their findings on the original paper and conclude Orthogonal LSTM does clearly leads to lower conicity than Vanilla LSTM, however, the results are mixed. Table 4 is a great summary, clearly defining how each of the claims is supported or not by their reproducibility study.\n* Recommendations for reproducibility\n \n  The report goes above and beyond to conduct a thorough code review of the original paper, which is a stellar contribution to both reproducible research and to the understanding of the code provided by the original paper. The authors further provide ample discussion and conclude the benefits of orthogonality and diversity training are more relevant for simpler tasks.\n* Overall organization and clarity\n  \n  The report does not have any significant typos. It is well organized into appropriate sections.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper47/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper47/AnonReviewer4"]}, {"id": "mI4Qj-Gk7Sr", "original": null, "number": 1, "cdate": 1614667343650, "ddate": null, "tcdate": 1614667343650, "tmdate": 1617290901826, "tddate": null, "forum": "lE0wqKGROKa", "replyto": "lE0wqKGROKa", "invitation": "ML_Reproducibility_Challenge/2020/Paper47/-/Official_Review", "content": {"title": "Review", "review": "Reproducibility Summary:\n- The summary did a nice job outlining the report.\n\nScope of reproducibility:\n- Makes clear what the scope of the report is, and provides nice justification for why certain parts were left out (i.e. missing data sets).\n\nCode:\n- Uses the original code\n- Does an extensive look and dissection of the code base to find some issues worth noting. For example:\n  - orthogonalization applied to both the P-path and Q-path), which wasn't obvious from the original text. They do a small experiment to test the model's sensitivity to this change.\n  - The final prediction is calculated differently than reported\n  - Unreported fine-tuning of the embeddings for the two paths independently\n  - An odd choice in how the dev set is chosen from the training set.\n  \nCommunication with original authors:\n- Mentioned sending email to clarify parts of the code with no response.\n  \nHyperparameter Search:\n- None done in the reproduction, and none done here.\n  \nAblation Study:\nN/A\n\nDiscussion on results:\n- Did a nice job raising concerns about the original paper's findings.\n- Raised many concerns, gave evidence for why these concerns would be problematic (even testing what the changes would be), and gave concrete steps for improvement.\n\nResults beyond the paper:\n- Expand the set of evaluation metrics\n- Test claim's generality on different architectures. Specifically, the authors applied the metrics to a Bi-directional LSTM model.\n\nOverall organization and clarity\n\nOverall, the report is well written and relatively clear. Some things I would suggest/some questions:\n- How many runs did you do for each experiment? Is this similar to what the original authors did?\n- table 6, how were the confidence intervals calculated?\n- The sub-section \"other attention mechanisms\" in section 7 is a bit out of place. Maybe you can remove the this entirely, and add it to the final discussion? Because you don't run more experiments here, it just doesn't seem to fit. If you do run experiments here, this needs to be made much clearer.\n- The original paper does not seem to do a parameter sweep of any kind, so this would have been a nice inclusion in the report. Event if it wasn't for all the data sets.\n- The original paper chooses the best model (out of a set of unknown size) from the validation accuracy and reports the test accuracy. I'm not apart of the community this paper is aimed at (i.e. NLP/Explainability), so I'm not sure how common this is as a practice. Usually, I would prefer to see multiple runs and either a median or average reported with confidence intervals. Of course this can be ignored if this isn't standard practice in this community.\n\nAgain. I think this report is well put together and the biggest weakness is the lack of hyperparameter search and ambiguity around how the models were reported (i.e. best of, mean, median) w/o confidence intervals.\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper47/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper47/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=N43DVxrjCw", "paper_id": "N43DVxrjCw", "reviews": [{"id": "9cPWPaWAMQ", "original": null, "number": 3, "cdate": 1614615290015, "ddate": null, "tcdate": 1614615290015, "tmdate": 1617290903063, "tddate": null, "forum": "N43DVxrjCw", "replyto": "N43DVxrjCw", "invitation": "ML_Reproducibility_Challenge/2020/Paper43/-/Official_Review", "content": {"title": "Review: Strong Accept", "review": "1. In this report the authors have tackled the following reproducibility claims from the original paper:\n  - Warm-starting a Neural Network training has poorer generalization compared to training with new data + old data from scratch\n  - Application of Shrink+Perturb technique proposed by authors to rectify and improve the warm-starting generalization.\n2. The authors have implemented the code by themselves and tried various hyperparameters as mentioned by the original authors. They communicated with the original authors to clarify some of the implementation details mentioned in the paper like when to stop for training convergence, hyperparameters to tune, etc. However, the public link for the code implemented by the report's authors is not accessible.\n3. In addition to implementing the code, the authors have also tried other techniques that might help with the warm-starting problem such as data-augmentation, early-stopping, regularization etc.\n4. In the results and discussions part of the report, the authors have described the implementation details of the project. The authors have reported that warm-starting definitely has a generalization gap, shrink and perturb method is effective in reducing the gap.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper43/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper43/AnonReviewer2"]}, {"id": "IJeEZov77X", "original": null, "number": 2, "cdate": 1614369396041, "ddate": null, "tcdate": 1614369396041, "tmdate": 1617290903154, "tddate": null, "forum": "N43DVxrjCw", "replyto": "N43DVxrjCw", "invitation": "ML_Reproducibility_Challenge/2020/Paper43/-/Official_Review", "content": {"title": "a relevant review toward the original paper with minor mistakes according to report tempelate", "review": "In the proposed paper, one of the main pros is that you've plotted and calculated each relation that was measured in the original paper and obtained mainly near or the exact values toward the original paper. But some minor issues showed off during reviewing your paper.\nFirst of all, you've forgotten to blind your names and affiliations, not a major problem but it might affect reviewers' ideas sometimes. After that, you've also forgotten to numerize lines, so I have to mention them using paragraphs' titles. \nAccording to the \"What was easy\" paragraph, you'd better re-write \"since many of the parameters are reported in the original paper\" into \"since many of the parameters ***were*** reported in the original paper.\" There also was so good that you've explained all the conditions you've put your dataset under test, like the optimizers, loss functions, etc. and I guess you've tested as far as I know enough conditions to explain your model and results.\nAs it seems, the original paper didn't do the ***data augmentation***, but it's so good to multiply the amount of data to exploit enough accuracy.\nIn the \"effect of hyperparameter\" paragraph, you've made a typo and wrote ***vales*** instead of ***values***, in the \"We iterate over all pairs for these vales\" sentence.\nIn the \"effect of data augmentation\" paragraph, you've mentioned that \"However, because the learning rate is low, the models are not fully converged even after 350 epochs\", although you've previously mentioned that your model converged to 99% of accuracy, so it wasn't crystally clear for me. In the sentence \"the original paper\u2019s authors look at the difference\", it would better to re-write ***look*** to ***looked***, and ***difference*** to ***differences***. In the last sentence of this paragraph \"Due to the limits of this report, we also leave the careful comparison between data augmentations and Shrink & Perturb as future research in this area\", it would be better to explain ***limits*** more.\nThe link you've attached as \"https://github.com/CS-433/cs-433-project-2-fesenjoon.\" didn't work properly, I couldn't find your project, according to the link you've attached in the ***Experimental setup*** paragraph.\nBut in total, you've represented your method very well.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper43/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper43/AnonReviewer1"]}, {"id": "qnWlSb5kKsP", "original": null, "number": 1, "cdate": 1613523392059, "ddate": null, "tcdate": 1613523392059, "tmdate": 1617290903251, "tddate": null, "forum": "N43DVxrjCw", "replyto": "N43DVxrjCw", "invitation": "ML_Reproducibility_Challenge/2020/Paper43/-/Official_Review", "content": {"title": "Well structured report, but a lot of inconsistencies in experiments. Not clear if reproduction wasn't proper or if the original paper results are bogus", "review": "This report is reproducing most of the experiments from the paper \"On Warm Starting Neural Network Training\". While the general trends are visible in the reproduced results, there are many details that are not the same. As the reproduced paper doesn't provide confidence intervals in their figures (which the original paper does) and they show test instead of validation results, it is not very easy to compare results. Equivalent experiments in most of the examples achieve different max accuracy. Even more concerning is that gap that is shown in the very first experiment in order to motivate the work, is almost not existing in Table 1 of reproduction. Other experiments also show unexpectedly good performance of warm start models in the reproduced results. Overall, experiments results within the report show inconsistent behavior and instability.\n\nThe report is well written and organised and it contains a summary section at the beginning. Report authors clarified questions with original authors. The link to the implementation doesn't work. I've searched the repository and that project is deleted. \n\nI like the report, but I am giving grade 5 because the results are not matching the original paper results, and since they are less extensive and elaborative and with no confidence intervals, I have more confidence in the results of the original paper. Additionally, the link to the code doesn't work, so it's not possible to see the setup of the reproduced experiments.\n\nBelow are comments related to different experiments in the order in which they appear in the report:\n- Experiment in Figure 1: Report authors use only 200/400 epochs instead of 350/700 epochs used in the original paper, but they are able to show the same effect. It is good that even with fewer time resources, we can show the same effect.\n- Table 1: While the original paper gives us validation accuracies, the report authors give us training and test accuracies, so it's not comparable. For LR, there is no gap according to Table 1, but similar is true for original Table 1. However, while in the original Table 1 gap is obvious between random init and warm start, in the reproduced study, that's not true. Most of the gaps are within one standard deviation and gaps are inconsistent, meaning that in some cases warm start is better. Also, test results here are much worse than original validation results. Did they train for the same number of epochs? The difference is too big to be explained by validation vs test set difference.\n- Figure 2: there is no confidentiality interval that exists in the original paper. As authors of the report saw that SVHN behaves differently, they added additional experiments here, which show slightly different behavior and require a convergence threshold of 99.9%. I would suggest changing the scale of Figures 2 b) and c) to show only information above 80% or 85 % of accuracy so that it is easier to see the gap.\n- Results in Figure 4 are different than in the original study. In this report, warm start models are performing consistently better than in the original paper, so we could see there was almost no gap visible in Table 1, and in Figure 4 performance of warm start is better than the random start, even though that's not true in the original paper. Again, the report deals with test errors while original papers worked with validation errors, but that shouldn't affect the conclusion. It is also interesting to note that the report is able to achieve better results on the test dataset with a few warm start experiments than the original paper achieves on the validation dataset with any model. That is suspicious to me.\n- While the original paper has confidence intervals for Figure 4, that is not given in reproduction (Figure 3) and the patterns show small but visible differences, which might be explained with confidence intervals. Again, the test accuracy that is achieved by the report is up to 5% higher than in the original paper.\n- What is the x-axis of Figure 5? Is it the number of epochs?\n- Figure 6 (matches original Figure 7): Behavior is inconsistent for different lambda values. No pattern can be spotted in this figure, except that for lambda=0 train time is strongly the highest. It is very strange that for lambda=0 training time is twice bigger than expected for around 25 thousand examples.\n- In general, results reported in those figures are less smooth, which is probably because the information is displayed in more coarse grain, but it may also be due to the instability of the models or issues with reproducibility. However, it is not clear from the report which one it is, and it seems it's rather from the former.\n- Authors add experiments on warm start with augmented data in which warm start slightly outperforms random initialization. However, in some of the repeated experiments, we can see similar behavior in the report, so it looks like warm start performs better throughout this report and not because of the data augmentation.\n- Figure 11: Why does shrink-perturb go down after on the graph in the bottom left corner when x > 0.6? Most of the results in this figure are inconsistent with the original paper as they show that fresh has the best performance, but results are inconsistent. Also, on the contrary from the rest of the report, here we can see that warm has the worst performance in all the cases.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper43/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper43/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=8jmIpypMzE", "paper_id": "8jmIpypMzE", "reviews": [{"id": "4RlRxbewm8K", "original": null, "number": 2, "cdate": 1614750040404, "ddate": null, "tcdate": 1614750040404, "tmdate": 1617290903764, "tddate": null, "forum": "8jmIpypMzE", "replyto": "8jmIpypMzE", "invitation": "ML_Reproducibility_Challenge/2020/Paper41/-/Official_Review", "content": {"title": "Review for reproducibility challenge", "review": "The overall paper presents good ablation with a clear introduction to the problem statement in the reproduction summary.\n\nIt was good to see a detailed hyper-parameter search over the baseline model. \nBut, it would have been great if the authors would have extended the work over real datasets in support of the points mentioned in the discussion section. \nAlso, if the authors can share more details regarding the time complexity for running the experiments which would help future researchers to tackle this problem first.\nThe discussion section mentioned by the authors listing down the strengths and weakness of the method which is a great reference point for future work. \nFrom the paper, it seems that the authors may not have any direct communications with the original authors. They mainly obtained information from the original paper and the original codebase. \nThe authors have clearly stated the scope of reproducibility with clarity in the claims they learned from the original paper with further sections explaining the clams.\nSmall suggestion: In page 9: section-\"Baseline improvement experiments\" if the table can be written in a more representable manner.\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper41/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper41/AnonReviewer3"]}, {"id": "0lkfESGaxVz", "original": null, "number": 1, "cdate": 1614550836644, "ddate": null, "tcdate": 1614550836644, "tmdate": 1617290903873, "tddate": null, "forum": "8jmIpypMzE", "replyto": "8jmIpypMzE", "invitation": "ML_Reproducibility_Challenge/2020/Paper41/-/Official_Review", "content": {"title": "A clear and fair reproductivity assessment report ", "review": "This report confirms most of the claims in the original paper and points out some minor issues of the proposed iFlow method that are not fully supported by the experimental observations. Furthermore, the report also mentions that the MCC scores of the iVAE\nreported by the authors are significantly worse than those in the iVAE paper. The limit of the report is the lack of experimental evaluations traversing different hyperparameter values due to the computation bottleneck.  The report states the coverage limit clearly. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper41/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper41/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=PRXM8-O9PKd", "paper_id": "PRXM8-O9PKd", "reviews": [{"id": "53cAI3aP_Lt", "original": null, "number": 2, "cdate": 1614439372649, "ddate": null, "tcdate": 1614439372649, "tmdate": 1617290904054, "tddate": null, "forum": "PRXM8-O9PKd", "replyto": "PRXM8-O9PKd", "invitation": "ML_Reproducibility_Challenge/2020/Paper40/-/Official_Review", "content": {"title": "In-depth and balanced reproducibility study of great value. ", "review": "The authors developed code for the original paper from scratch and communicated with the original authors for detail. They provide a in-depth, easily readable, well organized report and analysis. They include extensive HPO. They give valuable recommendations for future work. \n\nUnfortunately, code will only be submitted only after the review process.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper40/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper40/AnonReviewer2"]}, {"id": "19_Jg5yBHRl", "original": null, "number": 1, "cdate": 1614432742281, "ddate": null, "tcdate": 1614432742281, "tmdate": 1617290904155, "tddate": null, "forum": "PRXM8-O9PKd", "replyto": "PRXM8-O9PKd", "invitation": "ML_Reproducibility_Challenge/2020/Paper40/-/Official_Review", "content": {"title": "A detailed report with intensive experiments", "review": "*Problem statement: \nThe paper clearly states the reproducing details, together with the detailed results and difficulties.\n\n*Presentation:\nThe paper is well-organized and well-written. \n\n*Communication with original authors\nThe authors had some communication with the original authors.\n\n*Code:\nThe code is well-organized and can be reproduced. I have tested the code on my side and all components work well. \n\n*Recommendations for reproducibility\nThe authors provided useful comments for reproducing the original paper. I have read the code and found those comments are consistent with the provided codes. \n\n*A few concerns\n**The tense is not consistent in the whole paper. In some sections, the author used past tense while the present tense is used in some other sections. \n** It will be even better if the authors can provide a simple illustration on the two major algorithms, like Fig.3 and Fig.4 in the original paper. The figures and simple explanations would help readers to follow your report.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper40/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper40/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=8JHrucviUf", "paper_id": "8JHrucviUf", "reviews": [{"id": "o8B6WknJIDO", "original": null, "number": 2, "cdate": 1614746693546, "ddate": null, "tcdate": 1614746693546, "tmdate": 1617290904570, "tddate": null, "forum": "8JHrucviUf", "replyto": "8JHrucviUf", "invitation": "ML_Reproducibility_Challenge/2020/Paper38/-/Official_Review", "content": {"title": "review", "review": "The report is well written and has a concise explanation. Additionally, the authors provide a great summary at the beginning. I would like to know if the numbers from the TensorFlow implementation (authors' paper) match the results reported in the main paper. It would interesting to perform a hyperparameter search and provide code and docs so it would be reviewed before accepting the paper. After the authors of the report make some claims and report an improvement for their own implementation. I suggest accepting the report", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper38/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper38/AnonReviewer2"]}, {"id": "bGbS9I4Rcg", "original": null, "number": 1, "cdate": 1614567099258, "ddate": null, "tcdate": 1614567099258, "tmdate": 1617290904667, "tddate": null, "forum": "8JHrucviUf", "replyto": "8JHrucviUf", "invitation": "ML_Reproducibility_Challenge/2020/Paper38/-/Official_Review", "content": {"title": "The report reveals a lot of dark spots of the original paper", "review": "As a first remark, the report seems to repeat content. This is probably not the author's fault, I noticed the same problem with other reports. That is probably a problem with the instruction template. This is something for the organizers to take into consideration.\n\nGeneral remarks\nThe report follows the prescribed format. The authors reproduced the experiments in pytorch. The original implementation was in tensorflow. The author found errors in the implementation and a lot of gaps in the parameter tuning. In some cases, they get results opposite from the claims of the paper. The biggest problem of the paper they evaluated was the fact that the text and code were not in agreement. In fact, the code was convoluted and it was difficult to actually get the knowledge out of it. \nThe report is well organized and there is a clear correspondence between the code and the issues the report addresses\n\nProblems of the report\nThe report has a lot of references to nowhere, this is probably a problem with their latex referencing system. There are references to sections, tabs, and an appendix. While this is a technicality that can easily be resolved for the tables and sections, I couldn't locate the appendix. As mentioned in the comments the authors point that the pytorch function for the node convolution in pytorch is different from the one used in tensorflow. The original paper authors attribute the differences to that. In my opinion, this difference can not be responsible for the discrepancies. ", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper38/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper38/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=DXVAJGohUKs", "paper_id": "DXVAJGohUKs", "reviews": [{"id": "64uxu-z9p0d", "original": null, "number": 2, "cdate": 1614572568331, "ddate": null, "tcdate": 1614572568331, "tmdate": 1617290905213, "tddate": null, "forum": "DXVAJGohUKs", "replyto": "DXVAJGohUKs", "invitation": "ML_Reproducibility_Challenge/2020/Paper36/-/Official_Review", "content": {"title": "Deep Fair Clustering (DFC) for visual learning; Accurate and detailed report", "review": "The author(s) provide precise details in their report regarding the proposed algorithm and data set (MNIST) details. The objective function and model description are well defined. They provide every detail of the code and algorithms that have been used by other papers and provide the citation. The evaluation criteria; accuracy and NMI were used to evaluate cluster validity. They didn't discuss details of their result in Tables 3, 4, and 5, but they were understandable.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper36/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper36/AnonReviewer3"]}, {"id": "uU7ac1wMWsI", "original": null, "number": 1, "cdate": 1614503198996, "ddate": null, "tcdate": 1614503198996, "tmdate": 1617290905311, "tddate": null, "forum": "DXVAJGohUKs", "replyto": "DXVAJGohUKs", "invitation": "ML_Reproducibility_Challenge/2020/Paper36/-/Official_Review", "content": {"title": "A careful and well organised report with extensions", "review": "This paper provides a holistic reproducibility report of the original paper on the algorithm named 'deep fair clustering' (DFC). The following issues are examined.\n\n1. On the data sets 'Color Reverse MNIST' and 'MNIST-USPS' (they are the two data sets among four used in the original paper), DFC is tested against all the four metrics used in the original paper: 'Accuracy', 'NMI', 'Balance', and 'Entropy'. The mathematical details of these metrics are provided. In particular, a part of DFC and the data pre-processing are re-implemented since the corresponding code for the original paper is not accessible.\n\n2. Extension by using no pre-trained cluster centres. It is shown that by discarding pre-trained cluster centres, DFC has a noticeable drop in performance.\n\n3. Extension by using different divergence functions for regularisation. In particular, JS and CS divergences are used to replace the KL divergence used in the original paper. The comparison of performance is well documented.\n\n4. Extension by using non-binary/corrupted sensitive attributes. It is shown that with corruption, DFC has a noticeable drop in performance in all the four metrics.\nThe paper is well organised, and the clear structure makes the report easy to follow.\n\nPossible problems:\n\n1. The words' fair' and 'effective' have both general English meaning and context-specific definitions, and both are tightly connected to machine learning and artificial intelligence. Using such words without giving a brief introduction leaves the readers confused. The confusion is not reduced, e.g., even after authors write 'feature representations are considered fair if they are statistically independent of sensitive attributes.'\n\n2. The point of 'sensitive attributes' in section 2 is confusing. I am particularly lost at how this is related to turning the background of images to white or black.\n\n3. Usually, the change of regularisers would significantly modify the performance of an algorithm. Examples include enhancing sparsity by l1 or l0 penalty, enhancing prediction accuracy by l2 penalty, and so on. I am not sure if it is fair (see, this word 'fair' has a different meaning than it has in the paper) to test the claims' robustness by changing regularisation.\n\n4. How is the 'background' of an image or the 'background colour' defined?\n\n5. A typo in line 149, p(x=q(x)) should be p(x)=q(x).\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper36/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper36/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=yiAI9QN9nYt", "paper_id": "yiAI9QN9nYt", "reviews": [{"id": "SMFjCY6qG8", "original": null, "number": 2, "cdate": 1614549339151, "ddate": null, "tcdate": 1614549339151, "tmdate": 1617290907872, "tddate": null, "forum": "yiAI9QN9nYt", "replyto": "yiAI9QN9nYt", "invitation": "ML_Reproducibility_Challenge/2020/Paper26/-/Official_Review", "content": {"title": "SADNet reimplementation", "review": "\n> Overall approach to reproduce the results and the adjoining paper are quite clear.\n\n> The reproducibility summary is provided.\n\n> It seemed easy to reproduce the results from the paper although the authors had to resort to default hyperparameters as these were not readily available. Their results still tallied with that of the original paper showing that the model architecture is robust to change in hyperparameter settings. \n\n> It is not clear if the authors rewrote the original PyTorch code.\n\n> Even though no communication with the original authors was made, some areas to tidy up in the code are discussed by the authors.\n\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper26/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper26/AnonReviewer2"]}, {"id": "6VIkY2mieH", "original": null, "number": 1, "cdate": 1614245873602, "ddate": null, "tcdate": 1614245873602, "tmdate": 1617290907970, "tddate": null, "forum": "yiAI9QN9nYt", "replyto": "yiAI9QN9nYt", "invitation": "ML_Reproducibility_Challenge/2020/Paper26/-/Official_Review", "content": {"title": "A reproducibility study of the SADNet denoising model", "review": "The given report examines the reproducibilty of a deep denoising model SADNet for natural images based on spatial-adaptive residual blocks. The model was proposed in the paper \"Spatial-Adaptive Network for Single Image Denoising\" by Chang et al. The model was reimplemented by the authors of the report using the residual spatial-adaptive block and the context block from Chang et al.\n  \n**Reproducibility Summary:**\nThe report contains a reproducibility summary as required by the template.\n\n**Scope of Reproducibility:**\nThe authors of the report clearly state the scope of their reproducibility experiments.\n\n**Code:**\nThe code was provided. The authors reimplemented the training loop and the model and reused some code from the original repository (the residual spatial-adaptive block and the context block). The authors use the dataloader provided with the dataset. Overall, the code is well written but some comments and doc-strings would highly improve the readability. Unfortunately, I was not able to run the code due to CUDA incompatibilities.\n\n**Communication with Original Authors:**\nThe authors of the report state that no communication with Chang et al. was necessary to reproduce the results.\n\n**Hyperparameter Search:**\nThe authors use the hyperparameter settings stated in the paper. No further hyperparameter sweeps were performed. Given the long training time of three days this choice seems reasonable. However, the authors changed the initialization scheme to the Kaiming initializer (instead of Xavier uniform initializer). \t    \n\n**Ablation Study:**\nNo ablation study was carried out.\n\n**Discussion on Results:**\nThe authors were able to reproduce most of the results from the original paper. The PSNR/SSIM values closely match the values reported by Chang et al. However, visually the results shown in Figure 5 are qualitatively worse than the original results. Also runtimes are compared with the runtime stated in the original work (using different hardware) which is not appropriate. Running the original code on the same hardware would have been a more meaningful way of comparing runtimes.\n\n**Recommendations for Reproducibility:**\nNo recommendations made.\n\n**Results Beyond the Paper:**\nNo results beyond the original work reported.\n\n**Overall Organization and Clarity:**\nThe report is well-written and well-organized. The authors should add references for the first sentence of the introduction. Some small comments on the writing can be found at the end of the review.\n\n**Summary of Review:**\nThe report at hand successfully reproduced the original paper. The authors are very clear about their experimental setup and the problems that they faced during reproduction. However, there are some minor problems in the discussion. Nonetheless, I recommend to accept the paper to the ML Reproducibility Challenge 2020.\n\n**Minor Remarks:**\n\n- line 90: recieves -> receive\n- line 114-115: 1e-4 vs 10^8\n- caption Figure 2 and Figure 3: validation dataset should not be capitalized\n- Equation (1): the \\delta in front of m_i is missing\n- Equation (2): set-notation is not appropriate here: \\delta p^s and \\delta m^s should form a tuple instead of a set. However, this notation is also used in the original work.\n- line 144: \\sigma = {30, 50, 70}: here \\in should be used instead of \"=\"\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper26/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper26/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=vvLWTXkJ2Zv", "paper_id": "vvLWTXkJ2Zv", "reviews": [{"id": "LWpghIyOIlU", "original": null, "number": 2, "cdate": 1615429826020, "ddate": null, "tcdate": 1615429826020, "tmdate": 1617290909373, "tddate": null, "forum": "vvLWTXkJ2Zv", "replyto": "vvLWTXkJ2Zv", "invitation": "ML_Reproducibility_Challenge/2020/Paper21/-/Official_Review", "content": {"title": "Strong yes.", "review": "The authors reproduced the work of Learning Memory-guided Normality for Anomaly Detection. \n\nIn this work, the authors have:\n- Reused part of the original code and scripted some parts that were not available\n- Have communicated with the authors regarding the changes\n- Did a thorough ablation study\n\nAnd finally, went beyond the scope of the reproduction and suggested further improvements.\nIn the reviewer's opinion it is a thoroughly conducted study.\n\nSmall typos: Space missing line 45\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper21/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper21/AnonReviewer3"]}, {"id": "yxmHym7g6fk", "original": null, "number": 1, "cdate": 1614578880122, "ddate": null, "tcdate": 1614578880122, "tmdate": 1617290909463, "tddate": null, "forum": "vvLWTXkJ2Zv", "replyto": "vvLWTXkJ2Zv", "invitation": "ML_Reproducibility_Challenge/2020/Paper21/-/Official_Review", "content": {"title": "Excellent reproducibility report, but implications of findings slightly unclear", "review": "I would like to congratulate the authors on their commendable effort in preparing this reproducibility report. I believe the authors' effort will significantly contribute to the improvement of the reproducibility of this work. I have presented a more detailed evaluation below.\n\n__Pros:__\n1. The authors did a great job in presenting the reproducibility summary, especially the easy and hard parts of their reproducibility effort.\n2. The introduction and scope of reproducibility are clearly presented and nicely setup the rest of the report. I would also like to appreciate the authors' effort to present the mathematical foundations of the method. However, I feel the grammar and writing style could be improved for better readability. \n3. The authors built up on the original code base which only had the codes for the Prediction task with memory. I believe this is a significant achievement and hope that this experience was highly educational and rewarding for the authors. However, the original code repo has now been updated. So, it would be helpful if the authors could comment on discrepancies (if any) in their implementation and the one provided by the original authors in their final version. \n4. The authors mentioned performing a hyperparameter search and reported finding different set of hyperparameters than originally reported in the paper. Having a plot of the performance variance for different hyperparameters (in the supplementary) could add value to this effort.\n5. I would like to appreciate the several ablation studies performed by the authors to evaluate various components of the proposed methodology. The inferences from these studies though could be presented better. \n6. The authors performed useful additional experiments beyond the ones performed in the original paper. These experiments definitely add to my understanding of the method. Although I could follow the results of these experiments, I was slightly confused about the inferences presented by the authors. However, since this is a reproducibility report, I gave more weightage to the rationale behind the experiments rather than their interpretations.\n7. The authors allude to some reproducibility recommendations but it's not very explicit. I think these recommendations are extremely useful and it would help to have them clearly mentioned. \n\n\nDespite the several merits of the report, I have few concerns primarily pertaining to the presentation and writing/organization style of the report. I have detailed them below.\n__Cons:__\n1. It would help to have a figure/flowchart that outlines the several experiments that the authors tried to replicate and/or investigate in detail with additional experiments. I would strongly suggest adding this figure in the introduction or scope section. This figure would establish the context and methodology of the original paper as well as give the reader an overview of the rest of the report. \n2. With the original code repo being updated recently, the authors may have to briefly comment about the discrepancies (if any) in their implementation. Additionally, they need to update the report to incorporate the information that the original repo now contains the codes to both tasks. I don't think this needs to be very detailed but updating this information will add to the completeness of the report. \n3. Although the authors report that they communicated with the original authors, it is slightly unclear as to how this communication served to improve the authors' understanding and/or implementation of the methodology. Also, I am curious to know if the authors communicated the observed discrepancy about the ShanghaiTech dataset and the engineering fix they had to deploy. \n4. It would help to have a plot of the performance variation with changing hyperparameters. This result would indicate how sensitive the results are to hyperparameter values. Also, did the authors try different seeds? I understand this could be difficult to do on complicated dataset but it is an essential component to establish that one method statistically outperforms another method. As a recommendation, I would propose the authors to run their \"light weight\" experiments on multiple seeds and report the standard deviation in metrics. \n5. I think the overall presentation style needs to be improved. The current report has very interesting experiments and excellent insights. These insights need to highlighted properly. For instance, it will be helpful to have the results reported by the original authors alongside the results obtained in this report to clearly compare and contrast the discrepancies or agreements. Furthermore, it would help improve the readability if the authors could add a flowchart or table that summarized their findings in terms of which modules turned out to be redundant for each of the tasks. Having such a figure or table will significantly improve the impact of their findings. \n6. The discussions and implications presented by the authors don't seem very convincing. For instance, the authors mention _\"Figure 9 shows both models having trouble reconstructing the input frames, but the Prediction model reconstructs the image with considerably more artifacts making it easier to classify correctly.\"_ It is hard to conclude this without definite reconstruction error (MSE, perhaps?) values. \n7. Furthermore, did the authors try an epsilon-greedy type of approach to mitigate the problem of mode collapse in memory module? This would entail using the memory module as proposed with probability of (1-epsilon) and using a random combination of all memory items with epsilon probability. The value of epsilon could become another hyperparameter, but setting it to some constant value (eg. 0.1) could perhaps serve as an acceptable solution. However, this would be a minor comment and mostly out of my own curiosity. I have not used this concern to judge the merit of the reproducibility report. \n8. Finally, I would encourage the authors to add clear reproducibility recommendations. I believe the authors are at an appropriate stage to provide specific recommendations for this work and a good reproducibility report should have them.\n\nOnce again, I would like to congratulate the authors on their work and I hope they can address some of the concerns mentioned above to improve the impact of this report. I believe that if the authors could add the aforementioned summary figures and/or tables and improve the overall readability of the final version of the report, this work could be extremely useful to the field in general. ", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper21/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper21/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=TM_SgwWJA23", "paper_id": "TM_SgwWJA23", "reviews": [{"id": "QCVbSRRtEZW", "original": null, "number": 3, "cdate": 1615240080545, "ddate": null, "tcdate": 1615240080545, "tmdate": 1617290909612, "tddate": null, "forum": "TM_SgwWJA23", "replyto": "TM_SgwWJA23", "invitation": "ML_Reproducibility_Challenge/2020/Paper20/-/Official_Review", "content": {"title": "Review for Can gradient clipping mitigate label noise? ", "review": "The report aims to reproduce the results of the paper 'Can gradient clipping mitigate label noise?' The report gives a summary of how the reproduction is conducted and briefly introduce the original paper. The paper also gives the details including the hyper-parameters and computational infrastructures. \n\nThe authors provides the reproducing codes with detailed documentation.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper20/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper20/AnonReviewer2"]}, {"id": "rz-6XHM-M6a", "original": null, "number": 2, "cdate": 1614632450105, "ddate": null, "tcdate": 1614632450105, "tmdate": 1617290909704, "tddate": null, "forum": "TM_SgwWJA23", "replyto": "TM_SgwWJA23", "invitation": "ML_Reproducibility_Challenge/2020/Paper20/-/Official_Review", "content": {"title": "Good reproducability report", "review": "The report aims to reproduce a paper on so-called Partially Huberised losses. These losses are used to mitigate the label noise. The report replicates all the experiments from the original paper and makes insightful discoveries.\n\nThe report is well-written and easy to follow. The original paper is summarized and all the experiments are described in details. The report also mentions the communication with the authors of the original paper which revealed some typos or mistakes in the original paper.\n\nThe original paper was reproduced from scratch with a different framework (PyTorch, instead of Tensorflow). This is good way to test the reproducability.\n\nSuggestions for improvements:\n- The very first section \"Scope of Reproducability\" should discuss, the scope. What the report reproduces and what it does not.\n- The hyper-parameter search is the same as in the original paper. The report does not go an extra mile to search wider space. Nevertheless, I understand that such experiments may be time consuming and require a lot of computational resources.\n- It is always desirable to include extra datasets, extra experiments, more architectures to more thoroughly test the claims of the original paper.\n- Section 4.2.2 mentions that the reproduced experiments used the mixed precision for training. The report should clarify if this is different from the original paper and if it may influence the results.\n\nOverall, this is a good report. I recommend accept.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper20/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper20/AnonReviewer3"]}, {"id": "Fbgf2H2Inay", "original": null, "number": 1, "cdate": 1614586991266, "ddate": null, "tcdate": 1614586991266, "tmdate": 1617290909797, "tddate": null, "forum": "TM_SgwWJA23", "replyto": "TM_SgwWJA23", "invitation": "ML_Reproducibility_Challenge/2020/Paper20/-/Official_Review", "content": {"title": "Solid report and solid reproductions ", "review": "In this report, the authors reproduce the experiment parts of the paper: \"Can Gradient Clipping Mitigate Label Noise?\" by Aditya Krishna Menon, Ankit Singh Rawat, Sashank J. Reddi, Sanjiv Kumar.\n\nThe main contributions of this report are: \n1. The authors reproduce experiments of the original paper to prove that Partially Huberised Loss does have label noise robustness.\n2. The authors report corrected hyperparameters that were reported incorrectly in the original paper.\n3. Although it's not so much different from what the original paper insists, the authors provide results that are different from the original paper.\n4. The authors clarify that the ResNet-50 architecture used in the original paper differs from the architecture of He et al. 2015 (this choice was not made clear in the original paper) and explains why this modification is necessary.\n\nMinor issue:\nIn experiments using Long & Servedio dataset, there is no explanation for why is the accuracy becomes lower when the corruption rate \u03c1 is lower.\n\n\nVerdict:\nThe report contains some solid experiments and additional information and corrections not in the original paper. I can see researchers trying to build upon the original paper benefitting from reading this reproducibility report. For this reason, I recommend the report be accepted.\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper20/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper20/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=riCIeP6LzEE", "paper_id": "riCIeP6LzEE", "reviews": [{"id": "Mio1bmrO2C", "original": null, "number": 3, "cdate": 1615765585780, "ddate": null, "tcdate": 1615765585780, "tmdate": 1617290914808, "tddate": null, "forum": "riCIeP6LzEE", "replyto": "riCIeP6LzEE", "invitation": "ML_Reproducibility_Challenge/2020/Paper15/-/Official_Review", "content": {"title": "Solid reproducibility report, strong accept!", "review": "Overall, this report is of very high quality and impact. The authors reproduce the original paper from scratch. The authors perform hyperparam sensitivity study. The authors also perform extensive ablation experiments and uncover an interesting finding on the dependency of initialization. This project checks all components needed for a good reproducibility report, and I believe this is worthy of a journal submission. I would like to thank the authors for their hard work!\n\n* Reproducibility Summary\n\n  The report contains a well-written, concrete reproducibility summary. The summary outlines the scope of the paper to reproduce the RigL algorithm from scratch by re-implementing the methodology on PyTorch. The summary also concisely highlights the major findings, where the report gets within 0.1% of the reported values in the original paper on CIFAR10.\n\n* Scope of reproducibility\n\n  The report investigates several central claims from the original paper, Riga. The report contains an investigation of the sensitivity of hyperparameters, model ablation, and choice of initialization too.\n\n* Code: whether reproduced from scratch or re-used author repository.\n\n  Authors re-implement the code of RigL from scratch in Pytorch, which was original written in Tensorflow. This makes the report extremely strong, as it helps to robustly validate the core claims of the original paper. The authors provide their code in the supplementary material. It is also very much appreciated that the authors plan to release the training plots, which would be a strong contribution towards the understanding of RigL.\n\n* Communication with original authors\n\n  Authors of the report communicated with the original authors successfully, who helped the authors clarify implementation and evaluation details.\n\n* Hyperparameter Search\n\n  Authors tune the hyperparameters with Optuna and carefully examine the impact of each hyperparam chosen in the original paper.\n\n* Ablation Study\n\n  The report goes a step further to perform an ablation study to investigate the impact of ERK initialization for a given target parameter count and training budget. The paper also performs experiments on redistribution, which is shown to help RigL with random initialization but not ERK. This is a very interesting finding!\n\n* Discussion on results\n\n  The report contains ample discussion on the results. Primarily, they find the central claim of the original paper holds true. RigL is also found to be fairly robust to the choice of hyperparameters. The report finds further evidence that the choice of initialization has a much greater impact on the final performance, and proposes interesting future directions for research.\n\n* Recommendations for reproducibility\n\n  The authors highly commend the original paper on their state of reproducibility and thank the original paper authors for their communication.\n\n* Overall organization and clarity\n\n  The paper is well organized and well written.", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper15/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper15/AnonReviewer4"]}, {"id": "0kJIvItqi83", "original": null, "number": 1, "cdate": 1613682496512, "ddate": null, "tcdate": 1613682496512, "tmdate": 1617290914917, "tddate": null, "forum": "riCIeP6LzEE", "replyto": "riCIeP6LzEE", "invitation": "ML_Reproducibility_Challenge/2020/Paper15/-/Official_Review", "content": {"title": "Good Reproducibility Project", "review": "The authors have chosen to reproduce results related to 'Rigging the Lottery: Making All Tickets Winners'. The code was based on that of the authors of the original paper. Results are consistent with the original ones for similar testbenches. However, tuning hyperprameters turned out to be challenging.\n\nThe reproducibility report is very well written, the problem is first formulated, the methodology is clearly presented, and the results are well described. The authors also indicate communications with those of the original paper, which is good to see.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper15/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper15/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=3VXeifKSaTE", "paper_id": "3VXeifKSaTE", "reviews": [{"id": "WBX-MOI0Z4X", "original": null, "number": 3, "cdate": 1615240141886, "ddate": null, "tcdate": 1615240141886, "tmdate": 1617290913673, "tddate": null, "forum": "3VXeifKSaTE", "replyto": "3VXeifKSaTE", "invitation": "ML_Reproducibility_Challenge/2020/Paper6/-/Official_Review", "content": {"title": "Review for 'FixMatch and Investigation on Noisy Labels and Confirmation Errors of FixMatch'", "review": "The report aims to reproduce the results of the paper 'FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence' The report gives a summary of how the reproduction is conducted and briefly introduce the original paper. The paper also gives the details including the hyper-parameters and computational infrastructures. \n\nThe authors provides the reproducing codes with detailed documentation.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper6/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper6/AnonReviewer1"]}, {"id": "BhjeArHq-JA", "original": null, "number": 2, "cdate": 1614634539927, "ddate": null, "tcdate": 1614634539927, "tmdate": 1617290913767, "tddate": null, "forum": "3VXeifKSaTE", "replyto": "3VXeifKSaTE", "invitation": "ML_Reproducibility_Challenge/2020/Paper6/-/Official_Review", "content": {"title": "Good Summary of the original work, and reproduction of results ", "review": " I can confirm that the authors include a clear summary of their work. They perform all their experiments using the CIFAR-10 dataset and highlight that the original paper was missing some implementation related detailed, which was later clarified. The authors use the same hyper-parameters, as the original paper and perform some ablation studies for the confidence threshold. The authors reproduce the experiments using pytorch and do not provide any recommendations to the original authors. The paper is otherwise well written, though slightly confusing at times. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have not read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper6/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper6/AnonReviewer3"]}, {"id": "_pKnqHYn8x", "original": null, "number": 1, "cdate": 1613127750535, "ddate": null, "tcdate": 1613127750535, "tmdate": 1617290913862, "tddate": null, "forum": "3VXeifKSaTE", "replyto": "3VXeifKSaTE", "invitation": "ML_Reproducibility_Challenge/2020/Paper6/-/Official_Review", "content": {"title": "Review", "review": "This submission reproduces the self-supervised learning results of FixMatch on CIFAR-10 and studies how the interaction between supervised and unsupervised learning objectives might lead to confirmation errors.\n\n**Reproducing results.** The submission successfully reproduced SSL results on CIFAR-10, with error rates within the ranges provided in the original paper (c.f. Table 1). Authors reimplemented the method using Pytorch (the official code used TensorFlow), following the method description in the paper and checking the official code when something was unclear in the manuscript. I believe that reproducing FixMatch using a different deep learning framework is an important contribution to the community.\n\n**Beyond reproducing results.** Authors devote an important part of the submission to their hypothesis that FixMatch might suffer from confirmation errors, including an exhaustive literature review. This goes beyond reproducing results and changing some hyperparameters, and can be seen as an improvement to the original method. Unfortunately, it is unclear whether the reported gains (e.g. Table 3) are statistically significant due to the lack of cross-validation or additional random seeds. The method has potential for a future workshop or conference submission if more experiments to back up the hypotheses are reported, thus I encourage authors to pursue these ideas.\n\nGiven that the submission not only reproduces some of the results of FixMatch, but also explores some of its potential limitations and proposes improvements to the method, I recommend its acceptance. \n\nMinor comment: the first half of the paper provides error rates, but then accuracy becomes the metric of reference. While both are essentially measuring the same thing, I would encourage consistency by using the same metric throughout the entire manuscript.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper6/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper6/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=r87dMGuauCl", "paper_id": "r87dMGuauCl", "reviews": [{"id": "o3Q0BkIUUYn", "original": null, "number": 3, "cdate": 1614634764227, "ddate": null, "tcdate": 1614634764227, "tmdate": 1617290914039, "tddate": null, "forum": "r87dMGuauCl", "replyto": "r87dMGuauCl", "invitation": "ML_Reproducibility_Challenge/2020/Paper4/-/Official_Review", "content": {"title": "Good submission and well documented", "review": "The authors of this report aimed at reproducing the method presented in the paper \"Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention\" published at CVPR 2020 by Garnot et al.\nThe authors not only did they attempt to reproduce the code and evaluate it on the dataset used in the original paper, but they also went on to use another dataset to expand upon the evaluation process, including some changes to the way the test set was selected in the original dataset.\nGiven that the authors of the original paper have made their code available allowed for a direct comparison between the reproduced code and the original code. In fact, the authors of this report have had some issues on some aspects of the use of the original transformer implementation, but that was resolved in a communication with the authors of the original paper and of the Transformer one. Minor discrepancies and issues with the implementation were also resolved via checking the provided github code of the original paper, hence confirming the reproducibility of the original paper.\nFinally, although the report is well written overall, I would have expected the conclusion to be a bit more elaborate on what was easy and what did not work as expected; but that is a very minor issue.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper4/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper4/AnonReviewer1"]}, {"id": "93piBmH_ix2", "original": null, "number": 2, "cdate": 1614629440647, "ddate": null, "tcdate": 1614629440647, "tmdate": 1617290914135, "tddate": null, "forum": "r87dMGuauCl", "replyto": "r87dMGuauCl", "invitation": "ML_Reproducibility_Challenge/2020/Paper4/-/Official_Review", "content": {"title": "Well written and insightful reproducability report", "review": "This report aims to reproduce a paper on classification of time sequences of satellite imagery using transformers. The report describes the attempt to reproduce the original paper from scratch, then using the provided code. In addition, the report adds on more investigation on another dataset.\n\nIn general, the report is very cleanly written. It was easy to follow along. It is valuable that the authors include their misconceptions and how they fixed it. The report clearly states the scope of reproducability and follows it. In their scope, the authors attempted to reproduce the paper from scratch. Then, they discovered that the original paper falls short on the explanation of the exact architecture being used. The authors consult the the sources included with the original paper and contact the original paper authors. Overall, this shows a healthy and admirable approach to scientific investigation and collaboration.\n\nThe report examines the architectural choices made in the original paper. The report experiments with the proposed approach and compares with a more standard architecture (Vaswani et al., 2017). This part of the report reveals insightful results that the standard architecture yields similar or even better results.\n\nThe report extends the original paper with an extra experiment on a new dataset.\n\nSuggested improvements or extensions:\n- As far as I understood, the report does not conduct the hyper-parameter search. Nor it tries to determine the stability of the hyper-parameters. This investigation would greatly improve the report.\n- With an exception for the case study mentioned above, the report doesn't provide any ablation studies. \n- The figures are almost impossible to read in black and white. I encourage to modify the figures to make them more accessible to people with black and white printers and the color blind.\n\nOverall, this is a well-structured, well-written report that analyses the original paper. Furthermore, the report extends the original paper with the results on an extra dataset. I recommend accept.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper4/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper4/AnonReviewer2"]}, {"id": "jimcajW7vNW", "original": null, "number": 1, "cdate": 1614529871941, "ddate": null, "tcdate": 1614529871941, "tmdate": 1617290914265, "tddate": null, "forum": "r87dMGuauCl", "replyto": "r87dMGuauCl", "invitation": "ML_Reproducibility_Challenge/2020/Paper4/-/Official_Review", "content": {"title": "Few details missing", "review": "The proposed work reproduces the result from \"Satellite Image Time Series Classification with Pixel-Set Encoders and Temporal Self-Attention (CVPR 2020)\". The proposed work was able to reproduce the result (except for different dataset) from the original paper. However, the consideration of the following points might improve the quality of the proposed work\n\n1) A thorough hyperparameter search and a corresponding discussion is expected.\n\n2) The original paper also demonstrates that the processing time and memory requirement is considerably decreased. It would be better to comment/validate this statement.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "reproducibility_summary": "Report has summary", "familiar_with_the_original_paper": "I have read the original paper"}, "signatures": ["ML_Reproducibility_Challenge/2020/Paper4/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["ML_Reproducibility_Challenge/2020", "ML_Reproducibility_Challenge/2020/Paper4/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=iSSYEihSvdY", "paper_id": "iSSYEihSvdY", "reviews": [{"id": "bcut7m7Vr_", "original": null, "number": 3, "cdate": 1610600151538, "ddate": null, "tcdate": 1610600151538, "tmdate": 1610846670150, "tddate": null, "forum": "iSSYEihSvdY", "replyto": "iSSYEihSvdY", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/-/Official_Review", "content": {"title": "visualizing patient data", "review": "The presented paper reports on a user study with 48 participants (2/3 students in the healthcare field, 1/3 practitioners) where they evaluated the usefulness of 5 representations of patient data.  Given a scenario with fake data, and 10 tasks (questions relating to the data), participants interacted with the system, then provided their opinion of the different representation options.  Participants most preferred the textual summary, followed by text + timeline, ranking the other types of graphs more poorly. \n\nQUALITY:   The paper appears sound and presents sufficient detail to understand the work.  It is clearly organized, well-written, and is generally well done. \n\nOne of the limitations of the paper, which is buried on the last page is the issue of the presentation format.  The system was meant to be a mobile app, but was instead displayed on a laptop/desktop screen, which stretched things and sometimes forced them to scroll.  I sympathize because I assume the authors had to switch to an online study due to the pandemic -- but in a visualization study, this seems like a pretty big deal (and may have contributed to participants' favouring the text representation).  Could there at least be a bit more discussion about the implications of this?\n\nCLARITY:  This may be due to trying to anonymize the paper, but the relationship between MHMR and the visualizations was a bit difficult to untangle (at various points I thought MHMR was the novel system being proposed in this paper, then I thought it was an existing system by other authors just mentioned as background, then I thought it belonged to the authors but was being extended).  Clarifying the relationship that would help.\n\nIt also wasn't clear whether the implementations of the visualizations was being claimed as a contribution.  If so, more detail about how the author went from the \"video data\" to data that can be displayed in the visualizations is needed. For example, how were the \"physical health symptoms\" extracted for filtering?\n\nFor the line graphs, how were participants supposed to figure out the meaning of the filled circles vs empty circles? There doesn't seem to be any legend. \n\nOn a related note:  During the sessions, how much instruction were participants given about the graphs and how to interpret them?  Also, were they told to use specific graphs for specific tasks?  Or could they use whatever they wanted?  If it was open-ended, how did the authors ensure that the participants interacted with each type of graph sufficiently to actually have an opinion about them?  (Could they have defaulted to text because that's just the first one they understood and they didn't really bother with the others?)\n\nThere are no details about how the qualitative analysis is complete.  It seems to have been fairly superficial thus far, but some detail about the analysis process would be useful. \n\nMinor:  Table 1 needs a better caption actually describing what is being compared as opposed to just the name of the test.\n\nMinor:  I think there's a missing word or something in this sentence -- \"The quantitative summary displays the  number data in the text.\"\n\n\nORIGINALITY:  The study presents visualizations that extend what appears to be an existing system created by the authors.  The five representations are sufficiently different from each other and represent and interesting comparison.  I think they were somewhat simplistic and agree with the authors that other options are possible, in particular if interactivity is incorporated.\n\nSIGNIFICANCE:  The paper makes a reasonable contribution and should probably be published.  Given the format of their study and the length of the sessions, it seems like there should be richer data available for more in-depth analysis.  I was hoping for a bit more depth, especially in the reporting of the qualitative results and in the Discussion section of the paper. \n\nThe conclusions seem a bit strong given what was evaluated and the results.  Saying that participants had positive attitudes towards visualizations when they most preferred the text representation seems like a stretch.   Basically the text representation acted almost as a control condition, and none of the others did better than it.     I still think it's an interesting study, but caution should be used to not over-claim.\n\nOverall, I think there are lots of tweaks that could/should be done to the paper, but it's likely above the bar. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/AnonReviewer3"]}, {"id": "97V0nmfmKHa", "original": null, "number": 2, "cdate": 1610593961169, "ddate": null, "tcdate": 1610593961169, "tmdate": 1610846670229, "tddate": null, "forum": "iSSYEihSvdY", "replyto": "iSSYEihSvdY", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/-/Official_Review", "content": {"title": "This is a user study paper in which test 5 different visualization methods for patient's speed words extracted from videos. The experiments are designed well and could support the conclusion based on the user study. These user studies is useful to further visualization design for this specific visualization.", "review": "This paper is pretty clear for me to read. The testing data, user study experiments and testers is very clear introduced in this paper. \n\nThis paper's topic is a bit away from by own research background. I could not evaluate whether the relaed works section is enough or not. Based on the current related works, many existing works are mentioned. It seems that the existing works did not explorate so many visualization in a single user study. And some works did not visualize the data as the method used in this paper. \n\nThe main drawback of this paper is the limated testing data. There are many kinds of patient data, not only the words extected from videos. During health care process, the patients will do many test about many different features about themself. It's more interesting to test the 5 visualization methods for those data. \n\nThe five visualization methods are clear introduced in this paper. However, the author did not try to present a specific novel visualization methods for the specific data. Then try to prove that the proposed methods are better than the existing methods. \n\n\n \n\n ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/AnonReviewer1"]}, {"id": "vVodDdZs_yn", "original": null, "number": 1, "cdate": 1610592103533, "ddate": null, "tcdate": 1610592103533, "tmdate": 1610846670303, "tddate": null, "forum": "iSSYEihSvdY", "replyto": "iSSYEihSvdY", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/-/Official_Review", "content": {"title": "Exploring Alternate Methods of Visualizing Patient Data", "review": "This paper explores five different graphical and text-based visualizations for summarizing patient-generated data in the MyHealthMyRecord system. The authors conducted a remote user study with 48 participants belonging to three different groups (e.g., professional healthcare providers, first/second-year medical students, and third or greater year medical students) to evaluate the usability and perceptions of each of the visualizations. The key results from the statistical analysis and qualitative data showed that the participants preferred the Text Summary and Text Graph visualizations and that there was no significant correlation between medical expertise and preferences for visualizations across the different groups. \n\nOverall, this is an interesting paper and I was impressed to see the scale of the study and the effort that went into recruiting medical professionals of varying expertise. Recruiting and working with such populations can be difficult due to their busy schedules, so it is great to see that the authors were able to include a large number of these participants in their evaluation. \n\nHaving said that, this paper was a bit difficult to read and the core contribution of this work to HCI and/or Visualization is unclear (and hasn\u2019t been explicitly stated anywhere in the paper). One key takeaway is that the medical professionals in the study preferred text-based visualizations for understanding patient-generated data. But, to the extent that this finding is novel and interesting is unclear to me. There are some other issues with the paper in its current form as well, as noted below.\n\nThe paper mentions the design and implementation of five different visualizations, but it is difficult to tease out the design phase of these visualizations and whether there was consideration of any particular design goals. Furthermore, the use of different visual variables such as colour to represent positive and negative sentiments is not clear and inconsistently represented in the figures (e.g. in the bar graph). The visualization decisions taken in terms of representation, presentation and interaction choices are not clear nor convincing. \n\nFurthermore, it was not clear if a certain visualization intended to solve a certain purpose in the user study, which was a bit of a disconnect from the earlier description in the paper. It seems that the ratings were dependent on the particular tasks that were prescribed. Since different tasks could be intended for extracting different information, it may be that some of the tasks could be biased for text cloud usage\u2014it would be helpful if the authors could clarify this point in their revisions. Moreover, the reasons for preferences were not convincing as in some cases the usefulness ratings for a visualization did not align with user\u2019s preferences. \n\nMinor: Figures 6-7 take up a lot of space and do not convey much new information that cannot be easily summarized in the paper in a couple of sentences.  In Figure 8, it is not clear what \u201cyears of experience\u201d refers to? In understanding patient data in general or in using visualizations? \n\nOverall, this paper has a solid motivation and some interesting results, but it appears to be too preliminary for publication. As the authors acknowledge in their discussion, there are some significant limitations and threats to validity of the results, making it difficult to assess whether or not the paper is making a novel contribution to the fields of HCI and/or Visualization. \n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper46/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=tufnZGWrWjR", "paper_id": "tufnZGWrWjR", "reviews": [{"id": "TzpCqRIfscQ", "original": null, "number": 3, "cdate": 1610514883911, "ddate": null, "tcdate": 1610514883911, "tmdate": 1610846671085, "tddate": null, "forum": "tufnZGWrWjR", "replyto": "tufnZGWrWjR", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/-/Official_Review", "content": {"title": "The paper presents the use of a single depth camera for skeletal tracking which is used to provide third person virtual locomotion controlled by head tilt and/or a hand held controller. User study is conducted for VR sickness, performance, usability and embodiment. It is a detailed study, though COVID 19 limited the number fo participants. ", "review": "In VR first person  perspective is considered the better choice for embodiment. Third person perspective has its own advantages as evident in many 3D games.  This paper explores the third person perspective for VR. It uses a single depth camera for skeletal tracking which is then used for virtual locomotion. They conduct a well designed user study experiment to compare locomotion and interaction through head tilt as one option for locomotion and a controller as the other option. User study seems to indicate that embodiment is better with the head tilt as compared to use of the controller, whereas usability and performance are better with the controller. VR sickness was not significant. \n\nEven though COVID 19 limited the number of participants, the study seems to have been well conducted. The overall implementation and experimental results are worth reporting.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/AnonReviewer3"]}, {"id": "NjaVOxBn9GN", "original": null, "number": 2, "cdate": 1610386236665, "ddate": null, "tcdate": 1610386236665, "tmdate": 1610846671171, "tddate": null, "forum": "tufnZGWrWjR", "replyto": "tufnZGWrWjR", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/-/Official_Review", "content": {"title": "This study explores the third person perspective with first person perspective when using VR applications and how this impacts upon measures such as performance, usability, embodiment, VR sickness", "review": "This is an interesting study exploring the impact of the third person perspective compared with first person perspective when using VR applications. Whilst the research presented here is novel, I feel the introduction and background sections could have been somewhat simplified to more clearly outline the research problem that is being explored here. More diagrams could have been used to explain some of the visual concepts that have been attempted to be explained purely in text. Similar issues persist in the User Study section, for example, a diagrammatic representation of the experimental setup would have helped to show the reader what the system architecture/technical instrumentation setup is that was deployed in the experimental system. It is difficult to conceptualise how the system was set up purely from the textual descriptions provided. The sample size of this study is small, and it therefore difficult to generalise from the results presented here, however, the results are interesting, although not surprising. For example, the improved performance using the gamepad controller was to be expected (although looking at the sample, there may have been several participants that may not even be very familiar with using gamepad controllers), also in terms of usability, again the gamepad controller was more accurate and efficient (quite possibly in part due to familiarity?). Embodiment was found to be improved in the 3PP condition, again probably not surprising, but a valuable finding nonetheless. And third person perspective with first person perspective VR sickness was similar in both conditions - I'm not sure why the authors state that this suggests that perspective *could* play a role in VR sickness? This is suggested both in the abstract and the conclusion, but there is no explanation as to why the authors think this could be the case? Overall, the abstract and conclusions are almost identical and also weak, and do not do justice to the work that is presented in the main body of the paper, this could be improved somewhat. Overall a good study, unnecessarily complex in terms of the background and related work sections which could also be significantly improved via the use of appropriate diagrammatic representations instead of complicated textual descriptions/attempts an explanation. Overall, however, a good piece of work. It's a shame the sample size is so small, as the contributions had the potential of being greater if the sample was bigger.\n\n  \n\n \n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/AnonReviewer1"]}, {"id": "0LLgcXBUEZ", "original": null, "number": 1, "cdate": 1610137458098, "ddate": null, "tcdate": 1610137458098, "tmdate": 1610846671257, "tddate": null, "forum": "tufnZGWrWjR", "replyto": "tufnZGWrWjR", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/-/Official_Review", "content": {"title": "Embodied Third-Person Virtual Locomotion using a Single Depth Camera", "review": "The authors present a third-person perspective locomotion technique based on the integration of skeletal tracking and head-tilt-based input. A user study shows that the proposed method enables high avatar embodiment when compared with a controller. \n\nComments:\n- The paper is very well written, and the proposed method is clearly presented. \n\n- One major issue is that I find that the virtual environment is straightforward. When comparing locomotion techniques, one has to take extra care when designing the task and virtual environment. In the paper, the task is navigating a path in an \"open\" virtual environment containing minimal visual detail. Having an open virtual environment where the target locations/path are visible from the user's current position can significantly and negatively affect the comparison between locomotion techniques. As stated in the paper, \"a controller was found to be more accurate, efficient, easier to the user and overall preferred ...\". This could, in fact, be attributed to the trivial task given the virtual environment used. A better way of conducting the user study would be to create a virtual environment where target locations are obscured from the user's view. This forces the user to maintain route directions in memory and update their mental map of their position by looking around for landmarks. Given the simplicity of the task and environment used, in my opinion, the comparison has reduced to choosing a preferred method due to familiarity, which, not surprisingly, is the controller. \n\n- In the Introduction, there is a reference missing [?]. Similarly, in Section 3 there is another.\n\n- Related work: I would suggest including, at the end of the section, a paragraph comparing how the proposed technique differs from the ones mentioned, and in particular with [31], which is using a similar setup. Why haven't you used multiple depth cameras like [31]? This would have solved the problem of the user stepping outside the tracking area. Also, the users wouldn't have to face the camera all the time to avoid occlusions. \n\n- One participant could not complete the study because of tracking problems. Why was the tracking failing for this one participant?", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper37/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=IC54qQMBFJj", "paper_id": "IC54qQMBFJj", "reviews": [{"id": "_mGEgCmBcX", "original": null, "number": 3, "cdate": 1610558533820, "ddate": null, "tcdate": 1610558533820, "tmdate": 1610846671393, "tddate": null, "forum": "IC54qQMBFJj", "replyto": "IC54qQMBFJj", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/-/Official_Review", "content": {"title": "This study explores the effectiveness of typewriter art that deploys a range of techniques to reproduce a given input image. The results are interesting, although, in the grand scheme of things,  I'm not sure how much value there is in comparing erroneous manually produced examples.", "review": "This is a well written study that presents a novel technique to generate typewriter art equivalent images based on a given example image. The topic of study is a little bit abstract, and some may question the value or potential contribution of such work, however, the research presented here seems sound and this may be of interest to some researchers. \n\nThere are some weaknesses in the work though, for example, the algorithm presented at the start of Section 3.1 seems to be overly simplified, to the extent that it is not really possible to understand what the claimed technique is actually doing when it processes and produces outputs. The outputs themselves are impressive and the technique (if it were revealed in its full glory) may well be of value to a range of researchers within this field and possibly in related fields of study.\n\nThe manually produced equivalent outputs that are used to evaluate the technique are interesting, but it highlights the fact that the instructions produced by this technique must be overly complex and extremely difficult to follow if so many errors occurred when attempting to follow them. It's not clear what the value of this element of the study was in the grand scheme of things, and if human error is creeping into the process, then perhaps more effort should be invested into ensuring the instructions are delivered in a comprehensible format. Indeed there does not seem to be any example of what the instructions output by the technique look like etc. Overall, I believe there is scope to talk about the limitations of this study in a bit more depth and also to deliver amore formal representation of the technique/s that have been employed by the system, however, it is a well written, and rigorous study, that I believe makes a reasonable contribution to the Graphics Interface community. ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/AnonReviewer1"]}, {"id": "MU9K-R2nMxJ", "original": null, "number": 2, "cdate": 1610300106649, "ddate": null, "tcdate": 1610300106649, "tmdate": 1610846671476, "tddate": null, "forum": "IC54qQMBFJj", "replyto": "IC54qQMBFJj", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/-/Official_Review", "content": {"title": "The paper presents and analyses an approach to generate Typewriter Art. Overall, results are good and the paper is clearly written. Some limitations of the approach could be discussed in more detail.", "review": "The paper presents an algorithm to convert images into Typewriter Art. This leads to a problem formulation that is similar to ASCII art, but extended to account for the nuances of this medium (e.g. key strikes of different strength, and the ability to type multiple layers of characters on the same page). To search the space of possible outputs for a high fidelity match to the original image, the author\u2019s propose two algorithms: one taking a greedy approach, and the other using simulated annealing.\n\nAlthough the application is a bit niche, typewriter art provides an interesting extension of previous work on ASCII art. The presented results analysing how various loss functions, resolutions, and the character set and number of overstrike characters affect results is reasonably through and demonstrate how algorithm parameters and design decisions affect the aesthetic and fidelity of results. \n\nThe ability to approximately reproduce the typewriter art using a physical typewriter is charming, although I expected a bit more discussion on how to simulate and account for physical limitations of the actual device algorithmically. \n\nOn the negative side, the algorithm runtimes are quite long (~1 hour for 6k charachters). A brief discussion of how this could be improved would be useful (it seems like some amount of parallelization should be possible). I\u2019m also curious about the runtime of the greedy algorithm compared to simulated annealing.\n\nFrom an NPR perspective, I did find it a bit strange that most of the results and discussion focused on creating a high fidelity approximation of the original image as opposed to recreating the unique aesthetic of typewriter art. I was also curious if the authors considered animated typewriter art as a future work (something that seems very difficult to achieve using an actual typewriter).\n\nIn summary, as a first foray in this area, the paper does a good job of framing the problem, providing a workable approach and highlighting many open problems. As indicated above, I do feel that further discussion of how some of these open problems could be addressed would be helpful and add to the value of the paper.\n\nMinor comments:\nFig. 11: I\u2019m assuming left is un-optimized and right is optimized?\nFig. 16: I can\u2019t find a reference to this figure in the text.\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/AnonReviewer3"]}, {"id": "UlF7hFstLNy", "original": null, "number": 1, "cdate": 1609266412352, "ddate": null, "tcdate": 1609266412352, "tmdate": 1610846671573, "tddate": null, "forum": "IC54qQMBFJj", "replyto": "IC54qQMBFJj", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/-/Official_Review", "content": {"title": "Review of \"Algorithmic Typewriter Art: Can 1000 Words Paint a Picture?\"", "review": "This paper presents a method for approximating  a source image using a mechanical typewriter's character set.  A scanned set of typed characters provides tiles able to contribute to the tone of an output image.  Given a reference image as input, the paper uses simulated annealing to choose scanned glyphs in a few overlapping grids in order to best approximate the tone and structure of the image.  The process can be further modulated by allowing overstrike (multiple glyphs in the same position) and variable striking force.  The paper presents a number of results\u2014most rendered synthetically, and a couple typed manually.\n\nAt first glance, this is a perfectly reasonable idea, and it produces results that are fun and attractive.  It's pretty classic NPR: we're processing a source image to create an artistic output, but the output medium is constrained and we have to produce the best possible result under those constraints.  The algorithm, then, is a kind of projection operator onto the manifold of all images that can be formed from type.  There's not a huge amount of novelty here, but it's still interesting enough.\n\nBecause the technique operates on scanned images of typed characters, I see a kinship with Photomosaics, something not mentioned in the paper.  (The use of multiple overlapping grids is the obvious departure from Photomosaics.)  There's also some connection to Hertzmann's 1998 Painterly Rendering paper, in that we proceed through a set of layers, each layer optimized to pick up the residual energy not handled by previous layers.  I'd swear I've also seen the idea of an asymmetric MSE somewhere before, but I'm not sure I'll be able to pull that out of the memory hole.\n\nHowever, there were a number of small-to-medium issues with the paper, which left me unsure about whether it should be accepted.  Here are my main concerns:\n\n * There's a tension in work like this, having to do with the optimization's objective function.  The problem is that if you somehow achieve a perfect solution (i.e., no error between the source image and the typed characters), you won't be happy\u2014you'll just have the original image again!  These artworks are interesting precisely because there's error in the output, allowing the individual typed characters to show through while still communicating the source image.\n\n   I think the paper should do more to acknowledge this tension.  Perhaps it's as simple as noting in the introduction that we'll always end up with error in the optimization, and that's a good thing.  But this could inform changes to the algorithm to favour individual characters showing through when the image approximation is good enough.\n\n * It should always be clear which figures are rendered and which are physically typed.  One option is to say something like \"unless otherwise noted, all images are computer-generated\" (I think they're the majority...).\n\n * Figure 1: How many characters are there?  What does \"12 layers in 4 positions\" mean?  That's not like anything described in the paper.\n\n * The introduction should clarify that we're talking about mechanical typewriters\u2014even early electric typewriters can't vary their strike force.\n\n * By no means does Figure 3 outline an algorithm.  It shows the inputs and outputs, and nothing else.  I'm not sure how useful the figure is; I'd like to see more of the scanned typed page.\n\n * The connection made to halftoning in Section 2 is tenuous.  The scanned type samples are most definitely variable in tone, and Figure 17 shows clearly that this makes a big difference.  I'm not sure what to do about that.\n\n * There's some preprocessing that's not discussed in the paper.  How is a scanned page of type decomposed into individual glyphs?  How are the metrics of the typewriter (character spacing, leading, etc.) determined?  Obviously these problems are interrelated.\n\n * How does the complexity of the algorithm vary with the number of distinct characters available?  Are all of a typewriters characters used?  If we render a digital font, which characters are chosen?\n\n * What is up with Algorithm 1?  It's never referenced in the paper, and its details directly contradict those provided in the surrounding text.  The initialization is different, as is the order in which character positions are visited.  It doesn't use simulated annealing.  And so on.\n\n * The algorithmic details in Section 3 are confusing.  Some pieces add up to a complete algorithm, but some pieces supersede earlier ones.  The description of simulated annealing overrides the stopping condition in Section 3.2, right?  \n\n * The cropping in Section 3.4 isn't described in nearly enough detail for me to understand what's going on.\n\n * Section 3.5 describes simulated annealing in general terms, but doesn't provide enough detail to reproduce the probabilities and cooling schedule used the produce the results in the paper.  The paper should provide precise details about temperatures and acceptance probabilities, even if it's only in an appendix or in supplemental material.\n\n * Section 4 is called \"Results\", but to my eye it contains a lot more information and algorithmic details.  I think a lot of this material should be reorganized to pull out a real results section.\n\n * 4.2.1: So, do we start with a blank page, or with random characters, as stated in Algorithm 1?\n\n * I don't understand how to interpret Figure 7.  I need more guidance on what this plot means.  I also have no idea what the labels on the data points refer to.\n\n * 4.2.2 is slightly confusing.  The text says \"SA consistently finds a lower-error state...\", but the graphs in Figure 6 show PSNR, where higher is better.\n\n * In Section 4.2.3, I'm surprised that there's no attempt to experiment with light-to-dark or dark-to-light selection orders.\n\n * Section 4.3.1: Again, I see that cropping is important, but we're given no information on how it's done.  Also, give error measurements for the images in Figure 10.\n\n * Section 4.5 says that less tonal variation can \"draw more attention to the textual characters\".  But as noted above, maybe that's a good thing?\n\n * In Section 4.6, how are overlapping letters composited?  Scanned letters are greyscale images and not masks, so you need to something to combine overlapping layers of ink.  What is it?  Is it physically realistic?\n\n * The magic number of 5790, discussed in Section 5.1, is cute but tenuous.  After all, no attempt is made to use \"words\" (which would be very interesting, of course).\n\n * The experiment with multiple strike forces is interesting, but ultimately I'm not sure it's successful.  It's an idea that works reasonably well with synthetic results, but we see evidence that it's too fussy to reproduce by hand.  Are there examples of hand-made typographic art that exploits multiple strike forces?\n\n * Please provide links to source photos and scanned character sets, for anybody interested in following up on this work.  This could be in a supplement.\n\n * Section 5.2 says \"Tonally, the gradient produced in the rendered result is reflected in the physical typed result\".  Where is this?  What figure am I looking at?\n\n * The hand-typed result in Figure 20/21 is great!\n\n * Figure 22 and the text underneath it need a lot of work.  Text like \"the variation in strike force is apparent on B and % characters\" and \"note how the 12 and y characters\" is almost useless, especially when these characters appear multiple times.  If there's something specific to look at in Figure 22, point to it or highlight it in the images, possibly by adding close-ups.\n\n   Of course, it would be much easier to demonstrate the variation in tone in a simple experiment: just type the same letter a lot of times and show it to us.  Maybe measure the variation directly.  There's no need to evaluate this variation only in-situ in a complex image.\n\n * What's 0.15% in Section 5.2?  Maybe just say how many characters were mistyped?  How was that measured?\n\n * Overall the writing is fine, though there are grammatical mistakes in some places.  For example: \"this partly caused\" in Section 5.2, and \"it is more probably\" in Section 3.5\".  I'm sure these issues can be eliminated with careful proofreading.\n\nAdding up all the concerns above, I'm left somewhere in the middle.  The technique is probably publishable, but I think that many improvements are needed to the paper, perhaps too many to accept it directly.\n\nPostscript: if you haven't seen it, be sure to watch the 1988 film \"Primiti Too Taa\", my favourite piece of typewriter art. https://www.youtube.com/watch?v=mOdsmfjCunM", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper36/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=1dLDPJeafRZ", "paper_id": "1dLDPJeafRZ", "reviews": [{"id": "b-Yx1wvZ9M", "original": null, "number": 3, "cdate": 1610581849439, "ddate": null, "tcdate": 1610581849439, "tmdate": 1610846672018, "tddate": null, "forum": "1dLDPJeafRZ", "replyto": "1dLDPJeafRZ", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/-/Official_Review", "content": {"title": "Nice paper; no validation", "review": "The paper presents a new assistant tool for Autodesk Fusion 360, target at novice users, that notices regularities (equal sizes, parallelism, ratios, etc) and suggests to add those as constraints. These regularities can be processed either within a single sketch or across a collection of sketches. Once those constraints are in, the model can be parameterized and then reused in, say, Customizer. This simplifies the creation of parametric models and hopefully will increase their percentage in datasets like Thingiverse.\n\nI personally loved the paper: it's clearly written, solves a very well defined task, addresses an important problem (it is indeed very hard to create parametric models), and has quite a few clever ideas along the way. For example, the idea to use previous statistical analysis to understand the more used types of relations/regularities people use and suggest only those can be very powerful, even if the idea itself is straightforward. My only complain on the text is that it's a little repetitive and can be shorter (for example, beginning of the related work repeats word by word phrases from the intro, and 4.1 repeats parts of 3.2). \n\nMy only real concern, however, is complete absence of validation. I would have expected one or two user studies proving that the system is a) usable and b) saves time designing parametric models. This is the only reason why I'm not giving a higher score, other than that I'm quite sure this is useful and well done.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/AnonReviewer3"]}, {"id": "Iq-rr9l2erA", "original": null, "number": 2, "cdate": 1610577777489, "ddate": null, "tcdate": 1610577777489, "tmdate": 1610846672093, "tddate": null, "forum": "1dLDPJeafRZ", "replyto": "1dLDPJeafRZ", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/-/Official_Review", "content": {"title": "The paper presents an interactive software tool for facilitating the design process of CAD models by proposing constraints to novice users. While the tool seems practical and well implemented, there is no technical novelty in finding and proposing new relations. Furthermore, it is unclear how well it scales to more complex designs. ", "review": "The paper presents an interactive software tool for facilitating the design process of CAD models by proposing constraints to novice users. This user interface is available as a plugin for Autodesk Fusion 360.\n\nThe paper is well-written and easy to follow. It also presents an extensive overview of the related work. The problem that is being addressed is interesting and useful. Implementation and workflow are well explained. \n\nThe main contribution of the paper seems to be an intuitive user interface for CAD modeling. While the paper gives solid examples of the use case, a user study would improve the quality of the work. Furthermore, there is not much novelty in how to search for and how to compute relations for constraints.\n\nAnother downside is that the presented examples look too simplistic. It would be good to show a more complex sketch. It is unclear how fast the CODA computes and proposes constraints. How does the computation time increase with the object complexity? ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/AnonReviewer1"]}, {"id": "v4Mc845G0H", "original": null, "number": 1, "cdate": 1610334545487, "ddate": null, "tcdate": 1610334545487, "tmdate": 1610846672171, "tddate": null, "forum": "1dLDPJeafRZ", "replyto": "1dLDPJeafRZ", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/-/Official_Review", "content": {"title": "The paper presents an interface to help aid novice users in parameterizing CAD models. Simple examples throughout the paper help demonstrate its utility in designing well-parameterized CAD models. On the negative side there is no formal evaluation of the proposed tool, making it unclear how well it works in practice or how it scales to more complex CAD models.", "review": "While parameterized CAD models allow for quick adaptation and redesign of an existing model, authoring well-parameterized models is challenging \u2013 especially for novice users (e.g. hobbyists from the maker community). The paper presents an interactive software tool to aid in the design of CAD models, which aims to help novice users create well-parameterized models, by identifying unconstrained relations, and presenting them to the user via interactive animations.\n\nOverall, how the system is implemented and would be used is well-explained. The design of the system (e.g. how constraints are identified and presented to the user) appears grounded in the literature on how CAD software is used and the difficulties users encounter in creating parametric models. The presented case studies, including the design of the laptop stand, provide a tangle impression of how the system could be used to streamline the process of constraining parametric models. \n\nThat being said, I still find it unclear how well the system works in practice. It appears that the main novel contribution of the work lies in interface design. Without some form of formal evaluation of the tool\u2019s usability it is difficult to tell how well CODA achieves its intended goal \u2013 aiding novice users in the design of well parameterized CAD models. This problem is made more pronounced by the fact that many of the references used to support design decisions seem to be based off the work of experienced CAD users (e.g. Millis et al., Langbein et al). \n\nI am also concerned by the scalability of the interface to more complex models, it\u2019s unclear for me that users would be able to effectively navigate the increasing number of automatically generated constraints to create well-parameterized models. Some statistics on the number of constraints identified and presented to users for a selection of models may be helpful in this regard. Similarly, I\u2019d like to see some runtime information (e.g. how long it takes to generate constraints, and how interactivity scales with model complexity). \n\nAlso, the substantial literature on extracting constraints in the context of reverse engineering makes it harder to appreciate the approach for extracting unconstrained relations as a contribution. Some comparison of the proposed approach to pre-existing works in this context would strengthen the paper. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper34/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=6gaOU6UA6pa", "paper_id": "6gaOU6UA6pa", "reviews": [{"id": "zTYNhXKKu_O", "original": null, "number": 3, "cdate": 1610569878506, "ddate": null, "tcdate": 1610569878506, "tmdate": 1610846672311, "tddate": null, "forum": "6gaOU6UA6pa", "replyto": "6gaOU6UA6pa", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/-/Official_Review", "content": {"title": "Developable mold creation with paper and wax", "review": "The authors present a Blender add-on which allows a user to create a paper-and-wax mold for rapid prototyping. They show their method is fast and relatively cheap for simpler shapes. The resulting models are rough approximations, with the wax covering resulting in some defects, but this may be suitable just for prototyping. A main concern of mine is that the speed advantages would likely decrease with more complex shapes and would require successively more modelling and manual construction skill. \n\nPerhaps the first limitation is that the user must break the model up into developable pieces that approximate the shape. (Actually, the authors suggest that there is an automatic procedure, but do not discuss this method). For shapes with parts that are far from developable, this is a non-trivial modelling task, and may require many individual pieces (\"islands,\" for them). Here it could be useful to perhaps leverage techniques from \"Making Papercraft...\" by Mitani & Suzuki, or the more recent \"Shape Approximation by Developable ...\" by Ion et al. to come up with automated techniques.\n\nOn a related note, the use of LSCM is a bit strange, as it is attempting to produce a conformal parametrization (or UV unwrapping, as they call it), and would not necessarily preserve developability. I think again, it is left to the user to ensure that this does not become an issue.\n\nOn the positive side, I did find the exposition to be fairly clear, and it seems to be a novel approach as far as I can tell. And they've certainly put some effort into making a nice user interface. As such, I'm willing to give it a rating that just passes.\n\nLast note: the pictures for the tool (Figs. 4-7) are all rather low-quality and nearly impossible to read. These should certainly be improved, if the paper is accepted.", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/AnonReviewer1"]}, {"id": "LaEFwsGE97u", "original": null, "number": 2, "cdate": 1610564865447, "ddate": null, "tcdate": 1610564865447, "tmdate": 1610846672385, "tddate": null, "forum": "6gaOU6UA6pa", "replyto": "6gaOU6UA6pa", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/-/Official_Review", "content": {"title": "Fast but limited mold prototyping ", "review": "The paper presents a system to generate 2d cut patterns of casting molds that can be easily produced and assembled from paper to be used for casting objects. \n\nThe idea could be useful for fast prototyping but is very limited in terms of scope and automatisation. The method seems to be only useful for very simple polygonal shapes which excludes most use cases for molding. Even for these simple cases manual intervention seems to be usually necessary.\n\nMaybe I missed it, but I did not see any guarantees for unfoldability. Moreover, using LSCM for unfolding does not guarantee an isometric mapping. As a consequence the mould might not be assemblable from the 2d cut pattern.\n\nWhile the described process of waxing the paper and fabricating the molds is interesting, I am not convinced that the presented plugin provides a big advantage over manual modelling given the small scale of objects. Therefore I see the contribution mainly in the process itself.\n\nMy rating is still leaning towards acceptance as fast prototyping remains relevant and because the idea itself is innovative and could potentially inspire further research.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/AnonReviewer3"]}, {"id": "OBQa9XT--yX", "original": null, "number": 1, "cdate": 1610548602753, "ddate": null, "tcdate": 1610548602753, "tmdate": 1610846672469, "tddate": null, "forum": "6gaOU6UA6pa", "replyto": "6gaOU6UA6pa", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/-/Official_Review", "content": {"title": "A nice idea but lacking key information about the level of automation in the mold design software ", "review": "This work proposes a new DIY method of mold creation using paper and wax for casting operations. Apart from the idea, the method is augmented using a Blender app where the user can define cuts or perforations such that the mold can take the desired shape. \n\nThe strength of this paper is the nice, simple and probably practical idea. I would like to see more examples of casting different objects to support the practicality aspect. \n\nThe weakness of this paper is the exposition. I am not talking about writing. The most important question is that how much automation is in the mold design app? Reading the paper, I could not really tell. Furthermore, the texts in Figures 4, 5, 6, and 7 is not readable when I print the article. They can be improved. \n\nReferences are for the most part good. The work on making clear molds for photopolymers (\"FabSquare: Fabricating photopolymer objects by mold 3D printing and UV curing\") and on flexible shells (\"FlexMolds: automatic design of flexible shells for molding\") could be cited. \n\nI think the paper is clearly written and I only spotted a few possible mistakes in writing: \n- I think the reference bracket should come immediately after \"et al.\". \n- Section 3.1: \"also be divided onto multiple islands\" -> \"also be divided into multiple islands\" \n- Section 7, the quotation mark around \"draft quality\" should be corrected. ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper33/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=2u0ejbSOuWw", "paper_id": "2u0ejbSOuWw", "reviews": [{"id": "vD0i_Wylhfb", "original": null, "number": 3, "cdate": 1610575247293, "ddate": null, "tcdate": 1610575247293, "tmdate": 1610846672934, "tddate": null, "forum": "2u0ejbSOuWw", "replyto": "2u0ejbSOuWw", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/-/Official_Review", "content": {"title": "Challenges in Getting Started in Motion Graphic Design: Perspectives from Casual and Professional Motion Designers", "review": "The paper presents challenges faced by motion graphic designers based on an interview of 19 casual and professional motion designers working on a range of motion graphics projects. Their results reveal the difficulties of getting started in the field and the workarounds proposed by motion designers of varying expertise. Based on these findings, the authors identify opportunities for HCI\nto lower entry barriers by designing user-centered.\n\nThe paper is relevant to the HCI community and fairly well-written. I am particularly impressed by the diversity of the interview participants with respect to the countries represented. However, the participants are majorly males (75%) and it seems like most of them are University students. That brings to question, the generalizability of the findings across gender at least. \n\nAlthough only 5 females were involved in the interview compared to 14 males, it may be interesting to explore possible differences and similarities in barriers to entry, challenges, and proposed solutions across males and females. I would also like to see some reflection on the possible relationship between identified challenges and participants' training background. Perhaps, people trained in more technical backgrounds such as design and other IT related background may experience lower or different challenges compared to those trained in some social science backgrounds such as education and communication.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/AnonReviewer1"]}, {"id": "Vs8Otn1LFmy", "original": null, "number": 2, "cdate": 1610497966915, "ddate": null, "tcdate": 1610497966915, "tmdate": 1610846673125, "tddate": null, "forum": "2u0ejbSOuWw", "replyto": "2u0ejbSOuWw", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/-/Official_Review", "content": {"title": "Insight into designers' workflows and challenges for making motion graphics videos", "review": "This paper presents the results from a series of interviews with 19 professional and hobbyist designers of motion graphics videos, presenting the results in a way that aims to highlight HCI opportunities for improving the accessibility of tools for creating such videos.\n\nOverall, I find the quote-heavy insight into motion video designer's processes and challenges to be quite interesting and potentially useful to others in the area. This is the biggest strength of the paper.\n\nThe biggest weakness of the paper is the lack of a clear research thread that connects all the pieces throughout. The paper aims to improve accessibility to entry to creating these videos, and yet the up-front argument for the need isn't convincing. To be clear, I agree with the authors, but the argument as presented needs to be better grounded, e.g., in research telling us that people struggle with this. Points such as cost do not help, e.g., professional websites easily cost more than the figure listed, and yet simple websites are now very easy to create. Consider backing this better.\n\n - the RW seems to focus more on defending the importance of motion graphics and not situating the research goal of accessibility to new users. The end has a little on feature-rich software, but I feel this should be the focus.\n\n- The selection of experts / experienced people to learn about how to support accessibility (instead of studying beginners, for example) is suspect and not well defended.\n\n- The research questions leading into the semi-structured interview design and analysis strategy were not clear, and the ones hinted at (understand their struggles) are not defended from the perspective of supporting accessibility.\n\n- as a result of this, the insights / outcomes for HCI at the end read quite generic and not that helpful unfortunately.\n\nIn my personal opinion, this paper would be a lot stronger if the authors worked on streamlining the argument, making it more concise (it's currently verbose), and focused more on the value of understanding experts' challenges. It would be a lot shorter and have more potential for impact.\n\n(finally, small point: I did not find figure 2 helpful.)\n\nIn the end, for a GI paper I feel that this could be accepted based on the qualitative data as presented, although I worry about the potential for impact given the framing issues: readers may just look over it or ignore it based on the flaws listed.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/AnonReviewer2"]}, {"id": "GGLSbBs07M", "original": null, "number": 1, "cdate": 1610332401727, "ddate": null, "tcdate": 1610332401727, "tmdate": 1610846673021, "tddate": null, "forum": "2u0ejbSOuWw", "replyto": "2u0ejbSOuWw", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/-/Official_Review", "content": {"title": "Well-written paper exploring an interesting question of how to support casual motion designers. This reviewer has concerns about generalizability of findings, novelty of design recommendations, and some minor points on clarity of writing.", "review": "This paper presents the results of a qualitative interview study of the challenges and barriers casual and professional motion graphic designers experience when creating motion graphics videos. Based on the findings, design opportunities for HCI user-centered tool support are proposed. \n\nThe paper is generally well-written. The use of interviews is well-justified and the methodology section is explained with appropriate detail. Overall, the goal of supporting domain experts who are \u201ccasual motion designers\u201d is an interesting direction for exploration. I do have some concerns regarding 1) the generalizability of findings, 2) novelty of design opportunities and its relation to previous research and 3) clarity of writing. I believe addressing these will strengthen the manuscript and increase the significance of its impact. \n\nGENERALIZABILITY OF FINDINGS AND DESIGN IMPLICATIONS.\nIn the \u201cLimitations\u201d section, it is stated that \u201cAdobe After Effects\u201d has a significant prominence in the industry\u201d, and participants \u201cdid not have much to compare it with\u201d. Can the authors clarify what software systems the 19 participants used when creating motion design videos? At present, it is unclear whether these are general problems experienced causal motion designers, or whether the interview findings largely reflect the challenges of using Adobe After Effects? If it is the latter, the generalizability of findings and design implications may be problematic.\n\nDESIGN OPPORTUNITIES.\nSections 5.1, 5.2, 5.3, 5.4 seem a bit high-level and vague.\n\nThe design opportunities are mostly framed with regards to what is lacking in commercial software. Can the authors also ground their design recommendations in existing academic research? There seems to be a lot of work in this area, but at present, the authors only address or mention this superficially. Could the authors contextualize their design recommendations in relation to current literature? (e.g. with regards to novelty / significance?)\n\nI agree that there are challenges using feature-rich software tools but also wondered about the abundance of existing online tutorials and how or whether participants were able to utilize those. Is the barrier feature-rich software applications or is the barrier perhaps helping causal designers find appropriate, personalized resources to help them achieve their task while using feature-rich software?\n\nSuggestions -\na)  I was surprised that none of the design opportunities discussed technological support for the creative storytelling challenges of creating motion graphics videos. The interview findings suggested that the creativity aspect may be a possible barrier, e.g. \u201cblank canvas\u201d, \u201cthe confidence to\u201d, \u201cgetting inspired\u201d, \u201ccreative freedom\u201d.  This may be an interesting direction to explore in this manuscript or future work.\nb) I was also surprised, given the interview findings, that technology support for building online communities, learning or a shared knowledge base was not proposed in the design opportunities section. Can the authors clarify why this was the case?\n\nCLARITY OF WRITING.\nFrom the introduction and related work section, I was not sure exactly who the study is about (casual designers, professional designers, or both). It wasn\u2019t till Section 5 that clarified the authors\u2019 focus on domain experts who undertake the task of creating motion graphics videos and who need to convey nuanced subject matter. I suggest the authors make the focus on domain experts clearer in the framing and introduction of the work. The authors may also consider introducing the paper with a scenario of a domain expert and their motivation/challenges/workflow/tasks, etc to paint a more vivid picture of who the user is and the barriers they experience.\n\nMINOR.\n- Figure 3 is confusing. It introduces new information and terms (e.g. \u201cbriefs) but these terms aren\u2019t described in the text. Also, the caption talks about how casual designers skip \u201cthese steps\u201d but the words \u201cpre-production\u201d, \u201cproduction\u201d and \u201cpost-production\u201d are not present in the Figure, nor explained in the text. \n- Missing period at end of first paragraph Section 3.1\n- Missing colon page 5, end of paragraph \u201c.... to create different content types\u201d\n- Section 4.5 should refer to Table 2.  \n- Section 4.4 seems more relevant to professionals, rather than casual designers. ", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper31/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=Hce9RpAIZbc", "paper_id": "Hce9RpAIZbc", "reviews": [{"id": "lH1kywtL9Sk", "original": null, "number": 3, "cdate": 1610560423915, "ddate": null, "tcdate": 1610560423915, "tmdate": 1610846661862, "tddate": null, "forum": "Hce9RpAIZbc", "replyto": "Hce9RpAIZbc", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/-/Official_Review", "content": {"title": "EMS-based posture correction technique", "review": "This paper presents a nice interface design, implementation, and study relating to using Electrical Muscle Stimulation - where electrical pulses create involuntary muscle contraction - to support healthy posture awareness and correction in adults. I liked reading this paper - it was a simple idea, a nice thorough background treatment, and detailed implementation and study sections. I recommend it for publication.\n\nAlthough my initial reaction was to envision people being shocked and forced into uncomfortable positions (laugh), the fact that the sensation is a simple pulling and the user still has to fully correct their posture, is key to this actually being viable.\n\nI think the biggest weakness of the work is perhaps the verbose writing. It is quite long winded, and without removing any actual content I think the paper could be shortened significantly, increasing the potential for broader reading and thus its impact. \n\nI do have some comments\n - Please clarify if this work received institutional ethics clearance. It is hinted at in the paper but I couldn't find it mentioned explicitly.\n - I'm not sure the up-front framing does the work justice. The abstract highlights user perceptions, but the paper also found actual results on response time and posture accuracy. Perceptions, of course, are highly biased given that participants likely know your favorite. I would suggest couching analysis / presentation of user perceptions in a relevant way, e.g., may relate to willingness to adopt.\n - the RW is a bit too list-like. While this is helpful as a resource, I felt it would be stronger with a more thematic approach - may also help condense the writing.\n - For H4, your hypothesis is that \"will not be significantly different\". I think this test actually requires equivalence testing, which is not what you did. You may want to revise the hypothesis to match what you did, e.g., \"no evidence will be found for a difference between...\". Subtle but important difference, I think.\n - for the post-hocs did you do family-wise correction?\n - I was surprised to see little negative discussion from the participants on the EMS system. really? \n - ", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/AnonReviewer1"]}, {"id": "_vtfZ4h5ZFl", "original": null, "number": 2, "cdate": 1610540540369, "ddate": null, "tcdate": 1610540540369, "tmdate": 1610846661961, "tddate": null, "forum": "Hce9RpAIZbc", "replyto": "Hce9RpAIZbc", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/-/Official_Review", "content": {"title": "Novel technique and good study", "review": "The paper \"Automatic Slouching Detection and Correction Utilizing Electrical Muscle Stimulation\" presents a technique for detecting and correcting a slouching posture when seated at a desk. The technique uses a combination of IMU sensors and electrical muscle stimulation (EMS). A study is presented where EMS is compared to visual feedback when slouching is detected. Two tasks are studied, one where the participants are doing word processing on a laptop and one where the participants are playing a mobile game. Results show that slouching is corrected more quickly and accurately using EMS and that the participants preferred this approach over visual feedback.\n\nThe paper is very well written, well structured, and easy to follow. The technique presented is well-designed and the comparison between visual feedback and EMS is convincing. Generally, the explanations in the paper are very pedagogical. The coverage of related work is good, and it is clear to see that there's a novel contribution in the paper. \n\nOne thing I was missing from the paper was an understanding of how prevalent slouching is. It could, e.g., have been interesting to have a baseline in the study where only slouching detection was monitored without any feedback to correct it. This way, it would be possible to assess how much the technique improved overall posture.\n\nOverall, I recommend accepting this paper.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/AnonReviewer3"]}, {"id": "_UsQn3Fihis", "original": null, "number": 1, "cdate": 1610538349808, "ddate": null, "tcdate": 1610538349808, "tmdate": 1610846662049, "tddate": null, "forum": "Hce9RpAIZbc", "replyto": "Hce9RpAIZbc", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/-/Official_Review", "content": {"title": "First steps towards an in-depth investigation of automatic posture correction through ems", "review": "This paper reports on an early prototype and user evaluation of a wearable system that exploits electrical muscle stimulation to automatically correct slouched posture. The exploration of physiological feedback for the design of new interactive systems is a compelling research area and indeed research is needed to understand the integration of interactive technology with the human body. As such, the research is original in that it investigates the use of ems as a mean for automatic posture correction: previous studies focused on sensors systems for posture monitoring, with audio and visual and haptic feedback to promote voluntary posture correction.\n\nThe work, however interesting, is still in its infancy. With the evaluation, authors show that EMS is promising, but unfortunately, the most critical issues are only mentioned in the future work section and the discussion of the results is shallow. The length of the paper, therefore, does not match with the contribution: more work is needed to strengthen (1) the design and technical implementation of the system, as well as (2) the experimental evaluation and (3) the implications of the results. \n\n1.\tThe implementation of the system seems very straightforward with respect to the design choices to detect a slouch posture. The system look very much like an early prototype that can be used in early design stage to gather requirements or test design ideas. I was expecting many of the functionality reported as future work to be implemented in the system. \nThe threshold level and the time period to model the slouch posture seem to have been determined empirically, that the authors report to validate in a pre-study trial. I miss a detailed account on the empirical testing and the choices the authors made to finally opt for the selected sensor setup. \nI also wonder why the authors used SMS as a mean to trigger visual information on the mobile device. SMS delivery introduces an unreliable delay that affects the response time. How did the authors take that into account?\n\n2.\tThere are already IMU-based systems for slouch detection and the contribution of the paper relies on the use of EMS as an autocorrection mechanisms. In this respect, authors use visual and audio feedback as baseline for their evaluation. I wonder why they didn\u2019t compare their system with haptic feedback solutions. \nAuthors report that \u201cAs EMS also produces a tactile or haptic effect even at low intensities, participants were asked to not respond to the tactile or haptic effect to ensure haptic/tactile component of EMS does not contribute to the automatic correction process in any way\u201d. How can the authors be sure that they isolated the user response to haptic feedback? The authors report in the text that during the experimentation users seemed to learn how to interact with the system, which suggests that participants responded to the haptic feedback of the ems and create a sort of symbiotic interaction: a conscious autocorrection. This is a very interesting area to investigate and more longitudinal studies are needed to understand to what extent autocorrection mechanisms and haptic feedback (maybe together with audio and visual) can be designed to raise users awareness toward to their posture. Increasing awareness is only briefly mentioned in the discussion.\nI also have issues with the experimental setup. What is the effect of the hardware setup (laptop vs mobile) on users\u2019 posture? While I agree that the task are representative, the physical setup is not in the case of the mobile device. Were the participants able to move at least the device freely (e.g., bring the device closer to their head)? From Figure 1 it seems that participants had to interact with the device with their hands touching the table. \n\n3.\tI miss, in the discussion, the authors\u2019 interpretation of the difference in the intensity of the electrical stimulation for the two conditions. Was it something that depended on the physical setup of the experimental tasks?\nI also miss a more in depth discussion that resulted in insightful findings on the user experience that ultimately would inform the design of the wearable system. For example, the authors report that participants perceived ems feedback as more accurate. Neglecting the fact that there is no definition of what \u201caccurate\u201d means in this context, the authors only list some factors that \u201cmay have\u201d cause it, which makes the finding not particularly meaningful. \nMinor issues: \nI suggest authors to reduce the verbosity of the paper. There is room to reduce the state of the art and also there are repetitions in the text that could be removed, thus helping to shorten the paper and improve the clarity. For example the sentence \u201cSeventy- five percent of the study population (27 out of 36 users) reported that they would purchase EMS feedback for slouched posture correction if it were commercially available\u201c appears twice in the text.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper29/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=xJrzLYT2YL7", "paper_id": "xJrzLYT2YL7", "reviews": [{"id": "n9e8VS0NDom", "original": null, "number": 3, "cdate": 1610513758560, "ddate": null, "tcdate": 1610513758560, "tmdate": 1610846662189, "tddate": null, "forum": "xJrzLYT2YL7", "replyto": "xJrzLYT2YL7", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/-/Official_Review", "content": {"title": "The paper presents some accuracy improvements over order independent rendering of scenes with transparent objects, without requiring total back-to-front ordering of objects. A number of heuristics are introduced to get a practical solution. The contribution is more in the practive category. ", "review": "The topic of this paper is rendering of scenes with transparent objects. Usually, transparent objects are rendered in back to front order, which requires sorting. Sorting is computationally expensive and slows down rendering of large scenes with high depth complexity. Order independent methods have been proposed but usually result in artifacts and inaccuracies. The authors present a method that avoids total sorting, while providing reasonably good approximation.  They slice the view frustum into  bins, and assign objects  to these bins. Bins are rendered in order. Objects within a bin are dealt with in an order independent manner. Since total sorting is avoided, computational complexity is reduced. A number of heuristics are introduced to make the method yield reasonable results, such as objects crossing bin boundaries, distance within a bin, etc. . They have experiments which show improvements over the order independent method.  \n\nThe main contribution is in deciding to replace total ordering with partial ordering using bins. The method has its limitations, but seems practical as long as scenes do not have both high depth and high geometry complexity.  ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/AnonReviewer3"]}, {"id": "hIXb7BUTp47", "original": null, "number": 2, "cdate": 1610486328995, "ddate": null, "tcdate": 1610486328995, "tmdate": 1610846662316, "tddate": null, "forum": "xJrzLYT2YL7", "replyto": "xJrzLYT2YL7", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/-/Official_Review", "content": {"title": "minor advance to classic OIT problem", "review": "This paper presents a method for order-independent transparency, a longtime problem in real-time rendering. This paper combines McGuire & Bavoil's weighted blended order-independent transparency with depth binning, dividing depth uniformly and applying WBOIT to obtain a color for each bin, then combining the bins for the final pixel color. The results are a middle ground in quality and speed between plain depth peeling and the WBOIT approximation. The comparison is less favorable if depth peeling acceleration techniques are used, but still there are potential use cases for the proposed method.\n\nThe paper offers a minor contribution to the classic OIT problem and on that basis can be considered for acceptance. One weak point is that the results may be a little overstated relative to the state of the art. There has been a fair amount of work on OIT and just referring to Wyman's survey is not sufficient to cover it. In particular, the strand of work on depth peeling acceleration has not been discussed in the present paper. Acceleration methods can easily halve the cost of plain depth peeling (Everitt 2001) and one of these would be a more fair comparison.\n\nIt is not clear how easy it would be for a graduate student not previously familiar with OIT methods to reproduce this work. Given the practical nature of this research, a bit more advice about implementation might be worthwhile.\n\nI would have liked to see some additional characterization of the scenes, e.g., heat maps of layers (rather than just maximum layer\ncount), and some commentary on the number of layers per bin. It is easy to imagine that for some cases such as the foliage, most bins are empty and the work is being done by a few bins with most of the layers. It would also be worthwhile to show the relationship between error and bin count. The heat maps of error are quite helpful; it might also be instructive to zoom in on regions of particularly large error to show the improvement.\n\nI was happy to see that the authors reported their results in ms per frame rather than attempting to report fps. ", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/AnonReviewer2"]}, {"id": "jYgAL-J9_2u", "original": null, "number": 1, "cdate": 1609860792826, "ddate": null, "tcdate": 1609860792826, "tmdate": 1610846662416, "tddate": null, "forum": "xJrzLYT2YL7", "replyto": "xJrzLYT2YL7", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/-/Official_Review", "content": {"title": "Layered Weighted Blended Order-Independent Transparency", "review": "\nThis paper extends order-independent transparency using a layered approach in which\neach layer is independently composed using Blended Order-Independent Transparency (WBOIT) before \nbeing blended with other layers using the implicit sorting they provide. Blending artifacts are\ntempered using hand-crafted depth-dependent coefficients. The paper presents results on\na large variety of scenes showing different levels of depth and geometric complexity.\n\nThis paper uses lots of \"mathematical cooking\": It is a bit disappointing that no theory \n(as opposed to purely heuristic choices) backs up the use of particular equations, such as b_z or \nvalues like \\sigma.\n\nUnless I'm mistaken, I haven't seen in the result section a study of the effect of varying parameters\nsuch as the number of bins (I'm not saying layers because this term is used in Table 2 to\ncharacterize scene complexity). I would really like to see, for a given scene, a curve showing the blending error\nas a function of number of bins, as well as other parameters (such as sigma!) to see how the method\nbehaves. From the material that is given in the supplementary, creating such plots would be fairly straightforward.\n\nThis paper presents a rather simple idea but it is short enough to make it acceptable. I believe it would\nmake a valuable contribution to CGI.\n\nNotes:\n- end of 3.1: \"This naive approach is accurate if...\". It's not very accurate, but rather \"visually acceptable\".\n- in Figure 8, it would help a lot to show a reference image. Furthermore, on paper it is pretty impossible to \ndistinguish the 3 images\n", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper28/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=7rM-nGqEpIe", "paper_id": "7rM-nGqEpIe", "reviews": [{"id": "N8vVq0jyFz0", "original": null, "number": 4, "cdate": 1610685275353, "ddate": null, "tcdate": 1610685275353, "tmdate": 1610846663246, "tddate": null, "forum": "7rM-nGqEpIe", "replyto": "7rM-nGqEpIe", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/-/Official_Review", "content": {"title": "This work is a solid contribution to the problem of optimizing design edits. Specifically, this work proposes a robust algorithm for 2D vector graphics designs that automatically determines the design hierarchy and propagates edits without the need for human annotation.", "review": "PROS\nProposed algorithm is highly flexible with the ability to transfer design changes over multiple times of design relationships and has the benefit of not requiring user annotations.\nAlgorithm considers both design hierarchies with respect to design elements and animations.\n\nCONS\nEvaluation could be more detailed in comparing the proposed algorithm against the ablation studies with respect to pros and cons. Additionally, it would be interesting to evaluate the outputs with respect to the number of edits required by the designer in order to achieve the desired result. This latter point is touched on in future work as a way to improve the algorithm.\n\nQUALITY\nThe algorithm tackles a commonly-used design space and design constraints when determining its hierarchy, making its utility promising. Additionally, the evaluation supports the computational complexity of the algorithm by demonstrating its performance on a variety of design types against variations of the algorithm from an ablation study.\n\nCLARITY\nThe writing tends to have comma splices and choppy sentence transitions. Other than those points, the paper reads very well and communicates its problem and proposed solution clearly. Please see the subsection \u201cEdit Notes\u201d for more detail.\nThe paper layout causes the reader to repeatedly refer to figures and tables in other sections. For example, the text discusses Figure 4 after Figure 1 before Figure 2 or 3 are seen. Additionally, many examples refer back to Figure 1 on the first page.\n\nORIGINALITY\nThe idea of automatically propagating design edits has been done before, but this work focuses on removing as many constraints and burdens on the designer as possible. In other words, the problem is known and this solution makes forward progress.\n\nSIGNIFICANCE\nThis tool would be very convenient for designers by removing the need for tedious edits. The evaluation is not complete enough to state how much effort this will save designers.\n\nEDIT NOTES\nAbstract First Sentence: To create graphic designs such as infographics, UI designs, and explanatory diagrams, designers often need to apply consistent\u2026\nTwo sentences contain comma splices where no comma is needed: \nAbstract: Our method does not require any explicit annotation, and can be applied to any existing design regardless of how it was created.\nAbstract: We evaluate our algorithm on a range of real-world designs, and demonstrate how our approach can facilitate various editing scenarios.\nFirst sentence of Overview: The input to our method is a set of source elements that the user has manually edited, and a set of target elements to which the user wants to transfer the edits.\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/AnonReviewer1"]}, {"id": "Tt-sSnQ9fZx", "original": null, "number": 3, "cdate": 1610666360608, "ddate": null, "tcdate": 1610666360608, "tmdate": 1610846663160, "tddate": null, "forum": "7rM-nGqEpIe", "replyto": "7rM-nGqEpIe", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/-/Official_Review", "content": {"title": "great problem and motivation; quantity of heuristics makes it hard to read", "review": "This paper tries to propagate editing of vector graphics elements to similar elements within the same design, using graph kernels to estimate similarity.  It is an ambitious and worthwhile goal, and the presented work seems to make some progress. Graph kernels are a plausible mechanism for similarity estimation in this context, even if some of the elements used here are oversimplified. (In particular, centroid distance struck me as a poor measure of proximity given the prevalence of non-circular elements in the examples, such as the buildings or the horizontal text boxes.)\n\nI was intrigued by the paper but found it difficult to read, at least partly because the paper has a lot of different parts with no clear connection between them. The volume of heuristics (and subsequent testing of the heuristics) is high. I do not have a good solution to this, but the paper's length combined with the apparent immaturity of the method relative to its aims somewhat dampened my enthusiasm.\n\nThe similarity elements were chosen heuristically, based on observation of a set of reference designs. This is a reasonable way to proceed in early-stage work. I would hope that this could be improved on in future work, both by doing a more thorough survey and by appealing to general principles of graphic design.\n\nDoes the method work? Based on Figure 1, I expected to see some examples of design transfer being carried out on novel designs, but the paper doesn't have any of that. Can such edits happen in practice? How often would the method do something objectionable such that the user needs to correct it? Can it be fooled by extraneous elements, such as the map in Figure 1a? (The design may not include a convenient separation into layers.) There seems to be an implicit assumption about the simplicity of the design which may not always hold. In general, I thought there was a bit of a disconnect between the paper's aims and apparent contributions (taking Figure 1 as a preview of results) and then the actual results which concentrate on evaluating matches between manually-selected groupings and detected groupings. Should the paper be accepted, I would advocate being clearer about the paper's goals and contributions up front, with Figure 1 being emphasized less. (Or, if the authors do indeed have software that allows design transfers like those shown in Figure 1, they should tell us about it.)\n\nI appreciated the use of ablation experiments to explore the importance of different heuristic choices.\n\nMinor points:\n\nCitations are parentheticals and not words in a sentence. The paper incorrectly attempts to use them as words, with usages like the following: \"Our algorithm is directly inspired by [2]...\" This is obnoxious and should be replaced by something like \"directly inspired by the work of Fisher et al.\"\n\nReference 8 seems to be messed up, with the lowercase \"i\" and the unclear chapter tag.\n\n", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/AnonReviewer4"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/AnonReviewer4"]}, {"id": "qHeCBRZJ8Rh", "original": null, "number": 2, "cdate": 1610312869799, "ddate": null, "tcdate": 1610312869799, "tmdate": 1610846662967, "tddate": null, "forum": "7rM-nGqEpIe", "replyto": "7rM-nGqEpIe", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/-/Official_Review", "content": {"title": "This paper describes an algorithm to transfer edits of vector graphics elements from a source to one or multiple target elements automatically. In order to facilitate this the structure of these elements is analysed and correspondences determined.", "review": "The authors propose to construct relationship graphs (nodes: graphics elements, edges: relationships, e.g. text alignment, color, font) and compute correspondences: a) element-wise, i.e. per node based on properties such as type, shape, size; b) edge-wise, i.e. for the relationship of two elements, e.g. overlap; and c) for graphs using a graph walk kernel based on a) and b). After matching elements simple transfers would be possible, but more complex edits such as layout operations, further require nesting structures or ordering of elements which is obtained from clustering (using AGNES) and heuristic ordering.\n\nThe proposed method (and both stages separately) is evaluated for several vector graphics, where the \u201cground-truth\u201d has been constructed manually. Overall, I felt that the evaluation is quite extensive and basically demonstrated that the method works as suggested. Of course it would be very interesting to see the potential of making use of document edit history and user corrections (as suggested in the outlook), but this is clearly beyond the scope of this paper and future venue.\n\nOverall the paper is well written and easy to follow; the previous work section is quite dense for someone not working in this field (i.e. no background/recap of basics), I can\u2019t tell if there is prior work missing there. \n", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/AnonReviewer3"]}, {"id": "ncw0pEXlMl", "original": null, "number": 1, "cdate": 1609271172586, "ddate": null, "tcdate": 1609271172586, "tmdate": 1610846663066, "tddate": null, "forum": "7rM-nGqEpIe", "replyto": "7rM-nGqEpIe", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/-/Official_Review", "content": {"title": "Review of Multi-level Correspondence via Graph Kernels for Editing Vector Graphics Designs", "review": "This paper presents a method for identifying correspondences between elements in a vector graphic.  Individual objects such as paths and text can be compared in terms of shape, size, and rendering properties.  More complicated compound objects can then be compared by evaluating the similarity of the individual components, as well as the similarities of the geometric relationships between those components.  Once compounds are identified based on a source compound identified by a user, edits can be transferred across in bulk, allowing for editing operations at a very high semantic level.  The method is based on graph kernels.  The paper includes lots of interesting use cases and an ablation study to demonstrate the utility of the various heuristics that make up the similarity computations.\n\nI like this idea a lot.  Generally speaking I'm excited about any research that attempts to infer semantic content from raw vector graphics (\"path soup\"), in order to support content-aware manipulations.  The results suggest that the technique presented here is at least somewhat useful and reliable, though it's hard to tell how well that would scale to a general graphic design context.  I think the paper does a good job connecting to past work.  It might also be useful to cite these two papers:\n\n\thttp://www.gilbertbernstein.com/project_lillicon.html\n\thttps://research.adobe.com/publication/dynamic-planar-map-illustration/\n\nBoth involve some measure of inferring the structure of vector graphics images in order to process them intelligently.\n\nOverall I found the paper to be both long and confusing.  I'm left concerned.  It seems like there may simply be too much to say in the form factor of a GI paper.  And even with all the details that are presented, I'm still not sure I understand the algorithm in full.  I'm also not sure I understand when it will perform well or poorly.\n\nSome of this undoubtedly stems from my lack of familiarity with the techniques used.  Given that we're in a Graphics/HCI venue, and given that graph kernels are somewhat exotic, it may be worthwhile to introduce them more gently in this paper with an extra paragraph or two of text, instead of simply leaning on repeated references to Fisher, Savva, and Hanrahan [2].  (If nothing else, \"kernel\" is already a confusingly overloaded term in math and CS.)\n\nIt may even be possible to inject a new section around Section 3 that gives a high level view of the technique as part of an introduction to graph kernels, thereby preparing the reader to understand the meaning of the individual kernels that follow.\n\nBeyond that, I have a few main concerns about the paper:\n\n * I'm not sure I understand what a typical user interaction might look like.  Does the user select the contents of the red box and blue box in Figure 1(a)?  Later, the paper seems to suggest that the user selects the Italy stats, and the system discovers the Hungary and Greece stats automatically from the entirety of the rest of the vector image.  Is that correct?  What if the rest of the image is very complex?  Is it still easy to find these correspondences within a large mass of undifferentiated paths?\n\n * On a related note, most of the examples are based on isolated infographics, where almost every path and text element is part of some cluster.  How does the system perform (in terms of speed and robustness) when the vector art contains a large amount of extraneous vector material that doesn't correspond to any part of the source?  Can it weed out all those distractions?\n\n * Has this technique been implemented in a real interactive tool, or in an offline prototype?  Is it fast enough to use in practice?  Given all the pairwise comparisons needed between elements, and need to aggregate kernels over all paths of a given length, I worry that such a tool couldn't run interactively.  The paper never discusses this.\n\n * In Section 6.4, measuring the distance between elements via the distance between their centroids isn't very convincing. I feel like it would make more sense to develop a distance metric that's a better match to human perception.  How about just measuring the smallest separation between the two objects (i.e., the minimum distance between any points on the two objects), or at least the shortest distance between the bounding boxes?\n\nHere are a few smaller issues:\n\n * The writing could use a lot of improvement.  My biggest complaint is that one should never use a citation as a noun, as in \"...[10] computes perceptual grouping of discrete patterns, and [3] encodes the structure...\".  That's very hard to read.  There are also a number of typos and grammatical issues throughout the text that should be smoothed out with proofreading.  For example, on Page 2: \"several design software\", \"loose their structural information\", \"data-formats\", \"3D scene comparisons\".  \"For For\" in Table 1, etc., etc.\n\n * Section 4 might be more comprehensible if it were illustrated using a few abstract examples (i.e., simple paths and text rather than complete infographics).\n\n * Page 3 references Figure 4, but the figure is very far away in the paper.\n\n * What does \"(not closest on left!)\" mean in Figure 2?  Is that relationship explicitly encoded by the kernels?  Is it something else?\n\n * I don't understand the definition of \"overlay\" in Table 1.  Does it imply that A and B are identical?  That they have identical bounding boxes?  \n\n * In what way are alignment relationships similar to intersection relationships?\n\n * It's weird that the shape kernel doesn't use symmetric difference.  I would expect Figure 3(c) to include the door of the house as black pixels, because the two images differ there.  It's also worth pointing out that the shape kernel is sensitive to rotation and reflection\u2014a user may perceive rotated elements to be identical, but this kernel will miss that correspondence entirely.\n\n * The definition of k_type is a bit odd.  I'm not sure I completely understand what \"same category\" means.  More importantly, k_type is used as part of k_node, in a context where it will never be zero.  That is, k_node is defined conditionally in a way that doesn't require the full sophistication of k_type.  I'm not sure what to do about that.\n\n * I'm not sure I fully understand the motivation for the changing weights in 4.2.4.  Is that a new idea, or is it standard with graph kernel methods?  Perhaps an example could help.\n\n * The ablation study is interesting, and the results are somewhat convincing, but they still seem artificial.  I'd like to see a more \"realistic\" workflow being demonstrated if possible.  Maybe a video showing a typical interaction.  Maybe a few attempts to get professional graphic designers to use to the tool (see the Lillicon paper referenced above for a good example of this).  \n\nOverall I think the work is publishable, though it might conceivably be better off in a journal format, where it could be given more room to breathe.  As it is, I think it could use some careful rewriting to make the ideas clearer and the results more convincing.  I come down mildly positive about the work, but it'll be interesting to see what the other reviewers say about it.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper26/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=eVyaNs3sm8a", "paper_id": "eVyaNs3sm8a", "reviews": [{"id": "lWgqgZg8Sur", "original": null, "number": 3, "cdate": 1610591896478, "ddate": null, "tcdate": 1610591896478, "tmdate": 1610846665053, "tddate": null, "forum": "eVyaNs3sm8a", "replyto": "eVyaNs3sm8a", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/-/Official_Review", "content": {"title": "SwipeRing: Gesture Typing on Smartwatches Using a Circular Segmented QWERTY", "review": "This paper contributes the design and evaluation of SwipeRing, a novel circular keyboard designed to enable gesture typing on a smartwatch using a statistical decoder. The design uses a clever technique where the standard QWERTY keyboard is arranged into seven different zones around the edge of a smartwatch, freeing up the touchscreen real-estate (making it novel compared to other solutions in this space). A controlled user study compared SwipeRing with the C-QWERTY technique that uses a layout without keyboard zones to enable gesture typing. Key results showed that SwipeRing had 33% higher text entry speed and 56% lower error rate in comparison to C-QWERTY. \n\nThis is a largely well-written paper which tackles an interesting and important problem of improving text entry on smartwatches. The design has been clearly presented along with a thorough explanation of the layout optimization and related gesture modelling techniques.  The user study description is clear and the study can be reproduced based on the details provided. \n\nI do have some reservations about the paper that are mostly related to the user study design. One key issue is the choice of comparing SwipeRing to C-QWERTY since C-QWERTY doesn\u2019t appear to be the state-of-the-art in circular keyboard layouts.  I understand the author\u2019s argument that they were trying to tease out the benefits of the zone-based layout around the smartwatch bezel, but this makes the contribution of this work to be somewhat narrow. Second, although the choice to do a between-subject study was appropriate, I am a bit uncomfortable with seeing statistical findings and claims drawn from only 12 participants in each condition. Furthermore, the two study conditions were completely different: the C-QWERTY group participated fully online vs. the SwipeRing group participated in an in-person study. I am cognizant of the difficulties of running user studies during a pandemic, but I just wanted to raise issues around potential threats to validity of the results. Perhaps the discussion section would benefit from having an explicit limitations section.\n\nI was a bit confused with the start of the discussion section as it seemed to continue to mention new study results rather than reflect on the contributions of the work or broader implications. Some of the text on page 8 can be significantly condensed and/or integrated into the results section. Although the discussion around skill transfer was interesting, the lack of statistical findings is somewhat problematic given the motivation and claims described earlier in the paper. To the extent it is possible, I would suggest that the authors tone down skill transfer as one of their key motivation (e.g., in 2.2) and successful aspects of their design.\n\nText entry is a fairly crowded space in HCI research with many novel solutions have already been explored (including circular layouts). In this regard, SwipeRing appears to make an incremental contribution, yet a unique one given the use of zones to lay out the keyboard around the smartwatch bezel which clearly has some benefits. Overall, despite some weaknesses, this paper makes a reasonable contribution to input and interaction techniques in HCI and I would recommend this paper for acceptance at Graphics Interface. \n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/AnonReviewer3"]}, {"id": "un1E2tpLSVA", "original": null, "number": 2, "cdate": 1610589266468, "ddate": null, "tcdate": 1610589266468, "tmdate": 1610846665135, "tddate": null, "forum": "eVyaNs3sm8a", "replyto": "eVyaNs3sm8a", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/-/Official_Review", "content": {"title": "The paper presents SwipeRing, a circular keyboard designed for smartwatch text entry. A solid and interesting paper to read. Recommended for acceptance.", "review": "The paper presents SwipeRing, a circular keyboard designed for smartwatch text entry that arranges QWERTY layout into several segmented zones. The experimental evaluation compared the proposed design to a more traditional circular keyboard design that doesn't arrange keys into zones, showing faster entry speed and lower error rate with the proposed design.\n\nAs an HCI researcher not working on the specific topic of text entry design and wearable interfaces, I found this paper interesting to read, and the body of research work presented in the paper well-constructed and delivered. The building and construction of the SwipeRing keyboard appear to be really solid to a general audience, which has carefully motivated and justified the proposed design along with necessary information and details for replicating the design and implementation. So overall the technical quality of the work appears to be very well.\n\nAs for the intellectual merits and originality of the proposed concepts, the proposed design leverages segmented QWERTY layout and skill transfer from past experience of using QWERTY to support typing on smartwatches. It\u2019s also valuable to see a discussion on screen occupancy and a comparison of different keyboard designs on balancing visual occupancy and typing performance. While I\u2019m not familiar with the literature of mobile text entry, the paper seems to bear sufficient novelty. Perhaps one limitation is that there\u2019s not enough empirical support that skill transfer from past experience using a regular QWERTY keyboard is really happening. Also, the current evaluation compared SwipeRing to another circular keyboard design. It\u2019s curious how it may look like if comparing the design to other types of non-circular keyboard design. I think the current evaluation is valuable for making lower-level design decisions by having an internal baseline. A next step could be looking outward to compare the design with something that\u2019s more external, increasing the ecological validity of the evaluation.\n\nOne minor concern is that the Discussion is somehow repetitive, repeating results that have been presented earlier. The Skill Transfer subsection (7.1) may be considered more as a result rather than a part of the discussion.  Also very minor is that the result obtained from the post-experiment survey (Figure 12) was described as \u201cqualitative results\u201d (Figure 8 bottom), which seems strange to my eyes. The survey data are apparently quantitative so that statistical tests were possible.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/AnonReviewer2"]}, {"id": "Hqkb6w5F_pi", "original": null, "number": 1, "cdate": 1610473921403, "ddate": null, "tcdate": 1610473921403, "tmdate": 1610846665228, "tddate": null, "forum": "eVyaNs3sm8a", "replyto": "eVyaNs3sm8a", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/-/Official_Review", "content": {"title": "SwipeRing: Gesture Typing on Smartwatches Using a CircularSegmented QWERTY", "review": "\nThe authors present a new type of gesture-based binned-keys circular keyboard for smart watch text entry. They descibe their design process, how they decided on layout, their motivation, and an experimetn they conducted comparing their method to a comparable, roughly competitive other keyboard. They find that their version can produce higher WPM and lower error rates than other comparable keyboards, and compares favorably to other types of keyboards for smartwatches.\n\nPros:\n- excellently written, clear\n- good motivation, clear method (reproducible)\n- use of standard metrics helps compare to existing studies\n- great use of figures and graphs\n- good statistical tests, and relys on good descriptive statistics more\n\ncons:\n- seems to argue strongly for negatives of other approaches that seem a bit off\n- bare minimum participant pool for between subjects\n- strong learnability motivation but due to covid, participant sampling, couldn't evaluate this aspect strongly (postive: they did try)\n\nOverall I enjoyed this paper. It was well written and easy to understand. Even the more detailed math/simulation sections where they designed the smartwatch layout was clearer than most mathy sections of other papers.  Thus, the contribution should be clear to readers of the paper\n\nThe only writing issue I found was a strong repeated argument on how some other top-performing methods rely on aggressive statistical modeling and how this precludes (or makes difficult) non-dictionary vocabulary. I would argue this is false (while I am less familiar with the other techniques). This is not a fault of aggressive statistical prediction (the authors themselves leverage prediction in the presented technique), but of enabling such in the interface. For example, dwelling and other gestures suggested for this technique to add features could also be used to add precise but slow text entry to other techniques. So I think such strong claims should be reduced. As it stands, this technique uses less screen real estate (and perhaps a better layout) and still performs well so I don't think the authors need to be so defensive. Otherwise, the motivations were very clear and fed well into the design of the interface.\n\nIn terms of the experiment, I found the method clear and would be easy to reproduce. The chocie of measures was good, and enabled the authors to compare their implementation of other techniques to the existing results in the literature, adding replication data and more validity to their study. While I thought the number of participants was low for a between-participants design, without a pre-experiment power analysis the experiment does pass a bare-minimum rule of thumb number of participants. In times where running experiments is difficult, I find this quite acceptable.\n\nOn that note, with such a focus on skill transfer, it was really unfortunate that a experienced-person analysis could not be carried out (statistically). I do think the authors made an interesting case with great descriptive statistics with the few participants they had. Further, on this note, I think the use of figures and presentation of descriptive statistics was excellent, clear, and very informative. This gave the work much clearer results and generalizability rather than relying on just base p values and effect sizes alone. \n\nSo in summary, there were some small drawbacks but I find this paper to use strong methods, has interesting results that stem from a well designed study anchored in clear motivation. I would recommend this for acceptance.\n\n\n\nSmall points:\nI would consider reorganizing 7.1 into a part of the analysis and results and then into the discussion. It felt strange to introduce new data and analysis (the correlations, etc) so late in the paper. Not required, just a suggestion.\n\nreferences justifying why a score of ~115 on Procrustes analysis is good should be provided. E.g., later you also say 6-19 is good. Not everyone reading this paper will have worked with swipe gesture and common analysis again so a few sentences on it would really help expand the paper's audience.\n\n6.5 last paragraph,. second last sentence: piked  should be \"picked\"", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper19/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=-Yus5M-WjZT", "paper_id": "-Yus5M-WjZT", "reviews": [{"id": "4U9nH6pZRuW", "original": null, "number": 3, "cdate": 1610450512352, "ddate": null, "tcdate": 1610450512352, "tmdate": 1610846665706, "tddate": null, "forum": "-Yus5M-WjZT", "replyto": "-Yus5M-WjZT", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/-/Official_Review", "content": {"title": "Small but potentially useful contribution", "review": "This paper proposes three new metrics for assessing performance of multi-step text entry methods. The work has interesting potential for application in this domain, and multi-step entry methods are important, particularly for accessibility. The work is reasonable, but has a few weaknesses that limit its contribution\n\n**Framing.** The metrics are presented as performance metrics and positioned as an alternative to more traditional measures of speed and accuracy. But the measures actually reflect learning. They do not capture the end product but rather the process that the user took to get to that final product. This isn\u2019t to say that looking at learning isn\u2019t important, just that the paper lacked grounding in a discussion of it and how measuring it is typically tackled in multi-step evaluation work. For example, later in the paper one of the demonstrated uses of the new metrics was to aid in the identification of common character substitutions. Finding pairs of characters that are commonly swapped is fairly common. I imagine this work facilitates identification of them or presents a more systematic way of examining them, but it\u2019s hard to know exactly how without such a discussion of prior work. \n\n**Weak statistical results.** It was disappointing that significant results were not found for the new metrics over the course of the study. Particularly as measures of learning, this seems like a fairly important bar to pass. The paper does demonstrate some utility without that significance, but it leaves the reader questioning how strong these metrics are. Relatedly, the fact that there were other significant differences that the paper couldn\u2019t explain leaves me wondering if there isn\u2019t a problem in the data and if perhaps more work is needed to examine it in depth. \n\n**Ties to accessibility.** This is a small and easily addressable point but I think it\u2019s important. The research uses two accessible keyboards for the context of the study, but does not use assistive technology users in the experiment. I think this is reasonable given the purpose of the research which is to test the metrics and not the keyboards themselves. The paper even cautions the reader to not consider the results as indications of how to adapt or modify the keyboards (\u201c\u2026, not to change their mapping or design\u2026\u201d, Conclusion). This is great, but I think it should be stated more clearly that the specific results (i.e., which characters were problematic, confused, took longer to learn, etc.) would likely be different if the study were repeated with representative users, and thus the findings here should not be interpreted as recommendations for updating or changing the keyboard designs. Otherwise, I see some potential for harmful misinterpretation of the these results by future readers. \n\nOverall, this is a relatively modest paper, presenting a small contribution. The framing of the work and depth of the data analysis could be improved to strengthen the results, but it makes an acceptable contribution in its current form. I could see the work being useful to people working in this space. I remain ambivalent about its acceptance, and accordingly provide a weak vote in favour of its acceptance. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/AnonReviewer3"]}, {"id": "6hnPw_BYzpf", "original": null, "number": 2, "cdate": 1610429944695, "ddate": null, "tcdate": 1610429944695, "tmdate": 1610846665788, "tddate": null, "forum": "-Yus5M-WjZT", "replyto": "-Yus5M-WjZT", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/-/Official_Review", "content": {"title": "New action-level performance metrics that account and compensate for the different input methods of constructive and chorded input processes. ", "review": "This paper introduced new action-level performance metrics that account and compensate for the different input methods of constructive and chorded input processes. The results from a user study demonstrate how the proposed metrics can be applied to different multi-step techniques.\n\nIn general, the paper uses a sound approach. However, I believe there is some room for improvement. Below are lists of things I would like to see the authors address or clarify:\n\n- Section 2, the authors discussed some accuracy and performance metrics but did not mention throughput metrics [https://doi.org/10.1145/3290605.3300866]\n\n- Section 2, the authors state that accessibility text entry systems mainly use constructive or chorded techniques, but there is little discussion about each technique. I would suggest adding a description about each technique and how they are similar/different, at least in broad terms.\n\n- Section 6.3: The authors mentioned that there are \u201c\u2026 more sophisticated methods are available in the literature\u201d than UnitCX. I would suggest adding a paragraph in related work about the more sophisticated methods to measure inputs unit\u2019s complexity.\n\n- Section 7: Why did the authors decide to do a comparative study between a constructive and a chorded text entry technique? How does this approach support their motivation of introducing detailed metrics of multi-step keyboard interaction that can facilitate improved input method design? This should be explained better.\n\n- Section 11: The authors should discuss how their participant sampling affected the study, as none of the participants had prior experience with any chorded methods, but eight had used a constructive method in the past.\n\n- Section 13: Why did the authors decide to repeat the same phrases instead of introducing new phrases each time? Users might thus memorize the sequence of the whole phrase. How could this affect the outcome of the study?\n\n- Section 14.2: Action per Character (APC) should have been introduced before being used, e.g., in section 4 or 5. \n\n- Section 15: The discussion lacks citations of other work to relate the outcomes to the field.\n\n- Section 16: Why did the authors decide to first present the discussion in section 15 and then the Action-Level Analysis as section 16? Also, how does the analysis of the metrics help to inform designers to develop new action sequences beside \u201cencourage designers to place the most frequent letters toward the edge of the device\u201d which is well-known and has been studied in other research, e.g., [https://doi.org/10.1145/2702123.2702439]?\n\n- Clarity of Presentation: Overall, the presentation of the paper is clear. I would suggest improving the presentation of section 16 since the figures can be hard to follow.\n\n- Technical soundness and completeness: I believe this system can be implemented by a competent graduate student. After all, the core technology part uses existing applications, and only metrics need to be calculated.\n\n- References: Appears adequate. \n\nMost of the above are minor comments that can be addressed in the camera-ready version. In my opinion, although some findings might seem unsurprising, the paper has enough contribution. I would suggest accepting this paper. ", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/AnonReviewer2"]}, {"id": "mNkw2waX_l4", "original": null, "number": 1, "cdate": 1609946574544, "ddate": null, "tcdate": 1609946574544, "tmdate": 1610846665877, "tddate": null, "forum": "-Yus5M-WjZT", "replyto": "-Yus5M-WjZT", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/-/Official_Review", "content": {"title": "New performance metrics for text entry techniques that are either constructive or chorded.  ", "review": "This paper proposes new performance metrics for text entry techniques that are either constructive or chorded.  The paper validates the metrics by showing how they helped the authors analyze data obtained from a longitudinal study comparing a specific constructive technique and a specific chorded technique. \n\nThis is a focused submission, contributing metrics that have the potential to interest other researchers working on chorded or constructive text-entry techniques.  The paper makes a good case for the limitations of existing metrics in that they cannot capture how far away user actions are from the correct entry.  This in turn limits a researcher\u2019s ability to see whether user performance is improving with practice, even if they are not yet getting the actions completely \u201cright\u201d.  \n\nIn terms of validating the metrics, the paper\u2019s approach seems reasonable, but perhaps not overly strong.  The authors show how they used their metrics with their own data to draw conclusions about the techniques studied. It would be useful to reflect on the limitations of this validation approach and how others have validated text entry metrics in prior work.  For example, have arguments been primarily analytical, have other papers solicited feedback from researchers outside of the team, etc.?\n\nThe contribution seems thin for the length of the paper.  This is partly owing to a fair amount redundancy in the first four pages.  Regardless of the final decision for the paper, I would recommend restructuring and streamlining the first three sections to ensure that the motivation is presented only once, followed by a related work with a clear discussion of the gap in the literature that this work is filling.  This could then transition directly into the metrics and notation.\n\nIn terms of paper length, it also is not clear that the study needs to be described to the extent that it is if its main purpose is to demonstrate how the metrics were used on the data.  It appears there was a confound in the study in that participants had more prior experience with the constructive method than with the chorded method.  As such, it is not clear that seeing the statistical comparisons between the two techniques is adding value to the paper.\n\nA few other presentation issues that impact the paper\u2019s clarity:\n\n- For a more general HCI audience, I would recommend defining \u201cconstructive\u201d and \u201cchorded\u201d text entry methods early in the paper.\n- Table 1 does not help showcase why UnitER is an improvement ove ER.  It is true that the numbers are different, but without a more informative caption, it is not clear why this difference is meaningful.\n- There is notation in 6.1.1 that I did not see introduced in the \u201cNotation\u201d section. (e.g. a[1: ])\n\nGiven the venue, I am mildly supportive of the paper, but it is not a huge leap forward and the presentation could be improved.  To contextualize my assessment, I am an HCI researcher, but not an expert in text entry techniques nor in their validation.", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper16/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=bK03tED1vj5", "paper_id": "bK03tED1vj5", "reviews": [{"id": "Y0iW9Fv00Lk", "original": null, "number": 3, "cdate": 1610527969638, "ddate": null, "tcdate": 1610527969638, "tmdate": 1610846666019, "tddate": null, "forum": "bK03tED1vj5", "replyto": "bK03tED1vj5", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/-/Official_Review", "content": {"title": "Well done study but weak contribution", "review": "The paper \"Accountability-Aware Design of Voice User Interfaces for Home Appliances\" presents an exploratory study on the perception of accountability of automated systems. The authors explore what affects the perception of system accountability and the relationship to user satisfaction. The general domain of the paper is voice-controlled interfaces and the application domain is voice control of laundry machines. The study is based on showing participants (15) video prototypes of voice-based interactions with laundry machines and assessing their perception of accountability through questionnaires and interviews. Results show that the higher the level of automation the higher the level of perceived accountability. The authors recommend designers of voice user interfaces to give freedom in transitioning between guided use (more automation) and command-based use (more direct instruction).\n\nThe paper addresses a timely problem as voice-based user interfaces are becoming more and more common, yet still a source of frustration and error. The paper is well written, well structured, and generally easy to follow. There is good coverage of related work and the theoretical framework for accountability is nicely presented. The methodology of the paper is sound and the authors nicely combine questionnaire and interview data.\n\nI also have some concerns with the paper:\n - The design of the video prototypes seems to be very important to the participants' perception of accountability. However, the design decisions that were made making the video prototypes are not detailed, and what the video prototype shows is not shown (e.g., in images) or explained to the reader. Basically, the reader is kept completely in the dark about one of the most important parts of the study.\n - I am not sure what I have learned from reading this paper. The conclusion could be summarized with \"The more responsibility we give to the machine, the more accountable we perceive it to be for the outcome\". I don't see this as surprising at all.\n \nOverall, the paper presents a relevant and nicely executed study, however, it fails to deliver a convincing contribution and glosses over the design and description of the video prototypes that are central to the paper. Therefore, I lean towards rejecting the paper.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/AnonReviewer2"]}, {"id": "fvEauhjShEY", "original": null, "number": 2, "cdate": 1610487165567, "ddate": null, "tcdate": 1610487165567, "tmdate": 1610846666104, "tddate": null, "forum": "bK03tED1vj5", "replyto": "bK03tED1vj5", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/-/Official_Review", "content": {"title": "Review", "review": "This paper presents a study to understand user perspectives on the perceived accountability of washing machine voice user interfaces (VUIs). The researchers deployed an initial survey to elicit perspectives on the possibilities and concerns about VUIs used in the home setting. Next, they created video prototypes illustrating various errors that might occur when washing machines use VUIs and used them in interviews with 15 participants to elicit their perspectives on system accountability.  \n\nThe area of VUI design and especially their home applications are relevant areas of research in HCI and the current paper asks important questions about how users perceive errors and who should be accountable for them when considering these systems. The paper nicely grounds its analysis on previous work on accountability in HCI. The methods are, for the most part, clearly described and the findings can be used to inform accountability aspects of design in future VUIs for smart home appliances.\n\nDespite its strengths, the paper has several important shortcomings. First, while the findings mostly focus on smart washing machines in the study sections, they are broadly generalized to home all automation systems in the Discussion and Implications for Design.  This is problematic since the findings (both survey and interviews) are still exploratory and in the absence of multiple studies with different types of appliances, it is difficult to generalize the results to the perceived accountability of VUIs broadly. I believe this issue can be addressed effectively by revising different parts of the paper, especially the Introduction (i.e., framing) and Discussion/Implications for Design and specifying that the current findings are specific to VUIs for smart washing machines (with the possibility of some of them generalizing to other systems that need to be verified in the future). I would also mention the specific application under study earlier (in the Abstract or the Introduction at the latest) than where it is currently described (methods). Second, given the relatively small number of participants in the main study (15) I was surprised that the quantitative analysis was more detailed that the qualitative analysis, and that the latter was only limited to 8 participants. Given the exploratory nature of the study and that its focus is on users\u2019 perception, I would have liked to see more detailed qualitative data and analysis.  Also, I was wondering what type of thematic analysis the authors conducted? Finally, I found the Implications for Design section one of the weaker sections because the results are quite general and it is hard to imagine how they may be applied to actual design scenarios. I recommend removing and incorporating with the Discussion or Conclusion. I end with a minor structural suggestion: the first paragraph of section 6.2 can move to methodology and the second paragraph reduced to one sentence about the naming convention. ", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/AnonReviewer1"]}, {"id": "gVjEiA7WKWm", "original": null, "number": 1, "cdate": 1610464906351, "ddate": null, "tcdate": 1610464906351, "tmdate": 1610846666184, "tddate": null, "forum": "bK03tED1vj5", "replyto": "bK03tED1vj5", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/-/Official_Review", "content": {"title": "Nice study and overall well written paper", "review": "This paper describes a study into the perceived accountability of voice user interfaces. Participants watched videos of interactions with a washing machine in four conditions varying in how much control the user delegates to the machine. This is crossed with complexity in a high and low condition. The main takeaway, in my perspective, is that as more control is delegated to the washing machine, users' also tend to \"blame\" it more for negative outcomes.\n\nI think overall the paper is well done and presents a solid piece of research. The investigate aspect of accountability is timely and interesting, the study setup good, and I also see no issues with the analysis.\n\nOne thing that could be improved is the clarity around accountability and how it was measured. The definition given is that \"Accountability can be defined as who (e.g., user or system) is obligated or willing to be responsible or accountable for the satisfactory execution of a task, including one that has been delegated\". So accountability is when someone/something is accountable. That's oddly circular and I'm wondering whether that can be expressed differently. Also, in that statement responsible and accountable read like the exchangeable things, yet just below we learn that they do differ. In the main study, accountability is then elicited by asking participants to rank the four conditions from 1 (most accountable) to 4 (least accountable). This does lead to a slightly hard to read presentation of the results though. For example, in Figure 1, less is more accountable. If accountability is shown, it would be more intuitive if higher values corresponded to a higher sense of accountability. \n\nBut I don't think there are major issues and hence I am recommending acceptance.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper15/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=1S3TXjkEVmH", "paper_id": "1S3TXjkEVmH", "reviews": [{"id": "8yWJogX5_rP", "original": null, "number": 3, "cdate": 1610487344238, "ddate": null, "tcdate": 1610487344238, "tmdate": 1610846666722, "tddate": null, "forum": "1S3TXjkEVmH", "replyto": "1S3TXjkEVmH", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/-/Official_Review", "content": {"title": "Review", "review": "This paper presents two AR techniques for out-of-view target guiding awareness and variants in two experiments with human participants. In the first experiment, two variants of the SOUS technique, bSOUS and fSOUS, were compared using a target selection task. Both techniques are built on the existing FA technique and are less intrusive than the original technique. The first experiment showed that they both perform better (although by a small margin) than FA. Furthermore, they found that bSOUS was more robust in complex environments than fSOUS. In the second experiment, the authors compared four variants of the FA technique in a second experiment in which two additional behaviors were added to FA. The experiment showed that each technique offered trade-offs in speed and accuracy and there was some indication that the complexity of the environment was also a factor in how effective a particular techniques is. \n\nThe paper is clearly written and the techniques and rationale for selecting them are well described. The quantitative data is well presented and future research can explore how these techniques perform in realistic applications. This brings to my concerns about the paper: I had a hard time determining if the paper is making a large enough contribution to the field to warrant publication at GI. The research, as presented, has not resulted in large gains (although some statistically significant results were observed) and it remains to be seen whether each technique's particular gains would impact the user experience in concrete applications (e.g., gaming, etc.). Having said that, I appreciate that the authors discuss some of these aspects in the paper and especially in Section 7.3.  I suggest the authors add a limitations section and provide some ideas for how the research can be extended in the future. Another issue that needs clarification is the relationship between experiment 1 and 2: Upon my first reading, I got the impression that experiment 1 informed experiment 2 but it seems like both experiments were completed at the same time and by the same participants. I recommend the authors revise the methods section to clarify this point further. ", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/AnonReviewer3"]}, {"id": "9XJh8Pw9e7D", "original": null, "number": 2, "cdate": 1610336446937, "ddate": null, "tcdate": 1610336446937, "tmdate": 1610846666633, "tddate": null, "forum": "1S3TXjkEVmH", "replyto": "1S3TXjkEVmH", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/-/Official_Review", "content": {"title": "Techniques to guide user to out-of-view targets", "review": "The paper describes two experiments that evaluate different techniques to guide users towards a target outside their field of view. In the first experiment, they evaluate two techniques fSOUS (low visual salience) and bSOUS (visually salient) to guide users towards a target outside their field of view. They compare this technique against FlyingArrow, a previously proposed technique that uses an arrow inside the VE to guide the users. Results show their techniques to improve user performance over FlyingArrow in various environment types. In the second experiment, they test different modifications of FlyingArrow to improve their performance. They found that adding trails helped performance but were more intrusive. \n\nThis is a good paper, but some missing elements make judging the results difficult. Here are some questions I had while reading the paper:\n\nFor both experiments\n\n1) Why the in-view (faded) and out-of-view (sparked) targets had different selection feedback? Also, in Figure 6, the out-of-view target is red vs yellow for the in-view target. Is this difference part of the user study? Different selection feedback might have distracted users, but it was not mentioned when discussing the results.\n2) What are the target and cursor sizes, and why were those selected? Even if they are not part of the evaluated parameters, the user performance, especially if the selection is gaze-based.\n3) What device was used to track the eyes during the study for gaze-selection? Also, include device latency in the paper.\n4) Was the saccadic eye-movement considered for the data analysis?\n5) Explain what a short break means in study 2 and include if study 1 participants also took a break.\n\nFor experiment 1\n\n1) In section 5.6.2 the paper mentions that \u201cWe did not have to consider Fitts\u2019s Law for this study, because our targets have the same angular size\u201d. Yet, in the next paragraph, the paper discusses that the increase in angular distances did not follow Fitts\u2019 Law. I suggest removing this sentence as the experiment did not follow the correct protocol to make this conclusion.\n2) Some conclusions are too strong and not supported by the data. I recommend adding what data support these conclusions or removing the sentence. For example, \"we argue that the true strength of FA is not about maximizing speed of target acquisition, but to limit it\".\n\nFor experiment 2\n\n1) Why was the modified FlyingArrow white and not red like Gruenefeld et al\u2019 s paper? Colour has a large effect on visual cues, so I suspect this might affect the results, but it is not mentioned in the discussion.\n\nMinor comments\n\n1) It is difficult to understand the differences between FlyingArrow modifications from Figure 3\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/AnonReviewer2"]}, {"id": "BDe9RNvjwtJ", "original": null, "number": 1, "cdate": 1609626221581, "ddate": null, "tcdate": 1609626221581, "tmdate": 1610846666822, "tddate": null, "forum": "1S3TXjkEVmH", "replyto": "1S3TXjkEVmH", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/-/Official_Review", "content": {"title": "Good comparisons on out-of-view VR target acquisition", "review": "The paper describes and analyzes comparisons of different techniques to indicate and locate out-of-view targets in VR environment. The authors generally prefer the two SOUS methods over the prior work, FA method, but they didn't claim contribution to SOUS. So the contribution of the paper is mostly the comparative study.\n\nOverall the paper is well written, with details of the experiments recorded and analyzed. I think the technical contribution is weak, but the results may have good practical use.\n\nNote: Figure 3 may be wrong. b should be the technique with trail c should be the one without trail.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper13/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=uYX0tEWUmTO", "paper_id": "uYX0tEWUmTO", "reviews": [{"id": "PwGe02YmqZK", "original": null, "number": 3, "cdate": 1610594938059, "ddate": null, "tcdate": 1610594938059, "tmdate": 1610846667575, "tddate": null, "forum": "uYX0tEWUmTO", "replyto": "uYX0tEWUmTO", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/-/Official_Review", "content": {"title": "Selection techniques for 3d objects", "review": "The paper presents a controlled experiment for studying the selection methods for 3D objects. In the study the authors analyzed different strategies for selection. They found that traditional list based technique is more efficient than the other two methods. The paper explains the implications of the study findings which could be helpful for relevant researchers.\n\nThe paper is generally well written and easy to understand. The study is carefully designed and the  results are neatly presented. Finally, the authors provided the user study data which would be helpful for future research.\n\nIn terms of weakness, it remains somewhat unclear about the generalizability of the approach in other domains and datasets. Also, for different measures (e.g. accuracy) more rigorous statistical tests might be useful than reporting CI only? Finally, the online setup might results in a lot of confounding factors. I wonder whether the authors have ensured that such factors did not impact the results.", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/AnonReviewer3"]}, {"id": "5flTplSyKrT", "original": null, "number": 2, "cdate": 1610248196953, "ddate": null, "tcdate": 1610248196953, "tmdate": 1610846667668, "tddate": null, "forum": "uYX0tEWUmTO", "replyto": "uYX0tEWUmTO", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/-/Official_Review", "content": {"title": "generalizability and accountability issues", "review": "This paper contributes to an empirical study of comparing three different selection techniques for packed 3D objects, including a traditional list selection, an explosion selection, and a combination of both. The paper is well written and structured. The results are clearly reported, along with implications for design.  \n\nI have the following major concerns regarding this paper.\n\n1) This paper is motivated by selection tasks for tightly packed 3D cell models in the biology domain, which is very nice. However, this paper, including the title, currently frames the claims for general packed 3D objects selection. Given that the study was only conducted on embryo data in this specific domain, the generalizability of the results is questionable. While I appreciate using real-world data for the study, the embryo model only represents one very specific type of layout for packed 3D objects. It is unclear if the conclusions still hold for packed 3D models in other domains, such as mechanical engineering: selecting parts of a complicated machine. In short, this paper over claims in its title and introduction. The authors should tamper them down to highlight the focus on the application domain.\n\n2) An related issue is that only one dataset (one embryo) is used in the study. The layout, density, shape, and other factors of the 3D model could impact the results. This again limits the generalizability of the study results and damages the external validity of the study. I suggest the authors to conduct this experiment on more datasets with different characteristics. \n\n3) While the paper is motivated by the selection tasks in the biology domain and uses the data from this domain, the participants involved in the study were non-experts. This damages the internal validity of the study. Since they are non-experts, would they fully understand the task in the study? Would their actions represent typical experts' actions? Would they take the study seriously? Would they be able to provide genuine feedback that matches the experts'? The accountability of the results is then questionable. \n\nIn summary, the authors can frame their contributions to a specific domain problem or a general problem, but the design of the study and participants should match with their claims. Currently, I see this is a big problem for this paper.   \n\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/AnonReviewer2"]}, {"id": "7HPl3Js-BF5", "original": null, "number": 1, "cdate": 1610050784435, "ddate": null, "tcdate": 1610050784435, "tmdate": 1610846667754, "tddate": null, "forum": "uYX0tEWUmTO", "replyto": "uYX0tEWUmTO", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/-/Official_Review", "content": {"title": "Rather specialized system, but still of some general interest", "review": "This paper compares three different techniques for a 3D pair (sister) finding task: (1) selecting cells from a list, (2) from an exploded view, or (3) a combination of the two. The task and the requirements around it are pretty specific. For example, the individual items are very densely packed and (in actual use) require inspection of facing surfaces for the task. However, the evaluated system itself is comparably generic and (maybe surprisingly) does not cater all that much to the specific task. For example, the tool could have done more filtering, highlighting, and automated view changes based on the already entered pairs to reduce the amount of visible candidates in subsequent assignments. This might actually make the results more transferable to other domains.\n\nI found the paper a bit hard to read and follow and the writing could be improved. Especially Section 4 could be better at presenting the results. The main findings get a bit lost in the long stretches of details and largely small differences. One potential approach to this would be to add more tables, but also to revise the figures, which right now don't work very well. For example, the figure elements important for comparison of the conditions don't stand out a lot or one has to compare across different columns.\n\nI did not quite understand the authors application of preregistration and analysis. Preregistering on its own is a good idea, but this one doesn't follow any common format. There is a brief study design document, but it does not contain information on, for example, the analysis to conduct. I get that p-hacking or harking is no concern here as the study is exploratory, but still. I'd recommend having a look at the OSF's own guide to preregistration (https://help.osf.io/hc/en-us/articles/360019738834-Create-a-Preregistration). I also did not understand why the analysis was exploratory in the first place. For this kind of technique comparison, I think null hypothesis testing is usually fine. Reporting confidence intervals is independent of that and certainly encouraged. But I wouldn't hold the lack of p-values against this paper, the data is there for the readers to come to their own conclusions. I would recommend some small changes though. First of all, the paper needs to be clear what kind of confidence interval is used. I'm assuming it was the 95% CI of the mean, but this isn't stated anywhere. Furthermore, the presentation can likely be condensed by focusing on relevant significant digits. For example, time is reported to 1/100 of a second, which is likely more in the range of measuring inaccuracies than actual differences.\n\nOverall, the takeaway from this work is a bit of a mixed bag. There doesn't seem to be a clear answer to which technique is best. I think this is also because each of the techniques likely is not the best instance of that abstract technique. For example, it's not clear to me why users have to change the view themselves when inspecting pairs of cells, when the system could do that automatically once a pair is selected. Just a list of all cells is also likely not the best choice when users likely want access to close-by ones. Especially as selection in the list is through labels that are not visible in the main view, this is likely more complicated than necessary. But ultimately I think there is something interesting here and I would overall not object to acceptance.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper8/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=3fFZNlSO7GC", "paper_id": "3fFZNlSO7GC", "reviews": [{"id": "5jWcYBpPhMZ", "original": null, "number": 3, "cdate": 1610591186183, "ddate": null, "tcdate": 1610591186183, "tmdate": 1610846669111, "tddate": null, "forum": "3fFZNlSO7GC", "replyto": "3fFZNlSO7GC", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/-/Official_Review", "content": {"title": "Insight into issues and concerns around co-located smartphone usage between initimate partners", "review": "This paper presents detailed insight into issues and concerns that intimate cohabitating partners have about using smartphones while collocated. The in-depth qualitative analysis of a MTurk study provides a clear picture of the range and diversity of concerns, couples, and challenges. Following the paper presents a prototype developed from the results, and details a small in-lab study where people interact with the prototype.\n\nOverall this is a very clearly written paper, with a solid standard trajectory from gaining insight using surveys, creating a prototype, and initial evaluation of the prototype. I quite enjoyed reading the stories and insights about how couples deal with the common smartphone use issue, and I think this data can be useful to the community (although a geographic comparison would have been nice). It is a model HCI paper and a strong candidate for GI this year. \n\nDespite my enthusiasm for the survey results, on a whole unfortunately I found the paper to be lacking in maintaining that clear thread throughout. The app design is interesting, but I did not feel it was grounded sufficiently in the survey results. While the integration of personalization and privacy granularity was interesting, that could be derived from existing privacy literature. The inter-partner interaction particularly struck me as not grounded, for example the messaging: wouldn't existing messaging apps provide this feature? Wouldn't pre-designed messages come off as inauthentic? etc. As such the resulting app did not feel inspiring or all that novel.\n\nNext, I was happy to see that the authors observed real people using their prototype, which can be useful for getting initial reactions and feedback. However, given how personal and contextual real use is, we have to admit simply how unrealistic an in-lab study is for this kin of work. As such, unfortunately I find little value in the statistical results as it is unclear to me if they can generalize. The initial positive reactions and potential concerns presented were useful, but I would have hoped for a much deeper treatment of this.\n\nIn the end, while this is a solid GI paper, it does have shortcomings that make me worry about the long term impact. My thoughts are that the paper would be a lot stronger were it streamlined. It is awfully verbose and seems to take tangents, where I think a more focused and honest treatment of the data collected (e.g., downplay / exclude stats from in-lab study, etc.) would result in a cleaner, and more strong, result.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/AnonReviewer3"]}, {"id": "GZ6o42i3Sj", "original": null, "number": 2, "cdate": 1610575900162, "ddate": null, "tcdate": 1610575900162, "tmdate": 1610846669206, "tddate": null, "forum": "3fFZNlSO7GC", "replyto": "3fFZNlSO7GC", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/-/Official_Review", "content": {"title": "Review of CoAware: Designing Solutions for Being Aware of a C-located partner's smartphone usage activities", "review": "This paper is about the design of an app, called CoAware, that allows pairs to know about and see the usage of their partner's smartphone when they are physically co-located. The authors conducted an initial survey to understand people's willingness, interest and attitudes in having this knowledge, as well as their existing behaviour and practice in smartphone use during co-located activities such as during meals. The results of the survey were then used to inform the design of Co-Aware. An user evaluation of Co-Aware was conducted with 11 couples. The main findings of this evaluation were that people preferred knowing some detail about the type of use that was occurring, that notifications were intrusive and how much detail about smartphone use was depending on the type of application. There was also concern about having and maintaining some privacy about smartphone use.\n\nThis was a fun paper to read and the topic is intriguing. It will be of interest to the GI audience and will likely generate good conversations as most people have the experiences outlined in this paper. The authors used a well-designed methodology to create and evaluate CoAware. They discovered attitudes, practices and opinions from a wide audience via an on-line survey, and then motivated their app design based on the responses to the survey, followed by a user study. \n\nHowever, there are some issues with this paper that reduced its rating:\n1. Missing research objective/questions.\n2. Do not report results in the introduction.\n3. Once the common code set was created, how was the data then coded?\n4. Why is it interesting that the younger participants thought it was important to have apps?\n5. \"We believe\u2026.\" - Do not use believe here to explain a result like this? Re: privacy. The quote indicates embarrassment rather than sensitivity. Needs a reference from the literature.\n6. While the descriptive statistics for the survey are interesting, there should be some statistical reporting given the quantity of data received. Statistics would provide a much stronger argument for some of the claims/conclusions in the paper.\n7. \"Improved awareness may help people use phones wisely.\" How is wisely measured? How is the quality of domestic life measured? These were not measured anywhere in this paper and should not be claimed here.\n8. Discussion of survey is very limited and is not really a discussion of the survey results. I suggest combining results and discussion and answering the question \u201cwhy did you get these results?\u201d\n9. Why was 30-sec used for closing an app? How was this time determined?\n10. The theme table for study 2 is missing. What reliability method and measure was used?\n11. Figure 5 is very confusing. The grey scale does not seem to match for the different areas.\n12. Why would the authors use a non-parametric test for the within-subjects analysis and a parametric statistic for the between- subjects analysis. Need to report the normality statistics to justify the approach.\n14. Discussion from study 2 needs support from the literature. The claims made do not necessarily link to the evidence. For example the claim made about personal digital space and Screen Share is not supported by the data. There may be other reasons why there was lower comfort ratings that I think would be closer. Some evidence from the literature would also be useful. A correlational statistic would also have been useful to look at those linkages rather than guessing.\n\nTechnical issues:\n1. One question in Figure 1 is mis-worded, \"how many hours do you send\", I think should be \"spend.\"\n2. How was significance measured in Co-located Smartphone Use section, sentence 1\n3. Grey scale in Figure 2 is difficult to see, use patterns instead\n4. Writing is fairly sloppy and often colloquial (e.g., use of the verb \u201cget\u201d, words such as interestingly). A good editing pass is necessary.\n5. Do not begin sentences with a number (e.g., 78%)\n6. Figures with a, b, c, etc. on them are difficult to see. Need to revise format\n7. Figures should always be located after their in-text reference, not before.\n8. Using words such as \u201cOf course, \u2026..\u201d should never be used in a formal academic research paper.\n9. Need a statement about ethics approval for both studies.\n10. There is some switching between past and present verb tenses in paragraphs making the paper difficult to read.\n\n", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/AnonReviewer2"]}, {"id": "EZV0Jsq8vB5", "original": null, "number": 1, "cdate": 1610484514567, "ddate": null, "tcdate": 1610484514567, "tmdate": 1610846669286, "tddate": null, "forum": "3fFZNlSO7GC", "replyto": "3fFZNlSO7GC", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/-/Official_Review", "content": {"title": "CoAware: Designing Solutions for Being Aware of a Co-Located Partner\u2019s Smartphone Usage Activities", "review": "This paper details thoughts, practices, habits, and perceptions of smartphone use in couples. This is done through two studies and a prototype; first habits, perceived wants, and other requirements are gathered from participants in in depth interviews via MTurk; a prototype based on this analysis is created; and a lab study is used to find out user acceptability and other initial feedback of their prototype.\n\npros:\n- a motivated and fairly clear paper\n- good use of in-depth qualitative analysis, which is more appropriate for this type of work\n- good categories and stories led me along and helped me understand the data. \n- descriptive statistics back up qualitative results to give more depth about the sample\n\ncons:\n- perhaps less impactful results - it's not clear how the results differ from current knowledge\n- shallow discussion\n- mismatched participant pools\n- could have more method details for reproducibility\n\nSo overall I thought this paper was well done and informative. I think it's a strong work that provides the community with a body of insightful qualitative data that can be the basis for future work. I think the weakness is in the prototype and lab evaluation study which has questionable use and impact - this is admitted by the authors themselves. While the prototype on its own is fine, I think there was a missed opportunity for long-term evaluation. As this tool is meant primarily to be used in private spaces in private, romantic, long-term relationships, I think an \"in-the-wild\" study, even with just a few couples, would have been far more appropriate. As it stands, the lab study had good method and is acceptable, just that I feel the impact of those results is much less than the fascinating and in depth look into digital hygiene/habits in relationships. I think that the paper focused primarily on this first study was a good choice and enhances what I see as the the primary contribution.\n\nAgain on the positive note I think the qualitative analysis was well chosen, well organized, and the results well presented. I really feel like I got to understand the large amount of data generated in the MTurk study. In particular, I liked the means and averages and percentages given to back up or describe how common some sentiments were in the sample. My only small complaint, which may be due to length, was that there was not enough detail on how coders reconciled separate code bases, how much they differed, and how much they were similar. This would enhance the existing contribution. As it stands, I think it is okay to leave it out if space constrained (though a few extra sentences would be useful if it can be squeezed in), as even the same level of analysis from 1 coder would still make the results valuable to the community (though using 2, however well they matched, increases credibility). \n\nI thought discussion was a bit shallow, again perhaps due to the amount of research and space available. I was hoping for more insight...I feel like just thinking about various typical user needs and the proposed solution could have generated many of the same insights. Of course, with the work in this paper it is data grounded and thus more reliable, so this is still valuable. I just normally look forward to a broader and deeper discussion, especially from such rich qualitative data.\n\nA very small point is it was strange that the authors pulled 2 very culturally different countries as participants and did no cultural analysis. Especially as follow ups were done with exclusively NA participants. Views on family and socializing and rule-following are highly culture-sensitive, and while mentioned in the limitations, the exclusion felt very strange.\n\nThus, while there are drawbacks, I feel like the paper presents a reasonable and well done body of knowledge for the community, and is organized in a useful way that can act as a ground for further experiments and designs in this field. Thus, I would recommend acceptance. \n\nSmall points:\n-new design motivation in related work felt out of place (see 2.3 e.g., we had granularity levels. This is new information and the real app design doesn't show up for many pages, so consider organization)\n- Section 3 (first experiment) was initially unclear it was just a  requirements gathering experiment. This should be better clarified in the transition, as I was confused about what the experiment was about. Perhaps simply a better title for the section would improve e.g. \"Exploration of Couple Smartphone Awareness\"", "rating": "7: Good paper, accept", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper2/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=AhgksBTYwC5", "paper_id": "AhgksBTYwC5", "reviews": [{"id": "grfSFkCRxMc", "original": null, "number": 3, "cdate": 1610668317675, "ddate": null, "tcdate": 1610668317675, "tmdate": 1610846670633, "tddate": null, "forum": "AhgksBTYwC5", "replyto": "AhgksBTYwC5", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/-/Official_Review", "content": {"title": "Paper is well written and study seems valid", "review": "This paper describes a study looking at the relationship between affect and behaviour change in data videos.\n\nThe paper is well written and there has clearly been much thought put into the study design and analysis. I am not an expert in the area or the methods used, however the study design and analysis seem to be valid. The conclusions drawn from the results seem a little tenuous, but somewhat convincing.\n\nThe main issue I see in this work is that it doesn't address the potential issues of using affect to sway opinion instead of fact. If a video is heavily relying on affect, I don't see how this can be classified as a 'data video'. The related work does mention differences between the two (central route vs peripheral route), but a more thorough discussion is warranted. I note that the authors removed videos with false claims from the study, so perhaps this issue can be safely abstracted from the current study. Nonetheless, it seems important to discuss the potential application for misuse of such an approach.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/AnonReviewer2"]}, {"id": "XjW3jEHIOQ", "original": null, "number": 2, "cdate": 1610647137908, "ddate": null, "tcdate": 1610647137908, "tmdate": 1610846670555, "tddate": null, "forum": "AhgksBTYwC5", "replyto": "AhgksBTYwC5", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/-/Official_Review", "content": {"title": "Data videos need to be personalized", "review": "The paper studies publicly available data videos addressing health-related behaviour. Through a M-Turk study, it ask if the videos increase negative affects and if the negative affects are linked with personality traits, can predict changes to viewers\u2019 willingness to improve their behaviour. It further asks if the willingness can be predicted with personality traits and/or video attributes. The study finds that the perceived usefulness of the information presented in the videos along with neuroticism predicted our participants\u2019 willingness. The authors also find that the neuroticism-persuasiveness link relates to the likability of the video.\n\nMore information is required on how the final 9 videos were selected. Authors mention \u201clength, source credibility, information accuracy, etc\u201d - can they explain this in more detail. This is especially important as finding relevant videos is an important challenge in a study such as this. I am also not completely convinced that the PPQ Persuasive Potential Questionnaire can be used to assess the potential of data videos. As the paper also mentions, the original PPQ was specifically created for assessing the persuasiveness of systems - it is derived from the TAM/UTAUT models. The study needs to motivate how it can use the PPQ to analyze persuasiveness of videos better. There is literature in communication studies on \u201cNarrative Persuasion\u201d that might fit this better, and I would encourage the authors to look at other sources that look at the persuasiveness in videos. \n\nBesides these concerns, the study itself seems well-designed and the results seem robust. However, I have concerns that the final results are not novel enough. Yes, videos should be personalized, and yes, people high on neuroticism might be harder to persuade through negative videos. But the deeper question. which the authors don't seem to be considering, is whether negative videos are really persuasive in the first place. A separate study might use both negative videos and positive videos. \n\nIn summary , I feel like the authors need more details about the videos in the paper. How were they chosen? More details about what the content consisted of? How can we measure the persuasion of videos given the emotional and information content (and not use a related but not completely relevant measure, i.e. PPQ)?\n\nOn a side-note, the authors must reconsider using the Big-Five-10 questionnaire. It is fine as a base level test, but if the paper is delving deeper into how personality traits affect consumption, they need to look more questions/dimensions to truly isolate relationships.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/AnonReviewer3"]}, {"id": "jFeqt7WzAwR", "original": null, "number": 1, "cdate": 1610454961626, "ddate": null, "tcdate": 1610454961626, "tmdate": 1610846670455, "tddate": null, "forum": "AhgksBTYwC5", "replyto": "AhgksBTYwC5", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/-/Official_Review", "content": {"title": "Is fear an effective motivator for better health?", "review": "This is a well-written paper that explores an important problem, namely how can we use technology to foster better health behaviors. The authors conduct a mechanical turk study on ~100 participants (76 useful participants after filtering questions) to determine whether short health videos foster an increased level of fear or concern regarding health related issues and, alongside this, whether participants' behaviors will change.\n\nAt the outset, I question a fundamental assumption of this paper, best expressed by the authors in paragraph 2 of the paper:\n\"As behaviors are normally adjustable, people suffering from\nbehavior-induced health issues would benefit if they understood how\ntheir seemingly minor behaviors are tied to their serious medical\nissues. Further, they could be motivated to reevaluate their behaviors\nif they were guided with concrete behavioral suggestions on how\nto improve their health.\"\n\nLet me unpack this a bit. Is it truly the authors' contention that people do not understand the consequences of negative health behaviors? I, personally, don't think this is the case. I should exercise more, eat fewer calories, preference whole grains, fruits and vegetables, avoid sugar and saturated fat, drink less coffee ... The list goes on. And I *know* the negative consequences of these actions. But I persist -- not because I don't want to change but because the immediate temptation of a dessert outweighs the long-term thought process of fear of health-related issues. Or the immediate need of a coffee outweighs the fact that I've had five so far today. \n\nEssentially, to my mind, the underlying assumption that motivated exploring these health issues is faulty, and this, in turn, results in a set of results from which it is hard to draw anything useful. As the authors note, negative affect wasn't impacted by showing videos. Why? Because everyone already knows the negative consequences of much of the behaviors explored. Stated another way, if I think about this from, for example, Fogg's Behavior Model for persuasive technology, what the authors are trying to do is increase motivation, and to do this through negative emotional responses (specifically fear). However, the challenge is that the domain chosen -- health related interventions -- is one where the viewer already knows the consequences, undoubtedly fears them (at least in the abstract) and misses, instead, the ability to easily change behavior and/or some trigger to encourage them to make a better decision in the moment (again borrowing from Fogg's model). \n\nOne thing that I try to do in reviews is to highlight where and how I think the authors could re-interpret their data to enhance their results. Unfortunately, this is one case where I simply don't think it's possible to pull anything from the data set. The assumption of the authors was that people don't know the long term consequences of their behavior, they don't fear them enough, but here I think they do. The authors results even support this assumption -- show them the video and their fear is not increased; it actually is reduced. I think the problem is that -- even with the pre-existing fear -- there is no way to adjust motivation through that fear. Instead, we need to look elsewhere, to questions such as:\n- Can we motivate people by making positive behaviors fun?\n- Can we lower the barrier to act healthier (e.g. make it easier to exercise, add bike lockers at work, simplify showering and changing, subsidize public transit, offer free gym memberships, provide healthy lunch options at work ...)?\n- Can we remind people in a timely fashion to pursue those positive behaviors (e.g. daily exercise reminders, break reminders, etc.)?\n\nSo ... I commend the authors for the domain they are working in. However, I feel that the intervention chosen is simply the wrong one. On the positive, this was a relatively low cost study to run -- select some videos, show them to MTurkers, find the negative results -- so the cost of the false start was low.\n\nFinally, I spent some time thinking about whether or not, even with negative results, it might be worthwhile to publish this paper as a negative results paper, but, in this case, I don't see that path forward. Negative results are interesting when they are surprising and can better inform future work. Here, we've seen advertisements ad infinitum on the negative health aspects of x, y, or z, yet we persist. Because that the negative is insufficient is known. \n", "rating": "3: Clear rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper39/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=MavuzTzi4Sy", "paper_id": "MavuzTzi4Sy", "reviews": [{"id": "obufU1c1xPH", "original": null, "number": 3, "cdate": 1610592974707, "ddate": null, "tcdate": 1610592974707, "tmdate": 1610846670762, "tddate": null, "forum": "MavuzTzi4Sy", "replyto": "MavuzTzi4Sy", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/-/Official_Review", "content": {"title": "Many things unclear", "review": "This paper describes a web-based infovis system that suggests visualizations by recasting the recommendation problem into something called a \u201ck-armed contextual bandit problem\u201d and using an existing algorithm. I was able to try the online demo linked from the paper, and it seemed to work (though I wasn\u2019t sure how to use it) and clearly is the result of a significant amount of development effort. \n\nThe main issue is that it isn\u2019t entirely clear what the contribution is (is it the recommendation algorithm? the web application/system? a way to categorizing viz? new types of viz like the overview panel? understanding how people select and use different viz?). Related to this, it\u2019s not clear how this work improves on previous approaches, systems, etc., especially previous viz recommendation systems like those listed in paragraph 2 of the intro. Finally, it\u2019s not clear that the method(s)/system/techniques were really tested and validated in the study. \n\nThese issues might be a case of writing and presentation, perhaps there\u2019 some great work that can\u2019t be understood in the current paper form. I\u2019m not an infovis expert, so I\u2019m sure I\u2019m missing infovis research context that might have helped me fill in the blanks regarding some of the issues above. But GI is a general conference, so GI papers need to be clear enough that people who are out-of-area can still understand the basic things: what was done, how the everything works, why it\u2019s novel, and that it was validated. The issues above suggest this isn\u2019t the case. A careful full rewrite of the paper, likely with a revised and expanded study, might be able to address the issues. Unfortunately, as submitted, I would not argue for accept.  \n\n- - - \n\nThe second paragraph of the introduction names and cites past examples of what appear to be similar visualization recommendations systems, including some that also seem to recommend based on user goals and tasks and user preferences. But the descriptions are very brief, really only placing them in high level categories. Only [38] is included in the related work section with a few sentences of description, but even here, there is no clear comparison or explanation what is novel.  The rest of related work seems focused on recommendation algorithms or systems not mentioned in the intro as most similar systems.  This makes it very hard to understand exactly how this relates to, and is an improvement over, previous work. \n\nSince the majority of related work is about underlying recommendation algorithms, I expected to see this as a major contribution with a clear description of it. Section 3.3 and 4.1.5 have some description about this, but it is quite vague. In section 3.3., I understand that the recommendation seems to be based on what graphs the user clicks on and how long they study them (stated in paragraph 1), but how this works in terms of the algorithm isn\u2019t explained. The second paragraph describes how simulated data sets were used select an algorithm, but this isn\u2019t clear either.  In section 4.1.5, the first part repeats some of 3.3 with an obvious ML toolkit level explanation in paragraph 2. I wasn\u2019t able to understand what paragraph 3 is saying beyond that the model is trained, it runs each time the user does something (I think that\u2019s what a \u201ctrial\u201d means here), and that the model can be saved.  Figure 9 is so high level and generic that it could describe any ML system. \n\nI think section 3.1 and 3.2 are explaining a framework for categorizing different kinds of visualizations. The categorization in figure 3 makes good sense from as high level, but I\u2019m not sure what is new. The user study in section 5 seems to return to this focus on visualization types rather than the system or recommendation algorithm. \n\nThe system itself needs to be explained with enough detail that the reader can understand how it works and why is has new and better ideas. I read section 4.1 twice, and I still can\u2019t understand how the interface works (e.g. how a user navigates the system). For example, the overview plot seems to be central to the interaction flow, but I was never able to figure out what it is visualizing or how the user interacts with it. For the most part, this section seems to focus on describing different variations of visualizations (exemplary plots) which again relates back to Figure 3 and section 3.1 and 3.2. \n\nThe study results seem to focus on user interpretation of data from different kinds of graphs (e.g. noticing outliers or not, depending on number of dimensions). I think finding outliers was a specific study task, but this isn\u2019t stated. The second paragraph and first part of 5.2 are about types of plots preferred by participants from a specific domain. In either case, it isn\u2019t clear to me how this validates the system or recommendation algorithm. Perhaps this says something about what I\u2019m calling the \u201cframework\u201d of viz types (figure 3), but I\u2019m not sure.  The last part of 5.2 is the only direct result about the web application itself, but it isn\u2019t too positive. Given the lack of clarity in describing the system earlier, I\u2019m not sure this a main part or even something that is new and considered a contribution. \n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/AnonReviewer2"]}, {"id": "_cWCadbkeQq", "original": null, "number": 2, "cdate": 1610510481530, "ddate": null, "tcdate": 1610510481530, "tmdate": 1610846670855, "tddate": null, "forum": "MavuzTzi4Sy", "replyto": "MavuzTzi4Sy", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/-/Official_Review", "content": {"title": "My review", "review": "This paper presents an interactive prototype HMaViz which recommends to the user visualizations based on the user\u2019s data that they are trying to visualize. The system is based on a new framework proposed in the paper, and the recommendations are made using reinforcement learning, more specifically contextual bandit algorithms. \n\nAs noted on page 3 of the paper, the framework characterizes \u201cusers and visualizations\u201d on a number of criteria (number of data dimensions, visual abstractions, and visual patterns). The authors mention that although each of these criteria have been study separately, no existing framework has incorporated them together for visual recommendations. [Aside: I am not clear how these criteria characterize users.]\n\nFinally for contributions, the paper claims a user study that \u201cdemonstrates the usefulness of HMaViz on real-world datasets\u201d.\n\nAs someone who is familiar with viz research, but is in an adjacent field, I will admit that I struggled with the contributions being claimed. It is clear that the authors have done a tremendous amount of work that culminates in this paper, but the key contributions and clarity on how others will benefit from this work were not sufficiently evident to me.\n\nIf other researchers have looked at all these same criteria, but not put them together in a framework, perhaps there is a reason. Just because there is a gap in the literature, it doesn\u2019t necessarily mean that filling the gap will be a contribution. I would have liked to see more coverage on why this is a problem that needs addressing (Why do we need a framework?). I believe my desire for more coverage here stems at least in part from the Introduction, which I found to be overly brief. The Introduction mentions in the first paragraph that it is challenging for analysts to select the proper visualization tools to meet their needs because of \u201cthe ineffective layout design\u201d. From there on this is referred to simply as \u201cthe problem\u201d with no further explanation. What is the ineffective layout design? How big of a problem is it?\n\nThe intro goes on to indicate that others have tried to tackle this problem, but I am left unclear on why HMaViz, and the framework it is based on, are expected to work better than prior work. The related work section doesn\u2019t help me contextualize the contribution much better, unfortunately. Some of this comes in a short paragraph at the top of the righthand col on page 5 \u2013 a comparison with the Voyager and Draco systems, but it is short and I feel that it comes too late.\n\nIt is possible that some of my confusion may stem from the clarity in the writing. I am very sympathetic to non-native English writers, and in many places in the paper I can infer what I believe the authors intended. But there are a good number of places where it is unclear to me. For example, on page 2, in reference to a rule-based system system/approach it says \u201cIn addition, this work is lacking in supporting the empirical study.\u201d Does this mean that there is no user study that supports/validates the approach? It goes on to directly say \u201cA similar approach to this study was found in [38].\u201d But I am confused, because I thought it said there was no study. Another example, also on page 2 is referring to Figure 2 and says \u201cNotice that the visual features in our framework will be computed on the aggregated data, which allows us to handle large data.\u201d Am I supposed be noticing/seeing this in Figure 2? If so how? Or did the authors mean to say \u201cNote that\u2026\u201d which has a very different meaning.\n\nI applaud the authors for conducting a case study with 10 users, and that they went to clear efforts to have a varied sample of participants. However, I was left quite unclear on what was actually done and how the data was analyzed. The study is referred to as an experiment but it is also noted that \u201cthe qualitative analysis method is mainly used\u201d. Which qualitative analysis method? What were the conditions in the experiment? What did the users actually do? The Phase II description does not help me here. A key claim of the framework/system, as I have understood it, is that it learns from users\u2019 interactions. How was this validated in the user study?\n\nI do see that the authors have done a lot of other work, and so although they claim the user study as a contribution of their work, I don\u2019t believe it is the main contribution, nor should the bar be terribly high. It is one piece of several in this research. But even with that said, I believe the write-up of the study as it is now is below bar \u2013 both the description of the study and the analysis.\n\nOther/minor: \nThe resolution of the figures seems too low. While I can see most things okay, there are some elements that I want to be able to read (axes on the graphs for example), and even when I zoom in, the figures are just fuzzy. \n\nThere is mention that \u201cthe next level of analysis will be calculated as well (via another web worker)\u201d. Perhaps I missed it, but where do web workers come in?\n\n\nOverall, to summarize, there seems to be a substantive amount of work that went into this research. It is somewhat unclear to me, but it is possible that a substantial iteration on the writing in the paper (framing, contextualizing contribution, clarity) is all that is needed to make the contributions come through more clearly. However, it is possible that more actual work is needed, even before the iteration on the writing. \n\nI hope these comments are helpful and wish the authors success with their work.\n\n\n\n\n\n", "rating": "4: Ok but not good enough - rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/AnonReviewer1"]}, {"id": "WbLfSPMCph", "original": null, "number": 1, "cdate": 1610505287797, "ddate": null, "tcdate": 1610505287797, "tmdate": 1610846670956, "tddate": null, "forum": "MavuzTzi4Sy", "replyto": "MavuzTzi4Sy", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/-/Official_Review", "content": {"title": "Review of HMaViz", "review": "This paper tackles the problem of visualization recommendation. A framework is proposed to automatically generate visualizations from input data based on a number of dimensions. The recommendation challenge is formulated as a contextual bandit problem, and different contextual bandit algorithms are evaluated. An interactive prototype is developed based on the framework, and a user study was done to evaluate the system HMaViz.\n\nVisualization recommendation systems need to answer multiple questions: what data variables to show? What visual encodings to use? These questions, as acknowledged in the related work section, have been explored in previous work. This paper offers some new perspectives on the recommendation problem. I think the focus on data abstraction level, and the contextual bandit problem angle are interesting and novel in this paper. \n\nUnfortunately, the current submission lacks enough technical details and explanations for me to evaluate the effectiveness of the proposed framework and the algorithms. First of all, the visualization dimensions/criteria discussed in Section 3.2 and Section 4 do not match. Section 3.2 talks about the number of data dimensions, data abstraction and visual patterns; section 4 talks about statistical distributions (is it the same with visual patterns?) and data abstraction, the number of data dimensions is left out. Secondly, it is important to explain what contextual bandit problem is. Not everyone is familiar with this term. Providing background information on how the learning algorithms work is also necessary. In addition, the paper should include information on how the simulated data was generated, and how the algorithms were evaluated. Without such critical information, it is impossible to assess the soundness of the technical contribution, which arguably is the most interesting part of the paper.\n\nIt is also unclear how the recommendation engine works when there is little training data. Given that the paper claims to use a reinforcement learning approach, the algorithm might be able to start without a lot of data, and can adapt as new data comes in. But in the very beginning when there is no user interaction, how is the recommendation made? How are different types of user actions (e.g. changing data dimensions, changing visualization parameters, exploring visualizations) used to feed into the learning algorithm? These details are important for readers to understand how well the recommendation engine works.\n\nThe case study is not very informative to me. I couldn\u2019t tell how well the system works, and if any potentially useful visualizations are omitted by the recommender.  A comparative study with systems like Voyager and Draco would be insightful.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper38/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=C7nHFPmJbTX", "paper_id": "C7nHFPmJbTX", "reviews": [{"id": "vPyuYLtzwom", "original": null, "number": 3, "cdate": 1610569053377, "ddate": null, "tcdate": 1610569053377, "tmdate": 1610846671719, "tddate": null, "forum": "C7nHFPmJbTX", "replyto": "C7nHFPmJbTX", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/-/Official_Review", "content": {"title": "Novel application of stokes equations for fluid copy and paste, but comparison and results need work", "review": "This paper proposes a method for \"copy and paste\" editing of fluid simulations that combines regions from two different simulations by blending the vector fields across a boundary region using steady state Stokes interpolation and assuring a divergence-free flow.\n\nThe proposed approach seems to be a novel application of the work of Bhatacharya et al (2012). So while I find the contribution here to be modest, the problem is nicely motivated by providing insight into artefacts created by cut and paste editing, mainly i) non smooth and ii) divergent flows. These artefacts are resolved by the proposed approach by assuring that the boundary regions have smooth flows *and* are divergence-free by solving a constrained least squares problem.  As noted in the paper, the input vector fields already exhibit properties of physical fluids.\n\nThe related work discussion and background in this paper is excellent, and the authors have done a good job of situating their work relative to others in the field. However, not being an expert in fluid simulation, I would have appreciated a bit more detail about the cfd formulation used in this work, if only to make the paper more self contained and to define specific terms used throughout the paper.\n\nMy issue with this work, and it is a pretty major one, is that the results presented in the paper and supplementary video make it difficult to properly evaluate the approach. \n\nI understand that the two-tone tracer particles used in the fluid simulation may have been chosen to highlight artefacts, but in many cases the patterns produced are quite noisy and it is difficult to identify details, e.g. in Figure 4, flow velocity discontinuities are not clearly visible.  Perhaps larger figures would help.  Rendering smoke density may also make it easier to compare to results produced by other work, such as Sato et al 2018. Specifically, it would have been nice to see a comparison to tests performed in the supplementary video of Sato et al, in which they evaluated their approach for different directions and magnitudes of velocity fields.  I think the approach in this paper would perform better.\n\nHowever, in order to provide convincing evidence about the utility of the approach, a 3D implementation would best demonstrate how the method handles complex examples.  User interface challenges aside, it should be straightforward to extend the approach to 3D (as noted in Section 6) and demonstrate the technique with at least one compelling 3D example. \n\nAlso, there are also no timing results provided in the paper, but they would be helpful to know and specifically about the overhead compared to projected harmonic interpolation. However, I think timing information would only be meaningful for 3D simulations.\n\n", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/AnonReviewer3"]}, {"id": "rpkyF7_HRAF", "original": null, "number": 2, "cdate": 1610499282973, "ddate": null, "tcdate": 1610499282973, "tmdate": 1610846671804, "tddate": null, "forum": "C7nHFPmJbTX", "replyto": "C7nHFPmJbTX", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/-/Official_Review", "content": {"title": "Results are limited in 2D, but potentially valuable", "review": "This paper proposes a new fluid-interpolation scheme with a divergence-free constraint. The gap between the two input flows are smoothly interpolated using a devised vector laplacian.\n\nThe previous work did not enforce divergence-free constraints, and the idea of enforcing \"divergence-free\" constraint at the boundary also satisfies the internal divergence-free is both conceptually and mathematically interesting. Such an idea and the implementation are exciting, and I am in favor of accepting.\n\nAt the moment, the results are only limited to 2D, and I would like to see some 3D examples. I encourage the authors to provide at least one 3D example if the paper is accepted in the final publication, but this is not mandatory.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/AnonReviewer1"]}, {"id": "KQieEXxF4i", "original": null, "number": 1, "cdate": 1609944252326, "ddate": null, "tcdate": 1609944252326, "tmdate": 1610846671900, "tddate": null, "forum": "C7nHFPmJbTX", "replyto": "C7nHFPmJbTX", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/-/Official_Review", "content": {"title": "Difficult to see method advantage in examples", "review": "The paper presents a divergence-free method to blend two fluid simulations. This is an improvement over Sato et al which has no divergence-free guarantee. But the exact math is not new. On top of that, the results don't seem to have much visual improvement. There is still visuallly unnatural deformation and the field near the boundary between target region (outer) and blend region (middle) still has sharp changes. The animation created by harmonic interpolation seems more natural (about 1:00 in the video).\n\nI think the major problem is that the examples don't show how good the method is. It would improve the paper if there are more comparisons that can show the problems of the prior work's method (e.g discontinuities, divergence) while the authors' method is visually better.\n\nSome comments about the figures:\n\n- Figure 1 right and Figure 7 right have the outer region animation changed (strips not straight). But the authors' method is supposed to not alter the target animation outside the boundary of blend region.\n\n- Figure 2 left is not a frame of the resulting animation.\n\n- In Figure 4, it is difficult to notice any smoothness differences between the two methods. Both have some very sharp changes in the field. The authors can highlight the discontinuities in the right image.\n", "rating": "4: Ok but not good enough - rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper35/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=YXUV-SU6i8I", "paper_id": "YXUV-SU6i8I", "reviews": [{"id": "KkRq9MkCBoX", "original": null, "number": 3, "cdate": 1610523816076, "ddate": null, "tcdate": 1610523816076, "tmdate": 1610846672681, "tddate": null, "forum": "YXUV-SU6i8I", "replyto": "YXUV-SU6i8I", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/-/Official_Review", "content": {"title": "Good, small contribution - but some questions about the information criteria", "review": "This work discusses a modification on the Finger-Fitts (FFitts) model, and a study which demonstrates that it slightly outperforms the previous model (despite an additional regression-fitted parameter). The new model seems fairly sensible, but not particularly novel - for instance, it is very close to an old model by Welford, as cited by the authors of the present study. The main contribution here seems to be the evidence showing that this model is more suitable for predicting the movement times for finger touch events.\n\nI would have appreciated a quick explanation as to how $c$ was fitted to the data - whether it was determined directly through some mathematical procedure (as $a$ and $b$ often are), or whether some optimization strategy was used to determine its optimal value. In the former case, providing a formula for $c$ would be useful for future practictioners.\n\nI appreciate the authors' use of the AIC and WAIC to assess the impact of their additional parameter c. This helps addresses a major potential criticism of the work - otherwise, the addition of an extra parameter could significantly improve the fit without actually being meaningful or useful simply due to increased fitting power. I have a few small comments about the way they've employed the information criteria. First, I believe the authors should also report the BIC (Bayesian Information Criteria); both the AIC and BIC are commonly used to evaluate model suitability and have different statistical properties. Second, I question whether $\\sigma_a$ should qualify as a parameter in FFitts-We, given that it is set as the constant 1.5 and is not adjusted through model fit (unlike the $c$ parameter of FFitts-W). If $\\sigma_a$ is fitted, as opposed to simply fixed by a previous study, the comparison between FFitts-W and FFitts-We would become more valid. If the IC values are recalculated with two parameters for FFitts-We, I believe the AIC/WAIC values will come closer to that of FFitts-W, and the BIC values may even show FFitts-We slightly ahead.\n\nAlthough the work itself has a fairly small contribution, the short page length (4) merits consideration for inclusion, especially as the contribution is notable and focused. Given the importance of the information criteria analysis to this contribution, I would definitely like to see a revision to the paper to include the necessary corrections and additional analysis. ", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/AnonReviewer1"]}, {"id": "DIBvi4WR7rm", "original": null, "number": 2, "cdate": 1610420224159, "ddate": null, "tcdate": 1610420224159, "tmdate": 1610846672604, "tddate": null, "forum": "YXUV-SU6i8I", "replyto": "YXUV-SU6i8I", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/-/Official_Review", "content": {"title": "Small contribution is fine, but several issues with context and analysis ", "review": "This 4-page paper reports on a single experiment to test a revised version of FFitts Law [6] that uses nominal width instead of effective width, and an empirically determined third parameter instead of a constant value representing variance from absolute touch accuracy.  The results suggest the refined model is better, primarily based on lower AIC/WAIC and lower RMSE. The model itself is not new, and the work overall is very close to a recent UIST 2020 paper [19], but this is ok.  I have no problem accepting a paper to GI that makes a small contribution with a single experiment to provide some additional and refined empirical evidence for previous work. \n\nI really wanted to argue for accept, but I found several things that concern me. First, in spite of the title, this isn\u2019t a 1D task in terms of target size, it\u2019s a 1D movement for a 2D target. Second, the closely related [19] is not described in enough detail and the model tested in the submission is really exactly the same as the \u201csmaller-than\u201d model tested in [19].  Third, the main metrics used to compare the FFitts-W and FFitts-We and form the main contribution have apparent issues: AIC might be calculated as though FFitts-WE has 3 params instead of 2, and RMSE comparison uses no statistical test and the very small different size isn\u2019t acknowledged. Finally, the performance of FFitts-We is largely dependent on the sigma_a parameter, but the submission uses one calculated on an old phone in [6].  Perhaps all of these could be clarified and fixed with revisions, but maybe these are errors that undermine the validity and size of this already small contribution.  Unfortunately, as the paper is submitted I can\u2019t argue for accept.  \n\nAlthough this paper is all about a 1D task, it is not according to the standard definition used in pointing. A true 1D task is when the target is constrained in only one direction, the other target dimension is infinite. The constrained dimension is most typically an \u201camplitude\u201d constraint, meaning it is aligned with direction of movement (see Accot and Zhai\u2019s 2002 \u201cMore than dotting the i's\u201d paper for a good explanation of 1D pointing with different direction constraints). This is exactly how a 1D task is defined in the original FFitts paper [6]. This submission seems to conflate a 1D task to be only be about the direction of travel, but since the target is a circle, the task is 2D regardless of the movement directions tested. In fact, the paper used the \u201c2D\u201d version of the sigma_a parameter instead of the \u201c1D\u201d one in [6]. This seems to further acknowledge the tested task isn\u2019t really 1D.  \n\nThe very similar and closely related paper [19] should be described in more detail and more accurately. The current description is essentially two sentences in the intro and one sentence in the related work. In both places, the model and work of [19] are characterized simply as extending FFitts to 2D and using nominal width and height.  But there are important details about [19] not covered, such that it tested two variations of FFitts models for 2D targets, \u201cEuclidean\u201d and \u201csmaller-of\u201d.  The results showed the smaller-of model was best which is quite relevant to this submission, because the \u201c1D\u201d task (where W and H are the same) means that the smaller-of model with nominal width trivially reduces to the \u201cFFitts-W\u201d model (eq 8) in this submission.  In other words, the models are the same.  \n\nThe submission also doesn\u2019t properly acknowledge that the \u201cc\u201d parameter introduced in [32] (to avoid using sigma_a) was also tested in [19] with touch. Section 3 of seems to be suggesting that using c for touch in the submission is something new for touch, but it isn\u2019t. \n\nComparing models using AIC is great, much better that simply comparing R^2 values as was done in older papers. The main benefit of an AIC-based comparison is a penalty for adding more model parameters. This means if two models are similar in terms of fit, but one has fewer parameters, it will have smaller AIC. This raises a concern because Table 3 seems to suggest that FFitts-We has three parameters by also considering sigma_a. But sigma_a is a constant value for the regression (the submission is clear that sigma_a value is always 1.5 taken from [6]). If AIC and WAIC are calculated as though FFitts-We has 3 parameters, then those measures are incorrect, and given how close they are, one of the main results of the paper may be wrong. \n\nIt isn\u2019t stated, but I believe RMSE units must be in seconds. Therefore, the differences between the RMSE for the main FFitts-W and FFitts-We models are quite small: about 6ms or 1.2% of a typical 0.5s pointing task. Given RMSE values are calculated from several runs, the stddev or 95%CI of these average RMSE values should be reported, and a stats test to verify a claim like \u201cFFitts-W outperformed all other models\u201d for RMSE.  Some discussion about the practical relevance of such a small effect of 6ms difference should also be included. \n\nI wonder if using the sigma_a value from [6] is a good choice. That was measured on old phone technology, a Nexus with 480x800 resolution at 254PPI. The touch sensor hardware on a Pixel C tablet is likely much better, and it has a 21% higher PPI. This means a sigma_a on the Pixel C might be more accurate. [6] states that the sigma_a values they suggest should be verified in future work. A better approach would have been to include the simple and fast calibration task used in [6] to determine the best sigma_a for the Pixel C.  \n\nThis is a small point, but the ANOVA analysis in 4.3.1 is not very useful considering the goal of the paper. It only shows obvious effects of W and H on time and error. In addition, the analysis isn\u2019t complete without reporting posthoc tests.  I\u2019m guessing this was included because it\u2019s always reported, or perhaps to demonstrate that the study task was sound. Perhaps a sentence to explain the purpose of this analysis would help to guide the reader, or even remove it and explain to the reader why.\n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/AnonReviewer2"]}, {"id": "F_t3AX6bEG1", "original": null, "number": 1, "cdate": 1610399313772, "ddate": null, "tcdate": 1610399313772, "tmdate": 1610846672784, "tddate": null, "forum": "YXUV-SU6i8I", "replyto": "YXUV-SU6i8I", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/-/Official_Review", "content": {"title": "A short, well-presented modification to FFitts Law", "review": "This paper presents a modified version of the established FFitts law equation, which replaces the effective width component with width and a third coefficient, c. The authors present a study to validate their model, and compare the complexity of their model with the original FFitts equation, as well as two popular versions of Fitts' Law.\n\nI realize that the benefit of not specifically calculating effective width. The coefficient c is calculated a priori and can model hypothetical designs. However, are you not just hiding effective width measures in the \"empirically determined\" c? Furthermore, what is the procedure to measure and calculate c?\n\nThe paper is well-written and well-presented throughout. I appreciate the authors' inclusion of their model parameters and study procedure. Measuring the information criteria of the models is a nice touch, but I suggest writing out the acronyms AIC and WAIC when introduced in 4.3.4.\n\nI would like to see other additional studies to validate Finger-Fitts-W before accepting it, but I realize that publishing this short paper is an ideal way for researchers to investigate it further.\n", "rating": "7: Good paper, accept", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper32/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=UjWOHNd93Qd", "paper_id": "UjWOHNd93Qd", "reviews": [{"id": "samrhz0lbOC", "original": null, "number": 3, "cdate": 1610590118378, "ddate": null, "tcdate": 1610590118378, "tmdate": 1610846664465, "tddate": null, "forum": "UjWOHNd93Qd", "replyto": "UjWOHNd93Qd", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/-/Official_Review", "content": {"title": "Interesting paper on monitoring high performance computing systems", "review": "This paper presents Jobviewer, a visualization that helps monitoring a high perform computing system. The visualization uses a sequence of rectangles to show jobs along with curved links to connect to racks. Using this visualization the user can monitor the health of a computer node. The authors ran an informal user study with three participants to understand the utility of the design.\n\nThe visualization seems to have some useful components, however, the design lacks justification of key design decisions. The paper could be strengthen by explaining how the discussions with users had lead to the design. Another issue is that the visualization is not also very novel. There are similar visualizations that exist although for different data (e.g. [1]).\n\nThe user study of the paper is very limited with three participants who just provided some informal feedback which is not sufficient to validate the system. As a minor suggestion for writing, it would be helpful if the user study section is written in past tense (since they have already participated in the study).\n\nOverall, this is an interesting work however due to lack of novelty of the visualization and design rationale it is difficult to accept the paper in the current form.", "rating": "5: Marginally below acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/AnonReviewer3"]}, {"id": "ctMxFDWRsU5", "original": null, "number": 2, "cdate": 1610576523449, "ddate": null, "tcdate": 1610576523449, "tmdate": 1610846664553, "tddate": null, "forum": "UjWOHNd93Qd", "replyto": "UjWOHNd93Qd", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/-/Official_Review", "content": {"title": "Plausible; insufficient validation; needs clarifications", "review": "The paper proposes a user interface with a novel visualization to monitor a HPC cluster, health of its nodes, and user/job allocation. The proposed solution visualizes the system as a bipartite graph, where job are connected with nodes via graph edges, clearly indicating the correspondence, and nodes are colored based on the desired factor, e.g. CPU temperature. The paper validates its design via a small-scale user study, showing 2/3 volunteers succeeded in using hte system.\n\nThe designed interface seems plausible to me, the overall idea of the paper, as well as the design goals and outlines in Sec.3, make sense. I have a few complaints, however: A few design decisions, however, seem to be poorly justified, e.g. the use of radar charts to visualize all health metrics at the same time. Can humans actually quickly understand those? What do they add? \nAlso, I was not very clear on the design of the user study: were the five tasks developed with an expert? Do they reflect typical tasks of a system administrator, regardless of the UI, or were they created specifically to showcase the functionality of this interface. I would love a clarification on that (in the former case it is a more interesting usability study). I am also not sure how conclusive the user study is when two out of three succeeded to use, and one failed. I````````'d perhaps suggest testing on more volunteers?\n\nFinally, the text should be edited and spell-checked by a native English speaker, it has numerous errors, at times completely unclear, or style issues ('thick of its outline', 'irregular hot', 'and other stuff'). \n\nOverall, I think it is a reasonable approach, but I would like to see the edits and corrections above.", "rating": "6: Marginally above acceptance threshold", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/AnonReviewer1"]}, {"id": "Xbp3AuhjQ0o", "original": null, "number": 1, "cdate": 1610493666842, "ddate": null, "tcdate": 1610493666842, "tmdate": 1610846664628, "tddate": null, "forum": "UjWOHNd93Qd", "replyto": "UjWOHNd93Qd", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/-/Official_Review", "content": {"title": "Review of \"A graph-based visualization for monitoring of high-performance computing system\"", "review": "This paper proposes a visualization system for monitoring and analyzing high-performance computing (HPC) systems. The paper has a clear application domain, and validates the design through three use cases and a user study involving three participants.\n\nThe benefits of using visualization and interactive interfaces for understanding and monitoring computer networks (including HPC systems) are generally accepted and acknowledged. The paper describes a number of tools that are designed for this purpose, and discusses the limitations of each tool. It is unclear, however, which of these limitations are being addressed in this paper. In other words, the motivation for this work can be stronger: what specific problems or gaps are being addressed here, given that we already have a number of systems for HPC visualization?\n\nSection 3 goes straight into design goals and descriptions. A detailed task analysis is missing, which is crucial for validating the design goals and requirements. \n\nThe bipartite graph visualization is the main visual interface. The paper needs to do a more thorough literature review on related techniques and systems, some of the relevant references include:\n\nAris, A., & Shneiderman, B. (2007). Designing semantic substrates for visual network exploration. Information Visualization, 6(4), 281-300.\n\nLiu, Z., Lee, B., Kandula, S., & Mahajan, R. (2010, October). Netclinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks. In 2010 IEEE Symposium on Visual Analytics Science and Technology (pp. 131-138). IEEE.\n\nArendt, D. L., Burtner, R., Best, D. M., Bos, N. D., Gersh, J. R., Piatko, C. D., & Paul, C. L. (2015, October). Ocelot: user-centered design of a decision support visualization for network quarantine. In 2015 IEEE Symposium on Visualization for Cyber Security (VizSec) (pp. 1-8). IEEE.\n\nMcLachlan, P., Munzner, T., Koutsofios, E., & North, S. (2008, April). LiveRAC: interactive visual exploration of system management time-series data. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (pp. 1483-1492).\n\nI also have some doubts/questions regarding certain visual encoding choices: \n\n- the number of jobs running on a compute node is represented by the thickness of its outline, I think it will be hard for users to see this information. \n\n- If the chosen metric\u2019s value on a compute node varies significantly over two consecutive time steps, the blur effect is used to highlight the sudden change. How exactly is this done? \n\n- An alternative design for the compute node layout is to place them on a coordinate system (like in semantic substrate), as opposed to the circle layout in the current design. This alternate design might reveal more interesting information.\n\n- \u201cIf a compute node runs several jobs of multiple users, it has all corresponding colors\u201d: how is this done? Do you divide the node into pies and color each pie? That would be really hard to read. \n\nThe effectiveness of the design is evaluated using three use cases and one user study. Without a clear baseline, however, the evaluation feels weak. In particular, I am skeptical about the scalability of the tool. The paper will be stronger if you can convincingly demonstrate how your design outperforms an existing tool through a comparative study. \n\nThe writing also needs proofreading, there are many spelling mistakes or grammatical errors:\n\n- In the abstract: \u201cto visualize the monitoring the structural and met- rics data of HPC clusters\u201d\n\n- In the Intro: \u201cTheESE typically complex research instruments ranging from hun- dreds to thorusand of computing nodes\u201d\n\n- \u201cThe administrators often consider the compute node health\u201d\n", "rating": "4: Ok but not good enough - rejection", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper21/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=_VoSnnpUDkC", "paper_id": "_VoSnnpUDkC", "reviews": [{"id": "6gjs0yYVVAP", "original": null, "number": 3, "cdate": 1610573728518, "ddate": null, "tcdate": 1610573728518, "tmdate": 1610846664755, "tddate": null, "forum": "_VoSnnpUDkC", "replyto": "_VoSnnpUDkC", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/-/Official_Review", "content": {"title": "Simple and effective method with odd framing", "review": "The submission presents an algorithm that renders adversarial image examples for neural networks robust against discretisation and compression artefacts.\n\nMy main issue with this paper is the framing. The authors claim the observation that adversarial images are generally not robust with respect to image transferring or reloading. It is not clear to me why these specific applications have been picked. I would argue that image compression and quantisation artefacts are obviously a problem for attacks that rely on minimal perturbations of images. It is very clear what it happening here and, contrary to the authors statements, not surprising. \n\nIt also seems quite odd that the authors apparently use transfer through WeChat to assess these artefacts instead of just computing compressed images of several levels using any image library. This would be a much cleaner and transparent angle for this paper.\n\nDespite these very general remarks I think the method is valuable for two reasons: The method is simple, yet effective and is easily applicable as a post process to any method generating adversial images.\n\nI would have liked to see a better evaluation to assess the distribution of success rates and confidence values across images. It would also be helpful to focus on specific compression techniques with different parameters.\n\nSince I am not an expert on this topic I can not assess the novelty of the approach or if the issue of discretisation artefacts has been tackled in the context of adversarial image generation before.\n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/AnonReviewer3"]}, {"id": "QN2XZZ3DIMv", "original": null, "number": 2, "cdate": 1610137503909, "ddate": null, "tcdate": 1610137503909, "tmdate": 1610846664830, "tddate": null, "forum": "_VoSnnpUDkC", "replyto": "_VoSnnpUDkC", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/-/Official_Review", "content": {"title": "Generating Adversarial Examples for Robust Deception against Image Transfer and Reloading", "review": "The authors explore how storing and transmitting images affects the attack performance of adversarial examples. They propose a novel metric called \"Confidence Iteration\" to generate adversarial examples that are robust to said effects of storage and transmission.\n\nComments:\n- Although the objective is clear, there is no discussion on why more basic techniques cannot be used or fail to address this problem. For example, one would expect that using data augmentation during the training will increase the network's robustness to arbitrary transformations, including photometric, geometric, noise, etc. \n- In contrast to the authors' statement, the adversarial examples shown are noticeably noisy. It seems that applying a simple median filter before passing the image to the network would get rid of most of the noise.\n- The idea of studying the effects of compression and quantization on adversarial examples' effectiveness is useful. However, I find it trivial and would not call this a discovery of a \"new phenomenon\". Any information loss (due to any factor, not just these two), which leads to perturbations, can affect the network's performance. \n- It is unclear whether the Inceptionv3 model was trained on the created dataset or any other dataset. \n- Why was VGG11 used instead of Inceptionv3?\n- I find the \"Confidence Iteration\" trivial. The range of the colour values is not specified. Are the RGB images in the range of [0,1]? If so, the perturbations are up to 30%, which seems quite extreme considering the claim that the adversarial examples are \"stealthy\".\n- The paper requires proofreading as there are a few sentences that do not parse. \n\n", "rating": "3: Clear rejection", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/AnonReviewer2"]}, {"id": "DS1LsfBCZ76", "original": null, "number": 1, "cdate": 1609799840855, "ddate": null, "tcdate": 1609799840855, "tmdate": 1610846664917, "tddate": null, "forum": "_VoSnnpUDkC", "replyto": "_VoSnnpUDkC", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/-/Official_Review", "content": {"title": "Review for GI 2021 submission ID: 20. ", "review": "I do not think this work meets the bar for GI 2021. \n\nThe main issue is that they way the problem is posed is misleading.  This work over-emphasizes the process of \"saving\" and \"transmitting\" while both steps could be invertible. While this might seem like a small detail, it makes the introduction completely incomprehensible (I had no idea what authors mean when they say that saving a piece of data and the re-loading it somehow \"degrades\" it).\n\nI think it is interesting to study how compression and quantization artifacts affect the quality of adversarial examples. But classifying these artifacts based on the specific formats (JPG, BMP) or social media apps (WeChat) provides little insights and has little scientific value. In the former case, new formats might emerge (or old ones become obsolete) and it would be unclear how findings in this work apply to them. In the latter case, a small change in backend implementation might completely invalidate all the findings at any time. \n\nIf authors want to further investigate this with rigor, they could specifically focus on different kinds of compression algorithms and quantization steps that are used in existing formats of data transmission apps. This could be complemented with the study proposed in this paper, to demonstrate how this could translate to practical use case. \n\nAs a small note the proposed algorithm: it seems to suggest that physically saving data to the hard drive or transmitting it over the network is an important step. Obviously, it is slow and unnecessary. One can simply use any kind of data format conversion locally to see how this conversion affects the adversity of the proposed example. \n\nIt also would be interesting to see if some of these data conversion artifacts could be implemented as differentiable layers in a network. So one could directly optimize for adversarial examples back-propagating over particular compression algorithm. ", "rating": "1: Trivial or wrong", "confidence": "3: The reviewer is fairly confident that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper20/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=Zd5GbiuwX_t", "paper_id": "Zd5GbiuwX_t", "reviews": [{"id": "kxn6PxjkT1v", "original": null, "number": 3, "cdate": 1610695970238, "ddate": null, "tcdate": 1610695970238, "tmdate": 1610846668057, "tddate": null, "forum": "Zd5GbiuwX_t", "replyto": "Zd5GbiuwX_t", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/-/Official_Review", "content": {"title": "Review of \"Design and Investigation of One-Handed Interaction Techniques for Single-Touch Gestures\"", "review": "The paper proposes two one-handed techniques for selecting unreachable targets: FC is a cursor technique based on the force, while EFC is another cursor technique that uses a two-step operation. The problem is well-motivated: the smartphones' screen size is increasing while the thumb reachability remains the same. \n\nWhile I find the techniques potentially interesting, several drawbacks are not addressed by the authors that I think are critical:\n\nFirstly, the description of techniques is unclear and hard to follow; however, watching the demo video several times helped to understand the general idea and the interaction design, which are simple. The images of Fig.1 are very helpful, yet the caption is distracting.\n\nSecondly, several important decisions are not well-justified: e.g., the choice of the force threshold (1.8N) or the choice of the cursor-display ratio (being 3 times the finger movement distance), the choice of dwell time for the drag assistance. Conducting a pilot study or providing some references could help. \n\nFinally, the authors highlighted some of the limitations; however, from the experimental results, it is not clear and hard to conclude that the proposed techniques can compete with existing methods. Due to some factors:\n\n- Time and Accuracy tradeoffs:\nEFC seems to be slightly more accurate (to 2~6%) using some gestures than DT, but still very slow compared to DT and OM ($1.5\\times\\sim2\\times$ times). There is a chance that users could have reached better accuracy with DT when spending a little more time on precision/correction of the action and yet remain the fastest. This could be justified/rejected with the help of a longitudinal study and by recruiting more participants. \n\n- Jerk and Angular Acceleration:\nSince the main contribution of the paper is to show that the proposed techniques provide stable grasping with one hand, the discussion/elaboration on Jerk and Angular Acceleration data is required (e.g., how it was calculated, were there any observations, etc.). In 4.3.3, page 7, the authors assume that FC was the most \"stable\" due to continuous thumb touch on the screen, which does not necessarily mean stability (users can tap/double tap on the screen and result in shaking the phone and yet have stable grasp). It would be interesting to have a discussion section on how authors justify stability with the help of proposed metrics.\n\nOverall, while I\u2019m sympathetic towards the proposed techniques, the aforementioned issues prevent me from recommending the acceptance of this paper. As a side note, I would also be interested in seeing the comparison to iPhone's haptic touch/3D touch (where the onscreen keyboard turns into a virtual trackpad while holding the space bar). While it does not allow to perform \u201cdouble-tap\u201d or \u201cdrag\u201d, it enables a continuous movement of the cursor through the text with high precision.  \n\n\n\nMinor things:\n\n- Why did the authors decide to eliminate DT results from Tables 1 and 2?\n- Page 2: Lochtefeld \u2013> L\u00f6chtefeld et al.\n- Page 4: use \u2013> used\n- Page 7: Therefore, We -> Therefore, we\n- Subsection titles use modified font for 4.3.1, 4.3.2, 4.3.3, and 4.3.4. They should not: titles should use the same font face/size.\n- The p values and other expressions involving mathematical symbols should be typesetted in math mode, e.g., using $. This will help with the readability of equations. (In sections 4.3.2, 4.3.3, and others)", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/AnonReviewer3"]}, {"id": "3xA_21zvYgf", "original": null, "number": 2, "cdate": 1610600102229, "ddate": null, "tcdate": 1610600102229, "tmdate": 1610846667891, "tddate": null, "forum": "Zd5GbiuwX_t", "replyto": "Zd5GbiuwX_t", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/-/Official_Review", "content": {"title": "Review of \"Design and Investigation of One-Handed Interaction Techniques for Single-Touch Gestures\"", "review": "Even though there is potential value in the investigation reported on here, the paper falls between two contributions (and falls short of both). One contribution would be in the new techniques themselves (Force Cursor and Event Forward Cursor), but for this to be a strong contribution, the paper would need to show that the techniques are widely applicable, and the evaluation would need to show that the new techniques are an improvement over the state of the art. However, the techniques seem limited in terms of how and when they can be used, and the evaluation does not show strong advantages for the new techniques (and in fact shows that they are significantly slower than what is already delivered on smartphones). Second, the contribution could be in the analysis of a new approach to one-handed use, namely the use of a cursor to avoid one of the limitations of direct touch; this is potentially interesting from a broader perspective (and for this contribution it would not be a problem to show that the cursor-based techniques are slower). However, the paper does not take on this question to any great degree, and so there is little that can be learned from the paper as a high-level comparison of general approaches. As a result, it is unclear whether the community will find much value in the paper as it stands now - the paper is currently written to introduce the new techniques (i.e., the first contribution type discussed above), but the evidence does not strongly argue for the techniques, and the second contribution (the high-level consideration of different input styles) is not developed enough in the current version.\n\nComments on the design of the techniques themselves. There appears to be some brittleness in the techniques' design, in terms of repeated actions with the same object. Both of the techniques turn off on liftoff (although EFC has uses hysteresis to allow double tap), and this means that for multiple actions with the same object, the user would need to start the technique multiple times. For example, consider an action series with a graphical object where the object is first selected, then dragged to a new location, and then double-clicked. This is easily done with direct touch, but with the proposed techniques, the user would need to invoke the cursor and move the cursor to the graphical object three times. I do understand that the authors were considering atomic gestures such as taps and swipes, but there are many situations where these atoms would be chained together in action sequences, and the design of the new techniques fails to take this into consideration.\n\nThe evaluation of the techniques shows that they are substantially slower than both the \"ordinary\" and the \"shrink\" conditions. This is a major problem for the techniques that essentially condemns them to being unusable from a design standpoint. The authors seem to have found a reasonable explanation for the slower operation - the use of a cursor instead of direct touch - but the authors do not dig deeper into this difference in a way that we learn much about the high-level differences between input approaches. Whatever the reason, being 1.5x to 2.0x slower than no treatment at all is a critical flaw - and even though there is a small improvement in accuracy and stability for the new techniques, the large time cost means that the techniques are unsuccessful. (I will note as well that the added time may well account for the improvements on other measures; in addition, the authors are overreaching when they state that DT's higher SUS score is due only to its familiarity - the high score could easily be because the DT technique was faster than the other techniques as well).\n\nA couple of minor points:\n- the swipe in from the bezel is already used in some smartphones (e.g., Pixel 4); the authors should consider interference between their gestures and existing gestures\n- the dense presentation of follow-up results is difficult to parse and should be summarized\n\n \n", "rating": "5: Marginally below acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/AnonReviewer2"]}, {"id": "5X415xSlIeH", "original": null, "number": 1, "cdate": 1610558927016, "ddate": null, "tcdate": 1610558927016, "tmdate": 1610846667971, "tddate": null, "forum": "Zd5GbiuwX_t", "replyto": "Zd5GbiuwX_t", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/-/Official_Review", "content": {"title": "The paper is well written, except for a few shortcomings (listed in the review). I think with some minor revision, the paper is good to go.", "review": "# Summary of the paper\nThe paper introduces two one-handed interaction techniques for a large touchscreen mobile phone. The techniques are named FC and EFC, which utilize a remote cursor triggered by an edge gesture. Tap, double-tap, and drag could be performed by utilizing force (FC) and event forward (EFC), which should be the distinguishable contribution of this paper over existing works. However, the FC technique itself was already introduced in [14]. Therefore, the remaining contributions are the introduction of the EFC technique and their evaluations. I think the amount of new information on this paper is adequate to be published.\n\n# Review\nOverall, the paper is well written, except for a few shortcomings. I think with some minor revision, the paper is good to go. \n\n## Validity of the idea\nI empathize with the idea of allowing more gestures on the remote other than just a tap. Although the overall performance is less efficient than a direct touch and an existing solution (labeled OM in the paper), each new technique has its advantages: FC exhibited the most stable grip, and EFC exhibited the highest accuracy.\n\nHowever, justifications of some design factors are missing: the choice of C-D gain (multiply by three), 1.0 sec dwelling time for \"Drag Assistance\" in FC technique. They seem to be set arbitrarily and would be beneficial to be justified with some references or research.\n\nAlso, nowadays, iOS and Android actively utilize edge gestures for other purposes, so a collision of gestures may happen. This should be discussed in the paper.\n\nPerformance-wise, I believe there will still be room for improvement. Especially regarding the last two paragraphs of section 5.4 -- compensation for subtle drift in force gesture and double-tapping is a common and widespread method in commercial products. I'd like to see the result again after patching this, where I expect a considerable improvement in time and accuracy of FC and EFC.\n\n## The presentation of the statistical analysis results.\nThe way of presenting ANOVA and posthoc tests on sections 4.3.1, 4.3.2, and 4.3.3: \nexample) \"Tukey's HSD test was also\nsignificant (p < .05 between OM's DTap and OM's Swipe, OM's Drag and FC's DTap, FC's DTap and EFC's DTap, and EFC's Tap and EFC's Swipe, p < .01 between DT's Tap and DT's Swipe, DT's Tap and OM's Swipe, and DT's Swipe and OM's DTap, DT's Drag and FC's Swipe, DT's Drag and EFC's DTap, OM's Tap and OM's Swipe, and FC's DTap and FC's Swipe, and others p < 001.\"\n\nThe text is all monotonically listed just only with acronyms, \"and\", and commas, which makes it impossible to comprehend. I believe the information is there, but they are entirely unreadable.\n\nPlease consider a better presentation such as a table, bullet list, or annotation on the graph (e.g., https://www.researchgate.net/figure/Bar-graphs-of-post-hoc-tests-considering-the-area-A-mean-of-red-R-color-space-B_fig3_263430688). Maybe the interaction effects are hard to be presented in the table or graph. However, the current format is a disaster.\n\n## Jerk and Angular Acceleration\nThe jerk and angular acceleration are time-series data. They cannot be calculated into a number in an obvious way, unlike the execution time and accuracy. The authors should clearly define how they drew out the numbers from the collected data.\n\n## Discussion of the mix of DT and the technique\nIn reality, nobody will use any of the reachability compensation techniques (OM, FC, and EFC) on a target in the reachable area. So forced use of the technique on all the areas on the screen is unrealistic.\n\nTherefore, a more realistic situation will be a mixed technique -- use DT for reachable targets and use one of the proposed techniques on distance targets. Allowing a user to choose between DT and a proposed technique will be a more externally valid experiment design. For example, [25] allowed the participants to choose one among direct touch and support techniques and presented a method preference on different screen areas. I think this should be discussed as an immediate follow-up study.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper6/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=I0HZJde1BxQ", "paper_id": "I0HZJde1BxQ", "reviews": [{"id": "YnuD-p0Ck4B", "original": null, "number": 3, "cdate": 1610676067306, "ddate": null, "tcdate": 1610676067306, "tmdate": 1610846668668, "tddate": null, "forum": "I0HZJde1BxQ", "replyto": "I0HZJde1BxQ", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/-/Official_Review", "content": {"title": "Interesting but flawed study", "review": "The authors of this paper describe the design and prototype of a system to visually specify and identify the shape of tensors in a deep neural network (DNN) intended to highlight and help the user correct shape inconsistencies. This is a common bug and difficult to tell in real-time (where real-time refers to during the programming specification of the DL network.).  In the system Konjak the user creates the tensors and connects them using drag and drop interaction in an incremental specification.  The system then generates the appropriate code.   The premise is that real-time interactive visual specification both prevents errors and in doing so highlights how the networks operate  and thus scaffolds learning. \nThe authors carried out a user study to assess the utility and viability of the method.\n\nI am not expert in the educational challenges of DNN comprehension, but I very much liked the motivation of this paper. Unfortunately the work as reported suffers flaws that discourage me from recommending acceptance.  \nThe authors do a very poor job of comparing this approach to other DNN visualization and/or bug correction techniques.  The most well-known DNN visualization and specification tool , often used to scaffold novices, is the TensorFlow playground.  Programmatic tools like VariFlow provide code-level debugging detection and correction capabilities. How does konjak fit into and compare to these tools and use cases? What does it bring?\n\nThe user study is a classic example of a poorly designed study. If this study was supposed to examine how much better (or worse) that Konjak is than traditional coding tools, then why not study that? Why not do a between subjects study where one group tried to achieve the tasks with standard DNN   programming methods and the second group used Konjak? AS it si the study is a thinly vweiled attempt to confirm the assumption that this is valuable. MOreover, if the purpose of the study is to assess the utility for novices, why do experts form 1/3 of the participants?  The standard a=way to approach this is typically an expert review as parallel or separate sessions, and to run a reasonable number (where 12 is a minimum for a repeated measures study, and quite small for a feasibility study).   The authors make assertions like \"participants tend to use a live visualization\" as opposed to stating that participants expressed an opinion that they would use it if it were available. Very different. This is an example of poor reporting and not results misinterpretation, but it does not stand up to the kinds of scrutiny we would expect in user study results.", "rating": "5: Marginally below acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/AnonReviewer1"]}, {"id": "CoKrBY7v7hw", "original": null, "number": 2, "cdate": 1610648430983, "ddate": null, "tcdate": 1610648430983, "tmdate": 1610846668586, "tddate": null, "forum": "I0HZJde1BxQ", "replyto": "I0HZJde1BxQ", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/-/Official_Review", "content": {"title": "Interesting direction, but lack of rigor throughout.", "review": "This paper presents a system, Konjak, that synchronizes code editor and a visualization of the resulting Deep Neural Network structure. The purpose of these synchronized views is educational, i.e. targeted at helping DNN non-experts program DNN. The system is evaluated through a light user study.\n\nThe technical aspects of the paper are well presented and relatively easy to follow. The process (formative study, design, usage scenario, evaluation) is convincing. What is less convincing, however, is the execution of this plan. As I detail below, the formative study does not follow any particular methodology; the target users (novices) were not consulted or involved in the process at all until the final evaluation; the design decisions are not well justified; and the study is not convincing in its rigor, execution and interpretation.\n\nNot being an expert in DNN myself, I appreciate how the related work clearly explains how existing tools and approaches relate to Konjak. I would expect, however, that more explanation be given regarding how Skyline differs from Konjak. The authors state that both tools share concept and background, so I would expect more details about their differences to clearly identify how the proposed contribution differs.\n\nThe literature study is interesting in its aim; however its execution is not convincing. I am missing a methodology section that would explain how this study was actually conducted. There are dozens of ways of conducting such reviews and many would be valid approaches, but the lack of any methodology raises questions about soundness and rigor of the study, seriously limiting the usefulness of the results. Aspects that are missing include information about who conducted the study, how many people were involved, how many diagrams were studied (and I would also expect this dataset of diagrams to be accessible though supplemental material), which analysis/coding method(s) were used, how themes were identified, etc..\n\nOne key concern I have with the paper is that there are many claims made about how the tool is designed for novices, however, none of the formative work actually relates to novices. From a methodological perspective, does it make sense to review papers, likely written by experts on the topic? Would not the results tell us how experts represent these DNN? Why not asking novices to draw DNNs to extract the mental model that novices might have? This would lead to more insightful findings with regards to designing a tool for novices.\n\nI had a hard time making the connection between the study and the live visualization. Although the authors write that (paraphrase) **the design process follows the design principles described in the last section**, it is unclear to me what these design principles are, because they are not clearly articulated. It is left to the reader to attempt to make these connections, that should be more explicit. Right now, the design decisions seem quite arbitrary (e.g., why layer cards? why these ones?)\n\nSimilar to other parts of the paper, the study, although generally adapted to its purpose (qualitative and exploratory) has too many aspects that lack grounding/justification. First, if it is a tool for novices to learn about DNN, why involving experts? There might be some good reasons for that, but they are not presented (why is it useful to have this educator perspective?). Also, \"We designed the tasks by talking to expert machine learning users\" is not a well-rounded explanation for why these tasks were selected, how they were formulated, which alternatives were considered, what coverage they have, etc.. \nOne particularly concerning aspect of the study is that it is half-baked quantitative and half-baked qualitative. The number of participants is very reasonable for a qualitative study that could give some rich insights into how novices use the tool. However, this would also require following a rigorous methodology and go in much more depth than what is presented in the paper. The alternative is to be more on the quantitative side, but in this case the sample size should also be larger and less subjective data should also be looked at. There are also issues with the questionnaire, for example asking people if a representation accurately reflects their mental model of something after having them learn and use this mental model is biased. \nOverall, the study is too superficial and any given representation of a DNN would have led to positive results (of course having some kind of representation rather than just code will help). This does not mean that the designs implemented in Konjak are good.", "rating": "3: Clear rejection", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/AnonReviewer2"]}, {"id": "h_TqpX1EN78", "original": null, "number": 1, "cdate": 1609806235962, "ddate": null, "tcdate": 1609806235962, "tmdate": 1610846668480, "tddate": null, "forum": "I0HZJde1BxQ", "replyto": "I0HZJde1BxQ", "invitation": "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/-/Official_Review", "content": {"title": "GI 2021 submission 4", "review": "This paper proposes a novel user interface for coding deep neural networks. This tool allows to visualize your network both as the executable code as well as a stack of boxes. \n\nI am not an expert in HCI and I do not use visualization tools for my DNN designs very often. However, it seems to me that the proposed tool is sound. The user study also suggests that it could address common problems encountered by novice users and has value for educational purposes. \n\nI think the weakness is that it can mostly help with relatively simple errors, such as shape mis-match for tensors. There is definitely more value in a \"training-time\" or \"inference-time\" tool that enables to take a deeper look at neural responses in different layers to gain a deeper understanding of why network gives a particular output for a specific input. I think that mismatches in tensor shapes, while common, are fairly easy to debug once you gain some experience with NN modules. However, debugging an undesired behavior is much more challenging and under-explored.  I also wonder, how this tool would extend in more complex architectures (e.g., Siamese architectures or the ones that use a more complex tensor graphs). ", "rating": "6: Marginally above acceptance threshold", "confidence": "2: The reviewer is willing to defend the evaluation, but it is quite likely that the reviewer did not understand central parts of the paper"}, "signatures": ["graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["graphicsinterface.org/Graphics_Interface/2021/Conference", "graphicsinterface.org/Graphics_Interface/2021/Conference/Paper4/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=ubn8YxRp_ZT", "paper_id": "ubn8YxRp_ZT", "reviews": [{"id": "9W8vHzY_cQk", "original": null, "number": 1, "cdate": 1622218854818, "ddate": null, "tcdate": 1622218854818, "tmdate": 1622218854818, "tddate": null, "forum": "ubn8YxRp_ZT", "replyto": "ubn8YxRp_ZT", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper35/-/Official_Review", "content": {"title": "Something for the devs", "review": "Important to set up new VIVO devs. ", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=Hc503YPHtF", "paper_id": "Hc503YPHtF", "reviews": [{"id": "yy2y1XoZna5", "original": null, "number": 1, "cdate": 1622981745736, "ddate": null, "tcdate": 1622981745736, "tmdate": 1622981745736, "tddate": null, "forum": "Hc503YPHtF", "replyto": "Hc503YPHtF", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper34/-/Official_Review", "content": {"title": "Important topic", "review": "Data ingest is one of the biggest topics of the VIVO community. The author should include information if and how this aligns to similar(?) approaches like  SPARQL Generate. Other valuable information would be the required skillset to set this up. ", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=91FmlA0SyRc", "paper_id": "91FmlA0SyRc", "reviews": [{"id": "MR_1nMUkhBR", "original": null, "number": 1, "cdate": 1623063373449, "ddate": null, "tcdate": 1623063373449, "tmdate": 1623064321274, "tddate": null, "forum": "91FmlA0SyRc", "replyto": "91FmlA0SyRc", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper33/-/Official_Review", "content": {"title": "Geolocation or geospatial information management is undoubtedly an essential component for research discovery and for VIVO roadmap.", "review": "The proposed presentation is really interesting. Geolocation or geospatial information is undoubtedly an essential component for research discovery, as the authors point out. Finding that standard component of classification of this type of data is a very important challenge. The authors have enough knowledge to make interesting proposals in this regard and it is very relevant for the evolution of VIVO.\nPerhaps it would be interesting to see in the presentation a practical example of a proposed application.\n\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=sbA4bnE5_dv", "paper_id": "sbA4bnE5_dv", "reviews": [{"id": "AhPa_R84nGI", "original": null, "number": 1, "cdate": 1622321701564, "ddate": null, "tcdate": 1622321701564, "tmdate": 1622321701564, "tddate": null, "forum": "sbA4bnE5_dv", "replyto": "sbA4bnE5_dv", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper32/-/Official_Review", "content": {"title": "Critical community input to planning", "review": "The German VIVO community is one of the most firmly established in the world.  Results of its surveys are critical for planning VIVO enhancements needed by the German VIVO Community.\n\nSuggestions for methods to include recommendations of national groups in the planning of the VIVO Leadership Group would be appreciated.  Suggestions for improving the representation of the VIVO Leadership Group to recognize the needs of international communities would be most interesting.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=3ht_dupP1b4", "paper_id": "3ht_dupP1b4", "reviews": [{"id": "YdRK_Ei8cE8", "original": null, "number": 1, "cdate": 1622219083136, "ddate": null, "tcdate": 1622219083136, "tmdate": 1622219083136, "tddate": null, "forum": "3ht_dupP1b4", "replyto": "3ht_dupP1b4", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper31/-/Official_Review", "content": {"title": "Differences to earlier presentation?", "review": "AMP was already suggested as a suggestion for user experience. The authors should make clear what's new to this submission. Additionally there are big concerns about AMP being a user tracking device, invading the user's privacy. In the light of https://stoptrackingscience.eu/ the authors should explain if and why performance gains are worth the violation of the user's privacy.\n\nThe part about responsive design could be interesting for future work on \"tenderfoot\" and other responsive themes for VIVO. \n", "rating": "6: Marginally above acceptance threshold", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=1pGXglTsk31", "paper_id": "1pGXglTsk31", "reviews": [{"id": "WK0tjlqAFqT", "original": null, "number": 1, "cdate": 1622572037018, "ddate": null, "tcdate": 1622572037018, "tmdate": 1622572037018, "tddate": null, "forum": "1pGXglTsk31", "replyto": "1pGXglTsk31", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper30/-/Official_Review", "content": {"title": "Of great interest to the community", "review": "Using VIVO in non-traditional ways is always of great interest.  From discipline-specific VIVOs, VIVOs of historic figures, to use in showing collections of images, there always seem to be new applications.\n\nThe authors are experienced with VIVO and with library practice and will share important insights into the design and construction of an intriguing application.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=0r3B2hDv9Aq", "paper_id": "0r3B2hDv9Aq", "reviews": [{"id": "ba_BlsESO9E", "original": null, "number": 1, "cdate": 1622325740985, "ddate": null, "tcdate": 1622325740985, "tmdate": 1622325740985, "tddate": null, "forum": "0r3B2hDv9Aq", "replyto": "0r3B2hDv9Aq", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper29/-/Official_Review", "content": {"title": "Disambiguation is a key topic", "review": "Author disambiguation is a key issue for VIVO sites bringing in data from large non-institutional indices such as PubMed, SCOPUS and Web of Science.  The author should be able to describe how a commercial service addresses the problem.\n\nIt is important that this talk *not* be an advertisement for a commercial service.  A talk which describes how the service solves the problem so that institutions might decide whether to invest in such a service, or construct their own would be valuable.", "rating": "7: Good paper, accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=DSlk84-9dbW", "paper_id": "DSlk84-9dbW", "reviews": [{"id": "zs01_6xQ-BO", "original": null, "number": 1, "cdate": 1622573081371, "ddate": null, "tcdate": 1622573081371, "tmdate": 1622573081371, "tddate": null, "forum": "DSlk84-9dbW", "replyto": "DSlk84-9dbW", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper28/-/Official_Review", "content": {"title": "Outstanding investigators, outstanding work", "review": "The authors will present their work on a national RIS in Denmark using VIVO and other tools.\n\nThe authors are well-known to the community and have done outstanding work integrating data and developing important presentations of the data for use by the Danish research infrastructure.  We look forward to hearing about their new adventures.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=nLUd2fCZZN", "paper_id": "nLUd2fCZZN", "reviews": [{"id": "ZIvdcFfaia", "original": null, "number": 1, "cdate": 1622324552641, "ddate": null, "tcdate": 1622324552641, "tmdate": 1622324552641, "tddate": null, "forum": "nLUd2fCZZN", "replyto": "nLUd2fCZZN", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper27/-/Official_Review", "content": {"title": "Growing international presence with one non-US author?", "review": "The on-line VIVO conference in 2020 was the largest VIVO conference ever, with over 260 participants.  It is not clear that the pandemic was a problem for VIVO or its conference -- perhaps it was a blessing, forcing the community to adopt an alternate meeting strategy which resulted in the inclusion of those previously excluded by the high cost of travel to an in-person meeting.\n\nThe VIVO community is growing rapidly outside the US.  The recent Spanish meeting was the largest VIVO meeting ever held.  The EuroCRIS track this year is on Latin America.  The audience might be interested to hear how representation on the leadership group will become less US-centric, and more representative of the diverse VIVO community.\n\nThe recent work to significantly improve the internationalization of the software was done primarily by those outside the United States.  How is this work recognized, and how do people doing such work become involved in the governance of the project?\n\n", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=bEs3I1o576J", "paper_id": "bEs3I1o576J", "reviews": [{"id": "_2eerkhegsf", "original": null, "number": 1, "cdate": 1622982004037, "ddate": null, "tcdate": 1622982004037, "tmdate": 1622982004037, "tddate": null, "forum": "bEs3I1o576J", "replyto": "bEs3I1o576J", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper26/-/Official_Review", "content": {"title": "Improving the documentation is fostering reuse and application", "review": "Currently the VIVO ontology documentation has room for improvement. (Partially) automatic approaches can potentially help a lot. It would be interesting to know if this approach can be easily used for other ontology modules as well. Being it a python script it's also important to learn which skills and technological foundations one need to follow this approach. Maybe it's even possible to automate this in Github? ", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=p4qUXPWHAq", "paper_id": "p4qUXPWHAq", "reviews": [{"id": "w4bNX4GWCHZw", "original": null, "number": 1, "cdate": 1622218794337, "ddate": null, "tcdate": 1622218794337, "tmdate": 1622218794337, "tddate": null, "forum": "p4qUXPWHAq", "replyto": "p4qUXPWHAq", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper25/-/Official_Review", "content": {"title": "Crucial for a future VIVO Ontology ecosystem", "review": "Persons and organizations are main entities of research information. A new ORG ontology with improved interoperability will be a major milestone for VIVO and beyond.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=cyjh4e3J7Ez", "paper_id": "cyjh4e3J7Ez", "reviews": [{"id": "yQMOz2SwMVQ", "original": null, "number": 1, "cdate": 1622573330026, "ddate": null, "tcdate": 1622573330026, "tmdate": 1622573330026, "tddate": null, "forum": "cyjh4e3J7Ez", "replyto": "cyjh4e3J7Ez", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper24/-/Official_Review", "content": {"title": "Yet another critical use case", "review": "\"Where there is data, there is reporting.\"\n\nWho could imagine data without reporting?  Profile and visualizations are showy, but reports are required.  Getting reports from a Vitro/VIVO instances seems obvious -- these instances often have the accumulated record of the scholarship of the institution.\n\nThe audience will want to hear how the reporting problem was addressed from this outstanding collection of investigators with great experience in the VIVO community,", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=O_IoqBDjNPL", "paper_id": "O_IoqBDjNPL", "reviews": [{"id": "Kvxu5nlm3qh", "original": null, "number": 1, "cdate": 1622573984010, "ddate": null, "tcdate": 1622573984010, "tmdate": 1622573984010, "tddate": null, "forum": "O_IoqBDjNPL", "replyto": "O_IoqBDjNPL", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper23/-/Official_Review", "content": {"title": "Intriguiging discipline specific functionality", "review": "Creating tools for target communities is intriguing.  Can a common set of back-end data be used to provide discipline appropriate front-end services?  In this short talk the authors will describe their work in designing and build a prototype for those working in civil engineering, architecture and urban studies.  The use of Leaflet is also interesting.  finally, the faculty requirement for networking and exchange is intriguing -- this is often a need for researchers -- how can it be met in a VIVO-based platform?", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=2YG_Eh7jzBv", "paper_id": "2YG_Eh7jzBv", "reviews": [{"id": "uzemGCGaGzi", "original": null, "number": 1, "cdate": 1622571837624, "ddate": null, "tcdate": 1622571837624, "tmdate": 1622571858730, "tddate": null, "forum": "2YG_Eh7jzBv", "replyto": "2YG_Eh7jzBv", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper22/-/Official_Review", "content": {"title": "Great title -- of high interewt to ontology developers", "review": "Ontology development is a bit of a \"black box\" for the VIVO community -- people want ontologies, but have few notions of what ontology development is actually like.  \n\nThis talk serves to \"pull back the curtain\" and show people how it is done, and how it can be done without complex command line tooling.\n\nBravo!", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=E5semQxA6i3", "paper_id": "E5semQxA6i3", "reviews": [{"id": "OGUuF67Q1Z7", "original": null, "number": 1, "cdate": 1622572744905, "ddate": null, "tcdate": 1622572744905, "tmdate": 1622572744905, "tddate": null, "forum": "E5semQxA6i3", "replyto": "E5semQxA6i3", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper21/-/Official_Review", "content": {"title": "Unusual story of interest to some", "review": "The use of familiar systems to do unfamiliar things is potentially interesting.\n\nThe notion that local resources could be used to circumvent the traditional academic peer review publishing processes for the purpose of making \"special\" publications more accessible may seem bizarre to some and frightening to others.  And yet, non peer-reviewed materials are an output of universities.  This may need to be carefully explained.\n\nThe context and importance of the BLM protests to the United States may be culturally inaccessible, or difficult, for non-US audiences, as they are for some US audiences. Some context setting will be needed.  To the extent this can be done without appearing politically motivated seems daunting.  \n\nThe underlying assumption here appears to be that novelty is an important aspect of scholarly communication.  Is it?", "rating": "6: Marginally above acceptance threshold", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=SYwM0QPNR_B", "paper_id": "SYwM0QPNR_B", "reviews": [{"id": "SKl55FLYpm0", "original": null, "number": 1, "cdate": 1622325476740, "ddate": null, "tcdate": 1622325476740, "tmdate": 1622325476740, "tddate": null, "forum": "SYwM0QPNR_B", "replyto": "SYwM0QPNR_B", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper20/-/Official_Review", "content": {"title": "Critically important examples to share and discussions to be had", "review": "The authors propose a track to consider important examples of VIVO implementations in Latin America and consideration for future growth of VIVO in the region.  The authors are experienced with the issues and with organizing such conversations.\n\nThis critically important track should be a key contribution to the conference in 2021.  \n\nSome questions that might be important for the participants to consider: 1) how can developers from Latin American become involved in the improvement of the software for use across the region?; 2) how can leaders from Latin America become leaders in the VIVO community; 3) how can Latin American community needs be assessed so that these needs might be addressed in future versions of VIVO?\n\nThis is an outstanding track proposal that should serve as a catalyst for the improvement of VIVO in service to the Latin American community. ", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=refrl5jwzd", "paper_id": "refrl5jwzd", "reviews": [{"id": "zDK73SXbjyl", "original": null, "number": 1, "cdate": 1622571637557, "ddate": null, "tcdate": 1622571637557, "tmdate": 1622571637557, "tddate": null, "forum": "refrl5jwzd", "replyto": "refrl5jwzd", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper19/-/Official_Review", "content": {"title": "A central use case for VIVO", "review": "The concept of VIVO as a record of the the faculty's scholastic achievements is a central one.  Too often we see VIVO positions as a \"profile system\" or  \"front-end\" to an institutional repository (or other system of record).  Perhaps the authors can help the audience explain why a repository can never be the full record of the faculty's scholastic achievements.\n\nIt is vitally important that the audience can understand he role of VIVO data (one person's metadata is another person's metadata) for assessing scholarly output, and for strategic planning (identification of research opportunities and needs).\n\nHave the authors considered the use for VIVO data for assessing research impact?", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=jb35HAthef", "paper_id": "jb35HAthef", "reviews": [{"id": "dhemEuJptjT", "original": null, "number": 1, "cdate": 1622571293220, "ddate": null, "tcdate": 1622571293220, "tmdate": 1622571293220, "tddate": null, "forum": "jb35HAthef", "replyto": "jb35HAthef", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper18/-/Official_Review", "content": {"title": "Indeed a topic of interest", "review": "The work of the data ingest task force may well be unknown to much of the community.  Encouraging participation should be paramount.\n\nWhat parts of ingest are common?  Which are custom?  How is the task force considering the difference?  Is the goal unattended ingest?  Curated ingest?  Technically facilitated ingest?  \n\nWhat is the role of PIDs?  Of open data?  Of ORCiD?  What is the role of local data?  \n\nDoes the task force envision sharing data?  That is, can there be a set of locations, organizations, scholarly works, or other standard data sets or APIs that everyone might use to avoid duplication of effort and of representation.\n\nSo many questions --- should be a fund session, and hopefully, the beginning of a larger conversation.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=vqm9-hzTJA6", "paper_id": "vqm9-hzTJA6", "reviews": [{"id": "2uM1rWGFxsA", "original": null, "number": 1, "cdate": 1622571001179, "ddate": null, "tcdate": 1622571001179, "tmdate": 1622571001179, "tddate": null, "forum": "vqm9-hzTJA6", "replyto": "vqm9-hzTJA6", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper17/-/Official_Review", "content": {"title": "Important topic of interest to developers", "review": "The development of tools for VIVO, and in particular tools for data ingest, is of great interest in the VIVO community,\n\nThe author is a leader in VIVO implementation, and software development.\n\nThere is quite a bit described in the abstract.  Conference time slots are twenty minutes.  The author is urged to time the presentation to insure that that it can be presented in the allotted time.  Links from\nthe presentation to additional on-line material can be used to streamline the presentation while retaining technical depth.\n", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=urfcG0e2L9P", "paper_id": "urfcG0e2L9P", "reviews": [{"id": "NINSx2w4lsN", "original": null, "number": 1, "cdate": 1622570760937, "ddate": null, "tcdate": 1622570760937, "tmdate": 1622570776211, "tddate": null, "forum": "urfcG0e2L9P", "replyto": "urfcG0e2L9P", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper16/-/Official_Review", "content": {"title": "Relevance to other universities?", "review": "The evolution concept is of great interest -- TAMU has a large (huge) system and a mature installation.  The notion of on-going discovery of the nature of a RIM system, its functions, and its role in serving a university (even such a large university, or perhaps particularly because of TAMU's size) is of interest.\n\nThe scale of TAMU may be unrelatable to much of the audience.  The need for custom features may also be of little interest.\n\nThe keywords contain some technical terms, but it appears that this is not a technical paper -- rather an exposition of needs and how they were met.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=kI3XPskTZb0", "paper_id": "kI3XPskTZb0", "reviews": [{"id": "mvvec9O-O1m", "original": null, "number": 1, "cdate": 1622570403029, "ddate": null, "tcdate": 1622570403029, "tmdate": 1622570403029, "tddate": null, "forum": "kI3XPskTZb0", "replyto": "kI3XPskTZb0", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper15/-/Official_Review", "content": {"title": "RIM framework and use cases of interest", "review": "The author is well-known in the area of RIM consideration and evaluation.  The work of OCLC in this area is of great value.\n\nThe RIM framework and use cases could be of interest to the VIVO community beyond institutions in the United States.  \n\nThe US\nsetting, while familiar to many, has some peculiar features, in particular the nature of grant competition for research funding, the presence of large medical systems on university campuses, and the role of agricultural extension.  All five of these universities are major research universities.  Three are land grant.  Two have major medical systems on their campuses.  Understanding the nature of these institutions and the consequences for RIM systems at these institutions may be a challenge for non-US audience members.", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=LNrz0MEZAGq", "paper_id": "LNrz0MEZAGq", "reviews": [{"id": "LGqzh9bE169", "original": null, "number": 1, "cdate": 1622218505990, "ddate": null, "tcdate": 1622218505990, "tmdate": 1622218505990, "tddate": null, "forum": "LNrz0MEZAGq", "replyto": "LNrz0MEZAGq", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper14/-/Official_Review", "content": {"title": "Interesting usecase", "review": "This is a welcome submission highlighting an interesting and - to my knowledge - new approach to handle the data ingest. The author should introduce the benefits of Smartsheet compared to already existing solutions. ", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=WBrkE2Ml3qG", "paper_id": "WBrkE2Ml3qG", "reviews": [{"id": "N6QWU9CQjk4-", "original": null, "number": 1, "cdate": 1622218646023, "ddate": null, "tcdate": 1622218646023, "tmdate": 1622218646023, "tddate": null, "forum": "WBrkE2Ml3qG", "replyto": "WBrkE2Ml3qG", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper13/-/Official_Review", "content": {"title": "Very interesting submission", "review": "Identifying (open) data sources is a recurring task for RIS projects. The author could have a look at https://labs.tib.eu/rosi/ to see how his collection aligns with this one, which was introduced at an earlier VIVO conference.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=_ZSaqqlTIC4", "paper_id": "_ZSaqqlTIC4", "reviews": [{"id": "SOFMnHjcAHU", "original": null, "number": 1, "cdate": 1622569515302, "ddate": null, "tcdate": 1622569515302, "tmdate": 1622569515302, "tddate": null, "forum": "_ZSaqqlTIC4", "replyto": "_ZSaqqlTIC4", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper12/-/Official_Review", "content": {"title": "Of interest to those designing presentation of research information", "review": "The authors propose to present their work in redesigning a custom interface to VIVO to  meet the needs of their faculty.  The techniques used to gather faculty feedback and enhance faculty engagement with their on-line prescence is of interest to the community.\n\nAre the specific interests of the Duke faculty generalizable to faculty of other universities in other countries?  Of non-research faculty?", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=kW3owdkjBlM", "paper_id": "kW3owdkjBlM", "reviews": [{"id": "TbyKtK8GO8K", "original": null, "number": 1, "cdate": 1622324849662, "ddate": null, "tcdate": 1622324849662, "tmdate": 1622324849662, "tddate": null, "forum": "kW3owdkjBlM", "replyto": "kW3owdkjBlM", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper11/-/Official_Review", "content": {"title": "Technical talk focusing on new technologies", "review": "These outstanding authors are leaders in the technical elements of development and implementation of VIVO.  They are presenting important work in new technologies being used with VIVO.  \n\nIt is important that the authors briefly describe each of the components they are using , VIVO Scholars Discovery, and Angular, and what advantages they provide to those in the VIVO Community.  Are they ready for broad use by practitioners of ordinary skill?\n\n", "rating": "8: Top 50% of accepted papers, clear accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=x7QF6Fw6s-P", "paper_id": "x7QF6Fw6s-P", "reviews": [{"id": "JahVlndBMYa", "original": null, "number": 1, "cdate": 1622569262682, "ddate": null, "tcdate": 1622569262682, "tmdate": 1622569262682, "tddate": null, "forum": "x7QF6Fw6s-P", "replyto": "x7QF6Fw6s-P", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper10/-/Official_Review", "content": {"title": "Two impressive new tools in one talk", "review": "The introduction of PID-Graph to the VIVO community is incredibly important.  This resource provides opportunities for the collection of disambiguated, PID-identified, open data into any VIVO.  The introduction of the SPARQL-Generate is just as exciting -- this major new tool for generating RDF using SPARQL is precisely what the community needs to simplify the construction of data conformant with the VIVO ontologies.  This pairing and demonstration may significantly alter the data landscape for VIVO and similar platforms.", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=W7mSrdmz_d-", "paper_id": "W7mSrdmz_d-", "reviews": [{"id": "P7nYEX9W-qz", "original": null, "number": 1, "cdate": 1622568848015, "ddate": null, "tcdate": 1622568848015, "tmdate": 1622568848015, "tddate": null, "forum": "W7mSrdmz_d-", "replyto": "W7mSrdmz_d-", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper9/-/Official_Review", "content": {"title": "Important update on attempts to use ORCiD and other external data sources in VIVO", "review": "The VIVO community has long imagined a world where PIDs and open, external data source could be used to augment research information collected locally.  Local information, such as title, rank, department, and teaching, and external data, such as publications and project awards should come together in high-quality information about each scholar at an insitution.\n\nThe authors have studied ORCiD for data quality, and completeness over a period of three years.  This experience is invaluable to the VIVO community.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=fVeKBCqwkTw", "paper_id": "fVeKBCqwkTw", "reviews": [{"id": "WOQpI6vVYeV", "original": null, "number": 1, "cdate": 1622218360207, "ddate": null, "tcdate": 1622218360207, "tmdate": 1622218360207, "tddate": null, "forum": "fVeKBCqwkTw", "replyto": "fVeKBCqwkTw", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper8/-/Official_Review", "content": {"title": "Common problems are addressed", "review": "The mentioned challenges are ubiquitious. The suggested solutions will hopefully provide a valuable starting point for discussions. The authors could include their view of shortcomings of VIVO and their assessment of already existing solutions and their (non)viability.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=vMOxiBHYwJy", "paper_id": "vMOxiBHYwJy", "reviews": [{"id": "NcDISusyL8nO", "original": null, "number": 1, "cdate": 1622219263237, "ddate": null, "tcdate": 1622219263237, "tmdate": 1622219263237, "tddate": null, "forum": "vMOxiBHYwJy", "replyto": "vMOxiBHYwJy", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper7/-/Official_Review", "content": {"title": "Important topic!", "review": "The authors should please include if and how their approaches can be reused by others.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=9hZkG_8IlCz", "paper_id": "9hZkG_8IlCz", "reviews": [{"id": "wS9OY5IuyfZ", "original": null, "number": 1, "cdate": 1622323542924, "ddate": null, "tcdate": 1622323542924, "tmdate": 1622323542924, "tddate": null, "forum": "9hZkG_8IlCz", "replyto": "9hZkG_8IlCz", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper6/-/Official_Review", "content": {"title": "Important presentation from a mature VIVO implementation", "review": "Duke University is a major, top-ranked, private research university in the southeastern United States.  It's VIVO implementation, Scholars@Duke, has been a leader in the United States with respect to faculty participation, system integration, and delivery of data to components of Duke.\n\nThe author proposes and overview of their experience from their unique perspective of a top-flight VIVO implementation at a major US university.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=A3WeFysLj6e", "paper_id": "A3WeFysLj6e", "reviews": [{"id": "08TgcCWUuBA", "original": null, "number": 1, "cdate": 1622323008017, "ddate": null, "tcdate": 1622323008017, "tmdate": 1622323008017, "tddate": null, "forum": "A3WeFysLj6e", "replyto": "A3WeFysLj6e", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper5/-/Official_Review", "content": {"title": "Clear needs of Spanish research universities and clear consideration of VIVO with respect to those needs", "review": "The author describes a clear distinction between three major use cases for RIM software -- repository, CRIS, and portal.  This clarity is essential for conversations about the role of VIVO.  The Role of VIVO in the Spanish research scenario, particularly with respect to portal and CRIS functions, and its relation to the repository are all extremely interesting.  The author is well-positioned to provide an outstanding description of the role of VIVO in Spain.\n\nIn some regions outside Spain, VIVO is considered \"too difficult\" to be used as a CRIS or research portal, except by larger institutions with resources to commit to VIVO.  The audience might well be interested in how VIVO can be implemented as a research portal and/or CRIS with reasonable effort.", "rating": "10: Top 5% of accepted papers, seminal paper", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=XBjGw_-fmQK", "paper_id": "XBjGw_-fmQK", "reviews": [{"id": "0tV2I5xjiie", "original": null, "number": 1, "cdate": 1622217991016, "ddate": null, "tcdate": 1622217991016, "tmdate": 1622217991016, "tddate": null, "forum": "XBjGw_-fmQK", "replyto": "XBjGw_-fmQK", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper4/-/Official_Review", "content": {"title": "Interesting use case study", "review": "This abstract summarizes a common use case, which makes it very interesting for the community. The author's could highlight the workflow from CERIF to VIVO, as this is becoming increasingly important for CRIS in Europe. The future steps should include as much details as possible. Other projects are working on similar ideas, and this presentation could be an opportunit to inform them and open up networking opportunities and synergies.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=UcVNLo6UYr-", "paper_id": "UcVNLo6UYr-", "reviews": [{"id": "EVYjWZXcA69", "original": null, "number": 1, "cdate": 1622322293576, "ddate": null, "tcdate": 1622322293576, "tmdate": 1622322293576, "tddate": null, "forum": "UcVNLo6UYr-", "replyto": "UcVNLo6UYr-", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper3/-/Official_Review", "content": {"title": "Are there barriers to FAIR research information?", "review": "The authors will describe the results of workshops in which the FAIR principles were discussed in the context of research information, and precisely the kind of information VIVO is designed to collect and provide.\n\nA central question concerns the barriers to FAIR research information?  Is it possible to make research information FAIR?  If not, why not?  Which barriers are temporary and are expected to be removed over time, and which might be more intractable, leading to types of research information that may never be FAIR?", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=1VP6e2gxSjs", "paper_id": "1VP6e2gxSjs", "reviews": [{"id": "DZH5gxycPP0", "original": null, "number": 1, "cdate": 1622217790551, "ddate": null, "tcdate": 1622217790551, "tmdate": 1622217790551, "tddate": null, "forum": "1VP6e2gxSjs", "replyto": "1VP6e2gxSjs", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper2/-/Official_Review", "content": {"title": "Interesting submission", "review": "This use case is very interesting to that part of the community, who thinks a bit out of the box with VIVO. It would be interesting to learn about the ontology, and the workflows. Are different user groups (roles) involved? What skills are necessary to do this? How can the data be viewed/searched.", "rating": "7: Good paper, accept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=jYdC3Pd8n2W", "paper_id": "jYdC3Pd8n2W", "reviews": [{"id": "oCJq6FmQ0gB", "original": null, "number": 1, "cdate": 1622322034055, "ddate": null, "tcdate": 1622322034055, "tmdate": 1622322034055, "tddate": null, "forum": "jYdC3Pd8n2W", "replyto": "jYdC3Pd8n2W", "invitation": "vivoconference.org/VIVO/2021/Conference/Paper1/-/Official_Review", "content": {"title": "What can we learn from graphs of scholarship?", "review": "VIVO provides the means for creating open, detailed, graphs of scholarship across the world -- how the works are created, variety of works beyond papers, including projects, patents, \"grey literature\", early results, proposals, and other indicators of research interest.\n\nThe proposed talk provides an overview of technologies useful in analyzing graph-based data using AI techniques.  The VIVO audience is likely to be mostly unaware of these techniques and their predecessors.  An introductory talk regarding the value of such technqiues for inference from graph-based data would be attractive to the VIVO community,\n\nInsights regarding the use of the techniques to answer questions about scholarship posed by academic leaders and those interested in the the current and future research activities of the academic community would be most appreciated.", "rating": "9: Top 15% of accepted papers, strong accept", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct"}, "signatures": ["vivoconference.org/VIVO/2021/Conference/Program_Chairs"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2021/Conference", "vivoconference.org/VIVO/2021/Conference/Program_Chairs"]}]}, {"paper_url": "https://openreview.net/forum?id=fEOdATegued", "paper_id": "fEOdATegued", "reviews": [{"id": "GFRNXE8Az9J", "original": null, "number": 2, "cdate": 1591021294981, "ddate": null, "tcdate": 1591021294981, "tmdate": 1591021294981, "tddate": null, "forum": "fEOdATegued", "replyto": "fEOdATegued", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper37/-/Official_Review", "content": {"review": "CRIS/RIM systems serve well the purpose of supporting decision makers to make informed and strategic decisions, providing aggregated information on one of the key activities of the institutions. The more the number of integrations with other platforms, the richer the information in the CRIS/RIM. This contribution covers many important aspects of the research information ecosystem: a change in culture,  priorities, needs and awareness within institutions; the role of VIVO in the ecosystem (a RIM or a component of a RIM); open source VS commercial", "title": "RIM and VIVO to support and strengthen institution's mission", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper37/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper37/AnonReviewer2"]}, {"id": "IStrHxlL0jk", "original": null, "number": 1, "cdate": 1590700160228, "ddate": null, "tcdate": 1590700160228, "tmdate": 1590700160228, "tddate": null, "forum": "fEOdATegued", "replyto": "fEOdATegued", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper37/-/Official_Review", "content": {"review": "The important insight that research intelligence requires data sharing across institutions is long overdue.  Texas A&M is a system with multiple campuses?  Do they each have VIVOs?  Will they?  Can they, will they share their data?  Understanding the productivity and position of one's university requires that you understand the productivity and position of others.  The topic is important.  The conversation is necessary.", "title": "Data sharing, what a concept", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper37/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper37/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=uLHQoiwBXi7", "paper_id": "uLHQoiwBXi7", "reviews": [{"id": "aX6Jvpqw1XD", "original": null, "number": 2, "cdate": 1590699810647, "ddate": null, "tcdate": 1590699810647, "tmdate": 1590699810647, "tddate": null, "forum": "uLHQoiwBXi7", "replyto": "uLHQoiwBXi7", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper36/-/Official_Review", "content": {"review": "Many VIVO sites are not familiar with the Freemarker system, an open-source Apache Foundation system used by VIVO.  This talk should provide VIVO sites with the information they need to understand NEMO, the value it offers, while gaining insight into Freemarker and how it is used by VIVO.", "title": "Useful technical walkthrough", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper36/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper36/AnonReviewer2"]}, {"id": "fq8GlcJRmL", "original": null, "number": 1, "cdate": 1590525847994, "ddate": null, "tcdate": 1590525847994, "tmdate": 1590525847994, "tddate": null, "forum": "uLHQoiwBXi7", "replyto": "uLHQoiwBXi7", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper36/-/Official_Review", "content": {"review": "Important presentation about further development of VIVOs main frontend.", "title": "Valuable contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper36/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper36/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=0jXyOEu0TWc", "paper_id": "0jXyOEu0TWc", "reviews": [{"id": "0alkpzUxaIT", "original": null, "number": 2, "cdate": 1590699631695, "ddate": null, "tcdate": 1590699631695, "tmdate": 1590699631695, "tddate": null, "forum": "0jXyOEu0TWc", "replyto": "0jXyOEu0TWc", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper35/-/Official_Review", "content": {"review": "Being able to flip from concentration on one department, all topics, to one topic all departments is a testament to your planning and the versatility of the data and software being used.  Please include a brief (one slide?) overview of UC Davis -- grad/undergrad/faculty counts, research projects and dollars.  This helps our very diverse audience orient to the issues you are addressing.", "title": "Good start-up story", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper35/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper35/AnonReviewer2"]}, {"id": "KbSS9hutgD0", "original": null, "number": 1, "cdate": 1590489967334, "ddate": null, "tcdate": 1590489967334, "tmdate": 1590490293379, "tddate": null, "forum": "0jXyOEu0TWc", "replyto": "0jXyOEu0TWc", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper35/-/Official_Review", "content": {"review": "This presentation will walk you through the rather typical decision making process of determining if VIVO meets the requirements of your own institutional needs. The chosen subject area (\"Covid-19\") is particularly interesting and current.\nIn times like these it is especially important that research results get published quickly and are easy to access / have great accessability. And a research infomation system provides a great opportunity to do exactly that.\nFurthermore it is always interesting to see the different requirements an institution might have and the ensuing ideas on how to fulfill them with VIVO.", "title": "Interesting contribution especially for \"new\" VIVO users", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper35/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper35/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=Sz0dgsu0vEi", "paper_id": "Sz0dgsu0vEi", "reviews": [{"id": "dNPzCTPPrJ2", "original": null, "number": 2, "cdate": 1590699411114, "ddate": null, "tcdate": 1590699411114, "tmdate": 1590699411114, "tddate": null, "forum": "Sz0dgsu0vEi", "replyto": "Sz0dgsu0vEi", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper34/-/Official_Review", "content": {"review": "This talk focuses on the representation and accomplishments of faculty in non-traditional career tracks, where traditional is defined as evaluable by reviewing papers and funding of the faculty member.  It is not clear if this is a uniquely American problem.  About half the VIVO audience is from outside the United States.  It would be useful to be sure the problem is well understood.  And that TAMU is described -- the scale and diversity of a large land-grant university is often surprising to non-American audiences.", "title": "An American-only perspective?", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper34/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper34/AnonReviewer2"]}, {"id": "iju8E8zb6NC", "original": null, "number": 1, "cdate": 1590526468724, "ddate": null, "tcdate": 1590526468724, "tmdate": 1590526468724, "tddate": null, "forum": "Sz0dgsu0vEi", "replyto": "Sz0dgsu0vEi", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper34/-/Official_Review", "content": {"review": "This presentation can give insight into two wide-spread use cases: Combination of repository and RIS on the one hand, and providing specific faculty profiles for diverse faculty on the other hand.  It would be interesting to learn about the decisions and the framework behind the profiles. With regards to former publications and presentations about the VIVO project, it could be Boyer's model of scholarship. If this is the case, please elaborate, how concrete requirements were developed on that base.", "title": "Valuable contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper34/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper34/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=p6qud8KHqpB", "paper_id": "p6qud8KHqpB", "reviews": [{"id": "4lGj6-e7anP", "original": null, "number": 2, "cdate": 1590603904847, "ddate": null, "tcdate": 1590603904847, "tmdate": 1590603904847, "tddate": null, "forum": "p6qud8KHqpB", "replyto": "p6qud8KHqpB", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper33/-/Official_Review", "content": {"review": "Assessing research can be a difficult topic.  Cultural normals vary widely across disciplines and expectations for evaluation and review are quite different across the academy.  And yet, there is much work to be done to represent evaluation ontologically.  The authors' propose this novel approach.  The presenters should consider how such an approach might be used outside of Greece -- what must be considered to implement more broadly?", "title": "Evaluation of research, an interesting topic", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper33/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper33/AnonReviewer2"]}, {"id": "gaC_QKu_edt", "original": null, "number": 1, "cdate": 1590182756395, "ddate": null, "tcdate": 1590182756395, "tmdate": 1590182756395, "tddate": null, "forum": "p6qud8KHqpB", "replyto": "p6qud8KHqpB", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper33/-/Official_Review", "content": {"review": "This presentation would give insight into a practical application of the use case \u201cdecision-making\u201d, that is oftentimes discussed in the CRIS community, which makes it a welcome contribution to the conference program. However, there are ethical problems with performing research analytics on the person-level. I suggest to include some insights how the authors are processing this use-case, especially how it\u2019s possible to measure the quality of research based on research information. See https://sfdora.org/ and the Leiden Manifesto for further information on this topic.", "title": "Interesting submission, some open ethical ", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper33/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper33/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=YDv7K8aHiEO", "paper_id": "YDv7K8aHiEO", "reviews": [{"id": "jNwqoV96Nv2", "original": null, "number": 1, "cdate": 1590528074507, "ddate": null, "tcdate": 1590528074507, "tmdate": 1590528074507, "tddate": null, "forum": "YDv7K8aHiEO", "replyto": "YDv7K8aHiEO", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper32/-/Official_Review", "content": {"review": "Another show case of VIVO's ability to serve data to different front-ends. It would be great to hear if the TPF can be used by third parties, too, to power over-institutional research information systems, too.", "title": "Interesting use case", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper32/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper32/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=GDZZNBZOcaX", "paper_id": "GDZZNBZOcaX", "reviews": [{"id": "L2bBD97qgn_", "original": null, "number": 2, "cdate": 1590604442292, "ddate": null, "tcdate": 1590604442292, "tmdate": 1590604442292, "tddate": null, "forum": "GDZZNBZOcaX", "replyto": "GDZZNBZOcaX", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper31/-/Official_Review", "content": {"review": "Many in the audience will be unfamiliar with Scholar.  Why is it being developed? Who is developing it?  What is it -- what is the relationship of VIVO, VIVO Discovery, and VIVO Scholar?  Is the TAMU front-end the same as the Duke front-end?   Understanding the why and what of Scholar will help the community understand the opportunities afforded by VIVO Scholar.", "title": "What is Scholar?", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper31/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper31/AnonReviewer2"]}, {"id": "ILpvXnanJWj", "original": null, "number": 1, "cdate": 1590567882729, "ddate": null, "tcdate": 1590567882729, "tmdate": 1590567882729, "tddate": null, "forum": "GDZZNBZOcaX", "replyto": "GDZZNBZOcaX", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper31/-/Official_Review", "content": {"review": "Valuable contribution to the conference.", "title": "Good submission", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper31/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper31/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=wb4CKpV7sas", "paper_id": "wb4CKpV7sas", "reviews": [{"id": "qNt3ZGJJiaK", "original": null, "number": 2, "cdate": 1590604606665, "ddate": null, "tcdate": 1590604606665, "tmdate": 1590604606665, "tddate": null, "forum": "wb4CKpV7sas", "replyto": "wb4CKpV7sas", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper30/-/Official_Review", "content": {"review": "Engaging the community in the creation and refinement of the development priorities is an important idea.  The presenters are encouraged to engage the attendees (an interactive session?) and generate on-going participation in the development of the priorities.", "title": "Engaging the community", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper30/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper30/AnonReviewer2"]}, {"id": "ryThX4MJvs", "original": null, "number": 1, "cdate": 1590527702100, "ddate": null, "tcdate": 1590527702100, "tmdate": 1590527702100, "tddate": null, "forum": "wb4CKpV7sas", "replyto": "wb4CKpV7sas", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper30/-/Official_Review", "content": {"review": "VIVO's project statement of technical priorities are an important part of the VIVO conference.", "title": "Valuable contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper30/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper30/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=GlytqeT39Nc", "paper_id": "GlytqeT39Nc", "reviews": [{"id": "WuKsMKvCMIb", "original": null, "number": 2, "cdate": 1590604913528, "ddate": null, "tcdate": 1590604913528, "tmdate": 1590604913528, "tddate": null, "forum": "GlytqeT39Nc", "replyto": "GlytqeT39Nc", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper29/-/Official_Review", "content": {"review": "The presence of the euroCRIS track at the VIVO conference represents an important opportunity to explore collaboration between the projects.  The four presentations in this session, and the roundtable, should develop questions regarding the relationship between CRIS systems, the DRIS, and VIVO systems.  The perspectives of the presenters spans a range of institutional settings, further adding value to the track.", "title": "Exciting opportunity to explore collaboration", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper29/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper29/AnonReviewer2"]}, {"id": "uiA4GNbfPI2", "original": null, "number": 1, "cdate": 1590525253487, "ddate": null, "tcdate": 1590525253487, "tmdate": 1590525253487, "tddate": null, "forum": "GlytqeT39Nc", "replyto": "GlytqeT39Nc", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper29/-/Official_Review", "content": {"review": "Valuable contributions to the VIVO conference.", "title": "Valuable track", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper29/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper29/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=yfGS2gaCqh3", "paper_id": "yfGS2gaCqh3", "reviews": [{"id": "qGvDIvJty7", "original": null, "number": 1, "cdate": 1590605687730, "ddate": null, "tcdate": 1590605687730, "tmdate": 1590605687730, "tddate": null, "forum": "yfGS2gaCqh3", "replyto": "yfGS2gaCqh3", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper28/-/Official_Review", "content": {"review": "Visualizing ontologies is a very interesting idea.  VIVO has used hand-drawn visualizations [VIVO Ontology Diagrams](https://wiki.lyrasis.org/display/VIVODOC111x/Ontology+Diagrams) of core elements of its ontologies to help users understand relations between terms.  But much more is needed.  G-OWL is addressing key principles graphic presentation for the purpose of improving understanding.  This reviewer hopes the presentation can include at least one VIVO example to help the audience consider utility of a graphical approach to presenting ontological information.", "title": "Visualization an important contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper28/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper28/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=Y-RiiNJmvar", "paper_id": "Y-RiiNJmvar", "reviews": [{"id": "OpqtGNjXprA", "original": null, "number": 2, "cdate": 1590606054242, "ddate": null, "tcdate": 1590606054242, "tmdate": 1590606054242, "tddate": null, "forum": "Y-RiiNJmvar", "replyto": "Y-RiiNJmvar", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper27/-/Official_Review", "content": {"review": "The authors are engaged in very interesting work to assess research across institutions, at a national level and beyond.  The issues raised in the bulleted items in the abstract are fascinating.  In particular, how can the local nature of VIVO (institutionally focused, potentially rich data regarding researchers) contribute to research analytics using global data such as Dimensions?", "title": "Fascinating work from local to national to global", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper27/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper27/AnonReviewer2"]}, {"id": "Q5RNDpSHkk", "original": null, "number": 1, "cdate": 1590182568503, "ddate": null, "tcdate": 1590182568503, "tmdate": 1590182568503, "tddate": null, "forum": "Y-RiiNJmvar", "replyto": "Y-RiiNJmvar", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper27/-/Official_Review", "content": {"review": "It will be interesting to see a sneak preview into the final results of the project. Please elaborate on potential pitfalls when combining a data source like Dimensions with local data (how was the disambiguation done etc.?). \n\nImportant question: How can the competencies and the knowledge be build and kept in an organization when you use a variety of tools like VOSViewer, Neo4J, Tableau etc. And can the NORA approach be reused by others?", "title": "Accept, presentation should focus on pitfalls.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper27/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper27/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=VZOacEty0N", "paper_id": "VZOacEty0N", "reviews": [{"id": "KPSQhVSCR-", "original": null, "number": 2, "cdate": 1591019796654, "ddate": null, "tcdate": 1591019796654, "tmdate": 1591019796654, "tddate": null, "forum": "VZOacEty0N", "replyto": "VZOacEty0N", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper26/-/Official_Review", "content": {"review": "A very interesting project. Particularly the creation of a new ontology built on top of others experiences.", "title": "Interesting use of Vitro in the art-historical domain", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper26/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper26/AnonReviewer2"]}, {"id": "M3SJakHM2HL", "original": null, "number": 1, "cdate": 1590605290718, "ddate": null, "tcdate": 1590605290718, "tmdate": 1590605290718, "tddate": null, "forum": "VZOacEty0N", "replyto": "VZOacEty0N", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper26/-/Official_Review", "content": {"review": "The use of Vitro to present this collection is intriguing.  The development of ontology elements to represent the collection is equally intriguing.  Harvesting might be mentioned in passing unless there are PID or other issues related to synchronizing or harmonizing multiple data sources.  These issues may be a distraction in what otherwise should be a very clear example of the use of Vitro to organize and share an important collection.", "title": "Intriguing use case for Vitro", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper26/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper26/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=l0tq6FFp3lg", "paper_id": "l0tq6FFp3lg", "reviews": [{"id": "38b1h_L7S-X", "original": null, "number": 2, "cdate": 1590672127245, "ddate": null, "tcdate": 1590672127245, "tmdate": 1590672127245, "tddate": null, "forum": "l0tq6FFp3lg", "replyto": "l0tq6FFp3lg", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper25/-/Official_Review", "content": {"review": "This clear overview should provide a quick but very useful review of the process and findings of an analysis of the needs for a RIS system and what it must provide to TUC.  Due to the international nature of the audience, it would be best if the presenters could include one slide regarding TUC -- how many students, faculty, mission, budget , research focus -- so the rest of the presentation can be put in context.", "title": "Clear overview of requirements phase for a VIVO project", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper25/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper25/AnonReviewer2"]}, {"id": "WWbfCi7H3A8", "original": null, "number": 1, "cdate": 1590183529037, "ddate": null, "tcdate": 1590183529037, "tmdate": 1590183529037, "tddate": null, "forum": "l0tq6FFp3lg", "replyto": "l0tq6FFp3lg", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper25/-/Official_Review", "content": {"review": "This VIVO project leans on one of the core functions of VIVO, the self-editing feature to describe what the VIVO ontology is made for, the description of competencies. I suggest to give deeper insights especially into the following aspects: Where could the VIVO ontology be improved regarding the representation of academic projects, publications, and - most interestingly - the knowledge skills of researchers. And how are the authors going to solve what they call \u201cThe main challenge [...] to gather and provide meta-information about an entity, which cannot directly be taken from an existing data source.\u201d\n\nThere are so many interesting aspects in this abstracts that easily two presentations could be made of this. The last paragraph about different landing pages for different stakeholders was sometimes discussed in the last VIVO conferences, for example. It would be great to learn about the plans for TUCfis.\n", "title": "Very relevant contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper25/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper25/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=Hmn_SRsLX3-", "paper_id": "Hmn_SRsLX3-", "reviews": [{"id": "t8OUhY84FVw", "original": null, "number": 2, "cdate": 1590672471445, "ddate": null, "tcdate": 1590672471445, "tmdate": 1590672471445, "tddate": null, "forum": "Hmn_SRsLX3-", "replyto": "Hmn_SRsLX3-", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper24/-/Official_Review", "content": {"review": "Continuous Development has been discussed many times in the past, but I don't believe ever at this detail level.  I greatly appreciate the work and thought already put into this and I know that others will as well.", "title": "Interesting and Needed Work", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper24/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper24/AnonReviewer1"]}, {"id": "ZQOV6mQQuE_", "original": null, "number": 1, "cdate": 1590604190071, "ddate": null, "tcdate": 1590604190071, "tmdate": 1590604190071, "tddate": null, "forum": "Hmn_SRsLX3-", "replyto": "Hmn_SRsLX3-", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper24/-/Official_Review", "content": {"review": "In this original and detailed work, the UQAM team presents a comprehensive approach to the improvement of VIVO i18n capabilities.  Approaching work breakdown, project management, and tool support, the team describes an entire development environment optimized for their specific purposes.  Remarkable!", "title": "Outstanding and important contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "10: Top 5% of accepted papers, seminal paper"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper24/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper24/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=dFdvNDipdmI", "paper_id": "dFdvNDipdmI", "reviews": [{"id": "wT_YjiDdgT7", "original": null, "number": 2, "cdate": 1590672584443, "ddate": null, "tcdate": 1590672584443, "tmdate": 1590672584443, "tddate": null, "forum": "dFdvNDipdmI", "replyto": "dFdvNDipdmI", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper23/-/Official_Review", "content": {"review": "The utility of LOD for combining data across universities in a collection or system is largely unexplored.  The UQ network is large and diverse.  The effort to build a vocabulary to encompass the system, and to use LOD to combine data across sites is very interesting.", "title": "Linked Data value proposition", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper23/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper23/AnonReviewer2"]}, {"id": "ZVRpwFjlyWm", "original": null, "number": 1, "cdate": 1590527090092, "ddate": null, "tcdate": 1590527090092, "tmdate": 1590527090092, "tddate": null, "forum": "dFdvNDipdmI", "replyto": "dFdvNDipdmI", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper23/-/Official_Review", "content": {"review": "Great abstract. The LOD potentals of VIVO are not exploited enough. If possible, please include some thoughts if and how the LOD context could be extend beyond the UQAM network. As stated: ", "title": "Valuable contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper23/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper23/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=Gn-9gtwd3QL", "paper_id": "Gn-9gtwd3QL", "reviews": [{"id": "GJYQc6oy0Ii", "original": null, "number": 1, "cdate": 1590677882549, "ddate": null, "tcdate": 1590677882549, "tmdate": 1590677882549, "tddate": null, "forum": "Gn-9gtwd3QL", "replyto": "Gn-9gtwd3QL", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper22/-/Official_Review", "content": {"review": "A much-needed look to the future of VIVO.  I appreciate that this continues the modular idea and understands that VIVO is more than showing profiles.", "title": "A needed look to the future", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "10: Top 5% of accepted papers, seminal paper"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper22/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper22/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=DqjhgPsg_8", "paper_id": "DqjhgPsg_8", "reviews": [{"id": "kddWD2vYJTm", "original": null, "number": 1, "cdate": 1590526671957, "ddate": null, "tcdate": 1590526671957, "tmdate": 1590526671957, "tddate": null, "forum": "DqjhgPsg_8", "replyto": "DqjhgPsg_8", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper21/-/Official_Review", "content": {"review": "Internationalization is the potentially biggest driver for growth for the VIVO ecosystem. Lowering barriers to translating the ontology would enable wider parts of the VIVO community to work on translation. ", "title": "Valuable contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper21/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper21/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=dYlO0elyczY", "paper_id": "dYlO0elyczY", "reviews": [{"id": "9utH1fIiWbm", "original": null, "number": 2, "cdate": 1590672363284, "ddate": null, "tcdate": 1590672363284, "tmdate": 1590672363284, "tddate": null, "forum": "dYlO0elyczY", "replyto": "dYlO0elyczY", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper20/-/Official_Review", "content": {"review": "University Enterprise systems often include a large number of operational systems, focused on supporting the operations of some element of the university -- HR, Registrar, CRIS, etc.  The harmonization of data from these systems to an integrated graph is a key value proposition for VIVO.  The use of messaging is relatively novel.  The use of Kafka may be a first.  ", "title": "Important enterprise architecture presentation", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper20/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper20/AnonReviewer2"]}, {"id": "IlaAX8vKx_m", "original": null, "number": 1, "cdate": 1590421385277, "ddate": null, "tcdate": 1590421385277, "tmdate": 1590421385277, "tddate": null, "forum": "dYlO0elyczY", "replyto": "dYlO0elyczY", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper20/-/Official_Review", "content": {"review": "Distributed data sources are the rule rather than the exception. The thoughts outlined here sound very promising, especially if the authors can fulfull their plans \"to build a generalizable and adaptive solution to different organizational contexts\". ", "title": "Presentation about a common use-case", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper20/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper20/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=APib8cL0vfB", "paper_id": "APib8cL0vfB", "reviews": [{"id": "88j8O8ZMnGF", "original": null, "number": 2, "cdate": 1590684209072, "ddate": null, "tcdate": 1590684209072, "tmdate": 1590684209072, "tddate": null, "forum": "APib8cL0vfB", "replyto": "APib8cL0vfB", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper19/-/Official_Review", "content": {"review": "Most recent movement I'm aware of with Internationalization in recent years has been mostly theoretical or not fully moved back into the core code.  I'm very pleased by these important and well-organized sprints in moving Internationalization forward.  I look forward to these updates.", "title": "Movement in Internationalization", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "10: Top 5% of accepted papers, seminal paper"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper19/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper19/AnonReviewer1"]}, {"id": "RbtuX7hLwL", "original": null, "number": 1, "cdate": 1590672802193, "ddate": null, "tcdate": 1590672802193, "tmdate": 1590672802193, "tddate": null, "forum": "APib8cL0vfB", "replyto": "APib8cL0vfB", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper19/-/Official_Review", "content": {"review": "There are at least three important topics here: 1) the general problem of internationalization, language selection, language-aware editing; 2) the specific challenges of the VIVO environment; 3) the new functionality for the VIVO community being delivered by the sprints.  American audiences are often unaware of the first topic, it will need to be reviewed.", "title": "Important project update", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper19/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper19/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=-Oe6b569Pi6", "paper_id": "-Oe6b569Pi6", "reviews": [{"id": "FgDeo1N_Ta", "original": null, "number": 2, "cdate": 1591020086931, "ddate": null, "tcdate": 1591020086931, "tmdate": 1591020086931, "tddate": null, "forum": "-Oe6b569Pi6", "replyto": "-Oe6b569Pi6", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper18/-/Official_Review", "content": {"review": "Being able to track sources (people, organizations, papers, data, tools) is an important and crucial component of research activities. It will be very valuable for the research community to see the proposed solution to this problem, and to see how the community can contribute to the next steps", "title": "The more PIDs the better", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper18/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper18/AnonReviewer2"]}, {"id": "N4URYLap3qb", "original": null, "number": 1, "cdate": 1590673151959, "ddate": null, "tcdate": 1590673151959, "tmdate": 1590673151959, "tddate": null, "forum": "-Oe6b569Pi6", "replyto": "-Oe6b569Pi6", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper18/-/Official_Review", "content": {"review": "The need to identify instruments uniquely and to provide metadata about them is a frontier for laboratory science (and perhaps other research disciplines as well).  The increasing complexity of laboratory research and the limited space in publications often leaves questions about the equipment used, casting doubt on findings.  Hopefully the authors present a solution by which equipment can be identified (using tools that simply the production of metadata), and the means to find and consume metadata regarding instruments.", "title": "Fascinating, important problem, hopeful of solution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper18/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper18/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=QWAiowyrhzy", "paper_id": "QWAiowyrhzy", "reviews": [{"id": "fR2FrfpnsLI", "original": null, "number": 2, "cdate": 1590847633534, "ddate": null, "tcdate": 1590847633534, "tmdate": 1590847633534, "tddate": null, "forum": "QWAiowyrhzy", "replyto": "QWAiowyrhzy", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper17/-/Official_Review", "content": {"review": "Since VIVO can be used in such a diversity of ways, it is important for the community to share specific details about implementation patterns.\nThe elements of the ZEW implementation hit on common VIVO challenges:\n- reporting\n- integrations\n- ingest and migration\n\nThe proposal represents a strong contribution to the VIVO community's collective understanding of ways to address shared needs.\n", "title": "Important project update", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper17/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper17/AnonReviewer2"]}, {"id": "TOLbidKgMCo", "original": null, "number": 1, "cdate": 1590673359189, "ddate": null, "tcdate": 1590673359189, "tmdate": 1590673359189, "tddate": null, "forum": "QWAiowyrhzy", "replyto": "QWAiowyrhzy", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper17/-/Official_Review", "content": {"review": "This overview of ZEW and the role of VIVO at ZEW will be of interesting to the VIVO community.  VIVO as an internal-only integrator and source of integrated data for reporting is novel.  ", "title": "Excellent summary of the role of VIVO at ZEW", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper17/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper17/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=OOY26MPy6FR", "paper_id": "OOY26MPy6FR", "reviews": [{"id": "s2BPf-nmv1R", "original": null, "number": 1, "cdate": 1590673697948, "ddate": null, "tcdate": 1590673697948, "tmdate": 1590673697948, "tddate": null, "forum": "OOY26MPy6FR", "replyto": "OOY26MPy6FR", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper16/-/Official_Review", "content": {"review": "The creation of PIDs for conferences and events is an important next step in the creation of integrated research graphs.  Conference metadata is equally important.  How will the metadata be produced and housed?  That is, what will the data flow be from the organizers and presenters, to systems such as VIVO and users of such systems for consuming the conference metadata/", "title": "PID, Metadata, and data flow", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper16/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper16/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=DXaCNvkiUC5", "paper_id": "DXaCNvkiUC5", "reviews": [{"id": "JLckwbv6m_N", "original": null, "number": 2, "cdate": 1590673916175, "ddate": null, "tcdate": 1590673916175, "tmdate": 1590673916175, "tddate": null, "forum": "DXaCNvkiUC5", "replyto": "DXaCNvkiUC5", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper15/-/Official_Review", "content": {"review": "This demonstration of the ability to present VIVO using simplified Chinese is an important contribution.  Would be good to understand the nature of the work -- who had to do what to produce a translation and then present that translation in VIVO.", "title": "Important work", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper15/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper15/AnonReviewer2"]}, {"id": "pWVkfuhfT_-", "original": null, "number": 1, "cdate": 1590526845551, "ddate": null, "tcdate": 1590526845551, "tmdate": 1590526845551, "tddate": null, "forum": "DXaCNvkiUC5", "replyto": "DXaCNvkiUC5", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper15/-/Official_Review", "content": {"review": "I18N is one of the biggest potential driver for growth for the VIVO project. A Chinese VIVO would be a great show case for VIVO's ability to support non-western languages.", "title": "Valuable contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper15/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper15/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=Wx2ygcVooEd", "paper_id": "Wx2ygcVooEd", "reviews": [{"id": "bdyJ5YNUNNW", "original": null, "number": 2, "cdate": 1590690302481, "ddate": null, "tcdate": 1590690302481, "tmdate": 1590690302481, "tddate": null, "forum": "Wx2ygcVooEd", "replyto": "Wx2ygcVooEd", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper14/-/Official_Review", "content": {"review": "People need to see more than just a profile to understand the possibilities around VIVO.  Seeing these cases, infrastructure, and tools are essential to understanding and then being able to implement. ", "title": "Brings pieces together", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper14/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper14/AnonReviewer2"]}, {"id": "tQfojS9UDJ-", "original": null, "number": 1, "cdate": 1590674151662, "ddate": null, "tcdate": 1590674151662, "tmdate": 1590674151662, "tddate": null, "forum": "Wx2ygcVooEd", "replyto": "Wx2ygcVooEd", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper14/-/Official_Review", "content": {"review": "It is very important for VIVO audience to understand the value afforded by table, document, and graph approaches -- what are the strengths and weaknesses of each for business intelligence and research analytics.  This alone would be sufficient to warrant a presentation.  To demonstrate the value of an integrated data infrastructure at the national level is even better.", "title": "Very important basic concepts", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper14/AnonReviewer3"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper14/AnonReviewer3"]}]}, {"paper_url": "https://openreview.net/forum?id=gxbtVm_oCt3", "paper_id": "gxbtVm_oCt3", "reviews": [{"id": "v1WLOw_WlR", "original": null, "number": 2, "cdate": 1590674465287, "ddate": null, "tcdate": 1590674465287, "tmdate": 1590674465287, "tddate": null, "forum": "gxbtVm_oCt3", "replyto": "gxbtVm_oCt3", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper13/-/Official_Review", "content": {"review": "Engaging the faculty in an open process of assessment using a previously built data infrastructure is a thoughtful next step in the maturing of the assessment and measurement infrastructure of a university.  The role of ORCiD in such an ecosystem is intriguing.", "title": "Novel assessment of research outputs and impact", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper13/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper13/AnonReviewer2"]}, {"id": "n6C1gp0xe9E", "original": null, "number": 1, "cdate": 1590183653389, "ddate": null, "tcdate": 1590183653389, "tmdate": 1590183653389, "tddate": null, "forum": "gxbtVm_oCt3", "replyto": "gxbtVm_oCt3", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper13/-/Official_Review", "content": {"review": "The authors should give in-depth information about all mechanisms, data sources, processes and tools used for identifying, gathering, disambiguation and converting PID based data into useful information for a research analytics tool. ", "title": "Relevant contribution, please provide details about the processes and tools", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper13/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper13/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=IC8JBennTc4", "paper_id": "IC8JBennTc4", "reviews": [{"id": "1T6HIckHd9D", "original": null, "number": 2, "cdate": 1590674640464, "ddate": null, "tcdate": 1590674640464, "tmdate": 1590674640464, "tddate": null, "forum": "IC8JBennTc4", "replyto": "IC8JBennTc4", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper12/-/Official_Review", "content": {"review": "This useful overview focuses on OCRiD/VIVO Integration.  Discussion of the public and member API requirement of ORCiD would be useful for those considering how to go further with ORCiD in their VIVO implementations.", "title": "Useful overview of ORCiD in VIVO", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper12/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper12/AnonReviewer2"]}, {"id": "l3ADBLdRdFm", "original": null, "number": 1, "cdate": 1590182072958, "ddate": null, "tcdate": 1590182072958, "tmdate": 1590182096388, "tddate": null, "forum": "IC8JBennTc4", "replyto": "IC8JBennTc4", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper12/-/Official_Review", "content": {"review": "The talk could focus on how data management can be done from a client (like VIVO) into ORCID. This is especially interesting for institutions who would like to maintain the publication record etc. in ORCID for their researchers via the member\u2019s API. To my knowledge, there is no satisfying solution right now for this use case. Learning from others would be a great opportunity to strengthen the ties between VIVO and ORCID. The mentioned example of the Universit of Wollongong seems to go into that direction. \n\nThis could be a full presentation, too.", "title": "Good opportunity to learn more about PIDs in VIVO", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper12/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper12/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=uM63fu1pI_R", "paper_id": "uM63fu1pI_R", "reviews": [{"id": "r8FbkWnyeQT", "original": null, "number": 2, "cdate": 1590674839442, "ddate": null, "tcdate": 1590674839442, "tmdate": 1590674839442, "tddate": null, "forum": "uM63fu1pI_R", "replyto": "uM63fu1pI_R", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper11/-/Official_Review", "content": {"review": "ROR is an important new element in the research ecosystem.  VIVO sites creating research metadata need organizational identifiers to associate with contributors to research outputs, to characterize employment and other relationships to organizations, and to characterize training and education.  Having worked with GRiD data for sometime, the VIVO community should be eager to hear how ROR is progressing.", "title": "Critical to the emerging research graph", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper11/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper11/AnonReviewer2"]}, {"id": "63S_1SeExJd", "original": null, "number": 1, "cdate": 1590183394718, "ddate": null, "tcdate": 1590183394718, "tmdate": 1590183394718, "tddate": null, "forum": "uM63fu1pI_R", "replyto": "uM63fu1pI_R", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper11/-/Official_Review", "content": {"review": "PIDs are one of the main cornerstones of research information, and VIVO makes heavy use of information about organizations. This is a very welcome and relevant contribution to the VIVO conference. Please address scope of the data, update mechanisms and versioning of data. Another interesting points: Are closing or closed institutions included? Which organizations are out of scope? Is there provenance information? What happens after a name change of an institution? ", "title": "Very relevant contribution.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper11/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper11/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=s6Jlahv97TI", "paper_id": "s6Jlahv97TI", "reviews": [{"id": "hHjgfF4HLK", "original": null, "number": 2, "cdate": 1590675129130, "ddate": null, "tcdate": 1590675129130, "tmdate": 1590675129130, "tddate": null, "forum": "s6Jlahv97TI", "replyto": "s6Jlahv97TI", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper10/-/Official_Review", "content": {"review": "Disambiguation using machine learning, and a large dataset such as Dimensions such improve our ability to associate papers with people with less false positives and less false negatives.  The data in the abstract is encouraging, while the particular problem of Asian names is well-known, and largely unaddressed.  Is Observer an open API that can be used across systems?", "title": "A frontier for disambiguation", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper10/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper10/AnonReviewer2"]}, {"id": "FH6tSyByaFq", "original": null, "number": 1, "cdate": 1590183004924, "ddate": null, "tcdate": 1590183004924, "tmdate": 1590183004924, "tddate": null, "forum": "s6Jlahv97TI", "replyto": "s6Jlahv97TI", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper10/-/Official_Review", "content": {"review": "An interesting view into a practical project. Please include in-depth information about the recognized flaws in PubMed and Dimensions data. Especially the mentioned \u201clost data\u201d seems critical. Further information about potential reuse by third parties would be appropriate. This submission would give the audience to learn from a project related to VIVO.", "title": "Interesting view outside the box", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper10/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper10/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=IVTzPfdz2x9", "paper_id": "IVTzPfdz2x9", "reviews": [{"id": "MjAgYpDLf0e", "original": null, "number": 2, "cdate": 1590691834201, "ddate": null, "tcdate": 1590691834201, "tmdate": 1590691834201, "tddate": null, "forum": "IVTzPfdz2x9", "replyto": "IVTzPfdz2x9", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper9/-/Official_Review", "content": {"review": "Third party web-based plugins with a standard format and can be shared between systems? Like the idea!  Then also having a replacement for OpenSocial? Great bonus!  I believe this could be a great discussion.", "title": "SMART and an OpenSocial Replacement", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper9/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper9/AnonReviewer1"]}, {"id": "uX5avBqGDeo", "original": null, "number": 1, "cdate": 1590675341029, "ddate": null, "tcdate": 1590675341029, "tmdate": 1590675341029, "tddate": null, "forum": "IVTzPfdz2x9", "replyto": "IVTzPfdz2x9", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper9/-/Official_Review", "content": {"review": "The idea to integrate 3rd party apps in systems such as Profiles RNS and VIVO is very cool.  The proposal to use an existing platform (SMART technology and FHIR data standard) might be cool.  Let's see!", "title": "3rd party apps is cool.  Is SMART an answer?", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper9/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper9/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=kJjcIDgXrZ1", "paper_id": "kJjcIDgXrZ1", "reviews": [{"id": "2yTFlkItqr-", "original": null, "number": 1, "cdate": 1590698773844, "ddate": null, "tcdate": 1590698773844, "tmdate": 1590698773844, "tddate": null, "forum": "kJjcIDgXrZ1", "replyto": "kJjcIDgXrZ1", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper8/-/Official_Review", "content": {"review": "Using VIVO and semantic technologies to strengthen the evaluation of graduate programs across Brazil is certainly an ambitious project.  A talk on this effort with its 13 sub-projects should be very interesting.  There quite a few questions that could be asked -- why semantics?  What elements of the programs will be captured by the system?  Who is participating in the governance?  ", "title": "Ambitious project", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper8/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper8/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=hgKSPQP3M7Y", "paper_id": "hgKSPQP3M7Y", "reviews": [{"id": "q8BENTKtGNH", "original": null, "number": 2, "cdate": 1591061485333, "ddate": null, "tcdate": 1591061485333, "tmdate": 1591061485333, "tddate": null, "forum": "hgKSPQP3M7Y", "replyto": "hgKSPQP3M7Y", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper7/-/Official_Review", "content": {"review": "I am looking forward to hearing this presentation and the input it generates from the community.  I see this as the continuation of the modernization of VIVO and the ontologies it is currently using.", "title": "Moving the VIVO Ontologies Forward", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "10: Top 5% of accepted papers, seminal paper"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper7/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper7/AnonReviewer2"]}, {"id": "46KjesDHyv5", "original": null, "number": 1, "cdate": 1590847584214, "ddate": null, "tcdate": 1590847584214, "tmdate": 1590847584214, "tddate": null, "forum": "hgKSPQP3M7Y", "replyto": "hgKSPQP3M7Y", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper7/-/Official_Review", "content": {"review": "In the role of representing the network of scholarly activity, VIVO relies on detailed and comprehensive description of relevant concepts and relationships.\nOne of the ways that VIVO grows is by expanding its universe of ontological description.\nThis proposal is an important contribution to that expansion.\nIn addition to the description of this new ontology, it will be valuable to hear how it can be used in the VIVO application as well as whether there are existing ontologies from which AEON drew inspiration.\n", "title": "Expanding the VIVO universe of description", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper7/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper7/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=Hs7NpNcoPtO", "paper_id": "Hs7NpNcoPtO", "reviews": [{"id": "t9IQVI7Lktd", "original": null, "number": 2, "cdate": 1591020480295, "ddate": null, "tcdate": 1591020480295, "tmdate": 1591020480295, "tddate": null, "forum": "Hs7NpNcoPtO", "replyto": "Hs7NpNcoPtO", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper6/-/Official_Review", "content": {"review": "It is really important to hear directly from researchers (the ones who make research information systems meaningful) what is that they're looking for when they use the platforms. It will be interesting to see the outcomes of the study and see how it could scale to other countries as well", "title": "Including users input in software development is key", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper6/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper6/AnonReviewer2"]}, {"id": "SHxwjjpcmjQ", "original": null, "number": 1, "cdate": 1590699066103, "ddate": null, "tcdate": 1590699066103, "tmdate": 1590699066103, "tddate": null, "forum": "Hs7NpNcoPtO", "replyto": "Hs7NpNcoPtO", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper6/-/Official_Review", "content": {"review": "The work described is important for the development of user interfaces for research profile systems.  Visualization of scientometric data is a key element of such interfaces, and one that has not received significant attention in the literature.  Feedback from systems users is an approach to learning what works and what does not.", "title": "Visualizing data on profiles is important", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper6/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper6/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=uFK45DQOlwJ", "paper_id": "uFK45DQOlwJ", "reviews": [{"id": "H2Lvgt-qN_m", "original": null, "number": 2, "cdate": 1590675561913, "ddate": null, "tcdate": 1590675561913, "tmdate": 1590675561913, "tddate": null, "forum": "uFK45DQOlwJ", "replyto": "uFK45DQOlwJ", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper5/-/Official_Review", "content": {"review": "\"Identify health researchers getting public buzz\" is chilling.  Can this be an indicator of good work?  Or is it just an indicator of the often confused world of social media. So perhaps this approach is controversial.\n\nBut open discussion of alternative approaches, controversial or not, is a cornerstone of academic discourse.", "title": "Controversial idea", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper5/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper5/AnonReviewer2"]}, {"id": "uOatNrz2NeB", "original": null, "number": 1, "cdate": 1590527633850, "ddate": null, "tcdate": 1590527633850, "tmdate": 1590527633850, "tddate": null, "forum": "uFK45DQOlwJ", "replyto": "uFK45DQOlwJ", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper5/-/Official_Review", "content": {"review": "Interesting idea combined with a current event. ", "title": "Interesting contribution", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper5/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper5/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=6X5HByKw-2", "paper_id": "6X5HByKw-2", "reviews": [{"id": "Lfz-QrixsfA", "original": null, "number": 2, "cdate": 1590603599794, "ddate": null, "tcdate": 1590603599794, "tmdate": 1590603599794, "tddate": null, "forum": "6X5HByKw-2", "replyto": "6X5HByKw-2", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper4/-/Official_Review", "content": {"review": "How are research headings for each faculty member identified and managed?   Have the authors considered recommending things other than grant opportunities -- perhaps recommending collaborators, events to attend, papers to read?  The widgets idea, while interesting in its own right, might be the topic of another talk.  This talk might focus on recommending funding opportunities -- how does it work?  How well does it work?  How does this compare to other recommenders such as ProQuest?", "title": "Recommender is a cool use of VIVO", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper4/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper4/AnonReviewer1"]}, {"id": "-VOcJgbzaYs", "original": null, "number": 1, "cdate": 1590182848250, "ddate": null, "tcdate": 1590182848250, "tmdate": 1590182848250, "tddate": null, "forum": "6X5HByKw-2", "replyto": "6X5HByKw-2", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper4/-/Official_Review", "content": {"review": "An interesting proposal, especially the part about the recommendation engine for funding opportunities. Regarding the international audience it would be good to see some background on how the information about funding opportunities is gathered, respectively provided by the funders, and how it is maintained by the Duke staff. Another interesting aspect is, how the subject headings are generated/curated.", "title": "Interesting contribution especially regarding the recommender for funding opportunities.", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper4/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper4/AnonReviewer2"]}]}, {"paper_url": "https://openreview.net/forum?id=X7gI5_PNw_L", "paper_id": "X7gI5_PNw_L", "reviews": [{"id": "DNmToCETOI6", "original": null, "number": 2, "cdate": 1590603321296, "ddate": null, "tcdate": 1590603321296, "tmdate": 1590603321296, "tddate": null, "forum": "X7gI5_PNw_L", "replyto": "X7gI5_PNw_L", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper3/-/Official_Review", "content": {"review": "The ZDB is a remarkable resource.  This talk is of critical importance to the VIVO community, particularly regarding academic journals.  It is very important for the community to understand the content of the catalogue (what is included and what, if anything is not included), and the data held for each catalog entry.  Equally important is developing and understanding of how a university might use the APIs -- documentation, permissions, examples and so forth.", "title": "Important topic!", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper3/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper3/AnonReviewer2"]}, {"id": "XvYKcRRWw3C", "original": null, "number": 1, "cdate": 1590420870712, "ddate": null, "tcdate": 1590420870712, "tmdate": 1590420870712, "tddate": null, "forum": "X7gI5_PNw_L", "replyto": "X7gI5_PNw_L", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper3/-/Official_Review", "content": {"review": "The ZDB is a openly licensed treasure trove of journal and serials information and a potential datasource for every CRIS in the world. It would be great if the author would give some insights how the data can be consumed (API, dumps, formats etc.) and what the update cycles are.", "title": "Valuable contribution to the conference", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "7: Good paper, accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper3/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper3/AnonReviewer1"]}]}, {"paper_url": "https://openreview.net/forum?id=doaWBQJ7PrH", "paper_id": "doaWBQJ7PrH", "reviews": [{"id": "3Jgknwep7Jx", "original": null, "number": 2, "cdate": 1590847517522, "ddate": null, "tcdate": 1590847517522, "tmdate": 1590847517522, "tddate": null, "forum": "doaWBQJ7PrH", "replyto": "doaWBQJ7PrH", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper2/-/Official_Review", "content": {"review": "Visualization depicting research impact, based on novel sources: this is an important contribution to the VIVO ecosystem.\nThe topic and details of this proposal are of high interest.\nThe challenge will be in presenting the right balance of:\n- problem context\n- stakeholder engagement/process\n- design, and\n- implementation demonstration\n\nIt will additionally be helpful to clearly describe how other VIVO installations can use ROSI.\n", "title": "New extensions to VIVO's technology ecosystem", "confidence": "4: The reviewer is confident but not absolutely certain that the evaluation is correct", "rating": "9: Top 15% of accepted papers, strong accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper2/AnonReviewer2"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper2/AnonReviewer2"]}, {"id": "QXVT3R53yO", "original": null, "number": 1, "cdate": 1590602908112, "ddate": null, "tcdate": 1590602908112, "tmdate": 1590602908112, "tddate": null, "forum": "doaWBQJ7PrH", "replyto": "doaWBQJ7PrH", "invitation": "vivoconference.org/VIVO/2020/Conference/Paper2/-/Official_Review", "content": {"review": "Research impact is an important topic for the VIVO community.  The process by which requirements were gathered is of utmost interest, particularly as the academic disciplines mentioned represent much of the kind of work done in comprehensive universities.  A focus on requirements, design, and prototype methodology would be much quite interesting.", "title": "Topic of great interest to the VIVO community", "confidence": "5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature", "rating": "8: Top 50% of accepted papers, clear accept"}, "signatures": ["vivoconference.org/VIVO/2020/Conference/Paper2/AnonReviewer1"], "readers": ["everyone"], "nonreaders": [], "writers": ["vivoconference.org/VIVO/2020/Conference/Paper2/AnonReviewer1"]}]}]