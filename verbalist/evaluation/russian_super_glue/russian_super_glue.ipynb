{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'passage', 'idx', 'label'],\n",
       "    num_rows: 821\n",
       "})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"RussianNLP/russian_super_glue\", \"danetqa\")\n",
    "\n",
    "dataset = dataset[\"validation\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Есть ли вода на марсе?',\n",
       " 'passage': 'Гидросфера Марса — это совокупность водных запасов планеты Марс, представленная водным льдом в полярных шапках Марса, льдом над поверхностью, сезонными ручьями из жидкой воды и возможными резервуарами жидкой воды и водных растворов солей в верхних слоях литосферы Марса. Гидросфера Марса, вследствие господствующих низких температур на Марсе и нахождения запасов воды в твердом состоянии, также называется криолитосферой. Основная статья: История поисков воды на Марсе Марс весьма схож с Землей по многим показателям, что заставляло учёных XIX — начала XX века допускать, что на нём есть жизнь и есть жидкая вода. По мере роста объёма данных о планете, собранных различными методами, например, с помощью спектроскопических измерений, стало понятно, что воды в атмосфере Марса ничтожно малое количество, однако она всё же присутствует. Прежде всего внимание исследователей привлекли полярные шапки Марса, так как предполагалось, что они могут состоять из водного льда по аналогии с Антарктидой или Гренландией на Земле, однако высказывалась и гипотеза, что это твёрдый диоксид углерода.',\n",
       " 'idx': 0,\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 16.48s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "import torch\n",
    "from verbalist.generation.generation_utils import VerbalistConversation, generate\n",
    "\n",
    "weights_path = \"verbalist/model/models/verbalist_7b_v7/checkpoint-25900/adapter_model\"\n",
    "tokenizer_path = \"verbalist/model/models/verbalist_7b_v7/\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(weights_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    weights_path,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_path,\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT <s> system\n",
      "Ты — Буквоед, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им. </s> \n",
      "<s> user\n",
      "Почему трава зеленая? </s> \n",
      "<s> bot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `40` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `40` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Зеленый цвет растений является результатом фотосинтеза, который происходит в листьях растений. В процессе фотосинтеза растения используют солнечный свет, воду и углекислый газ, чтобы произвести питательные вещества, такие как глюкозу и аминокислоты. В результате этого процесса растения вырабатывают кислород, который используется для дыхания, и выделяют кислород, который является основным продуктом фотосинтеза. Зеленый цвет растений является результатом наличия хлорофилла в листьях, который отвечает за получение зеленого цвета.\n"
     ]
    }
   ],
   "source": [
    "inputs = [\"Почему трава зеленая?\"]\n",
    "\n",
    "conversation = VerbalistConversation()\n",
    "conversation.add_user_message(inputs[0])\n",
    "prompt = conversation.get_prompt(tokenizer)\n",
    "print(\"PROMPT\", prompt)\n",
    "generation_config = GenerationConfig(\n",
    "    bos_token_id=1,\n",
    "    eos_token_id=2,\n",
    "    pad_token_id=0,\n",
    "    max_new_tokens=512,\n",
    "    # no_repeat_ngram_size=15,\n",
    "    repetition_penalty=1.0,\n",
    "    temperature=0.5,\n",
    "    top_k=40,\n",
    "    top_p=0.95,\n",
    "    # do_sample=True,\n",
    ")\n",
    "output = generate(model, tokenizer, prompt, generation_config)\n",
    "# print(inp)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danet\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'verbalist/evaluation/russian_super_glue/valid_evaluations/verbalist_7b_v7_checkpoint-25900/DaNetQA.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=131'>132</a>\u001b[0m evaluation \u001b[39m=\u001b[39m EvalRussianSuperGlue(\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=132'>133</a>\u001b[0m     dataset_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdanetqa\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=133'>134</a>\u001b[0m     model_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mverbalist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=136'>137</a>\u001b[0m     eval_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mverbalist_7b_v7_checkpoint-25900\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=137'>138</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=139'>140</a>\u001b[0m evaluation\u001b[39m.\u001b[39;49mevaluate()\n",
      "\u001b[1;32m/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     functions_map \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdanetqa\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdanetqa,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     }\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     functions_map[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset_name]()\n",
      "\u001b[1;32m/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m predicts \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m ground_true \u001b[39m=\u001b[39m []\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(eval_folder \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mDaNetQA.log\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     idxs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m tqdm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpu8/home/kosenko/verbalist/verbalist/evaluation/russian_super_glue/russian_super_glue.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m         \u001b[39m# print(item)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'verbalist/evaluation/russian_super_glue/valid_evaluations/verbalist_7b_v7_checkpoint-25900/DaNetQA.log'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class EvalRussianSuperGlue:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name=\"danetqa\",\n",
    "        model_type=None,\n",
    "        model=None,\n",
    "        base_folder=None,\n",
    "        eval_name=None,\n",
    "    ) -> None:\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset = load_dataset(\"RussianNLP/russian_super_glue\", dataset_name)\n",
    "        self.dataset = self.dataset[\"validation\"]\n",
    "        self.model = model\n",
    "        self.model_type = model_type\n",
    "\n",
    "        self.base_folder = Path(base_folder)\n",
    "        self.eval_name = eval_name\n",
    "\n",
    "    def evaluate(self):\n",
    "        functions_map = {\n",
    "            \"danetqa\": self.danetqa,\n",
    "        }\n",
    "        functions_map[self.dataset_name]()\n",
    "\n",
    "    def danetqa(self):\n",
    "        print(\"danet\")\n",
    "\n",
    "        eval_folder = self.base_folder / f\"{self.eval_name}\"\n",
    "        eval_folder.mkdir(exist_ok=True)\n",
    "        output_file = eval_folder / f\"DaNetQA.jsonl\"\n",
    "        if output_file.is_file():\n",
    "            print(\"score file\")\n",
    "            predicts = []\n",
    "            ground_true = []\n",
    "            with open(output_file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "                for i, line in enumerate(lines):\n",
    "                    line = json.loads(line)\n",
    "                    line[\"label\"] = bool(\n",
    "                        f'{line[\"label\"][0].upper()}{line[\"label\"][1:]}'\n",
    "                    )\n",
    "                    line[\"label\"] = int(line[\"label\"])\n",
    "                    predicts.append(line[\"label\"])\n",
    "                    ground_true.append(dataset[i][\"label\"])\n",
    "                    # print(line)\n",
    "                    # break\n",
    "                # print(predicts, ground_true)\n",
    "                acc = accuracy_score(ground_true, predicts)\n",
    "                print(f\"Accuracy: {acc}\")\n",
    "        else:\n",
    "            predicts = []\n",
    "            ground_true = []\n",
    "            with open(eval_folder / \"DaNetQA.log\", \"w\") as f:\n",
    "                idxs = []\n",
    "                for item in tqdm(self.dataset):\n",
    "                    # print(item)\n",
    "                    prompt = f\"{item['question']}\\nКонтекст: {item['passage']}\\nИспользуя контекст, ответь на вопрос используя только да или нет.\"\n",
    "                    result = self.get_answer(prompt=prompt)\n",
    "                    print(prompt, file=f)\n",
    "                    print(f\"predict answer = {result}\", file=f)\n",
    "                    print(f\"real answer = {item['label']}\", file=f)\n",
    "\n",
    "                    answer = None\n",
    "\n",
    "                    if \"да\" in result:\n",
    "                        answer = 1\n",
    "                    elif \"не\" in result:\n",
    "                        answer = 0\n",
    "                    else:\n",
    "                        answer = int(not bool(item[\"label\"]))\n",
    "\n",
    "                    predicts.append(answer)\n",
    "                    idxs.append(item[\"idx\"])\n",
    "                    ground_true.append(item[\"label\"])\n",
    "                    # break\n",
    "                acc = accuracy_score(ground_true, predicts)\n",
    "                print(f\"Accuracy: {acc}\")\n",
    "\n",
    "                with open(output_file, \"w\") as f:\n",
    "                    for idx, predict in zip(idxs, predicts):\n",
    "                        answer = {\n",
    "                            \"idx\": idx,\n",
    "                            \"label\": str(bool(predict)).lower(),\n",
    "                        }\n",
    "                        json.dump(answer, f)\n",
    "                        f.write(\"\\n\")\n",
    "                with open(eval_folder / \"DaNetQA.txt\", \"w\") as f:\n",
    "                    f.write(acc)\n",
    "\n",
    "    def get_answer(self, prompt):\n",
    "        models_map = {\n",
    "            \"verbalist\": self.verbalist_generation_1,\n",
    "        }\n",
    "        answer = models_map[self.model_type](prompt)\n",
    "        answer = answer.strip()\n",
    "        answer = answer.lower()\n",
    "        return answer\n",
    "\n",
    "    def verbalist_generation_1(self, prompt):\n",
    "        conversation = VerbalistConversation()\n",
    "        conversation.add_user_message(prompt)\n",
    "        prompt = conversation.get_prompt(tokenizer)\n",
    "        # print(\"PROMPT\", prompt)\n",
    "        generation_config = GenerationConfig(\n",
    "            bos_token_id=1,\n",
    "            eos_token_id=2,\n",
    "            pad_token_id=0,\n",
    "            max_new_tokens=512,\n",
    "            # no_repeat_ngram_size=15,\n",
    "            repetition_penalty=1.1,\n",
    "            temperature=0.5,\n",
    "            top_k=40,\n",
    "            top_p=0.95,\n",
    "            # do_sample=True,\n",
    "        )\n",
    "        output = generate(\n",
    "            self.model,\n",
    "            tokenizer,\n",
    "            prompt,\n",
    "            generation_config,\n",
    "        )\n",
    "        return output\n",
    "\n",
    "\n",
    "evaluation = EvalRussianSuperGlue(\n",
    "    dataset_name=\"danetqa\",\n",
    "    model_type=\"verbalist\",\n",
    "    model=model,\n",
    "    base_folder=\"verbalist/evaluation/russian_super_glue/valid_evaluations/\",\n",
    "    eval_name=\"verbalist_7b_v7_checkpoint-25900\",\n",
    ")\n",
    "\n",
    "evaluation.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
