{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Аггрегация разметки датасета ruModAr\n",
    "*Subset edition*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аггрегация строится по следующей системе:\n",
    "\n",
    "1. Сбор размеченных пулов с Толоки. Возможны варианты:\n",
    "    - только общий пул нужно аггрегировать, тогда забирается только он\n",
    "    - часть данных находится в контрольных заданиях и экзамене, тогда к основному пулу добавляются данные задания\n",
    "2. Фильтрация разметчиков:\n",
    "    - в общем пуле есть некоторое количество заранее размеченных заданий - контрольных\n",
    "    - хорошим считается разметчик, который показывает `accuracy >= 0.5` на данных заданиях\n",
    "    - формируется список \"плохих\" разметчиков\n",
    "3. Аггрегация ответов разметчиков по заданиям:\n",
    "    - форматирование в заданиях может отличаться от изначального из-за выгрузки с Толоки\n",
    "    - учитываются только ответы \"хороших\" разметчиков\n",
    "    - аггрегация по подготовленным пулам - создается массив карточек вида {key: value}, где key - кортеж из всех значимых элементов задания, value - список из кортежей вида (user_id, answer)\n",
    "4. Голосование большинством по каждому заданию:\n",
    "    - минимально необходимое большинство составляет 3 голоса, так как такое большинство валидно для перекрытия 5\n",
    "    - по результату формируется датафрейм с заданиями и ответами\n",
    "5. Подгрузка оригинальных данных с разметкой в виде таблицы с заданиями и ответами\n",
    "6. Соединение таблиц:\n",
    "    - очистка форматирования в таблице с ответами разметчиков и в таблице с правильными ответами\n",
    "    - создание единых столбцов с полным заданием\n",
    "    - соединение таблиц по данному столбцу\n",
    "    - валидация размеров\n",
    "7. Подсчет метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разметке было 1800 заданий: по 600 заданий на каждую математическую операцию и по 300 на две опции:\n",
    "- можно символ `->` заменить на просто `=`\n",
    "- можно символ `->` заменить на ` + 1 =`\n",
    "\n",
    "Разметчики делали выбор, и записывали свое решение. Проверяется не столько способность решить пример, сколько умение логически размышлять и делать вывод из контекста - уже решенных примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор данных разметки и фильтрация разметчиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный датасет представляет из себя лишь подмножество, которое было специально сгенерировано. Это не тестовый сет датасета из мультимодального бенчмарка (инструкционный сет)! Размер выборки - 1800 объектов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments = pd.read_csv('assignments_from_pool_41461361__28-09-2023.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разметчикам предлагалось на основании контекста из решенных пяти примеров и одного нерешенного примера ответить на вопрос, чему равен нерешенный пример, если заменить в нем специальный символ `->` соответственно контексту.\n",
    "Вход: \n",
    "- INPUT:context (пример: `2 + 2 -> 5`).\n",
    "- INPUT:problem (пример: `3 + 3 ->`).\n",
    "\n",
    "Выход:\n",
    "- OUTPUT:solution (целое число, например: `7`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INPUT:context</th>\n",
       "      <th>INPUT:problem</th>\n",
       "      <th>OUTPUT:solution</th>\n",
       "      <th>GOLDEN:solution</th>\n",
       "      <th>HINT:text</th>\n",
       "      <th>HINT:default_language</th>\n",
       "      <th>ASSIGNMENT:link</th>\n",
       "      <th>ASSIGNMENT:task_id</th>\n",
       "      <th>ASSIGNMENT:assignment_id</th>\n",
       "      <th>ASSIGNMENT:task_suite_id</th>\n",
       "      <th>ASSIGNMENT:worker_id</th>\n",
       "      <th>ASSIGNMENT:status</th>\n",
       "      <th>ASSIGNMENT:started</th>\n",
       "      <th>ASSIGNMENT:submitted</th>\n",
       "      <th>ASSIGNMENT:accepted</th>\n",
       "      <th>ASSIGNMENT:reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48 * 22 -&gt; 1057\\r\\n7 * 23 -&gt; 162\\r\\n56 * 68 -&gt;...</td>\n",
       "      <td>80 * 35 -&gt;</td>\n",
       "      <td>2801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://platform.toloka.ai/task/41461361/00027...</td>\n",
       "      <td>000278a671--6514b53aaa6bb16340de1f8c</td>\n",
       "      <td>000278a671--651555040b89303759a5c4f3</td>\n",
       "      <td>000278a671--651555040b89303759a5c4f0</td>\n",
       "      <td>1d09bb1b80a54c03c195eb8af088f05b</td>\n",
       "      <td>APPROVED</td>\n",
       "      <td>2023-09-28T10:27:16.309</td>\n",
       "      <td>2023-09-28T10:31:26.669</td>\n",
       "      <td>2023-09-28T10:31:26.669</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       INPUT:context INPUT:problem  \\\n",
       "0  48 * 22 -> 1057\\r\\n7 * 23 -> 162\\r\\n56 * 68 ->...    80 * 35 ->   \n",
       "\n",
       "   OUTPUT:solution GOLDEN:solution  HINT:text  HINT:default_language  \\\n",
       "0             2801             NaN        NaN                    NaN   \n",
       "\n",
       "                                     ASSIGNMENT:link  \\\n",
       "0  https://platform.toloka.ai/task/41461361/00027...   \n",
       "\n",
       "                     ASSIGNMENT:task_id              ASSIGNMENT:assignment_id  \\\n",
       "0  000278a671--6514b53aaa6bb16340de1f8c  000278a671--651555040b89303759a5c4f3   \n",
       "\n",
       "               ASSIGNMENT:task_suite_id              ASSIGNMENT:worker_id  \\\n",
       "0  000278a671--651555040b89303759a5c4f0  1d09bb1b80a54c03c195eb8af088f05b   \n",
       "\n",
       "  ASSIGNMENT:status       ASSIGNMENT:started     ASSIGNMENT:submitted  \\\n",
       "0          APPROVED  2023-09-28T10:27:16.309  2023-09-28T10:31:26.669   \n",
       "\n",
       "       ASSIGNMENT:accepted  ASSIGNMENT:reward  \n",
       "0  2023-09-28T10:31:26.669              0.022  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignments.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим ответы к универсальному виду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments['OUTPUT:solution'] = assignments['OUTPUT:solution'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока в ответах есть Nan'ы, нельзя сделать ответы интами, потому будут строками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments['GOLDEN:solution'] = assignments['GOLDEN:solution'].apply(lambda x: x if str(x) == 'nan' else str(int(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фильтруем толокеров с `accuracy < 0.5` на контрольных заданиях, чтобы не учитывать их ответы при подсчете метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users total:  251\n",
      "Bad users: 5\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "users_dict = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for idx, row in assignments.iterrows():\n",
    "    context = row[0]\n",
    "    problem = row[1]\n",
    "\n",
    "    out = row[2]\n",
    "    \n",
    "    gold = row[3]\n",
    "\n",
    "    user = row[10]\n",
    "\n",
    "    if str(user) != \"nan\" and str(gold) != \"nan\":\n",
    "        if out == int(gold):\n",
    "            users_dict[user][\"good\"] += 1\n",
    "        else:\n",
    "            users_dict[user][\"bad\"] += 1\n",
    "\n",
    "print(\"Users total: \", len(users_dict))\n",
    "bad_users = []\n",
    "for key, value in users_dict.items():\n",
    "    percentage_good = value[\"good\"]/(value[\"good\"] + value[\"bad\"])\n",
    "    if percentage_good < 0.5:\n",
    "        bad_users.append(key)\n",
    "\n",
    "print(\"Bad users:\", len(bad_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 из 251 разметчиков на контрольных заданиях показали слишком плохое качество, чтобы учитывать их ответы для расчета метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделяем контроль от основы, так как контрольные задания создавались отдельно и не должны учитываться при подсчете метрик. На контрольных заданиях есть `GOLDEN:solution`. Также отсеиваем возможные баги Толоки, когда в строке может не быть задания - `INPUT:context` содержит NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignments_no_control = assignments[assignments['GOLDEN:solution'].isnull()]\n",
    "assignments_no_control_no_null = assignments_no_control[assignments_no_control['INPUT:context'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбор ответов разметчиков и голосование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем ответы голосования большинством для каждого задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "text_dict = defaultdict(list)\n",
    "\n",
    "for context, problem, user, out in zip(\n",
    "    assignments_no_control_no_null[\"INPUT:context\"], assignments_no_control_no_null[\"INPUT:problem\"], \n",
    "    assignments_no_control_no_null[\"ASSIGNMENT:worker_id\"], assignments_no_control_no_null[\"OUTPUT:solution\"]\n",
    "    ):\n",
    "    if user not in bad_users:\n",
    "        text_dict[(context, problem)].append([\n",
    "                user,\n",
    "                {\"out\": out}\n",
    "        ])\n",
    "\n",
    "print(len(text_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 1774, 4: 26})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(text_dict.keys())\n",
    "Counter([len(text_dict[keys[i]]) for i in range(len(keys))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть 26 заданий, где перекрытие 4. Значит, для этих заданий порогом будет большинство в 3 голоса (порог аналогичен перекрытию 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_full = {}\n",
    "for i in range(len(keys)):\n",
    "    ans = text_dict[keys[i]]\n",
    "    lst = [ans[j][1]['out'] for j in range(len(ans))]\n",
    "    cnt = Counter(lst)\n",
    "    if len(lst) == 5:\n",
    "        most = Counter([ans[j][1]['out'] for j in range(len(ans))]).most_common(1)[0][1]\n",
    "        if most >= 3:\n",
    "            res = Counter([ans[j][1]['out'] for j in range(len(ans))]).most_common(1)[0][0]\n",
    "            preds_full[keys[i]] = res\n",
    "    elif len(lst) == 4:\n",
    "        most = Counter([ans[j][1]['out'] for j in range(len(ans))]).most_common(1)[0][1]\n",
    "        if most > 2:\n",
    "            res = Counter([ans[j][1]['out'] for j in range(len(ans))]).most_common(1)[0][0]\n",
    "            preds_full[keys[i]] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1794"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсеялись 6 заданий, где большинства не набралось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_full_df = pd.concat([pd.DataFrame(preds_full.keys(), columns=['context', 'problem']), pd.DataFrame(preds_full.values(), columns=['lb'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сопоставление разметки и ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Забираем задания из датасета с правильными ответами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('exp_wa.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После скачивания с Толоки в текстах рушится форматирование, потому нельзя просто сделать join двух табличек. Нужно убрать все \"лишнее\" форматирование сразу из двух табличек, чтобы остались только тексты, пунктуация и пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(text):\n",
    "    text = (text.strip().replace('\\n', ' ').replace('\\t', ' ')\n",
    "            .replace('\\r', ' ').replace('  ', ' ').replace('  ', ' ')\n",
    "            .replace('  ', ' '))\n",
    "    return text\n",
    "\n",
    "res_df['INPUT:context'] = res_df['INPUT:context'].apply(format_text)\n",
    "res_df['INPUT:problem'] = res_df['INPUT:problem'].apply(format_text)\n",
    "\n",
    "preds_full_df['context'] = preds_full_df['context'].apply(format_text)\n",
    "preds_full_df['problem'] = preds_full_df['problem'].apply(format_text)\n",
    "\n",
    "res_df = res_df.rename({\n",
    "    'INPUT:context': 'context',\n",
    "    'INPUT:problem': 'problem',\n",
    "    'outputs': 'lb'\n",
    "}, axis=1)\n",
    "\n",
    "res_df['full'] = res_df['context'] + ' ' + res_df['problem']\n",
    "preds_full_df['full'] = preds_full_df['context'] + ' ' + preds_full_df['problem']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем left join, чтобы соединить голосование и правильные метки для одних и тех же заданий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = res_df.merge(preds_full_df.drop(['context', 'problem'], axis=1), on='full', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1794"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_valid = new[new['lb_y'].notna()].copy()\n",
    "len(new_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ни одна строка не была утеряна."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_valid['lb_y'] = new_valid['lb_y'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lb_x</th>\n",
       "      <th>context</th>\n",
       "      <th>problem</th>\n",
       "      <th>full</th>\n",
       "      <th>lb_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>874</td>\n",
       "      <td>199 + 998 -&gt; 1197 191 + 519 -&gt; 710 557 + 78 -&gt;...</td>\n",
       "      <td>31 + 843 -&gt;</td>\n",
       "      <td>199 + 998 -&gt; 1197 191 + 519 -&gt; 710 557 + 78 -&gt;...</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lb_x                                            context      problem  \\\n",
       "0   874  199 + 998 -> 1197 191 + 519 -> 710 557 + 78 ->...  31 + 843 ->   \n",
       "\n",
       "                                                full  lb_y  \n",
       "0  199 + 998 -> 1197 191 + 519 -> 710 557 + 78 ->...   874  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_valid.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подсчет метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в правом столбце меток осталось 1794 непустых строк, значит, форматирование было подчищено корректно и ничего не потерялось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем посчитать разные метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994425863991081"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_valid['lb_x'] == new_valid['lb_y']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Accuracy = 0.999`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ ошибок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на ошибки в голосовании большинством. Сначала добавим указание на части датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(new_valid['lb_x'] != new_valid['lb_y']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разметчики почти идеально решили задачу. Только в одном задании большинство ошиблось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lb_x</th>\n",
       "      <th>context</th>\n",
       "      <th>problem</th>\n",
       "      <th>full</th>\n",
       "      <th>lb_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>-445</td>\n",
       "      <td>366 - 677 -&gt; -310 797 - 428 -&gt; 370 322 - 621 -...</td>\n",
       "      <td>25 - 471 -&gt;</td>\n",
       "      <td>366 - 677 -&gt; -310 797 - 428 -&gt; 370 322 - 621 -...</td>\n",
       "      <td>-447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lb_x                                            context      problem  \\\n",
       "1164  -445  366 - 677 -> -310 797 - 428 -> 370 322 - 621 -...  25 - 471 ->   \n",
       "\n",
       "                                                   full  lb_y  \n",
       "1164  366 - 677 -> -310 797 - 428 -> 370 322 - 621 -...  -447  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_valid[new_valid['lb_x'] != new_valid['lb_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, разметчики верно поняли, что тут специальный символ меняет результат на единицу, но перепутали и вместо прибавления единицы вычли ее. Больше анализировать в обработанных данных нечего - ошибок больше не осталось. Нужно смотреть на полный пул отдельных ответов разметчиковна каждое задание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = assignments_no_control_no_null.iloc[:, [0, 1, 2, 10]].rename({\n",
    "    'INPUT:context': 'context',\n",
    "    'INPUT:problem': 'problem',\n",
    "    'OUTPUT:solution': 'label',\n",
    "    'ASSIGNMENT:worker_id': 'user'\n",
    "}, axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соединяем контекст и нерешенный пример, чтобы было удобно соединить с правильными ответами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['full'] = new.context + ' ' + new.problem\n",
    "new['full'] = new['full'].apply(format_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = new.merge(res_df.drop(['context', 'problem'], axis=1), on='full', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соединяем с правильными ответами по полному тексту задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['sign'] = new.problem.apply(lambda x: x.split()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на разницу и абсолютную разницу ответов разметчиков и правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['diff'] = new['label'] - new['lb']\n",
    "new['abs_diff'] = new['diff'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибками считаем те строки, где разность не равна нулю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['error'] = (new['diff'] != 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>problem</th>\n",
       "      <th>label</th>\n",
       "      <th>user</th>\n",
       "      <th>full</th>\n",
       "      <th>sign</th>\n",
       "      <th>lb</th>\n",
       "      <th>diff</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48 * 22 -&gt; 1057\\r\\n7 * 23 -&gt; 162\\r\\n56 * 68 -&gt;...</td>\n",
       "      <td>80 * 35 -&gt;</td>\n",
       "      <td>2801</td>\n",
       "      <td>1d09bb1b80a54c03c195eb8af088f05b</td>\n",
       "      <td>48 * 22 -&gt; 1057 7 * 23 -&gt; 162 56 * 68 -&gt; 3809 ...</td>\n",
       "      <td>*</td>\n",
       "      <td>2801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context     problem  label  \\\n",
       "0  48 * 22 -> 1057\\r\\n7 * 23 -> 162\\r\\n56 * 68 ->...  80 * 35 ->   2801   \n",
       "\n",
       "                               user  \\\n",
       "0  1d09bb1b80a54c03c195eb8af088f05b   \n",
       "\n",
       "                                                full sign    lb  diff  \\\n",
       "0  48 * 22 -> 1057 7 * 23 -> 162 56 * 68 -> 3809 ...    *  2801     0   \n",
       "\n",
       "   abs_diff  error  \n",
       "0         0      0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = new[new['error'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diff\n",
       "-2      116\n",
       "-1       76\n",
       " 1       25\n",
       " 100      7\n",
       "-3        5\n",
       "       ... \n",
       " 504      1\n",
       " 96       1\n",
       "-30       1\n",
       " 78       1\n",
       " 640      1\n",
       "Name: count, Length: 168, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors['diff'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее часто встречающаяся ошибка у толокеров, как и следовало ожидать, это просчет на -2. Природа этого просчета в простой арифметике. По заданию специальный символ может превращаться в `+ 1 =`, значит необходимо к результату вычисления прибавить единицу. В случае отрицательных чисел прибавление единицы число по модулю уменьшает. Отсюда и ошибка. Пример:\n",
    "\n",
    "`-10 + 1 = -9`\n",
    "\n",
    "`10 + 1 = 11`\n",
    "\n",
    "А толокеры могут путать правила и делать так: \n",
    "\n",
    "`-10 + 1 = -11`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "-    89\n",
       "+    17\n",
       "*    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[errors['abs_diff'] == 2]['sign'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набиольшее количество таких ошибок допущенно в примерах с вычитанием, так как именно там много отрицательных чисел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "-    57\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors[(errors['abs_diff'] == 2) & (errors['lb'] < 0)]['sign'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что и требовалось доказать! Наиболее частая ошибка ярче всего проявляется в примерах с вычитанием. В большинстве случаев такая ошибка делается одним или двумя разметчиками, что не приводит к ее появлению при голосовании большинством. Однако в одном примере собралось сразу 3 разметчика, которые сделали одинаковую ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "-    225\n",
       "+    120\n",
       "*     83\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors['sign'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, среди всех ошибок чаще всего разметчики ошибаются именно в примерах с вычитанием."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь оценим вероятность ошибки грубо по всему пулу без заведомо \"плохих\" разметчиков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Сложение</th>\n",
       "      <th>Вычитание</th>\n",
       "      <th>Умножение</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Доля ошибок от всего пула</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.009222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Сложение  Вычитание  Умножение\n",
       "Доля ошибок от всего пула  0.013333      0.025   0.009222"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Сложение\": new[(new['error'] == 1) & (new['sign'] == '+')].shape[0] / len(new),\n",
    "    \"Вычитание\": new[(new['error'] == 1) & (new['sign'] == '-')].shape[0] / len(new),\n",
    "    \"Умножение\": new[(new['error'] == 1) & (new['sign'] == '*')].shape[0] / len(new),\n",
    "}, index=['Доля ошибок от всего пула'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, вероятность ошибки на примере с вычитанием в 2 раза выше, чем на примере со сложением и почти в 3 раза больше, чем в примерах с умножением."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
