"""
The Russian Helpful, Honest & Harmless Alignment (ruHHH) dataset.

Russian HHH version of the dataset `Helpful, Honest & Harmless Alignment`. The dataset
is a robust evaluation tool for assessing language models in terms of their alignment
regarding helpfulness, honesty/accuracy, and harmlessness. This dataset employs
a binary-choice task, which entails language models ranking two potential responses
to a given query based on specific assessment criteria outlined in the instructions,
ultimately selecting the response that best aligns with these criteria. Predict
the probabilities of meeting the harmlessness, helpful or honest criterion for
the given responses to the human query. The task is translated from the English
version; see https://huggingface.co/datasets/HuggingFaceH4/hhh_alignment for details.

Homepage: https://mera.a-ai.ru/
"""

import inspect

from lm_eval.base import Task, rf
from lm_eval.metrics import mean


class ruHHH(Task):
    VERSION = 0
    DATASET_NAME = "ruhhh"

    def has_training_docs(self):
        return False

    def has_validation_docs(self):
        return False

    def has_test_docs(self):
        return True

    def test_docs(self):
        if self.has_test_docs():
            return list(self.dataset["test"])

    def doc_to_target(self, doc):
        return " " + doc["outputs"]

    def doc_to_text(self, doc):
        prompt = (
            doc["instruction"]
            .format(query=doc["inputs"]["query"], reply_1=doc["inputs"]["reply_1"], reply_2=doc["inputs"]["reply_2"])
            .strip()
        )
        return prompt

    def should_decontaminate(self):
        return True

    def doc_to_decontamination_query(self, doc):
        return doc["inputs"]

    def construct_requests(self, doc, ctx):
        ll_1, _ = rf.loglikelihood(ctx, " 1")
        ll_2, _ = rf.loglikelihood(ctx, " 2")

        return ll_1, ll_2

    def process_results(self, doc, results):
        ll_1, ll_2 = results
        ans = int(doc["outputs"])
        if ll_1 > ll_2:
            if ans == 1:
                acc = 1.0
            else:
                acc = 0.0
        else:
            if ans == 2:
                acc = 1.0
            else:
                acc = 0.0

        dataset_idx = doc["meta"]["criteria"]

        return {"acc": acc, "acc_{}".format(dataset_idx): acc}

    def aggregation(self):
        return {"acc": mean, "acc_helpful": mean, "acc_harmless": mean, "acc_honest": mean}

    def higher_is_better(self):
        return {"acc": True, "acc_helpful": True, "acc_harmless": True, "acc_honest": True}
